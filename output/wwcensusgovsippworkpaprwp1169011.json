{
    "title": "The Seam Effect with Social Security Income in the Survey of Income and Program Participation",
    "publication_date": "1989-09-01",
    "authors": [
        {
            "full_name": "Graham Kalton",
            "firstname": "Graham",
            "lastname": "Kalton",
            "affiliations": []
        },
        {
            "full_name": "Michael E Miller",
            "firstname": "Michael E",
            "lastname": "Miller",
            "affiliations": []
        },
        {
            "full_name": "Daniel H Hill",
            "firstname": "Daniel H",
            "lastname": "Hill",
            "affiliations": []
        }
    ],
    "abstract": "Census Bureau interviewers are officially referred to as \"Field Representatives.\" Throughout this report, however, the more functionally descriptive term 'interviewer' will be used to facilitate distinctions between them and 'reinterviewers.' 3 ~h i s is not to say that SIPP data are in any sense more error prone than other survey data. The error that exists, however, is more easily seen because of the longitudinal nature of the data.",
    "full_text": "This report contains the findings of research conducted under a Joint Statistical Agreement between the Bureau of the Census and the Survey Research Center, University of Michigan. The Joint Statistical Agreement was entitled \"Measuring Gross Change in Panel Surveys\", and the research was conducted during the period 1987-88.\n\nAn important type of nonsampling error that has been identified in the Survey of Income and Program Participation (SIPP) is known as the seam effect. The SIPP is a panel survey with an interval of four months between waves, but with information on many income sources being collected on a monthly basis. A common finding has been that more month-tomonth changes in recipiency of most income types occur when the data are collected in different waves (e.g., between months 4 and 5, or 8 and 9) than when the data are collected in the same wave (e.g., months 1 and 2, 3 and 4, 6 and 7). This finding, termed the seam effect, can affect the measurement of gross change and measures of durations of spells on social programs. It has been a central focus of the research conducted under the JSA.\n\nThe report comprises three chapters. The first, by Kalton and Miller, examines the seam effect in relation to the monthly amounts of Social Security payments reported in the first twelve months of the 1984 SIPP Panel. The analyses take advantage of a known 3.5% increase in Social Security payments that occurred in January 1984 to compare the characteristics ofrecipients who reported an increase that month with those of recipients who failed to do so.\n\nChapter 2, by Hill, investigates the seam effect for several characteristics in the 1984 SIPP Panel, and also for characteristics in the Panel Study of Income Dynamics (PSID). The conclusion reached is that the seam effect in PSID is at least as severe as that in SIPP. The paper also reports findings on some of the correlates of the propensity to provide inconsistent reports which give rise to the seam effect.\n\nAs part of the SIPP quality control program, a small subsample of SIPP respondents is reinterviewed each month. The aim is to evaluate and to indicate when retraining is required. Although the reinterview program is not designed to provide evidence on nonsampling errors, it has the potential to do so. Chapter 3, by Hill, explores the use of the reinterview data for investigating nonsampling errors in the SIPP. The chapter demonstrates that the reinterview data can be useful for this purpose, and suggests some changes to the program that would improve its utility for nonsampling error research.\n\nThis paper is concerned with a type of measurement error encountered in panel surveys that has become known as the seam effect. This effect has been found to be pervasive in the Survey of Income and Program Participation, a household panel survey program of the U.S. Bureau of the Census. In order to describe the seam effect it is first necessary to give some basic details of the SIPP design.\n\nThe SIPP is an ongoing survey program with a new panel being introduced each year.\n\nEach panel collects detailed information on the economic resources and participation in welfare programs of sample members by means of interviews conducted every four months for a period of 32 months. At each wave of a SIPP panel sample members are asked whether they received any income from a wide range of income. sources and transfer programs (e.g., Social Security, Federal Supplemental Security Income., Aid to Families with Dependent Children, Food Stamps) during the preceding four months. For each source, they are asked for each of the preceding four months in turn, starting with last month and working back to four months ago, first whether they received any income from that source and then, if so, how much was received. Merging the data collected in the individual waves of the panel for each sample member thus creates a continuous monthly history of recipiency or non-recipiency of each income source, and of the amounts received, if any, for the 32-month life of the panel.\n\nAnalyses of the month-to-month variation in recipiency of the various income and transfer program sources and in the amounts received from the individual sources has uncovered the common pattern that changes in recipiency status and in amounts received occur much more frequently between months for which the data are collected in different waves (months 4 and 5, 8 and 9, 12 and 13, etc.) than between months for which the data are collected in the same wave (months 1 and 2, 2 and 3, 3 and 4, 5 and 6, etc.) of the panel.\n\nSince changes occur more frequently at the seam between two waves of data collection, this pattern has become known as the \"seam effect\". Findings on the seam effect are reported by Burkhead and Coder (1985), Coder et al. (1987), and Weidman (1986) in relation to SIPP, and by Moore and Kasprzyk (1984) and Kalton et al. (1985) in relation to the Income Survey Development Program (ISDP) 1979 panel, a pilot survey for the SIPP. Marquis and Moore (1989) report on a study of the seam effect based on a comparison of survey reports with administrative records. Further references are given by Kasprzyk (1988) and in the SIPP quality profile (Jabine et al., 1989). Hill (1987) reports the occurrence of a similar seam effect with the Panel Study of Income Dynamics. This paper examines the seam effect in relation to the monthly amounts of Social Security payments reported in the 1984 SIPP Panel. As preparation for the analyses that follow, Section 2 below provides some necessary background on the 1984 SIPP Panel and describes the data set used for the analysis. Section 3 then presents the results of some analyses that document the magnitude of the seam effect for Social Security income. Section 4 takes advantage of a 3.5% increase in Social Security payments that was introduced in January 1984 to compare the characteristics of recipients who reported an increase in that month with those of recipients who failed to do so. The final section of the paper discusses the findings.\n\nThe analyses reported in this paper relate to the first three rounds of data collection for the 1984 SIPP Panel. That panel started with about 20,000 interviewed households. The sample was made up of four subsamples, called rotation groups, of approximately equal size, with one rotation group being interviewed each month to collect data for the preceding four months. The first rotation group was interviewed for the first time in October 1983, and then reinterviewed in February 1984, June 1984, etc. The second rotation group was first interviewed in November 1983and reinterviewed in March 1984, July 1984, etc. Similarly, the third and fourth rotation groups were first interviewed in December 1983, andJanuary 1984, respectively, and then reinterviewed at four-monthly intervals. As a consequence of this data collection procedure, data for two adjacent months were collected in different waves for one rotation group but in the same wave for the other rotation groups. Thus, for instance, data for September and October 1984 were collected in different waves for the first rotation group (the first wave for September and the second wave for October) but in the same wave (the first wave) for the other three rotation groups. For the present analyses, this rotation scheme system has the benefit of providing the opportunity to compare the change between two adjacent calendar months when the data were collected in different waves with the corresponding change when the data were collected in the same wave.\n\nAll persons aged 15 and over in the approximately 20,000 households sampled at the first wave of the 1984 SIPP Panel became panel members who were followed even if they changed addresses or moved out of their sampled households. Children under 15 in sampled households became panel members at later waves after reaching the age of 15, provided that they were still living with a panel member at that time. Persons who were not in the initial sample but who subsequently resided with panel memberstermed associated personswere included in the survey while they continued to live with panel members.\n\nThe data set used for this study was constructed by merging the public use files for the first three waves of the 1984 SIPP Panel. A number of exclusions were then made from the merged file. First, the fourth rotation group has been excluded because data were not collected from this group in the second wave. Second, all associated persons have been excluded. Third, all children aged under 15 at the first interview have been excluded. Fourth, all panel members leaving the survey population (e.g., through death, entering an institution, or emigration) have been excluded. Fifth, all sample persons who were nonrespondents on one or more of the first three waves have been excluded. The study is thus confined to panel members aged 15 and over at the first wave who responded on each of the first three waves of the 1984 SIPP Panel.\n\nA final set of exclusions has been made on the basis of the variable under study, the monthly amounts of Social Security income. These amounts were subject to some item nonresponse. When this occurred, an imputation procedure was used to assign values for the missing amounts. Since imputations are likely to distort measures of individual monthly changes, imputed amounts have been treated as missing values in the analyses that follow.\n\nAs such, they have been excluded from the analyses. Also excluded are a small number of extreme amounts of $1500 or more of Social Security income in a single month.\n\nOne way to illustrate the seam effect with the amount of Social Security received is to correlate the amounts received in different panel months. Table 1 presents the correlation matrix for the monthly amounts of Social Security received in each of the twelve panel months covered by the first three waves of the 1984 SIPP Panel. This correlation matrix is computed for a subsample of the Panel. Extreme values of monthly amounts of $1500 or more and changes of more than $200 between months have been excluded (ten records in the subsample had amounts of $1500 or more for one or more months and six records had changes of more than $200 between months). Each of the correlations is based on a subsample of about 3000 persons who reported amounts of Social Security income in both of the two months involved (excluding imputed values and extreme values as noted above).\n\nTable 1 Cross-Month Correlations for Social Security Income Amounts\n\nThe correlations in Table 1 exhibit the same pattern that Kalton et al. (1985) found with the ISDP 1979 Panel: For a given difference in panel months, the correlations when both amounts are collected in the same wave are appreciably higher than when they are obtained in different waves. In particular, the leading diagonal, which gives the correlations of amounts from adjacent months, shows the drop in correlation between months 4 and 5 and months 8 and 9. The correlation matrix in Table 1 in fact partitions into two parts: the correlations between amounts for months within a wave (above the stepped line in the table ) \n\nare on average about 0.99 whereas those between amounts in different waves (below the stepped line) are on average about 0.92.\n\nTable 1 relate to panel months, which represent different calendar months for the different rotation groups. Table 2 provides another way of illustrating the seam effect, this time relating to calendar months. The table, which relates to the full Panel (apart from the exclusions noted in the previous section), gives the distributions of the percentage changes in the amount of Social Security income received from one calendar month to the next. Separate distributions are given for the situation where the data for both the current month and the preceding month are collected in the same wavethe within-wave distributions (W)and the situation where the data for the two months are collected in different wavesthe between-wave distributions (B). The results for each month are bsrsed on persons reporting receiving Social Security income in that month and the preceding one.\n\nTable  2 shows that they are very similar for each of the months, with very little change reported. The only exception is January, 1984, when a 3.5% increase in Social Security payments was introduced. The average within-wave percentage change distribution for all months excluding January is given at the bottom of the\n\n7 Month September October November December January February March April , May Average Within (W) or Between (B) wave W W B W B W B W W B W B W B W W* B Percent change from Total 100.0 100.0 100.0 100.0 100.0 100.0 100.0 100.0 100.0 100.0 100.0 100.0 100.0 100.0 100.0 100.0 100.0\n\nSample size 4917 3285 1510 3257 1496 3221 1491 4809 3191 1475 3157 1451 3113 1440 4650 Reduction previous month No chiinge 99.1 99.2 36.0 97.8 29.5 97.2 23.1 36.6 96.7 36.1 97.6 41.7 99.0 40.4 99.1 98.3 34.4 More than 10% 0.2 0.1 6.4 0.2 5.9 0.3 6.2 0.3 0.2 6.3 0.1 5.4 0.1 6.1 0.3 0.2 6.0 10% or less 0.1 0.2 21.4 0.9 23.0 0.5 24.3 1.0 0.3 21.7 1.2 20.4 0.2 18.7 0.2 0.4 21.6 Increase 10% o r less 0.3 0.3 27.6 0.7 34.2 1.5 38.9 60.5 2.5 29.5 0.9 26.3 0.3 27.4 0.1 0.8 30.7 More than 10% 0.3 0.2 8.6 0.4 7.4 0.5 7.5 1.6 0.3 6.4 0.2 6.2 0.4 7.4 0.3 0.3 7.3\n\ntable. The between-wave distributions are also very similar for each of the months, and their average is given at the bottom of the table. As these average distributions show, 98.3% of amounts show no change from the last month when the amounts for Both months were collected in the same wave whereas only 34.4% of amounts show no change from the last month when the amount for the last month was collected in the previous wave. The marked contrast between the average within-wave and between-wave distributions of percentage change clearly demonstrates the magnitude of the seam effect.\n\nThe December to January change in Social Security amounts was measured as a within-wave change for the three rotation groups analyzed in this study. As noted above, the percentage change distribution from December to January differs markedly from the withinwave percentage change distributions for other adjacent months. This difference can be explained by the 3.5% increase in Social Security payments that began in January, 1984. As can be seen from Table 2, three-fifths of the respondents reported an increase of under 10% for January. However, over one-third did not report an increase at that time. While it is conceivable that some Social Security recipients experienced a drop in their payments in January that exactly counterbalanced the 3.5% increase, this eventuality. seems improbable.\n\nIn the following analysis we assume that those who reported that they received the same payments in December and January have failed to report the increase.\n\nTable 3 presents a breakdown of the percentage change distribution for January by rotation group. The table shows that the proportion of Social Security recipients failing to report the January increase differs appreciably by rotation group, being lowest for rotation group 1 and highest for rotation group 3. In interpreting this finding, it should be noted that rotation group 1 was interviewed in February about the October to January period, rotation group 2 was interviewed in March about the November to February period, and rotation group 3 was interviewed in April about the December to March period. Thus, the proportion failing to report the increase rises the longer the interval between the occurrence of the increase and the interview date. The next step in our analysis is to compare the characteristics of persons who reported the 3.5% increase in January with those of persons who failed to do so. For this purpose, we needed to identify those who reported the 3.5% increase. A histogram of the percentage increases from December to January showed that a sizeable number of cases fell in the neighborhood of 3.5%, but that there were no clearcut boundaries to distinguish those reporting Table 3 Percent Change from December to January by Rotation Group 3.5% increases from others. Based on a review of the histogram, we chose to classify those reporting January increases between 2.0% and 4.1% as correctly reporting the 3.5% increase. This classification is necessarily imperfect, but we believe it should suffice for the following analyses. This classification yielded 2310 \"correct\" reporters, 1762 \"incorrect\" reporters (that is persons who reported no increase from December to January), and 737 reporters for whom it was uncertain whether or not they had reported the 3.5% increase. The last group is excluded from the following analysis.\n\nA logistic regression modelling exercise was conducted to find a combination of explanatory variables to predict correct reporting of the January increase. The variables examined as potential explanatory variables were: rotation group (three groups); interview status (self reporter, proxy informant); highest grade of education attended (0-8, 9-12, over 12); gender; marital status (married and living together, other); race (white, non-white); age (above median age, below median age); receipt of pension (yes, no); January household income (above median income, below median income); and January Social Security payment (above median payment, below median payment). Five \"correct\" and 66 \"incorrect\" reporters were excluded from these analyses since they were coded as a category other than self reporter or proxy informant.\n\nGroup 3 % 0.2 0.3 45 .O 53.0 Reduction > 10% s 10% No change Increase s 10% The logistic regression analyses employed the approach described by Koch et al. (1975) for the analysis of complex survey data. Weighted proportions and a corresponding Group 1 % 0.3 0.2 29.4 68.4 Group 2 % 0.4 2.4 35.8 59.6 covariance matrix were computed for the contingency table defined by the cross-classification of the potential explanatory variables and the response variable using the OSIRIS IV Statistical Software System (Computer Support Group, 1984). The weighted proportions were transformed into logits, and the logits were modelled relative to the complex sample covariance matrix using the weighted least squares approach described in Grizzle et al. (1969).\n\nWald statistics were generated in GENCAT (Landis et al., 1976) to test hypotheses about the relationship of the predictor variables to the logits.\n\nAfter examining several competing models, the following model was chosen as the most appropriate:\n\nwhere p = the predicted proportion giving correct responses R, = 1 for rotation group 1, 0 for rotation group 2, -1 for rotation group 3 R, = 0 for rotation group 1, 1 for rotation group 2, -1 for rotation group 3 S = 1 for self reporter, -1 for proxy informant W = 1 for white, -1 for non-white P = f if the January Social Security payment is the median payment of $413 or less, -1 if it is greater than $413.\n\nThe analysis of variance for this model is given in Table 4. According to this model, there is a clear linear trend by rotation group (as observed in Table 3), and self reporters, whites, and persons receiving larger Social Security payments are more likely to report the January increase than their counterparts.\n\nThe logistic model can be used to predict the percentage of correct reports in each of the cells of the crosstabulation of the explanatory variables involved. These predicted percentages are presented along with the observed percentages of correct reports for each of the cells in Table 5. As can be seen from that table, the predicted percentages of correct reports range from a high of 75% (rotation group 1, white, self reporter, with a January Social Security payment' of over $413) to a low of 26% (rotation group 3, non-white, proxy informant, with a January Social Security payment of $413 or less). The observed percentages are generally close to the predicted percentages.\n\nTable 5 Weighted Observed and Predicted Percentages of Correct Reports of the 3.5% January Increase in Social Security Payments -Rotation Group 1 2 3 Race White Non-white White Non-white White Non-white Interview Status Self Proxy Self Proxy Self Proxy Self Proxy Self Proxy Self Proxy January Payment Over $413 $413 or less Over $413 $413 or less Over $413 $413 or less Over $413 $413 or less Over $413 $413 or less Over $413 $413 or less Over $413 $413 or less Over $413 $413 or less Over $413 $413 or less Over $413 $413 or less Over $413 $413 or less Over $413 $413 or less Percentage Reporting the January Observed % 73 69 67 52 57 63 60 42 64 60 5 1 44 49 52 4 ! 3 26 55 55 45 32 43 3 1 0 16 increase Predicted %\n\nGiven that a respondent failed to report the 3.5% increase in January, the question arises as to whether that increase appears at some other time, such as the preceding or succeeding seam. Table 6 presents evidence on that issue. The table gives for each rotation group the percentage of respondents who reported an increase of around 3.5% in some other month among those who failed to report an increase in January (columns (a)) and it also gives comparable percentages for those who did report an increase of around 3.5% in January (columns (b)). Overall, of those who reported the 3.5% increase in January, some 9% also reported an increase of this magnitude at the previous seam and some 7% also reported such an increase at the subsequent seam. For those who failed to report the increase in January, the corresponding percentages are appreciably larger at 27% and 11%. It appears that a sizeable number of the January increases are appearing at an adjacent seam, mainly the previous one. The percentages reporting an increase at the preceding seam among those failing to report the January increase differ markedly by rotation group, ranging from 19% for rotation group 1 to 35% for rotation group 3. Shifting the change to the previous seam thus appears to be more likely the greater the time interval between the occurrence 0-f the change and the date of interview. Another finding in Table 6 is that some 7% of those who failed to report the increase in January reported an increase of around 3.5% at some other time within the second wave, but none of those who reported the January increase did so.\n\nIt therefore seems likely that some of those who failed to report the increase in January misplaced the date of the increase within the wave.\n\nTable 6 Percentages of Respondents Reporting Increases of Around 3.5%* in Social Security Payments at Various Months for (a) Those Reporting no Increase in January and (b) Those Reporting an Increase of Around 3.5% in January, by Rotation Group *An increase of between 2.0 and 4.1%.\n\nThe causes of the seam effect have not been clearly identified. One possible explanation is that the excess changes at the seam are a manifestation of the general problem of measuring gross changes in panel surveys. Measures of gross changes between waves of a panel survey are generally overstated because of changes in measurement errors between the waves (Kalton et al., 1989). Another possible explanation is that the fewer changes within a wave are the result of a false consistency of within-wave reporting. Respondents may give the same answers for each month because they have forgotten that a change occurred during the four-month reference period or simply because repeating the same answer requires less effort. Based on their record check study, Marquis and Moore (1989) conclude that both these explanations operate, that is, that there is both an overstatement of changes between waves and an understatement of changes within waves.\n\nThe analyses of the reporting of the January, 1984, increases in Social Security payments presented in Section 4 lend support to false consistency within a wave as a partial explanation of the seam effect for this variable. Over one third of Social Security recipients failed to report the increase as taking place in January, and the extent of the failure to report the increase rose with the interval between January and the month of interview. A fair proportion of those who failed to report the increase in January did, however, report an increase of around 3.5% at one of the adjacent seams, mostly the earlier one. These findings are consistent with a reporting behavior of giving the amount for the latest month, and then reporting the same amount for the preceding three months. Such behavior would produce stable reports within the wave and lead to excess changes being reported at the preceding seam.\n\nDetermining the causes of the seam effect is important in order to guide the search for a solution. If false consistency is indeed a major cause, then some form of dependent interviewing may be a remedy. One form of dependent interviewing would be to first ask the respondent for data relating to the latest month of the current wave, and then to provide the respondent with the data reported for the last month of the previous wave. Armed with these fixed endpoints, the respondent may then be asked to provide the data for the intervening months. The Bureau of the Census is engaged in various studies of the seam effect (Petroni et al., 1989), one of which involves the use of dependent interviewing.\n\nWe have seen repeated evidence in the SIPP, and in its predecessor the ISDP, that between-wave change dominates within-wave change.' Most analysis, to date, has been largely descriptive of recipiency data (see e.g., bloore and Kasprzyk, 1984, Burkhead and Coder, 1985, Coder, 1986, Rascavage, 1986, and Weideman. 1986) and has resulted estimated between-to (average) within-wave transition ratios in the range of three to nine.* Since the same problem appears regardless of when the seam month occurs in calendar time, it is suggestive of substantial response error in reporting of montldy recipiency.\n\nFVlether or not this type of error is peculiar to studies employing the SIPP methodology of sequential-retrospective reporting for months in the reference period is a question of some considerable practical importance which has not pet been addressed. In the present paper we provide some evidence on this by comparing the between-and witlrin-wave transitions observed for the SIPP with those observed in another study, the Panel Study of Income Dynamics (PSID), which employs a different methodology in collecting monthly data. We ask the very specific question of whether there is any evidenc'e that the PSID methodology results in fewer between-relative to witlrin-wave transitions than the SIPP methodology. M?lile, in general, we would need to compute the complex samphg errors and conduct formal tests to answer this question, in the present case these statistics are not necessary.\n\nAnother questioq of considerable concern is how these errors miglit s e c t estimates of models intended to explain the dynamics of welfare participation and employment. Hill and H i l l (1986) have found that in the context of a proportiolial hazards model of transitions to employment estimated with SIPP data, whether or not the week of the transition was a seam l ~h i s research was sponsored, in part, by a Joint Statistical Agreement (JSA 87-5) between the United States Bureau of the Census and the Survey Research Center of the University of Michigan. The current paper is an extention of a simrlar paper presented and the 1987 American Statistical Association meetings. The author would like to thank Dan Kasprzyk, Graham Kalton and Charlie Brown for their helpful suggestions and Judy Connors for her SIPP data management assistance. Any errors are the responsibility of the author.\n\n2 ~h e r e is evidence that the 'seam problem' is not confined to discrete data. Kalton, Lepkowski, and Lin (1985) find similar patterns for changes in income.\n\nweek was the single most important predictor. If the response errors leading to exaggerated between-relative to within-wave transitions are systematically associated with either employment status or its detemzinants then it may result in serious biases in behavioral models. Using data from the PSID's 1984 and 1985 interviewing waves which incorporated an overlapping seam design, we will attempt to answer the question of whether there are sigrdicant associations of response errors around the seam to factors which might be viewed as determinants of behavior. We will dso attempt to isolate some of the causes of reporting inconsistencies which tend to amplify or attenuate between-relative to within-wave transitions.\n\nAs noted above, the methodology employed in the SIPP to obtain monthly recipiency and amounts data is sequential and retrospective. Early in the questionnaire, the respondent is asked about the receipt of income from an exhaustive list of possible sources. In addition, after wave 1, respondents were reminded of the income sources they reported during the prior wave and asked if they continued to receive that income in the current reference period. Once the individuals income recipiency 'roster' is completed for the period, the respondent is asked about the timing of receipt within the four-month reference period. This questioning is sequential. For each income type listed in the roster the respondent is asked about whether it was received (and how much) in the calendar month prior to the interyiew, then for the month prior to that, etc. until the reference period is complete.\n\nThe type of seam problem that has been of such concern in past analysis of the SIPP is clearly evident in the reported transitions in unemployment compensation presented in Figure 1. To make comparisons completely comparable with the PSID we limit out attention here to Rotation Group 4, Waves 1 and 3, of the 1984 SIPP Panel. The members of this subsample experienced their fist 'seam' between December 1983 and January 1984. The figure shows a pronounced 'bulge' in reported exits from unemployment compensation programs during this seam period-approximately twice as many ~e o p l e exited at this time than at any other time.\n\nPrevious analysis show this same pattern appears for all calendar months. The corresponding bulge for entrances, while still quite noticeable, is less dramatic.\n\nWith respect to recipiency measures such as for unemployment compensation, the PSID methodology differs in three major respects &om the SIPP. First, the PSID has donger recall period. The PSID has been collecting information from the same families (and the descendents of these families) annuallv since 1968. The interviewing is conducted in the spring and summer with the reference period being the prior calendar year. Thus, the reference period requires recall of at least fifteen months and for some respondents, who are not interviewed until the end of the Summer, as much as twenty-one months. The second major difference in PSID methodology, is that we do not even try to obtain monthly amounts-only annual total amounts and monthly receipency are recorded. Finally, rather than ask about each month retrospectively and sequentially, the PSID asks the respondent to give the beginning and ending months for each continuous spell of recipiency. 4 SIPP pattern of Figure 1. The PSID, in general, appears to have somewhat less witlh-wave transition and a markedly more pronounced bulge in exits from unemployment compensation at the seam than the SIPP. Otherwise, however, the patterns of monthly transitions fiom the two studies are quite comparable.\n\nThis same general conclusion holds for Foodstamp recipiency, as examination of Figures 3 and 4 will confirm. With Foodstamps, however, the dominance of seam transitions over within-wave transitions is even more pronounced than with unemployment compensation in both studies. Unlike unemployment compensation, foodstamps are not necessarily individual specific, but are provided to recipiency units which are either individuals, families, or subfamilies. Part of the large amount of between-wave change may be due to changes in the composition of households between waves, coupled with some confusion regarding who is in the recipiency unit. Also, unemployment compensation tends to be a shorter duration phenomenon than foodstamp receipt, and true transition may be more common.\n\nMWe there is no evidence in these data to suggest that the PSID methodology results in any better quality data than the SIPP methodology, there are some differences in the Figure 9 Food Stamp Recipiency Transitions (Percent by Month) SIPP O c t -s a p N o v -O c t D a c -N o v J o n -D a c F a b -J o n n o r -F a b R p r -U o r N o v -O c t b J o n -O a c F a b -J o n R U o r -F a b 13 ENTRRNCES r mgO E X I T S ENTRRNCES Figure 2 Unemployment Compensation Transitions (Percnet by Month) PSID Figure 4 Food Stamp Recipiency Transitions (Percent by Month) PSID a O c i -S a p m N o v -O c t a O a c -N o v O a c -N o v J o n -D a c f a b -J o n n o r -F a b A p r -n o r m J o n -O a c P S I 0 mmn E X , 7 s 0 ENTRRNCES m E X I T S ENTRRNCES importance of between-and within-wave transitions between the two studies. The most important is that, by design, the PSLD has fewer seams than the S P P . This can be seen quite clearly in Figure 5 which plots the percent of the PSID individuals reporting transitions in secondary employment and in AFDC receipt, by month.3 There are twenty-two withinwave transitions for each income source, and one between-wave transition occurring between December 1983 and January 1984. Again, we see that the seam problem is less severe for the short-term individual specific measure (extra jobs) than for the longer term family level variable (AFDC). If the source of the 'seam problem' is an exorbitant amount of between-wave change, then the PSID methodology may be superior. There is some evidence, however, that at least part of the cause of the seam problem is too Little within-wave change.4 In this case the more kequent interview schedule of the SIPP may be a definite advantage. P b 6 Withinvermurr Between-Wave Tranritionr in PSID (Pencent by Month) ' Jan-Feb DecJan Month h he populations of inference for Figure 3 are, for the extra jobs figures, a l l individuals who had some secondary or 'extra' job in the two year period January 1983-December 1984 and, for the AFDC figures, all individuals receiving AFDC in at least one month during the same two-year period. s i g d c a n t under-reporting of the January 1984 increase in Social Security benefit levels within waves for rotation groups 1-3 of the 1984 SIPP panel. ' ~a l t o n and Miller (1987) find signdicant under-reporting of the January 1984 increase in Social Security benefit levels within waves for rotation groups 1-3 of the 1984 SIPP panel.\n\nIn conclusion, there is no evidence to suggest that the excess of between-wave relative to within-wave transitions is peculiar to the SIPP.. The same patterns appear for the PSID which employs a radically different collectioll methodology. If anything, the PSID's longer reference and recall period may lead to more pronounced seam problems. One common element to the design of both studies which may be responsible for this problem is simply that the time-unit of measurement, the month, is shorter t h a l the reference and recall period.\n\nHaving established the dominance of between-wave transitions in the PSID as well as the SIPP, we now turn to capitalizing on the overlapping design of the PSID in isolating factors affecting inconsistent within-and between-wave transitions. The measure we will concentrate on is employment status and we will be especially concerned with transitions between December of 1983 and January of 1984.\n\nData on employment status in this latter month were collected during both the 1984 and 1985 interviewing years. Table 1 presents a cross classification of the two January reports for all respondents who were either a 'head of household' or a wife of the head of household in each year.5 Because the 1984 questions upon w h ~h these reports are based were not asked of individuals who were not in the labor force as of the time of the I984 interview, such individuals are eliminated &om the a ~a l y s i s . ~\n\nOverall, the figures in Table 1 suggest substantial agreement in reports from the two interviewing years. The simple response variance indicated by the numbers in Table 1 is only .045. hlost of this agreement, however, is the result of conststent reports of employment in the two years. Ninety-seven percent of those reporting in 1984 that they were employed in January, also reported that they were employed in January of 1984 when asked about it in '~ecause the study began in 1968 we originally used the n o r archaic and admittedly sexist 1960 Census definition of Head of Household in our original design. Furthermore, since the PSID is a panel study, we cannot deviate from our o r i p d design if we wish to maintain its longitudind value.\n\nore precisely anyone either retired, permanently dsabled, keeping house, or a student, and who was not working at least ten hours a week at the time of the 1984 interview was skipped out of the employment work history sequence in 1984. This is an unfortunate restriction because it reduces the variance in both the outcome measure we are interested in (response error) and in a potentially important predctor (initial employment status). 'employed' responses are people who had continuous emplojment throughout the reporting period and the reporting task for these people is orders of magnitude less difficult than for those experiencing a variety of employment situations.\n\nGiven the type of data in Table 1 along with reports on employnent status in December of 1983, there are several ways we could proceed in isolating factors associated with erroneous seam transitions. We could, for instance, analyze the simple response variance directly as has OyMuircheartaigh (1985),~ since spurious between wave transitions and response variance are closely related. A more direct approach, however, involves concentrating only on those cases reporting transitions (either within a wave or between waves) and examining the extent of agreement in between and within-wave transitions.\n\n7 O'Muircheartaigh employed CPS interview/reinterview data in his analysis of response variance in reports of employment status. Such reports, while tending to attenuate the 'seam problem' which has most concerned analysts in the past, are nevertheless, reflective of poor response quality.\n\nThe advantages of this approach over the analysis of simple response variances me largely interpretational and analytic. The interpretational advantage is that we can see directly the effects of factors on the likelihood of reporting inconsistencies which both exaggerate and attenuate measured between-wave change. The analytic advantage becomes apparent once we note that any observed effect on the simple response variance may come about either via an effect on the probability of actually being in a stable emplojment situation or via a true effect on the error variance of the response. By ignoring those individuals with stable employment situations, we are in effect controlling for stable employment situations and we can more directly attribute any observed effects to true response quality.\n\nIn order to understand'the effects of factors on the observed between-and within-wave transitions it is necessary to develop a model. Specifically, we assume that each individual i has a propensity R to provide reports of type j (where j <0,1,2> corresponds to consistent transition reports, inconsistent reports which tend to attenuate between-wave transitions, and inconsistent reports which tend to amplify between wave transition measures). These response propensities are composed of systematic and stochastic components. The systematic portion of the response propensity consists of the effects of a series of exogenous measured factors X while the stochastic portion, denoted p , reflects the effects unmeasured excluded factors and chance. As a first order approximation, the response propensities can be expressed as:\n\nSeam-Attenuating Inconsistencies R.. = XiBj t p..\n\n1)\n\nThe individual is assumed to provide the response j with the highest propensity score R.\n\nZf the error term p follows a Type I extreme value, or log-Weibull distribution with density 4\n\n= exp(-p) exp[-exp(-p)] then we can model the response process according to the multinomial logit model. In this case, the probability that individual i will fall into response class j is:\n\nThe factors (X) assumed to affect the propensity to provide reports of varying quality are of four types. The first type are factors which affect the difficulty of the recall task the respondent is being asked to perform. These consist of the length of the recall period, the number of intervening transitions in employment status, the length of time the person has been employed by the employer as of the time of the 1985 interview, whether or not the respondent is the reference person, the person's industry of employment, whether or not he is self employed, and whether or not he has extra jobs in addition to his 'main job'. Cognitive English. This measure is derived from a sentence-completion test administered to the respondent in 1972. Scores on this test have been found to be highly correlated with more rigorous 'IQ' tests but are also highly culturally dependent. Since the PSID questionnaire is written in Standard American English, however, it is reasonable to assume that both c o p t i v e and language skills on the part of the respondent will affect the quality of the data derived from it.\n\nThe final set of factors are included as controls and consists of basic demographic measures. These are race (whether Black), education, age, gender (whether male), and income.\n\nThe results of the multinomial logit analysis of within-and between-wave transition inconsistency for employment status are presented in Table 3. The coefficients for consistent transition reports are normalized to zero, and the coefficients presented for the two types of inconsistencies can be thought of as deviations from the effects of the factors on consistent reports. Positive coefficients, therefore, represent adverse effects of the corresponding factor on data quality.\n\nThe &st pair of columns in Table 3 correspond to the model which includes demographic factors only. Whether or not there are systematic associations of these factors with the propensity to provide erroneous transition reports is particularly important because most event history analyses will include these factors as predictors. Indeed, in many cases the major motivation in analyzing the micro-dynamics is to understand better the reasons for persistent differences in experiences of various demographic subgroups of the population. The only demographic factor having a sigmficant effect on the propensity of respondents to provide inconsistent reports which attenuate between-wave transitions is total f d y income.\n\nEach thousand dollars of such income has the effect of raising the log of the odds of such an inconsistent report being given by .016 points. Even this effect is only marghally sigruficant.\n\nIn contrast, both race and age have strongly slgrlficant effects on the propensity of respondents to provide transition exaggerating inconsistent reports. Blacks are far more likely to provide inconsistent reports which serve to amplify between-wave transitions tllan are non-~lacks.' Similarly, the older the respondent, the more likely he is to provide seamtransition amplifying reports.\n\nThere are a variety of reasons why we might see such race and age effects. Cognitive psychologists have often argued that age reduces the efficiency with which people encode events into memory as well as the efficiency with which they retrieve data from memory. Lf this is the case, then the age effect may simply be reflecting less accurate recall. Past empirical evidence, however, has not cotlsistently shown such a relationship. Indeed, OIMuirchearchtaigh (1986) finds that older respondents have lower simple response variances in reinterview data for the CPS than younger respondents. This is in direct conflict with our findings ~resente'd in Table 3. There are several Merences between his analysis and ours which might account for the conflicting results Perhaps most important is our exclusion of those reporting being either retired, a student, a housewife, or permanently disabled and who did not work at the time of the 1984 interview These people are disproportionately located at both extremes of the age distribution and O'lIulrcheartugh's age effects are most pronounced at these extremes. The only elderly people left In our sample are those working at least ten hours a week at the time of the 1984 interview. .\\Ian! of these people are likely in part-time or casual employment situations and this type of emplojment might be particularly prone to mis-reporting. Similarly, Blacks are far more likely than non-Blacks to experience labor force disruptions and the difficulty of their recall task is likely to be far greater. Additionally, the reporting task is probably made more difficult for some Blacks because they are less facile in standard American English than are non-Blacks. Difficulty o f Task and Other Controls While the differences between O'Muircheartaigh's and our age effects are easily explained by differences in procedures, they also suggest what is a dficult problem i n studes such as ours where there is no independent validating data. This is that without such data we cannot tell to what extent older respondents, for instance, are providing better reports (as O'hluircheartaigh suggests) or that they just have nothing of interest on a particular topic to report. If they do not, then their reporting task is trivial unless they happen to be in some nebulous transitory or casual emplojment situation.\n\nIf age and race are truly responsible for lower quality of data for older and Black respondents, then the estimated coefficients on these variables should not be greatly reduced when we control for factors reflecting the difficulty of the reporting task, the cognitive and language skills of the respondent, and the nature of the interview situation itself. The figures presented in columns three and four of Table 3 indicate that this is the case. Indeed, the effects of age and race are slightly increased by the inclusion of measures intended to capture the effects of task, and cognitive ability on response quality. On the other hand, the only such measure to have a truly sigdicant effect on response propensities is tenure with the employer of record at the time of the 1985 interview. While not entirely tautological-people can and do experience periods of unemplojment and absences from the labor force in the nlidst of a period of emplopent with a single employer-there is a strong definitional component to this effect.\n\nThe inclusion of task aid cognitive factors also has the effect of increasing the power of the demographic effects on the propensity to provide inconsistent reports which attenuate between to within-wave transition ratios (column 3). Specifically, both gender and income now become sigJuficant-with males and low income respondents being si@cantly less likely to provide such reports.\n\nAlthough none of the other variables are sigmficant at conventional levels, a couple of factors do have sufficiently large estimated effects relative to their estimated standard errors to be worth noting. Specifically there is some evidence to suggest that self-employed  1985 respondents were respondents in 1972,' it was necessary to include two measures-the test score of the 1972 respondent, and an interaction of this score and a dummy variable indicating a change in respondent between 1972 and 1985. The estimatrd effect of one's own test score is given by the coefficient on the f i s t of these variables, while the effect of the test score of the 1972 respondent on some other 1985 respondent is given by the sum of the coefficients on the two variables. The former effect on the propensity to provide seamamplifying effects is negative, while the latter effect is virtually zero. To test the signrficance of the cognitive skills/language test-score it is necessary to remove both measures hom the analysis and perform a likelihood-ratio test. The results of this test is a reduction i n the loglikelihood value of 3.07 which implies a X-square of 6.14 with 4 degrees of freedom.1Â° Finally, given their prominence in psychological discussions of recall accuracy, two variables should be noted for their lack of apparent effect on our measures of response . consistency. These are length of recall and the number of transitions intervening between the time of the 1985 interview and the period being reported. Both of these were expected to adversely affect response quality, but the estimated effects are so small relative to their standard errors as to preclude our rejecting the hypothesis of zero effect. If' anything, the point estimates suggest that both factors are associated with higher quality recall. With respect to the reported number of intervening transitions this may be the result of respondent heterogeneity with those reporting within-wave change providing better data than those who do not. With respect to length of recall, our results may be consistent with very rapid memory decay-so rapid that the difference between nine and nineteen months recall is irrelevant.\n\nBefore concluding our discussion it is worthwhile to consider the question of whether there is a common structure to the determinants of the two types of inconsistencies we have identified. If they do share a common structure, then their effects may tend to cancel each other out in structural analysis, and their net effect may only be to reduce measures of goodness-of-fit. Casual comparisons of the coefficients in columns three and four are not very useful. Some factors appear to affect the propensities in opposite directions (e.g. race) which would imply that these errors would reinforce each other in biasing structural parameter he remaining eighty percent of 1985 respondents are composed primarily of children or spouses of the 1972 respondent.\n\n' O ~h e n test-score is included as the sole predictor we find it to be significant at the 95% level of s i m c a n c e . U l e n race is added, however, the effect of test-score becomes insigdicant .\n\nestimates. Other factors appear to affect the response propensities in the same direction (e.g.\n\ntenure with current employer)-something which would attenuate their net effects on structural parameter estimates.\n\nv A formal test of whether the two types of response errors are reinforcing or off-setting is possible. Specifically, we can constrain the effects to be equal by re-analyzing the model using a dummy dependent variable for whether either type of inconsistency occurs and compare its goodness-of-fit with that from the unconstrained model. Lf there is a significant reduction in the X-square statistic then the joint structure hypothesis can be rejected. The results of this analysis are presented in the final column of figures in Table 3.l' The X-square statistic declines siguflcantly from 92.4 with 32 degrees of 5eedom to 45.1 with 16 degrees of freedom.\n\nThus we can be confidellt that the effects of the two types of response errors on structural model estimates (e.g. those of a proportional hazards model of unemployment) will not be offsetting.\n\nIn order to summarize our findings: and to provide the reader with a more intuitive appreciation of the size of effects we do find; Table 1 presents the results of simulations based on the coefficients presented in columns three and foirp of Table 3 for selected predictors.\n\nBecause the model is non-linear we perfom these simulations by calculating predicted values of the probability of each response separately for each respondent and then averaging these probabilities across respondents. The simulations are performed first using the actual values of the X's and then adding to each B separately an amount ~0~eSponding to (1/100th) of a standard deviation. The resulting change in the prehcted probabilities is then scaled by ( I / 100th) of the standard deviation of the dependent variable. The resulting coefficients presented in Table 4 are therefore analogous to sriu~dardized regression coefficients.'* Using these measures, we see that the most important predictor of the propensity of respondents to provide seam transition attenuatmg reports is income, with a one standard deviation ($14,472) increase resulting in a ,0967 standard deviation, or 3.35 (=.0967*.3469) percentage point, increase in the probability of prov~dlng such a report. This effect is followed very closely by gender with standardized coefficient for males being -.0953. For the \"such a model is analogous to an analysis of simple response variance or gross-difference rates for the population of individuals reporting a transition (either between or within waves) between December 1983 and January 1984.\n\n12unlike standardized regression coefficients, however, there is not a one-to-one relationshp between the relative size of these coefficients and other measures of predictor importance such as t-ratios.\n\nIn this paper we have employed monthly data from the 1984 and 1985 waves of the Panel Study of Income Dynamics to investigate the extent and determinants of excessive measured change between waves relative to measured change within waves of panel surveys.\n\nWe find that, in spite of different and presumably more directive question sequences, the dominance of between-wave change in the PSI0 is at least as severe as in the SIPP. If anything the PSID data are worse in this regard than the SIPP. In addition, some hypotheses were noted without being tested. For one thing, the data suggest that the 'seam problem' may be more severe for measures that are tied to groups of individuals (e.g. Foodstamps)\n\nrather than to a specific individual (unemployment compensation). There is also the suggestion in the data that the average duration of receipt of income sources may positively affect the severity of the seam problem.\n\nOur attempt to understand the determinants of seam problems using overlapping reports of employment status &om the last two waves of the PSID was only partly successfd.\n\nWe did identify signLficant correlates of the propensity to provide inconsistent reports which amplified between-to within-wave transition ratios, but we faded to identify their causes.\n\nBlacks and older respondents were found to be sigdlcantly more Likely to provide seam transition amplifying reports, but none of the measures intended to explain why this might be the case (with the exception of employment tenure) had the expected s i d c a n t effects.\n\nThere was some weak evidence that cognitive ability and facility in standard American Enghsh enhanced the quality of reports, but no evidence of the much touted effects of length of recall and hterference of like events was found. Similar inexplicable effects of gender and income for the propensity of providing inconsistent reports which tended to attenuate between wave changes were also found.\n\nNevertheless, the simple fact that there are systematic associations between various demographic factors and the propensity of respondents to provide inconsistent reports leading to seam problems is important. It means that micro-dynamic analyses such as those based on event history models are not justified in ignoring response errors. It also means that improved data collection methodologies need to be sought and tested.\n\nThe SIPP reinterview program is an ongoing systematic operation which is intended to moilitor data quality by checking the interviewers' work. The sample to be reinterviewed each month is a multistage probability sample of current SIPP respondents. The sample selections are made monthly at the Regional Offices with instructions fiom the National Field Office in Suitland, Md. The first stage of sampling consists of partitioning the interviewers into twelve groups two of which are selected for reinterview each month. The selectiolrs me inade by the national field office in Suitland. The second stage consists of randomly selecting a sample of the selected interviewers' sampling units. This is accomplished by selecting every 'nth' unit fiom the Interviewer's Assignment and Control form begumkg with the 'kth' unit.\n\nIffewer than five units are selected subsequent passes through the listing are conducted u t i l five units are selected. Both the selection intervd 'n' and the random start number 'k' are determined by the national field staff and transmitted monthly to the Regional Offices. The final stage of the reinterview sanlple selection is to select one individual per unit for reinterviewing. T l ~s is accomplished by determining the number of individuals interviewed in the unit and using a random selection table to choose wllich of these individuals is to be interviewed.\n\nThe result of this sample selection procedure is that each individual interviewed in the main SIPP study has a probability of\n\nwhere Pit is the probability that individual i's unit, U, was selected in month t, given that his u interviewer was, and fsit is the number of individuals interviewed in that individual's unit in month t. P : can vary fiom 113 to 1 depending on the number of units assigned to the interviewer.\n\nThe implication of equation 1) is that if inferences are to be made fiom the reinterview sample to the SIPP sample as a whole, the analyst will need to know a) the ilumber of units assigned to each interviewer and b) the number of individuals interviewed by the interviewer in the selected unit. While it is theoretically possible to obtain measures from the public release data, they codd not be obtained with complete accuracy and it would be quite expensive.* Thus, it would be helpful if these numbers could be transcribed to the Reinterview Questionnai~e at the Regional Ofice.\n\nOnce individuals are selected for reinterview, the Reinterview Questionnaire and Reconciliation Record (RQRR) is prepared. This is done by anyone familiar with the SIPP at the Regional Office other than the reinterviewer. This restriction is imposed so as to maintain the independence of the interview and reinterview responses. The preparation consists first of transcribing the identification codes and names of the individual to be reinterviewed, the interviewer, and the original respondent. Second, the \"Office Check Items\" are transcribed -from the unedited original interview to the RQRR's Section 2. These items determine the question flow in both original interview and reinterview questionnaires.\n\nFigure 1 illustrates the question flow for Section 2 of the Reinterview Questionnaire.\n\nThe questions actually asked of the respondent in both the interview and reinterview are printed in bold, while the Office Check Items which are transcribed to the Reinterview Questionnaire frcm the original appear in normal print. Unless otherwise indicated, questions are asked in sequence. In most cases, however, respondents are skipped around certain questions and these skips are indicated in the figure by lines and mows. Lf, in response to question 1, for instance, the respondent said he had a job for at least part of the reference period ('yes' on item I.), he is skipped around the questions about whether he spent any time looking for a job (2a.), or whether he wanted a job (3a.), and is asked about whether he had a job each week of the reference period instead (4.). In Figure 1, a skip such as this whlch results from a response to a question asked in the reinterview study is depicted with a dotted line. Skips froni Office Check Items, being automatic from the reinterviewer's point of view, are depicted as solid lines.\n\nIt does not take a great deal of study of Figure 1 to see that the skip sequences employed in the SIPP can be quite complicated. Indeed, a major goal of the reinterview program is to see if individual interviewers are following these skip sequences properly. It is important to note that the Office Check Items are transcribed from the original questionnaire before it is edted by the Regional Office staff. This is done so that the question flow employed by the *one could obtain an estimate of the interviewer's assigned workload by sorting the sample unit file by interviewer ID and counting. Similarly an estimate of the number of individuals interviewed by the interviewer within the sample unit could be obtained by subtracting the number of children less than fourteen &om the household size variable on the public release file. While sampling rates from these estimates would be preferable to those based on, for instance, average workloads within regional offices (since even within RO's workloads vary greatly), it would be far better if the actual numbers used in the reinterview selection procedure were recorded and passed on to the analyst. sufficiently serious, the original interview is returned to the field so that missed questions can be asked of the respondent. These editing changes and 'send-backs' are done after the reinterview is completed.\n\nThe final task in preparing the reinterview questionnaire is to transcribe the original question responses to the 'reconciliation' portion (section 3) of the questionnaire. To help insure independence between the interview and reinterview responses, the reinterviewer is instructed not to look at these answers until after the questions have been re-asked.\n\nWhen the materials are prepared the reinterview is assigned to the reinterviewer and is conducted by telephone. Once a respondent is contacted the reinterviewer records the time, date, mode, and person number of the reinterview respondent. Next the Control Card items for the selected sample individual are verified. First, and in many respects most importantly, the reinterviewer determines if the proper sample unit was actually visited by the original interviewer. Second, the reinterviewer ascertains if the living quarters, household composition, relationshp to reference person, household membership status and birth date are properly recorded on the (photo-copy of the) Control Card.\n\nNext, the reinterviewer begins the Labor Force and Recipiency portion of the reinterview (Section 2) which is as depicted in Figure 1. Only when this is completed does the reinterviewer tun1 to the Reconciliation section. At this point, the answers just obtained are transcribed by the reinterviewer to reconciliation section and are compared with the original responses. The respondent is then asked to help reconcile any discrepancies, and the reinterviewer records which of the two reports is judged to be correct.\n\nAfter the reinterview is completed it is returned to the Regional Office where a summary report for each reinterviewer is compiled. On the basis of these reports reinterviewers are either congratulated, counselled, retrained or dismissed.\n\nIn the normal course of the reinterview program a summary report is prepared and these are analyzed on an annual basis by the Field Division. A special keying operation was conducted during the summer of 1987 to prepare the data from the 1984 panel's reinterview questionnaires for the analysis which follows.\n\n. With the two independent observations provided by the interview and reinterview responses it is possible to estimate the simple response variance for the various questions. 5\n\nTo do so: we first confine our attention to that portion of the reinterview sample where a) the reinterview was successfully conducted and b) it was determined that the interviewer had visited the proper sample unit in conducting the original interview. We also eliminate from our sample those cases where the date of the original interview as recorded in the interview failed to match the date coded in the public release files,6 and those few cases where, even though the reinterview was conducted, no substantive questions were re-asked. These restrictions leave us with a sample of 1,559 cases of interview/reintervieur data for waves 2 and 3 of the 1384 panel.\n\nIn comparing interview and reinterview data we have a choice of using the pre-edited original interview information which was transcribed to Section 3 of the RQRR or the postedited data which is available froin the public release files. Evidently, however, not d the information from the original interview is transcribed to Section 3. Transcriptions are made only if a discrepancy is encountered. Hour hscrepancies resulting from a question being skipped in one interview and not the other are treated is not clear. Thus we use instead original reports as recorded on the public release files and recognize that some of the discrepancies between interview and reinterview reports are* due to edits and imputations performed subsequent to the original interview\n\nWe can distinguish two distinct types of inconsistencies when the interview and reinterview reporti do not agree-response inconsistencies and procedural or 'slup' inconsistencies. Response inconsistencies have been studied extensively in the CPS and quite elegant models of response variance have been developed (see e.g. OIMuircheartaigh, 1986).\n\nThe underlying response model most commonly employed can be expressed as:\n\n5 ~o the extent that the respondent's reintervlew response is affected by their memory of their response in the interview response errors m the t w o will tend to be positively correlated rather than independent. Thus, to this extent, the estimated response variances presented in the present analysis will tend to be conservative.\n\n'several hundred reinterviews for waves 2 and 3 of the 1984 panel were found to match on the basis of wave and entry identscation numbers. but were found to have original interview dates which differed by roughly a multiple of four months. Apparently, the wrong reinterview schedule was employed for some subsequent waves of the reinterview program. While the content of the reinterview schedule remained the same throughout the panel, the form number changes each wave, and this fonn number is used as the wave identifier.\n\nwhere yit is the report provided by the ith respondent duringthe tth measurement ( t = l for interview, 2 for reinterview), yi is the true value of g , pi is the bias in individual i's reports, and tit is the random component to individual i's reports. The simple response variance is simply the variance of the eit across t. With categorical data such as we will be examining, response variance can be estimated as one-half the fraction of responses to a given question which differ between the interview and reinterview reports (2.e. one-half the gross difference rate).\n\nWe will reserve the term response variance or 'response inconsistencies' for estimates involving cases where the question was actually asked of the respondent in both the interview and reinterview and where a response was recorded. Given the complicated skip sequences employed, it should riot be surprising that there are differences between the two reports not just in responses, but in whether or not the question was asked each time. Discrepancies between the interview and reinterview arising because a question was skipped in one and not the other will be referred to as 'procedural d i ~c r e ~a n c i e s ' . ~, ~ An example map be useful in clarifying these distinctions.  2 presents these discrepancy rates and the dual response rates for each of twelve substantive questions asked i n the SIPP reinter vie^.^ There is considerable variation in the overall discrepancy rates for these questions ranging from less than two percent for questions on employment during the reference period (1) and continued Medicaid coverage (26b) to about seven percent for the Health Insurance coverage (27a) and the employer's contribution to Health Insurance (27f) questions.10 This pattern is quite similar to that reported b y the Census Bureau's Reinterview Evaluation Section (see e.g. Smith, 1987). While it does vary from question to question, the majority of the discrepancies in the data as a whole are procedural rather than response discrepancies. Given the skip patterns depicted in Figure 1 ' O ~h e overall discrepancy rate over ad items was 3.82% which is only moderately higher than the 3.07% reported by St. Clair (1985) for Waves 2-4 of the 1984 Panel. Most of this difference is probably due to differences in the definitions of difference rates. It is also likely, given the results of Section 4 below, that our rate would have been lower bad we included wave 4 in our analysis.\n\n2 'Xo' 59 3 172 234 Blank 1,250 7 29 1,286 1 'Yes' 7 29 3 '\n\nit is not surprising that virtually all of the discrepancies on the Medicare coverage question were procedural in nature-i.e. the result of the question being skipped in one interview and not in the other. There are, after all, three distinct ways in which a respondent can be routed around question 23a and four ways in which he could be routed to it.''\n\nTabie 2 Discrepancy Rates for the Substantive Reinterview Questions Discrepancy Rates (percent) Question Overall Procedural Response Dual Response 1. Have job? 2a. Look for job? 3a. Want job? 4. Each week? 9a. U.I. Comp? 23a. Medicare? 24. Food Stamps? 26a. Mcaid now? 26b. Mcaid B4? 27a. Health Ins? 27e. Via emplyr? 27f. Emplyr pay? *Rate suppressed due to the s m a l l number of cases in the denominator.\n\nhe respondent is routed around 23a if either 1) R6=N, R21=N and R22=N, 2) R6=Y, and R8=Y, or 3) R6=Y, R8=N, R9=N and RlO=N. The respondent is to be asked question 23a if either 1) R6=N and R21=Y, 2) R6=N1 R21=N and R22=Y1 3) R6=Y1 R8=N, and R9=Y1 or 4) R6=Y1 R8=N, R9=N, and RlO=Y.\n\nProcedural discrepancies also accounted for most of the overall discrepancies in all the remaining questions except for the initial employment and health insurance questions. That these are the initial questions in a sequence which all respondents are to be asked is sigdicant and points to the fact that some of the procedural inconsistencies are the result of response inconsistencies in earlier portions of the interview.\n\nResponse inconsistencies also vary widely from a low of less that three-tenths of onepercent for the Foodstamp authorization question to more thazi seven and a half percent for the employer health insurance contribution question. The high response variances of health insurance coverage and employer contribution of .03 (=.5*6.03/100) and .038 (=.5*7.62/100), respectively, would suggest that there is something wrong with these questions. The full health insurance coverage question reads: 27a)\"During the 4-month period, did ... have group or individual health insurance in ... ' S own name?\"\n\nWhile the problem with this question is quite likely that 'whose name the insurance is in' is not particularly salient or important to the respondent, it would be interesting to know how many respondents are giving either \"group\" or \"individual\" as their initial response.\n\nSimilarly, from the respondent's point of view, reasonable responses to the question:\n\n27f)\"Did the employer or union (former employer or pension plan) pay for all or part of the cost of this plan?\" codd be 'employer', 'union9, 'all9, 'part', 'no', or 'yes'. The allowed responses are 'all', 'part' and 'none9. Thus, it is quite likely that the interviewer is having to probe for the 'all', 'part', or 'none' responses in a large number of cases when the respondent's answer is 'yes', 'employer' or 'union'. Part of the response variance may be due to variance in how and whether these probes are being made.\n\n. UThile response variance is most troublesome for the health insurance questions, it is also quite high for discouraged worker question. In this case, the question seems rather unambiguously worded and it would seem that the problem must lie in the ambiguity of the concept it self.\n\nBefore leaving our discussion of the extent of interview/reinterview discrepancies it should be noted that independent analyses of the reinterview data by Bureau staff revealed the same pattern of results for the health and discouraged worker questions. As a result the health questions have been substantially modified, while the discouraged worker question has been dropped.\n\nIn summary, simple comparisons of interview and reinterview reports from the reinterview data are sufficient to highlight some questions and procedures that are particularly problematic in the current SIPP instrument. Considerable error is probably being introduced to the data, for instance, because the skip sequences are sometimes quite complex and may not always be successfully followed. Additional errors occur because not all the questions are as clearly worded as we would like, and the reinterview data reflect these glitches in the form of h g h response variance.\n\nIf the procedural and response variability is the same for all respondents, then its existence is relatively benign. In multivariate analysis its existence in dependent variables will only reduce the model's goodness of fit and in independent variables will -(predictably) bias the estimated coefficients toward zero.12 If, on the other hand, the extent of response or procedural variance differs systematically from one respondent to the next, all manner of problems can be expected to arise in bivariate or multivariate analysis. The purpose of this section is to explore the extent to which response and procedural variance differs systematically with characteristics of respondents and interviewers.\n\nTraditionally, analysts have chosen some form of logit model (see e.g. O'Muircheartaigh and Wiggins, 1981) in investigating the association of respondent and interviewer characteristics with response discrepancies. Such analyses are done on a question by question 0 basis. In a preliminary investigation of such a model with the current data, the author found that, given the rarity of response discrepancies and the relatively small size of the SIPP reinterview program, there were too few cases of response discrepancies to analyze effectively in this manner.\n\nAn alternative modeling approach is to analyze the reinterview data, not on a questionby-question basis, but as single experiment in ahlch the outcome is the number of discrepancies occurring in the course of the reinterview. Each question asked in the reinten-iew can be thought of as a Bernoulli trial with a 'success' being defined as a report being given which differs &om that provided in the origmal interview. If we assume that these 121t will also exacerbate the seam problem (see h&re and Kasprzyk, 1984, Burkhead and Coder, 1985, or Kalton, Lepkowski and Lin, 1985, for information on this problem in the SIPP).\n\ntrials are independent,13 then the reinterview process itself would be a series of Qi Bernoulli trials where Qi is the total number of questions put to the ith respondent. Furthermore, the a total number of inconsistencies, ni, in Qi trials would be binomially distributed and if Qi where sufficiently large, we could treat the distribution of ni, conditional on a set of exogenous variables, as N(Qip,Qip(l-p)) where p is the probability of a response inconsistency. In other words, if each respondent were asked a very large nunlber of questions (say 1000) then we could treat the number of inconsistencies observed as a continuous variable and apply ordinary least squares to determine the relationship of response vanalice to a set of exogenous factors (Xi).\n\nAs Figure 2 indicates, however, the probability of an inconsistency on any one question is so low that the distribution of the sum of inconsistencies is highly skewed-so highly skewed that Qi would have to be extremely large for the central limit theorem to apply. In such cases, the Poisson distribution is often a useful approximating distribution to the binomial (see, e.g. Lindgren, 1976j,14 and as we shall see below, has some particularly attractive features in the present application. According to the Poisson distribution, the probability of exactly n inco~lsistencies occurring is:\n\nwhere X is the mean number of inconsistencies observed (i.e. X = Qp). Both the meal and variance of the Poisson distribution are A. Figure 2 presents, in addition to the actud distribution of response errors in the SIPP reinterview data, the theoretical distribution obtained from the Poisson using the sample average number of response inconsistencies of -171\n\n1 3 ~o t e that this independence assumption represents the null hypothesis to be tested. 1t is not a maintained assumption of the model. Indeed, one of the most important findings of our analysis will be that the &dependence hypothesis can not be rejected when we restrict oaattention to response inconsistencies, but must be rejected when we add in procedural inconsistencies. Thus, the questionnaire sequencing acts as a strong correlating influence on the errors &on1 one question to the next.\n\n14we have a choice here in how we conceptualize the response process. We can consider the Poisson as merely an approximation to a binomial process which is useful for rare events, or we can consider the response process itself Poisson. Each question 'q' could, in theory, be presented to each respondent 'i9 a very large number of times and we could count the number of times the responses are inconsistent (n. ). If these inconsistencies occur randomly and 19 independently in time (sequence), then n. would be Poisson with a mean of A. 19\n\nFurthermore, the sum of these counts over a sequence of questions (q E < 1, .., Qi> ) will also be Poisson with mean Xi = CXiq. [27 Poisson Actual Actual and Theoretical Probabilities of Counts of Response Discrepancies 90 80 7 0 60 r, C a, so 0 C Q) e 4 0 30 2 0 1 0 0 N u m b e r o f I n c o n s ~s t e n c ~e s 2 per reinterview. While a x statistic for testing the goodness of fit of this model to the empirical distribution is easily constructed, it is not necessary in the present case-the theoretical distribution fits the data like a glove.\n\nThe mean and variance of the observed data are .171, which is yet further confirmation of the extremely good fit of the Poisson to the response inconsistency data. Since respondents were asked, on average 6.3 questions per reinterview, this would imply an average response discrepancy rate of 2.7% (=(.171/6.3)*100) and an average response varialce of .0135. Conceptually, the nearly perfect fit of the response inconsistency data to the Poisson suggests that if respondents were asked a reinterview question repeatedly (and their memories of their previous responses were wiped clean) inconsistent reports would appear infrequently, randomly and independently in time. Lndeed, the Palsson can be shown to be the maximum entropy or dsorder process. One might think that given the skip sequences used in the SIPP that errors 111 one variable would lead to errors m subsequent ones, and the illdependence aspect would not be accurate. This would be the case for procedural or overd inconsistencies, but is not for response incons~stencies-any subseque~le inconsistencies resulting from a response error are, by construction. procedural and are not counted in the response discrepancy rate. 15 WWe all t h s is interesting and reassuring. ~t may not be entirely obvious that the fie of the unconditional distribution is particularly relevant In developing a multivariate model. As it turns out however, if the mean number of mcorlslsteilcies (Xi) given by individual i over a number of independent trials is related to a set of mdividud characteristics Xi according to: 16 and if ni follo~vs a Poisson distribution, then Expressions 4.1) -4.3) form the basls of what 1s sometimes referred to as Poisson Regression (see Maddala , 1984). The likelihood of observing a sample of N cases 1 5 ~h i s does me, that the number of questions from w h c h the response discrepancy counts are derived vary from one respondent to the next. T h s complication is easily handled as shown in equation 4.2).\n\n161n the parlance of collective risk theory, where Poisson models are used extensively, the term Qi in equation 4.2), the number of questions asked of the ith individual, is h s 'exposure'. P(ni) can be obtained by substituting 4.2) into 4.1). That is: Substituting 4.5) into 4.4)) taking logs, and collecting terms yields the following log likelihood function:\n\nIt can be sho~vn that so long as the X's are not perfectly cohear (and so long as exp((XiO)) > 0 for some i) this log-likelihood function is globally concave in the ~' s . \" This means that efficient and consistent estimates of the proportionate effects of exogenous factors on inconsistency rates can be obtained quickly by any one of a number of maxinlization routines.\n\nIn the present analysis we employ the Davidson-Fletcher-Goldfarb-Shanno version of the David-Fletcher-Powell algorithm to m-ze 4.6) and obtain our estimates of 0.l\" Estimated standard errors are constructed from the diagonal elements of the inverse-Eessian matrix. 19   There are several attractive features of Poisson regression in analyzing response discrepancies. First, the effects of change independent variables are easily interpretable and \"See Hausman, Hall, and Griliches (1984).\n\nhe algorithm we employ is written in Pascal by the author using sub-routines described in Press, Flannery: Teukolsky and Vetterling (1986). The programs were compiled on a Zenith 20286 micro-computer using the TURBO-PASCAL 4.0 compiler and a. 20287 numeric coprocessor. The extended precision real number type provided by this compiler allows the computation of very precise numeric derivatives and thereby reduced pr~grcunming time considerably.\n\nI g ~h e estimated standard errors, therefore, are based on the assumption of simple random sampling. If we define the population of inference as the full SIPP sanlple, then we should have weighted the data by the inverse of the selection probabilities discussed in Section 2 a d computed complex sampling errors using some form of replication. Unfortunately the number of units assigned to interviewers and the nunbers of eligible persons in these units, necessary to the construction of the weights, were not available and we are forced to abandon h t e population inferences.\n\ncan be readily compared with the results of other analyses in the literature. To see t h s first note that:\n\nwhere GDR and SRV are, respectively, the gross-difference rate and simple respoilse 9 q t h variances for the q question. Second, note that taking logs of equation 4.2) yields: Therefore, a unit change in X.. will result in a proportionate20 change in the mean 31 discrepancy rate of P . and in the estimate simple-response variance of 13.12. The second The independent variables we employ in our analysis are of two types-those intended to capture (at least some of) the effects variability in interviewing process, aid those characteristics of respondents which might affect response variability. The first of the interviewing process variables is simply the calendar nlonth in wluch the original interview was taken. Since the data are taken from the second and third waves of the 1984 panel, the study was still quite new to the interviewers at the beginning of our observation period. We would expect more inconsistencies in these months. By the end of our observation period, on the other hand, most interviewers had been administering the study monthly for a fuU year, and we would expect their error rates to have settled down. Because we vrould expect declining marginal improvements with additional months of experience, we include the natural logarithm of the interview month rather than the month itself in our empirical specification.\n\n50~ecall that, for f(x) > 0, Oh(f(x))/& = (af(x)/&)/f(x) and thus the changein h(f(x)) resulting from a change in x is proportionate to the size of f(x).\n\nThe second interviewing process variable is a scale based on the overall performance of interviewers in the various Regional Offices. The underlying rationale for t h s scale is that an unknown' portion of the observed variation between these offices is due to differences in interviewers and in local procedures and the remainder is due to differences in the characteristics of the respondents. If all of the individual-to-individual variability is due to these Regional Office factors, then a scale constructed from the Regional Office rates should bear a one-to-one relationship with the individual discrepancy rates, a d should explain all of the variance in them. That is. if interviewers and regional office characteristics determine the individual's response variance then:\n\nwhere RORi is the Regional Office discrepancy rate for the ith individual's region, and o is a constant. Zf on the other hand, the reason Regional Offices differ is that the characteristics of their respondents differ then the one-to-one relationship between the Regional Office rate and the individual rates shouid disappear once the individual factors are controlled. That is, in: y should be sigmficantly less than unity and should not explain a sigrdicant portion of tile variance.\n\nThe third and forth interviewing process variables included are the relationship of the individual to the household reference person, and a dununy variable for whether a proxy informarit was used in the original interview. The relationship to reference person measure is also a dummy variable equaling 1 if the individual is some one other than the reference person or his/her spouse (e.g. cldd, parent, aunt, etc.).\n\nThe individual characteristics included in our empirical specification are the same ones thought to affect market productivity in the human-capital model of earnings. These consist of age (and its square), education, race, and gender. We also include income itself in some of our specifications.\n\nTable 3 presents both bivariate and multivariate estimates of the Poisson regression  The fact that the coefficient on the log or, the Regional Office inconsistency rate is so close to unity, and is higldy significant means that differences in something at the regional level are important. but the bivariate results can provide no clue as to what it might be.\n\nWhile the effect of the original iilcerview having been taken with a proxy respondent is to increase response inconsistency, the effect is not sufficiently strong to attain statistical sigdicance. The positive coefficient for the relationship to reference person dummy variable indicates that the response consistency for reference persons and their.spouses is hlgher (hy about 38.3 percent) ~h a n that obtained from otlier persons ill the household.\n\n.\n\nThe effects of age on respolise inconsistency rates is highly n o n -h e x . The coefiicients of -.485 and .47 on age and age square, respect~vely. suggest that response quality increases with age at a decreasing rate until age 51 where it attains its maximum.21 For respondents much older or younger than this, response quality IS s~gnrficantly lower. W-nile m the present case it is clear from the individual coefficient's standard errors that the age effects are signScant, in general, one would need to test the ch;mge in the goodness of fit when age and its square are dropped out of the analysis as a set. T h s can be accomplished by means of a likelihood-ratio test constructed from the log liketdlood values present in the second columu of 2 figures. In the present case the x associated w~th tile h!pothesis that age (and its square) are not associated with response quality is 8 ( = 3'(-771 1 -(-775.4))), and has 2 degrees of freedom. Thus, the null hypothesis of no age effect can he rejected soundly. The ha1 two variables with significait brvariate associations with response inconsistencies are education and income. Each one-year increase in educational attainment is associated with a 4.4 percent decrease i n the response inconsistency rate.\" The extremely sigmficznt coefficient of -.827 on income, sirmlarly, 1s ~nterpreted as indicating that a dollar increase in monthly personal income is associated w ~t h a .83 percent decrease in the response $consistency rate. Monthly perso~ial income 1s the most powerful predictor of response 2 2 1 ~o see this simply differentiate hiX = -. a s w a g e -.1iX(age) with respect to age and set the result equal to zero. Solving the result for the age yelds 51.06 = lo\"(-.485/(2*.47))-the a e at which h X attains its minimum.\n\n\"The interpretation of the coefficients from the Poisson regression is best seen by noting that, for education, h ( X ) = -.044*Ed. Differentiating t h s w.r.t. Ed yields dX/X = -.044-thus the coefficient for variables which enter the >; matrix lineatly is interpretable as the proportionate change in the mean inconsistency rate associated with a one unit increase in the independent variable. inconsistencies included in our analyses. Conceivably some of this effeet may be a reflection a tendency for fewer imputations being made for relatively complete interviewers and these interviewers tend to be interviews withpeople who have some income to report.\n\nThe bivariate results just discussed are analogous to simple correlations in linear models.\n\nThe multivariate results presented in the last. two columns of Table 3, in contrast, are analogous to multiple correlation coefficients. These coefficieilts are, therefore, interpretable as the uet effects of the various factors on response inconsiste~lcy one obtains when the effects of cther factors are controlled. Thus, it is not surprising that these multivariate effects are, in general: weaker than their bivariate counterparts. Indeed: with the single exception of the Regional Office lliconsistency index, all the coefficients in column 3-the specification which includes everything but income-are of the same sign as those in column\n\n1, but are smaller in absolute value. The estimated standard errors are also, in general, larger in the multivariate analyses-a second indication that the various predictors are correlated with each other. The decreased size of the estimated effects and their increased estimated variance combine to decrease the significance of almost all predictors b~ the multivariate analysis which excludes income. The only predictor to go from statistical significance to insigxdcance, however. is relationship to reference person. This indicates that most of the observed bivariate effect of not being the reference person (or his/her spouse) is, perhaps, due to the fact that most of these other indviduals are children and children are younger, less educated and less Uely to have income to report than their parents. Once the effects of these correlated factors are controlled, these individuals have response inconsistencies which are insipficantly Merent &om those of reference persons (and spouses of reference persons). The combined effeet of age and age-squared: by the way, remains sigdicant even though the individual coefficients are not. &%en income is added to the nlultivariate specification of the response inconsistency Poisson regression, every other individual characteristic becomes i n s i d c a n t . Taken literally, this result would suggest that all of the effects of age and education on response quality discussed up to this point are the result of the correlation of these factors with income. We find this result hard to believe. \\Vhy income, itself, should have a positive effect OR response quality is a mystery, 23\n\nBefore moving on to our analysis of total inconsistencies, two further aspects of the multivariate Poisson regression estimates of response inconsistencies should be noted. First, . ,.\n\n2 3 One possibility is that the focus of the SIPP is income and transfer program participation and neither the respondent nor the interviewer may be taking the interview as seriously when the individual has 'nothing to report.', than when individual income is substantial. Actual and Theoretical Probabilities of Counts of Total Discrepmcies Actual Negative binomial N u m b e r o f I n e o n s ~s t e n c ~e s where I?(.) is the Gamma function:\n\nThis rather intimidating function is in fact a negative-binomial a d can be simplified considerably by defining p z 6/(1+6), and q = l / ( l + J ) and by noting that:\n\nOxice we make these substitutions and perfonn the recursions we obtain for 4.7):\n\nThe mean aud variance of ni for the negative binomial are: respectively.\n\nFigure 3 includes the predicted probabilities for this negative binomial distribution with p set equal to the sample mean divided by the variance (ii/v(n)), and e.q((XiO) set to the square of the sample mean divided by the variance minus the mean ( ~i * / ( v ( n ) -f i ) . ~~ Clearly the negative binomial fits the unconditional distribution sigruficantly better than does the Poisson.\n\nIt is still not a perfect fit by any means. The chi-square obtained for the test that the unconditional distribution of total inconsistencies is a negative-binomial is 36.3 with six degrees of freedom. Part of the reason that the negative-binomial does not fit the data better is that it ignores the dependency of procedural errors in one question on procedural or response errors in preceding questions. This is a difficult problem and one which we will defer for future research.\n\n2 5 ~h i s is the method of moments technique for fitting the data to the distribution. One can easily verify these formulas using the expressions for the mean and variance of the negative binomial provided above.\n\nThe fit of the negative binomial, however, is sufficiently better than that of the Poisson that it seems preferable to use it as the basis of our multivariate model of total inconsistencies.\n\nThe log-likelihood function can be obtained by substituting equation 4.9) into z.4) and taking logs. This yields, for a sample of size N: Maximization of 4.10) with respect to the was acconlplished using the same DFGS algorithm employed in our earlier estimation of the Poisson regression model. The results of t h s estimation are presented in Table 4.\n\nThe results of the maximum Likelihood negative-binomial analvsis of total inconsistencies ('Table 4) look very much like those obtaned for response inconsistencies using Poisson regression (Table 3). The interpretation of these coefficients is the same as that of the Poisson regression coefficients-for those variables entering linearly (e.g. education), a one unit increase is associated with a proportionate change in the inconsistency rate of d (a 5.2% decrease for education in the bivariate model). The od!. red difference between the Poisson regression coefficients for response inconsistencies and those of the negative-binomial for total inconsistencies is that the latter are generally larger m absolute value and have lower estimated variances. The same substantive results hold.\n\nAs was the case for response inconsistencies. the total inconsistency rate decliries significantiy with time, and there remains a one-to-one relationship between regional office inconsiste~lcy rates and individual rates. Reference persons (and their spouses) have sigdicantly lower inconsistency rates than do more distantly related individuals in the sampling unit, but this is evidentlv due to their lugher lncome and education and to the fasr that they are more apt to be 'middle aged'. Inconsistency rates decline with age until attaining a minimum at age 44 and increase thereafter. Higher educated individuals have lower total inconsistency rates, although t h s effect disappears if one controls for income (i.e. ~t is not si&cant in the multivariate model).\n\nUnlike the Poisson results for response inconsistencies, race is a sigmficant correlate of total inconsistencies. Blacks have total inconsistency rates some twenty-eight percent higher than non-Blacks, and this effect does not appear to be merely a reflection of their lower average educations and incomes. Evidently intemiewers are 'hitting the check points' less consistently for Black respondents than they do for non-Black respondents.\n\nBivariate Parameter Log-likelihood -.872\"* Constant (.094) -1577.9 .726** 6 (.076) Interview -.198* Month (.097) -1576.8 Regional Office .985** Discrepancy Rate (.236) -1569.5 .I49 Proxy Respondent (.108) -1577.7 Odd Relationship .382** to Reference Person (.121): -1573.8 -.511** Age (decades) (.125) -1565.8 Age-squared .5745** (decades-squared) (.123) -.052** Education (.013) -1572.1 .011 Whthr Female (.094) -1578.8 .284* Whthr Black (.143) . -1576.9 -.698** Income ($100'~) (.135) -1567.2 In (likelihood) (d.f.) Multivariate without Income with income .807+ .592 (.434) (.455) .779** .797*X (.065) (.062) -.191* -.i80\" (.090) (.090) 1.043** 1.022** (.209) (.221) .262+ .I97 (.142) (.143) .lo9 .I21 (.loo) (.103) -.326** -.I89 (.140) (.143) .400** .2711 (-136) (.138j -.028* -.011 (.014) (.015) .019 -.149-(.085) (-091) .275* .258-(.135) (.134) -.588** (.162) -1546.4 -1541.7 (11) (12)\n\nTable 4 Maximum Likelihood Negative-Binomial Regression Estimates Total Inconsistencies (Asymptotic Standird Errors in Parentheses)\n\nThe bivariate results are obtained by estimating the model with the variable interest and the constant and shape parameter (6) only.\n\n+si@cant at the 10% level. *si@cant at the 5% level. **si@cant at the 1% level.\n\nFinally, as was the case of response inconsistencies, monthly ~ersonal income is the strongest predictor of total inconsistency rates, and when it is included in the multivariate model along with the other predictors, absorbs most of their effects.\n\nIn sum, given the strong similarity of the results of the Poisson regression model of response inconsistencies and the negative-binomial model of total inconsistencies, we are lead to suspect that response and procedural inconsistencies share a common causal structure.\n\nWhatever this structure is, it evidently involves characteristics of both the respondent and the interviewer (or at least of the Regiosal Office).\n\nBefore closing out our discussioil of the negative-binomial regression results it is useful to explore briefly the implications of the fact that response errors are well described as a Poisson process whereas procedural errors are not. What it means is that, abstracting from skip sequence effects, the occurrence of a response error in one question has no effect on the probability of a response error ia a subsequent question. One can easily imagine mechanisms which would result in this not being the case. If a respondent realizes that he made a mistake:\n\nfor instance, and 'got away with it' on one question, then he might be less careful with subsequent answers. But the close fit of the Poisson to the response error process indicates that there is no net effect of any such mechanisms.\n\nThat the inclusion of procedural errors destroys the fit of the Poisson model to the data suggests that the sequencing processes itself acts as a correlating influence on the inconsistency probabilities from one question to the next. This raises the possibility that more sequencing is being done in studies like the SIPP than. is optimal. This potential problem is analogous to the problem of optimal interviewer workloads when the interviewer acts as a correlating influence for response errors. The trade-off in that case is that training costs decrease with work load while response variance increases. h the present case, the overall interview length can be reduced by skipping entire classes of respondents around questions based on their responses to earlier questions. The resulting interviewing time savings come at a cost of increased response (broadly defined) variance and therefore decreased question reliability. As is the case with interviewer workloads, this cost is generally ux1known and is often ignored in the survey design process,26 with the result that sequencing may be over utilized just as work loads are often too high.\n\n-LoDecreased question reliability is not the only cost of extreme sequencing. Bias may also be introduced. Take, for instance, the employment sequence of Items 1-4 in Figure 1. Those answering yes to item 1. (that they had a job) were not asked if they spent time looking for a job. RIany people may have a job, at least for a few days, and may also have spent time looking or even collecting unemployment compensation. Thus total estimates of the number of people seeking jobs would be biased downward by the sequencing.\n\nIn this-paper we have analyzed data from the SIPP reinterview program to see if it can be of value in understanding nonsampling error issues. We concluded that it can, indeed, be very valuable in several ways. First, it allows us to appreciate the fact that not all inconsistencies in the data are due to respondents providing unreliable reports. A goodly portion of the discrepancies between interview and reinterview reports is due to inconsistencies in the interview procedures. The skip sequences used in the SIPF are complex and are not always successfdy followed by the interviewers. Second, the remtervicw data hzs proven valuable in identifying particular questions with unusually high response variances. This is important not just for analyst who may wish to correct for question reliability, but for future redesigns of the SIPP questiomxaire. Third, we have shown wit11 the reinterview data that data quality does vary systematically from one type of respondeilt to the next. Data quality appears to be sipdicantly lower for low income, Black, and either very young or very old respondents. Finally, while there are signdicant effects of t l h g s which can only be attributed to the interviewing procedure or the interviewer her or hinxelf, the quality of SIPP data apparently improved sipdicantly between February and August of 1984.\n\n\\ U d e the SIPP reinterview program is useful in furthering our understaxding of response e=ors, there are a nurnber of changes which would make the program even more useful. Some of these changes are relatively minor. These include:\n\n1) Keying the person number of both the original and reinterview respondents (items g and 0); and\n\n2) Transcribing to the reinterview form the information necessary for the construction of reinterview sampling weights (i.e. the number of units assigned to the interviewer during the wave in question and the number of reinterviews taken).\n\nOther improvements are more difficult and costly, but might have substcmtial pay-offs and should probably be considered. These include:\n\n3) Rotating content to cover the SIPP questionnaire more completely (The present analysis shows that as little as two waves of reinterviews at the present reintcrview sample size are sufficient to uncover the most serious problems in questions.\n\nTherefore, four times as much content could be usefully covered without increasing the size of the reinterview program.); and 4) Randomizing the assignment of reinterviewers.\n\nFinally, the results of the present analysis lead to one recommendation for the future redesign of the main SIPP instrument itself. This is that the rather baroque skip sequences currently being used be simplified-they are causing relatively minor response errors to be amplified into much more serious problems.\n\nMixed 1985. For those who reported in 1984 being unemployed, i n contrast, only forty-nine percent provided a consistent report one year later. Most of the others said in 1985 that they were employed in January of 1984-suggesting that they had forgotten ad about the u n e m p l o ~e n t they reported a year earlier. Most of the individuals providing consistent\n\nO o l 1 -.032 -.002 -.011 .\n\n+ Some evidence of effect. * Sigruficant at p = .05.\n\n**\n\nCoqnitive Factors\n\nThere is some evidence that cognitive ability in standard American English as measured by the sentence completion test administered in 1972 does reduce the propensity to provide inconsistent seam-transition amplifying reports. Since only twenty percent of the\n\nx\n\npresents the recorded responses for the interview and reinterview for Item 4.-the question regarding receipt of state unemployment compensation. Actual responses in both interviews were recorded for only some thirteen percent (=100*207/1559) of the cases. Of these 2.9% (=100*(3~3)/207) of the reports were different. The simple response variance for this question is, therefore, .0145. or half the gross difference rate amongst those respondents who answered the question in both the interview and reinterview. We will define the procedural discrepancy rate as the simple gross difference rate for whether the question was skipped. For the unemployment compensation question results in Table1\n\n, the procedural discrepancy rate is 6.54 percent ( = 100*(7+59+7+29)/1559). ' 1t would be interesting to see to what exteni'changes in respondent could account for these discrepancies. Unfortunately, respondent identifiers from the reinterview form were not keyed.\n\nwhere\n\nSeeHill and Hill (1986) for a comparison of proportional hazards models of re-employment transitions estimated on SIPP data with seam transitions and PSID data without. Race effects were found to be much strong in the latter study. Thus true racial differences in reemployment probabilities may be being obscured in the SIPP by the erroneous seam transition reports."
}