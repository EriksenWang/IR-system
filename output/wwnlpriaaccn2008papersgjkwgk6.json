{
    "title": "N/A",
    "publication_date": "2002-06",
    "authors": [
        {
            "full_name": "S Maybank",
            "firstname": "S",
            "lastname": "Maybank",
            "affiliations": [
                {
                    "organization": "Institute of Automation, Chinese Academy of Sciences",
                    "address": {
                        "city": "Recognition Beijing",
                        "postcode": "100080"
                    }
                },
                {
                    "organization": "School of Computer Science and Information Systems, Birkbeck College",
                    "address": {
                        "city": "London",
                        "postcode": "WC1E 7HX"
                    }
                }
            ]
        }
    ],
    "abstract": "N/A",
    "full_text": "Weiming Hu, Xue Zhou, Min Hu, and Steve Maybank, Senior Member, IEEE Abstract-Occlusion reasoning is one of the most challenging issues in visual surveillance. In this letter, we propose a new approach for reasoning about occlusions between multiple people. In our approach, occlusion relationships between people are explicitly defined and deduction of the occlusion relationships is integrated into the whole tracking framework. The prior knowledge is supplied by a set of models which include a 2-D elliptical shape model, a spatial-color mixture of Gaussians appearance model, and a motion model with constant velocity. An observation likelihood function is constructed based on the similarity between the observations and the object appearance models with given states. The occlusion relationships are deduced from the current states of the objects and the current observations, using the observation likelihood function. The previous occlusion relationships are not required for deducing the current occlusion relationships. The problem of tracking and occlusion reasoning for more than two people is formulated mathematically, and a solution is proposed based on particle filtering. Experimental results on several real video sequences from indoor and outdoor scenes show the effectiveness of our approach.\n\nIndex Terms-Occlusion reasoning, particle filtering, tracking multiple people, visual surveillance.\n\nOcclusion reasoning for object tracking is one of the most challenging problems in visual surveillance. This is because during occlusion, only portions of each occluded object are visible and the correspondences between objects and their features become ambiguous [22]. The aim of occlusion reasoning for tracking is to explicitly determine the occlusion relationships between objects and then accurately localize the objects. As people activities are of key interest in monitored scenes, we focus on reasoning about occlusions between multiple people.\n\nThere exist approaches for tracking multiple objects, in which the occlusion relationships are not explicitly defined and determined. For example, Bar-Shalon and Fortmann [23] use the joint probabilistic data association filter (JPDAF) to track multiple objects, by finding the exclusive correspondence between different objects. Rasmussen and Hager [11] propose a framework that describes data association to improve the performance of tracking multiple objects. The accurate localization of objects present to occlusions needs a very long running time. Khan et al. [16], [17] use a Markov random field to model motion interaction, and the motion model is naturally incorporated into a MCMC (Markov Chain Monte Carlo)-based particle filter for effective multiple object tracking. However, their model is used to describe the interactions between different objects rather than reason about occlusions.\n\nSome approaches track multiple people through occlusions using 3-D calibration information. For instance, Isard and MacCormick [21], and Zhao and Nevatia [18], [19] investigate tracking in calibrated images, where calibration information is utilized to reason about occlusions. Mittal and Davis [20] reason about occlusions using multiple calibrated cameras. As camera calibration is costly, we only consider un-calibrated occlusion reasoning in this letter.\n\nThe 2-D un-calibrated people tracking approaches base occlusion reasoning on people appearance models. Non-parametric people appearance models including appearance template-based [1], [7], [12], color histogram-based [2], [13]- [15], and kernel density-based [3], [4], and parametric appearance models [5], [6] are used to track multiple people through occlusions. For instance, Senior et al. [1], [12] use an appearance template to record the RGB color of each pixel of each person. Each appearance template is associated with a set of probability masks, each of which represents the probability of the corresponding pixel belonging to that template. Before the occurrence of an occlusion, the template is continuously updated on each new image as it arrives. During occlusions, foreground pixels are segmented into different regions corresponding to different templates according to the learned templates and the predicted people positions. People are then tracked according to the segmented regions. Wu et al. [7] apply the Bayesian network to track two faces through occlusions using multi-cameras, with the participation of the appearance templates. They put the occlusion relationships between objects into the object states, and thereby combine prior expectations of occlusion with the likelihood function. They assume that the occlusion relationships between objects are independent of the current states of the objects, and dependent on the previous occlusion relationships. Qu et al. [15] propose a distributed Bayesian formulation using multiple interactive trackers that require low complexity for real time tracking applications. They extend the conventional Bayesian tracking framework by modeling object interaction in terms of potential functions. They combine the color histogram model and the PCA-based mode to efficiently model object appearance.\n\nConsidering that most current methods [1]- [6] cast occlusion reasoning as a classical segmentation problem, i.e., classify foreground pixels into several sub-regions according to prior knowledge and then track people based on the segmented\n\nregions, in this letter we omit the process of segmenting the motion region into sub-regions corresponding to different people, and propose a new approach for occlusion reasoning between multiple people. In the approach occlusion relationships between people are explicitly defined and deduced, the models for the different people are matched against the image in the order consistent with the occlusion relationships, and then the localizations of the people are optimized. The main contributions of our approach are:\n\n• Tracking and occlusion reasoning for more than two people are formulated mathematically. The occlusion relationships between multiple people are incorporated into a tracking framework in which the main focus is on finding the positions of the people. • The occlusion relationships are deduced from the current states of the people and the current observations, with the participation of the observation likelihood function. This is in contrast with previous work such as [7] in which it is assumed that the occlusion relationships between objects are independent of the current states of the objects, and dependent only on the previous occlusion relationships. To implement these contributions, we apply the ellipse shape model, the spatial-color mixture of Gaussians appearance model [24], and the motion model with constant velocity. An observation likelihood function is constructed based on the appearance model used. A standard particle filter is adopted to optimize object states and occlusion relationships.\n\nIn our approach, pixels are classified as foreground/background for each frame using background subtraction, without segmenting the foreground pixels into objects. Motion regions are extracted from foreground pixels. The extracted motion regions in the current frame are compared with the motion regions in the previous frame according to their positions and appearances. If the current frame contains a motion region which does not correspond to any motion region in the previous frame, then a new object is detected as a tracked object and the appearance model for the object is initialized according to the new motion region. If a motion region gradually becomes smaller to the point where it can be ignored, then object disappearance occurs and the tracking of the object terminates. If two or more objects come into the scene with one occluding the other, then they are tracked as a single object. If it is detected that a motion region tracked as an object in the previous frame has divided into some smaller motion regions in the current frame, then the objects are tracked separately: pixels in these smaller motion regions are used to initialize the models of these objects. The appearance model for each person is updated in each of the frames in which the person is absent from any occlusion. If it is detected that a person is present to occlusion, the appearance model of the person is kept constant. The motion model is used to predict the states of the people at time according to the tracking results at time . The occlusion relationships between the people are deduced according to the predicted states, the observations, and their shape and appearance models. The human shape model and the appearance model with predicted states and deduced occlusion relationships are projected to the image plane, and the observation likelihood is used to further update the states of the objects and their occlusion relationships for maximizing the posterior probability of the states and the occlusion relationships given the observations. We consider occlusions between objects. We denote the state of object at time by . The observation image (contained in the foreground pixels) at time is denoted by , with history . The occlusion relationship between objects and at time is represented as if occludes if no occlusion if occludes .\n\n(1) So, the object state vector is which is simplified with , and the occlusion relationship vector is which is simplified with . The state is predicted using probability and the occlusion relationships are deduced according to the predicted states , with the participation of the shape and appearance models of the people. Then, the observation likelihood is used to further update the state vector and the occlusion relationship vector for maximizing the posterior probability . To estimate and , we should construct proper human body models and a proper observation function.\n\nHuman body models include the shape model, the appearance model and the motion model.\n\nThere are many different shape models for the human body. The more parameters there are in a shape model, the more accurate the tracking results, but the more expensive the computation. The aim in this letter is to reason about the occlusions between multiple people. We do not consider tracking the articulated motions of a human body and do not estimate the pose of each part of a human body. Therefore, we select a simple elliptical model involving only a few parameters, to simplify the computation. As shown in Fig. 1, a human body is modeled as a 2-D vertical ellipse with a parameter vector , where is the center of the ellipse, is the length of the major axis of the ellipse, and is the eccentricity of the ellipse. For the tracking, the state of the ellipse is taken to be which is an example of a state introduced in Section II.\n\nIn this letter, we use the spatial-color mixture of Gaussians appearance model in [24] to model the spatial layout of the colors in a person in an image. Let and be the mean and the covariance of the color feature in the th mode of the mixture of Gaussians, and and be the mean and the covariance of the spatial feature. Let be the probability density function value of the color of a pixel conditional on the Gaussian , and be the probability density function value of the position of the pixel conditional on the Gaussian . Then, the probability density function value of the pixel under the spatial-color mixture of Gaussians appearance model is:\n\nwhere is the number of Gaussians and is the normalized weight of the th mode of the mixture of Gaussians. The K-means clustering algorithm is used to initialize the parameters of the mixture of Gaussians and the Expectation-Maximization (EM) algorithm is used to refine these parameters. Please see [24] for detail.\n\nThe spatial-color mixture of Gaussians appearance model improves the popular color histogram-based appearance model because it considers not only the colors in a region but also the spatial layout of the colors.\n\nApplication of motion models, in the form of prior knowledge, to object tracking can reduce the search space and make the tracking results more accurate. As the changes in motion velocity and object sizes between successive frames are very small, for simplicity we assume a constant velocity and a constant height and eccentricity of the ellipse shape model. The motion model is described by the function below (3) where and are the and coordinates of the position of a person, and and are the height and eccentricity of the ellipse corresponding to the person in the image at time .\n\nThe observation likelihood function represents the probability of an observed image (contained in the foreground pixels), given states of objects and their occlusion relationships . The observation likelihood depends on the similarity [8] between the observations and the appearance reflected by the appearance models of objects, the shape models with given states, and the occlusion relationships. The similarity is measured according to the comparison between the appearance model of each person and the observation specified by the shape model of the person with given states and occlusion relationships.\n\nWe first determine the corresponding observation of an object under its given states and occlusion relationships. The given occlusion relationships , involving object specify all objects occluding object . Let be the region of foreground pixels within the ellipse of object with the given state at time . If object is not occluded, its corresponding observation is ; and if object is occluded by objects which are indexed by , its corresponding observation is (4) Based on the determined corresponding observation of object , we estimate the likelihood of the pixels in given the spatial-color mixture of Gaussians appearance model of object , Let represent a pixel in , let be the number of pixels in , and let be the probability density function value of pixel given . The likelihood of the pixels in given the model is defined as (5) The larger the , the more the compatibility between the pixels in and the model . The log function and the exp function in (5) are used to transform the product of probability density function values to sum of the logarithmic values of the probability density function to avoid the underflow produced by the product of probability density function values.\n\nAs the motions of objects are independent, the similarity between the appearance models of all people and the observations is measured by the sum of the similarities between the appearance model of each person and the corresponding observation of the person. Then, the observation likelihood function is defined as (6) where is the number of people in the scene at time .\n\nWe found that, given the states of the objects, their occlusion relationships are fixed. So the occlusion relationships between objects are dependent on the current states of the objects, and independent of their previous occlusion relationships. The transition of occlusion relationships [7] from the previous step to the current step is not needed. It follows that we use the likelihood function whose definition involves the current observations and the shape and appearance models of the people, to estimate the occlusion relationships. The optimal occlusion relationships maximize the likelihood function given the states of the people (7) i.e., the optimal type of occlusion relationships is selected from the combinations of occlusion relationships between the people, to maximize the value of the likelihood function given the states of the people.\n\nIn implementing the deduction of occlusion relationships between people, it is checked whether the ellipses specified by the states of the people intersect or overlap. Only for the people whose ellipses intersect or overlap, the observation likelihood function is used to determine \"who occludes whom\". So when there are a large number of people in the scene, but most of them are absent from occlusions, only the combinations of occlusion relationships between the people present to occlusions are mainly considered. Then, the computational complexity is decreased.\n\nThe process of tracking with occlusion reasoning is to maximize the posterior probability according to the motion model and the observation likelihood . Particle filtering is a simple and effective method for computing posterior probabilities from non-Gaussian, non-linear, and high-dimensional observation data. In this letter, a standard particle filtering approach [7], [9]\n\nThen the occlusion relationships at time are deduced according to the estimated object states. In our approach, the particles are defined in the joint state space of all objects. If a new object enters the scene, then the state components of the object are added to the joint state space and the particles are updated. The particle components of the object in all the particles are sampled initially according to the prior probability distribution which is assumed to be the uniform distribution. For example, if an object indexed by enters the scene, particle components of object are sampled and then added to the previous particles -the particles become . If an object leaves the scene, the state components of the object are removed from the joint state space (the dimension of the state space is reduced), and the particle components of the object are removed from all the particles. For example, if object leaves the scene, particles are changed to be . To adapt different parameters and increase the robustness and the effectiveness of the inference component, a hierarchical strategy is used to estimate the states of objects. Firstly, the size of the ellipse of each person is set equal to be the size of the ellipse of the person in the previous frame. The particle filtering process is used to estimate the optimal positions of the objects. Then, the positions are fixed and the particle filtering process is used again to estimate the optimal sizes of the objects.\n\nThe above algorithm is implemented using MatLab on the Windows XP platform. Computation time is measured on a P4-2.8G computer with 512M RAM. A simple background subtraction algorithm [10] is applied to extract the foreground pixels. The success of tracking and occlusion reasoning is checked by our own judgment. The results of occlusion reasoning are illustrated using the recovered occlusion relationship diagram whose -coordinate is the frame number, and -coordinate is the occlusion relationship. In the following, we demonstrate four examples of tracking with occlusion reasoning, and then illustrate some comparison results.\n\nThe test video for this example is captured in an outdoor environment. Its resolution is 320 240. Fig. 2 contains some key frames illustrating the tracking of two people through occlusion. The recovered occlusion relationship is shown in Fig. 3. Before Frame 741, there was no occlusion between the two people, and thus the occlusion relationship equals to 0. From Frame 741 to Frame 760, the front person (Person A) occluded the back person (Person B), and thus the occlusion relationship equals to . The two people separated after Frame 760, so the occlusion relationship then equals to 0.\n\nThe test video for this example is captured in an outdoor environment. Its resolution is 320 240.   changes in people's appearances, then our approach can handle long-term multiple occlusions.\n\nThis is an example in which a person appeared within the image. The test video for this example is in the PETS 2004 database which is an open database for the research on visual surveillance. The video is available on http://home-pages.inf.ed.ac.uk/rbf/CAVIAR/ShopAssistant2Cor.avi. Its resolution is 384 288. It shows a shopping center. Fig. 6 shows some frames of the results of tracking people in the video. Before Frame 201, three people are tracked. Two of them occluded each other in the midsection of the scene and one of them moved at the right-bottom corner of the scene. From Frame 201, a person entered the scene by emerging from a door placed away from the edge of the image. Tracking of the person is successfully initialized. From Frame 314, the person who moved at the right-bottom corner of the scene left the scene. For the video, all the four people are accurately tracked and their occlusion relationships are correctly determined.\n\nThis video is taken from the same scene as Example 3. It is available on http://homepages.inf.ed.ac.uk/rbf/CAVIAR/. In the video, there are many people walking or standing and talking. Fig. 7 illustrates some frames of tracking results when large mutual occlusions between five people occur from Frame 200  to Frame 400. During these occlusions, these people are still tracked successfully and their occlusions are deduced correctly using our approach.\n\nWe contrast the tracking results of our approach with the ground truth which is labeled by the suppliers of the PETS 2004 database: the pixel position of the center of the ellipse of each person is contrasted with the center of the manually labeled image bounding box of the person. In the following, the contrast results for three people occluded extensively are shown. Fig. 8 shows the trajectory of Person A who is the first person counting from left to right in Frame 200, where the dashed line is the ground truth trajectory, and the solid line is the trajectory obtained by our approach. From Frame 200 to Frame 400, for Person A the average warp between the trajectory obtained by our approach and the ground truth is 9.2 pixels. This warp is comparatively large. The reason is that the lower part of this person is occluded in most of the time that the person appeared in the scene, and therefore the height parameter of the ellipse of the person cannot be updated adaptively. Fig. 9 shows the trajectory of Person D who is the fourth person counting from left to right in Frame 200. From Frame 200 to Frame 400, for person D the average warp between the trajectory obtained by our approach and the ground truth is 5.0 pixels. Fig. 10 shows the trajectory of Person E who is the fifth person counting from left to right in Frame 200. From Frame 200 to Frame 400, for Person E the average warp between the trajectory obtained by our approach and the ground truth is 4.9 pixels.\n\nTo evaluate the performance of our approach, we compare our approach with the one in [1], [12]. The appearance template-based occlusion reasoning approach in [1], [12] is a typical segmentation-based one, which has high reliability in segmenting foreground pixels, but needs a large area of memory to store the template.\n\nExample 1 is used to compare the performance of our approach with the performance of the segmentation-based approach. Fig. 11 illustrates the tracking results obtained by the approach in [1], [12], corresponding to Example 1. From Frame 751 to Frame 754, the occluded person is not correctly tracked. From Frame 755 to Frame 757 the occluded person is lost in tracking.\n\nFig. 12 compares the ellipse centers for our approach with those for the segmentation-based approach. The horizontal and vertical coordinates in the image are respectively the -coordinate and -coordinate of the center of each ellipse. The trajectory curves of the un-occluded person (Person A) are shown in (a) and the trajectory curves of the occluded person (Person B) are shown in (b). From Fig. 12, we can see that the curve produced by the segmentation-based approach is farther from the ground truth than the one produced by our approach. This is more noticeable for the occluded person as shown in (b).\n\nTable I shows the quantitative comparison between our approach and the segmentation-based approach for Example 1 with respect to the following quantitative criteria: TABLE I QUANTITATIVE COMPARISON FOR EXAMPLE 1\n\n• the number of frames in which tracking was successful, corresponding to the tracking success rate; • the average position error-the average pixel distance between the estimated ellipse center and the center of the corresponding ground truth bounding box. • the average size error-the average warp between the estimated ellipse size and the size of the corresponding ground truth bounding box. • runtime per frame. From this table, it can be seen that position errors and size errors of tracking the two people using our approach are less than those using the segmentation-based approach. However, the runtime of our approach is more than that of the segmentation-based approach. This is due to the time taken to estimate the parameters of the spatial-color mixture of Gaussians appearance model.\n\nIn this letter, we have presented a new approach for occlusion reasoning for tracking multiple people. In our approach, occlusion reasoning is integrated into the whole process of tracking, in order to obtain better tracking accuracy during occlusions. Prior knowledge is represented by a set of models: a 2-D elliptical shape model, a spatial-color mixture of Gaussians appearance model, and a motion model with constant velocity. We have constructed an observation likelihood based on the similarity between the appearance models of the people and the observations. The occlusion relationships are deduced from the current states of the objects and the current observations. The previous occlusion relationships are not required for deducing\n\nthe current occlusion relationships. Tracking and occlusion reasoning for more than two people are formulated in the particle filtering framework, and a solution is proposed. Experimental results on several real video sequences from indoor and outdoor scenes have demonstrated the effectiveness of our approach.\n\nIEEE TRANSACTIONS ON CIRCUITS AND SYSTEMS FOR VIDEO TECHNOLOGY, VOL. 19, NO. 1, JANUARY 2009 1 Occlusion Reasoning for Tracking Multiple People Weiming Hu, Xue Zhou, Min Hu, and Steve Maybank, Senior Member, IEEE\n\nAbstract-Occlusion reasoning is one of the most challenging issues in visual surveillance. In this letter, we propose a new approach for reasoning about occlusions between multiple people. In our approach, occlusion relationships between people are explicitly defined and deduction of the occlusion relationships is integrated into the whole tracking framework. The prior knowledge is supplied by a set of models which include a 2-D elliptical shape model, a spatial-color mixture of Gaussians appearance model, and a motion model with constant velocity. An observation likelihood function is constructed based on the similarity between the observations and the object appearance models with given states. The occlusion relationships are deduced from the current states of the objects and the current observations, using the observation likelihood function.\n\nIndex Terms-Occlusion reasoning, particle filtering, tracking multiple people, visual surveillance.\n\nOcclusion reasoning for object tracking is one of the most challenging problems in visual surveillance. This is because during occlusion, only portions of each occluded object are visible and the correspondences between objects and their features become ambiguous [22]. The aim of occlusion reasoning for tracking is to explicitly determine the occlusion relationships between objects and then accurately localize the objects. As people activities are of key interest in monitored scenes, we focus on reasoning about occlusions between multiple people.\n\nThere exist approaches for tracking multiple objects, in which the occlusion relationships are not explicitly defined and determined. For example, Bar-Shalon and Fortmann [23] use the joint probabilistic data association filter (JPDAF) to track multiple objects, by finding the exclusive correspondence between different objects. Rasmussen and Hager [11] propose a framework that describes data association to improve the performance of tracking multiple objects. The accurate localization of objects\n\nManuscript received May 14, 2007; revised November 08, 2007. This work was supported in part by the National Science Foundation of China under Grant 60520120099 and Grant 60672040. W. Hu, X. Zhou and M. Hu are with the National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences, P. O. Box 2728, Beijing, 100080 (Tel.: 86-10-6255 6911, Fax: 86-10-6255 1993, e-mail: {wmhu, xzhou, mhu}@nlpr.ia.ac.cn). S. Maybank is with the School of Computer Science and Information Systems, Birkbeck College, Malet Street, London WC1E 7HX (e-mail: sjmaybank@dcs.bbk.ac.uk). Color versions of one or more of the figures in this paper are available online at http://ieeexplore.ieee.org. Digital Object Identifier 10.1109/TCSVT.2008.2009249\n\npresent to occlusions needs a very long running time. Khan et al. [16], [17] use a Markov random field to model motion interaction, and the motion model is naturally incorporated into a MCMC (Markov Chain Monte Carlo)-based particle filter for effective multiple object tracking. However, their model is used to describe the interactions between different objects rather than reason about occlusions. Some approaches track multiple people through occlusions using 3-D calibration information. For instance, Isard and MacCormick [21], and Zhao and Nevatia [18], [19] investigate tracking in calibrated images, where calibration information is utilized to reason about occlusions. Mittal and Davis [20] reason about occlusions using multiple calibrated cameras. As camera calibration is costly, we only consider un-calibrated occlusion reasoning in this letter.\n\nThe 2-D un-calibrated people tracking approaches base occlusion reasoning on people appearance models. Non-parametric people appearance models including appearance template-based [1], [7], [12], color histogram-based [2], [13]- [15], and kernel density-based [3], [4], and parametric appearance models [5], [6] are used to track multiple people through occlusions. For instance, Senior et al. [1], [12] use an appearance template to record the RGB color of each pixel of each person. Each appearance template is associated with a set of probability masks, each of which represents the probability of the corresponding pixel belonging to that template. Before the occurrence of an occlusion, the template is continuously updated on each new image as it arrives. During occlusions, foreground pixels are segmented into different regions corresponding to different templates according to the learned templates and the predicted people positions. People are then tracked according to the segmented regions. Wu et al. [7] apply the Bayesian network to track two faces through occlusions using multi-cameras, with the participation of the appearance templates. They put the occlusion relationships between objects into the object states, and thereby combine prior expectations of occlusion with the likelihood function. They assume that the occlusion relationships between objects are independent of the current states of the objects, and dependent on the previous occlusion relationships. Qu et al. [15] propose a distributed Bayesian formulation using multiple interactive trackers that require low complexity for real time tracking applications. They extend the conventional Bayesian tracking framework by modeling object interaction in terms of potential functions. They combine the color histogram model and the PCA-based mode to efficiently model object appearance.\n\nConsidering that most current methods [1]- [6] cast occlusion reasoning as a classical segmentation problem, i.e., classify foreground pixels into several sub-regions according to prior knowledge and then track people based on the segmented 1051-8215/$25.00 © 2009 IEEE\n\nregions, in this letter we omit the process of segmenting the motion region into sub-regions corresponding to different people, and propose a new approach for occlusion reasoning between multiple people. In the approach occlusion relationships between people are explicitly defined and deduced, the models for the different people are matched against the image in the order consistent with the occlusion relationships, and then the localizations of the people are optimized. The main contributions of our approach are:\n\n• Tracking and occlusion reasoning for more than two people are formulated mathematically. The occlusion relationships between multiple people are incorporated into a tracking framework in which the main focus is on finding the positions of the people. • The occlusion relationships are deduced from the current states of the people and the current observations, with the participation of the observation likelihood function. This is in contrast with previous work such as [7] in which it is assumed that the occlusion relationships between objects are independent of the current states of the objects, and dependent only on the previous occlusion relationships. To implement these contributions, we apply the ellipse shape model, the spatial-color mixture of Gaussians appearance model [24], and the motion model with constant velocity. An observation likelihood function is constructed based on the appearance model used. A standard particle filter is adopted to optimize object states and occlusion relationships.\n\nIn our approach, pixels are classified as foreground/background for each frame using background subtraction, without segmenting the foreground pixels into objects. Motion regions are extracted from foreground pixels. The extracted motion regions in the current frame are compared with the motion regions in the previous frame according to their positions and appearances. If the current frame contains a motion region which does not correspond to any motion region in the previous frame, then a new object is detected as a tracked object and the appearance model for the object is initialized according to the new motion region. If a motion region gradually becomes smaller to the point where it can be ignored, then object disappearance occurs and the tracking of the object terminates. If two or more objects come into the scene with one occluding the other, then they are tracked as a single object. If it is detected that a motion region tracked as an object in the previous frame has divided into some smaller motion regions in the current frame, then the objects are tracked separately: pixels in these smaller motion regions are used to initialize the models of these objects. The appearance model for each person is updated in each of the frames in which the person is absent from any occlusion. If it is detected that a person is present to occlusion, the appearance model of the person is kept constant. The motion model is used to predict the states of the people at time according to the tracking results at time . The occlusion relationships between the people are deduced according to the predicted states, the observations, and their shape and appearance models. The human shape model and the appearance model with predicted states and deduced occlusion relationships are projected to the image plane, and the observation likelihood is used to further update the states of the objects and their occlusion relationships for maximizing the posterior probability of the states and the occlusion relationships given the observations. We consider occlusions between objects. We denote the state of object at time by . The observation image (contained in the foreground pixels) at time is denoted by , with history . The occlusion relationship between objects and at time is represented as if occludes if no occlusion if occludes .\n\n(1) So, the object state vector is which is simplified with , and the occlusion relationship vector is which is simplified with . The state is predicted using probability and the occlusion relationships are deduced according to the predicted states , with the participation of the shape and appearance models of the people. Then, the observation likelihood is used to further update the state vector and the occlusion relationship vector for maximizing the posterior probability . To estimate and , we should construct proper human body models and a proper observation function.\n\nHuman body models include the shape model, the appearance model and the motion model.\n\nThere are many different shape models for the human body. The more parameters there are in a shape model, the more accurate the tracking results, but the more expensive the computation. The aim in this letter is to reason about the occlusions between multiple people. We do not consider tracking the articulated motions of a human body and do not estimate the pose of each part of a human body. Therefore, we select a simple elliptical model involving only a few parameters, to simplify the computation. As shown in Fig. 1, a human body is modeled as a 2-D vertical ellipse with a parameter vector , where is the center of the ellipse, is the length of the major axis of the ellipse, and is the eccentricity of the ellipse. For the tracking, the state of the ellipse is taken to be which is an example of a state introduced in Section II.\n\nIn this letter, we use the spatial-color mixture of Gaussians appearance model in [24] to model the spatial layout of the colors in a person in an image. Let and be the mean and the covariance of the color feature in the th mode of the mixture of Gaussians, and and be the mean and the covariance of the spatial feature. Let be the probability density function value of the color of a pixel conditional on the Gaussian , and be the probability density function value of the position of the pixel conditional on the Gaussian . Then, the probability density function value of the pixel under the spatial-color mixture of Gaussians appearance model is:\n\n(\n\nwhere is the number of Gaussians and is the normalized weight of the th mode of the mixture of Gaussians. The K-means clustering algorithm is used to initialize the parameters of the mixture of Gaussians and the Expectation-Maximization (EM) algorithm is used to refine these parameters. Please see [24] for detail.\n\nThe spatial-color mixture of Gaussians appearance model improves the popular color histogram-based appearance model because it considers not only the colors in a region but also the spatial layout of the colors.\n\nApplication of motion models, in the form of prior knowledge, to object tracking can reduce the search space and make the tracking results more accurate. As the changes in motion velocity and object sizes between successive frames are very small, for simplicity we assume a constant velocity and a constant height and eccentricity of the ellipse shape model. The motion model is described by the function below (3) where and are the and coordinates of the position of a person, and and are the height and eccentricity of the ellipse corresponding to the person in the image at time .\n\nThe observation likelihood function represents the probability of an observed image (contained in the foreground pixels), given states of objects and their occlusion relationships . The observation likelihood depends on the similarity [8] between the observations and the appearance reflected by the appearance models of objects, the shape models with given states, and the occlusion relationships. The similarity is measured according to the comparison between the appearance model of each person and the observation specified by the shape model of the person with given states and occlusion relationships.\n\nWe first determine the corresponding observation of an object under its given states and occlusion relationships. The given occlusion relationships , involving object specify all objects occluding object . Let be the region of foreground pixels within the ellipse of object with the given state at time . If object is not occluded, its corresponding observation is ; and if object is occluded by objects which are indexed by , its corresponding observation is (4) Based on the determined corresponding observation of object , we estimate the likelihood of the pixels in given the spatial-color mixture of Gaussians appearance model of object , Let represent a pixel in , let be the number of pixels in , and let be the probability density function value of pixel given . The likelihood of the pixels in given the model is defined as\n\nThe larger the , the more the compatibility between the pixels in and the model . The log function and the exp function in (5) are used to transform the product of probability density function values to sum of the logarithmic values of the probability density function to avoid the underflow produced by the product of probability density function values.\n\nAs the motions of objects are independent, the similarity between the appearance models of all people and the observations is measured by the sum of the similarities between the appearance model of each person and the corresponding observation of the person. Then, the observation likelihood function is defined as (6) where is the number of people in the scene at time .\n\nV. OCCLUSION RELATIONSHIP DEDUCTION We found that, given the states of the objects, their occlusion relationships are fixed. So the occlusion relationships between objects are dependent on the current states of the objects, and independent of their previous occlusion relationships. The transition of occlusion relationships [7] from the previous step to the current step is not needed. It follows that we use the likelihood function whose definition involves the current observations and the shape and appearance models of the people, to estimate the occlusion relationships. The optimal occlusion relationships maximize the likelihood function given the states of the people (7) i.e., the optimal type of occlusion relationships is selected from the combinations of occlusion relationships between the people, to maximize the value of the likelihood function given the states of the people.\n\nIn implementing the deduction of occlusion relationships between people, it is checked whether the ellipses specified by the states of the people intersect or overlap. Only for the people whose ellipses intersect or overlap, the observation likelihood function is used to determine \"who occludes whom\". So when there are a large number of people in the scene, but most of them are absent from occlusions, only the combinations of occlusion relationships between the people present to occlusions are mainly considered. Then, the computational complexity is decreased.\n\nThe process of tracking with occlusion reasoning is to maximize the posterior probability according to the motion model and the observation likelihood . Particle filtering is a simple and effective method for computing posterior probabilities from non-Gaussian, non-linear, high-dimensional observation data. In this letter, a standard particle filtering approach [7], [9] is applied to find the maximum of the posterior probability density function. The posterior density is represented by particles where corresponds to the state of object , deduced occlusion relationships , and the weights of the particles. The propagation of the filter is outlined as follows. 1) Initialization: . Particles are sampled according to the prior probability distribution which is assumed to be the uniform distribution. The ranges for , , , and in each object are , , , and , respectively. The occlusion relationships specified by the states are deduced. The weights are computed by the observation likelihood: . 2) a) Re-sampling: In order to avoid degeneration of particles, particles at time are re-sampled to produce a new particle set according to . In this process, particles with large weights are sampled several times, and particles with small weights are ignored. The total number of particles is kept constant. b) Prediction: Particles at time are generated according to the prediction model which is described by (3). c) Deduction: The corresponding occlusion relationships , given the states , are deduced according to , as described in Section V. d) Measurement: Each particle is re-weighted by the observation likelihood\n\nThen, the weights are normalized (9) e) Estimation: The states of objects at time are estimated as the summation of the weighted particles: (10) Then the occlusion relationships at time are deduced according to the estimated object states. In our approach, the particles are defined in the joint state space of all objects. If a new object enters the scene, then the state components of the object are added to the joint state space and the particles are updated. The particle components of the object in all the particles are sampled initially according to the prior probability distribution which is assumed to be the uniform distribution. For example, if an object indexed by enters the scene, particle components of object are sampled and then added to the previous particles -the particles become . If an object leaves the scene, the state components of the object are removed from the joint state space (the dimension of the state space is reduced), and the particle components of the object are removed from all the particles. For example, if object leaves the scene, particles are changed to be . To adapt different parameters and increase the robustness and the effectiveness of the inference component, a hierarchical strategy is used to estimate the states of objects. Firstly, the size of the ellipse of each person is set equal to be the size of the ellipse of the person in the previous frame. The particle filtering process is used to estimate the optimal positions of the objects. Then, the positions are fixed and the particle filtering process is used again to estimate the optimal sizes of the objects.\n\nThe above algorithm is implemented using MatLab on the Windows XP platform. Computation time is measured on a P4-2.8G computer with 512M RAM. A simple background subtraction algorithm [10] is applied to extract the foreground pixels. The success of tracking and occlusion reasoning is checked by our own judgment. The results of occlusion reasoning are illustrated using the recovered occlusion relationship diagram whose -coordinate is the frame number, and -coordinate is the occlusion relationship. In the following, we demonstrate four examples of tracking with occlusion reasoning, and then illustrate some comparison results.\n\nThe test video for this example is captured in an outdoor environment. Its resolution is 320 240. Fig. 2 contains some key frames illustrating the tracking of two people through occlusion. The recovered occlusion relationship is shown in Fig. 3. Before Frame 741, there was no occlusion between the two people, and thus the occlusion relationship equals to 0. From Frame 741 to Frame 760, the front person (Person A) occluded the back person (Person B), and thus the occlusion relationship equals to . The two people separated after Frame 760, so the occlusion relationship then equals to 0.\n\nThe test video for this example is captured in an outdoor environment. Its resolution is 320 240.   changes in people's appearances, then our approach can handle long-term multiple occlusions.\n\nThis is an example in which a person appeared within the image. The test video for this example is in the PETS 2004 database which is an open database for the research on visual surveillance. The video is available on http://home-pages.inf.ed.ac.uk/rbf/CAVIAR/ShopAssistant2Cor.avi. Its resolution is 384 288. It shows a shopping center. Fig. 6 shows some frames of the results of tracking people in the video. Before Frame 201, three people are tracked. Two of them occluded each other in the midsection of the scene and one of them moved at the right-bottom corner of the scene. From Frame 201, a person entered the scene by emerging from a door placed away from the edge of the image. Tracking of the person is successfully initialized. From Frame 314, the person who moved at the right-bottom corner of the scene left the scene. For the video, all the four people are accurately tracked and their occlusion relationships are correctly determined.\n\nThis video is taken from the same scene as Example 3. It is available on http://homepages.inf.ed.ac.uk/rbf/CAVIAR/. In the video, there are many people walking or standing and talking. Fig. 7 illustrates some frames of tracking results when large mutual occlusions between five people occur from Frame 200  to Frame 400. During these occlusions, these people are still tracked successfully and their occlusions are deduced correctly using our approach.\n\nWe contrast the tracking results of our approach with the ground truth which is labeled by the suppliers of the PETS 2004 database: the pixel position of the center of the ellipse of each person is contrasted with the center of the manually labeled image bounding box of the person. In the following, the contrast results for three people occluded extensively are shown. Fig. 8 shows the trajectory of Person A who is the first person counting from left to right in Frame 200, where the dashed line is the ground truth trajectory, and the solid line is the trajectory obtained by our approach. From Frame 200 to Frame 400, for Person A the average warp between the trajectory obtained by our approach and the ground truth is 9.2 pixels. This warp is comparatively large. The reason is that the lower part of this person is occluded in most of the time that the person appeared in the scene, and therefore the height parameter of the ellipse of the person cannot be updated adaptively. Fig. 9 shows the trajectory of Person D who is the fourth person counting from left to right in Frame 200. From Frame 200 to Frame 400, for person D the average warp between the trajectory obtained by our approach and the ground truth is 5.0 pixels. Fig. 10 shows the trajectory of Person E who is the fifth person counting from left to right in Frame 200. From Frame 200 to Frame 400, for Person E the average warp between the trajectory obtained by our approach and the ground truth is 4.9 pixels.\n\nTo evaluate the performance of our approach, we compare our approach with the one in [1], [12]. The appearance template-based occlusion reasoning approach in [1], [12] is a typical segmentation-based one, which has high reliability in segmenting foreground pixels, but needs a large area of memory to store the template.\n\nExample 1 is used to compare the performance of our approach with the performance of the segmentation-based approach. Fig. 11 illustrates the tracking results obtained by the approach in [1], [12], corresponding to Example 1. From Frame 751 to Frame 754, the occluded person is not correctly tracked. From Frame 755 to Frame 757 the occluded person is lost in tracking.\n\nFig. 12 compares the ellipse centers for our approach with those for the segmentation-based approach. The horizontal and vertical coordinates in the image are respectively the -coordinate and -coordinate of the center of each ellipse. The trajectory curves of the un-occluded person (Person A) are shown in (a) and the trajectory curves of the occluded person (Person B) are shown in (b). From Fig. 12, we can see that the curve produced by the segmentation-based approach is farther from the ground truth than the one produced by our approach. This is more noticeable for the occluded person as shown in (b).\n\nTable I shows the quantitative comparison between our approach and the segmentation-based approach for Example 1 with respect to the following quantitative criteria: TABLE I QUANTITATIVE COMPARISON FOR EXAMPLE 1\n\n• the number of frames in which tracking was successful, corresponding to the tracking success rate; • the average position error-the average pixel distance between the estimated ellipse center and the center of the corresponding ground truth bounding box. • the average size error-the average warp between the estimated ellipse size and the size of the corresponding ground truth bounding box. • runtime per frame. From this table, it can be seen that position errors and size errors of tracking the two people using our approach are less than those using the segmentation-based approach. However, the runtime of our approach is more than that of the segmentation-based approach. This is due to the time taken to estimate the parameters of the spatial-color mixture of Gaussians appearance model.\n\nIn this letter, we have presented a new approach for occlusion reasoning for tracking multiple people. In our approach, occlusion reasoning is integrated into the whole process of tracking, in order to obtain better tracking accuracy during occlusions. Prior knowledge is represented by a set of models: a 2-D elliptical shape model, a spatial-color mixture of Gaussians appearance model, and a motion model with constant velocity. We have constructed an observation likelihood based on the similarity between the appearance models of the people and the observations. The occlusion relationships are deduced from the current states of the objects and the current observations. The previous occlusion relationships are not required for deducing\n\nthe current occlusion relationships. Tracking and occlusion reasoning for more than two people are formulated in the particle filtering framework, and a solution is proposed. Experimental results on several real video sequences from indoor and outdoor scenes have demonstrated the effectiveness of our approach."
}