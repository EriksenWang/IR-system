{
    "title": "New Appearance Models for Natural Image Matting",
    "publication_date": "2007",
    "authors": [
        {
            "full_name": "Dheeraj Singaraju",
            "firstname": "Dheeraj",
            "lastname": "Singaraju",
            "affiliations": []
        },
        {
            "full_name": "Carsten Rother",
            "firstname": "Carsten",
            "lastname": "Rother",
            "affiliations": []
        },
        {
            "full_name": "Christoph Rhemann",
            "firstname": "Christoph",
            "lastname": "Rhemann",
            "affiliations": []
        }
    ],
    "abstract": "Image matting is the task of estimating a fore-and background layer from a single image. To solve this ill posed problem, an accurate modeling of the scene's appearance is necessary. Existing methods that provide a closed form solution to this problem, assume that the colors of the foreground and background layers are locally linear. In this paper, we show that such models can be an overfit when the colors of the two layers are locally constant. We derive new closed form expressions in such cases, and show that our models are more compact than existing ones. In particular, the null space of our cost function is a subset of the null space constructed by existing approaches. We discuss the bias towards specific solutions for each formulation. Experiments on synthetic and real data confirm that our compact models estimate alpha mattes more accurately than existing techniques, without the need of additional user interaction.",
    "full_text": "Image matting addresses the problem of estimating the partial opacity of each pixel in a given image. In particular, one assumes that the intensity I i of the i th pixel can be written as the convex combination of a foreground intensity F i and a background intensity B i , as\n\nwhere α i is referred to as the pixel's partial opacity value or alpha matte. By definition, this value is constrained to take values in [0, 1]. We note that for each pixel in color images, (1) gives us 3 equations in 7 unknowns. Consequently, the image matting problem is highly under-constrained. To this effect, the user is required to provide some additional information in order to make the problem well posed. Such information is typically provided in the form of a trimap by marking different regions in the image as (a) foreground; α = 1, (b) background; α = 0, and (c) unknown; α ∈ [0, 1].\n\nThe goal of image matting algorithms is therefore to estimate the alpha mattes of the pixels in the unknown re-gion. Incipient methods such as [12] use the trimap to construct basic color models for the foreground and background, which are subsequently used to estimate the alpha mattes in the unknown region as per (1). Due to their naive modeling schemes, such algorithms fail on images with complex intensity variations. Methods such as [2,15] solve such issues by using local propagation techniques to estimate the alpha mattes. However, their good performance is subject to the use of a tight trimap.\n\nSubsequent research in image matting witnessed the use of a number of algorithms originally intended for image segmentation [11,17,3,4,1,20]. In most cases, these algorithms use a sparse trimap to estimate a binary segmentation, which is then used to generate a tight trimap for the image. The alpha mattes are estimated using this tight trimap and can then potentially be refined by alternating between re-estimation of the alpha mattes and the trimap. It is important to appreciate the fact that matting and segmentation are different problems. In order to estimate the alpha mattes of an image, one needs to develop extremely accurate models for the scene's appearance. This is not so for the case of segmentation, where it suffices to define image features that help to distinguish the object from the background.\n\nConsequently, recent work in image matting has seen a surge of research towards developing algorithms that exploit various features specific to the matting problem [6, 19,16,7,10,9]. It was shown in [6] that if one assumes the intensities of the foreground and background layers to vary linearly in small image patches, then the alpha mattes could be estimated in a closed form fashion. It was later demonstrated that the performance of local propagation based methods such as [6] could be improved by additionally learning global color models [19,16,9]. Recent work has also focused on enforcing sparsity of the alpha mattes [7,10]. For a more detailed review of image matting algorithms, we refer the reader to [18].\n\nIn this paper, we propose to improve the state of the art for image matting by developing accurate models for a scene's appearance, and hence fundamentally improve the building blocks of matting algorithms. In particular, we focus on the Matting Laplacian proposed by [6], which is a matrix characterizing a cost function for image matting. This cost function is derived under the assumption that the foreground and background layers of each image patch exhibit linear variation in the intensities. As we show, this assumption can be an overfit for the image data, if the colors of either layer are locally constant. Specifically, we show that for small perturbations in the image data, [6] might construct a null space of possible solutions, which is larger than desired, thereby making the problem more ambiguous.\n\nWe then show how one can construct more compact models for the alpha mattes, which have a null space of provably smaller dimension than that of [6]. Furthermore, the different formulations have a different bias towards specific solutions, which we will discuss in detail. Compelling experiments on synthetic and real images validate our claims. Consequently, we present a new framework for closed form solutions to image matting, which is theoretically principled and yields high quality alpha mattes.\n\nNote that since the Matting Laplacian has been used in [6, 19,16,7,10,9] for regularization of the alpha mattes, our framework can be used to improve the performance of these algorithms. Furthermore, our framework can be applied to alternative applications such as light mixture estimation [5], since they use variants of the Matting Laplacian.\n\nOmer and Werman [8] empirically showed that the distribution of colors in real images is locally linear in RGB space. Inspired by this work, Levin et al. [6] state that given any small patch in the query composite image, the intensities of the corresponding foreground and background layers can be assumed to lie on lines in RGB space. In particular, for a small patch W i centered around pixel i, there exist colors (F i1 , F i2 , B i1 , B i2 ) such that the foreground and background colors (F j , B j ) of each pixel j ∈ W i can be expressed as\n\nUnder this assumption, [6] showed that there exist affine\n\nsuch that the alpha matte α j of each pixel j ∈ W i can be written as\n\nwhere I R j , I G j and I B j refer to the RGB values of pixel j. The problem of estimating the mattes α in the image can consequently be posed as one of finding the minimizer of\n\nwhere V is the set of all pixels in the image. Essentially, this corresponds to minimizing the residual of the affine model v i defined in (3) for every small patch W i . Note that [6] actually uses a modification of the cost function J(α, v) by introducing an additional regularization term, as\n\nThe regularization term is introduced in order to enforce the affine function\n\n, or in other words, enforce constancy of alpha mattes over the patch W i . The motivation for this is twofold. Firstly, the user provided scribbles are typically sparse and constrain far fewer pixels than the perfectly tight trimap. Hence, for many pixels in the image, an α of 0 or 1 is desired, independent of the appearance model. Secondly, real images often have highly textured patches that do not satisfy the color line model, but nonetheless may have uniform alpha mattes across the patch. The alpha mattes of such patches can be explained by an affine model of the form v = (0, 0, 0, c), c ∈ [0, 1]. Therefore, the model allows for certain complex cases beyond the color line model of (2).\n\nNote that the constructed cost function J (α, v) depends on two unknown quantities; the alpha mattes α and the affine functions v. However, [6] showed that this can be reduced to a cost function that depends solely on the alpha mattes. For the sake of simplicity, let us define matrices G i ∈ R (|Wi|+3)×4 and ᾱi ∈ R |Wi|+3 . The first |W i | rows of G i are given by I R j I G j I B j 1 , j ∈ W i and the last three rows are given by ( )I 3 0 , where I n is an identity matrix of size n × n. The first |W i | entries of ᾱi are given by α j , j ∈ W i and the last three entries are equal to 0. Given this notation, J (α, v) can be rewritten as\n\nNow, we see that we can estimate the affine function v i for each patch W i , as\n\nTherefore, using the expression for v i from (7), we see that the cost function J (α, v) can be reduced to a cost function dependent on the alpha mattes only, as\n\nThe matrix L is referred to as the Matting Laplacian and we refer the reader to [6] for a detailed derivation of its entries. Note that the constructed cost function is quadratic in the alpha mattes. Therefore, the minimizer of this cost function can be estimated by solving a linear system. Hence, we have a closed form solution for the alpha mattes. What is the null space? It is of interest to inspect the nature of the solutions to this system for a small patch W i in the image. Let us define a matrix\n\nTherefore, by construction, the columns of the matrix G i and their linear combinations are null vectors of the matrix M i . If the foreground and background layers truly satisfy the color line model, we know that the vector of alpha mattes ᾱi is given by G i v i . In other words, the vector of alpha mattes is given by a linear combination of the columns of G i and hence lies in the null space of M i . Also, in such cases G i is of rank 4, and therefore M i has a null space of dimension 4. As a result, the vector of alpha mattes is only one of the potential minimizers of the constructed cost function. For instance, we have seen from our earlier discussion that the constant solution is also part of the null space. It is precisely for this reason that the user is required to mark scribbles in the image and embed constraints, so that the algorithm can recover the true alpha mattes as the minimizers of J (α).\n\nIn practice, it can be observed that [6] does not always recover the ground truth alpha mattes. This is due to several reasons, a few of which are outlined below.\n\n1. Violation of the color-line model: In natural images, it often happens that the image data does not satisfy the color line model. In the case of complex intensity variations, it is obvious that the color line model is too simple to explain the image intensities. In such scenarios, one would have to resort to data driven schemes such as [19,9] for generating candidate foreground and background colors. However, we are particularly interested in the case when the intensity variations are much simpler than the color line, such as being locally constant. As we shall show later, the true dimension of possible solutions for such image patches is less than 4 and hence the algorithm of [6] provides an overfit. Since such patches occur commonly in natural images, it is of interest to construct more compact models for the alpha mattes in such patches. 2. Insufficient user interaction: Recall that the system constructed by [6] has a 4-dimensional null space for each local image patch considered by the algorithm. Hence, high level user interaction is required to resolve any ambiguities. One could potentially incorporate prior knowledge in order to bias the system towards certain family of solutions.\n\n[6] biases the mattes to be locally constant, which can prove to be unsatisfactory in practice. As shown in Figure 2(c,e) when the user marks pixels corresponding to one layer only, [6] assigns constant alpha mattes equal to 0 or 1 to all unmarked pixels, based on whether the scribbles correspond to background or foreground respectively. We will address this problem in detail later. Alternatively, [7] biases the mattes towards 0 or 1 using non-linear priors. This resulting system is however prohibitively slow in practice. Moreover, the mattes estimated at the scribbled pixels do not necessarily match the values specified by the user. Note that one could also predict the alpha value for each pixel with a certain confidence value, as in [19,9]. However, such frameworks are beyond the scope of this paper.\n\nIn this work, we consider the cases when the color line models are violated, such that at least one of the foreground or background layers lie on a point rather than a line in color space. Specifically, we inspect the rank of the matrix G i introduced in Section 2 and analyze the cases when the rank of the matrix is less than 4. We show that for these cases, the intensities of the composite image lie on linear/affine spaces of dimension less than or equal to 4. Since in general, the Matting Laplacian of [6] has a 4 dimensional null space, we demonstrate that our method is more robust to noisy data.\n\nFurther, we show that the solution space of our formulation includes the constant alpha solution, which is important for highly textured areas. We will also show that the model of [6] has a natural bias towards constant solutions, while our model has a natural bias for a constant 0 (or 1) solution. Both biases, our and [6] are not optimal, since the ideal bias is towards 0 and 1 simultaneously. Unfortunately, the ideal bias leads to a non-linear system, e.g. as shown in [7], which is very challenging to optimize and hence [7] is not ranked very well in recent evaluations [10]. We will see in section 4, that our method performs on average favourably, which suggests that robustness to noise overweighs the influences of the different bias. Also, we will show that for the special case where the user specified unknown region is bounded by constraints of one type only, e.g. only foreground, the bias of our formulation towards 0 is clearly preferable.\n\nWe first consider the case when the colors of exactly one layer satisfy the color line model, while the colors of the other layer are constant and hence satisfy a color point model. Without loss of generality, assume that the foreground intensities are constant and that the background intensities lie on a color line. It is easy to check that if the type of models were interchanged, our following analysis would result in the same cost function. Now, by the hypothesis,\n\nTherefore, the composite intensity I j of a pixel j ∈ W i can be expressed as\n\nFor this scenario, we derive two important results as given by Theorem 1.\n\nTheorem 1 Consider an image patch W i around a pixel i ∈ V, such that the RGB intensities of the pixels in the patch, satisfy the line-point color models. Define a matrix G LP i ∈ R |Wi|×3 , whose rows are given as I R j I G j I B j , j ∈ W i . Also define a matrix ᾱi ∈ R |Wi| , whose entries are given by α j , j ∈ W i 1. If the foreground color point does not lie on the background color line and there are at least three pixels a, b, c\n\n2. If Rk(G LP i ) = 3, the alpha matte α j of each pixel j ∈ W i , can be expressed as a linear function of the pixel's intensities, via unique coefficients\n\nProof. Please refer to technical report [13].\n\nObserve that this is different from (3) derived under the color line assumption, where the alpha mattes were affine functions of the intensities. Now, there is no constant term present in the expression for the alpha mattes. As earlier, we can estimate the unknowns by minimizing the cost function\n\nIf we assume that the alpha mattes of the pixels in the patch W i are known, the coefficients v i for each patch W i can be estimated by minimizing the function J 3 (α, v), as\n\nSubstituting the expression for v i from ( 12), we see that the cost function J 3 (α, v) can be reduced to a cost function dependent on the alpha mattes only, as\n\nAs earlier, the constructed cost function is quadratic in the alpha mattes. Therefore, the alpha mattes can be estimated in closed form by solving a linear system. What is the null space? We now repeat the exercise of inspecting the nature of the solutions to this system for a small patch W i in the image. Let us define a matrix\n\n. By an earlier argument, we know that the columns of the matrix G LP i and their linear combinations, are null vectors of the matrix M LP i . Recall from Theorem 1 that ᾱi = G LP i v i . Therefore, we can conclude that the vector of true alpha mattes lies in the null space of M LP i . Since G LP i is rank 3, we have that the null space of M LP i is of dimension 3. When the image data exactly obeys the line-point model, the RGB intensities lie on a plane spanned by the model parameters F , B 1 and B 2 . Since the locus of any point x on the plane can be expressed in terms of the perpendicular to the plane d ∈ R 3 as d x = 1, we note that there exists a linear function d such that ∀j ∈ W i : d I j = 1. Consequently, the matrix G i constructed by Levin et al.\n\n[6] is also rank 3, because the last column comprising of all 1s can be expressed as a linear combination of the first 3 columns that contain the image intensities. Hence, the null space of the Matting Laplacian is also 3 dimensional.\n\nNote that in the statement of Theorem 1, we have mentioned that there must be at least three pixels in the window a, b, c\n\nThis corresponds to the condition that the composite intensities completely span the plane defined by the foreground color point and the background color line. However, when the alpha mattes of all the pixels in a window are constant, i.e. ∀j ∈ W i , α j = k ∈ [0, 1], the intensities span only a subset of the plane defined by the foreground color point and the background color line. Specifically, they span a line on this plane and hence the rank of G LP i is 2 in this case. Since this line is a part of the plane discussed above, all the composite intensities do still satisfy the locus ∀j ∈ W i : d I j = 1. Hence, we see that our constructed cost function naturally allows for locally constant alpha mattes, because there exists a linear function kd ∈ R 3 such that ∀j ∈ W i , α j = (kd) I j = k(d I j ) = k. This is an important property when dealing with trimaps that are not tight. What happens on real, noisy images? Unfortunately, real data is always corrupted by some noise. In case the image data has a slight perturbation from the exact color-line model, the intensities do no longer lie on a plane. Hence, there is no d ∈ R 3 such that ∀j ∈ W i : d I j = 1, and the matrix G i constructed by [6] is rank 4. As a result, the null space of the Matting Laplacian is rank 4. The null space obtained using our framework, however, still has a null space of dimension 3, by construction. Since the first 3 columns of G i are exactly the same as G LP i , the column span of G LP i is a subset of the column span of G i . Therefore, the null space obtained using our framework is a strict subset of the null space constructed by [6]. This implies that our proposed model is more compact than that of [6]. Hence, the key observation is that the extra degree of freedom of the Matting Laplacian is used to explain image noise. What is the bias? The space of solutions for the alpha matte given by our model or the model of [6] is typically quite large (see [7]). However, there is an implicit bias towards the result given by the linear solver. In fact, this bias is enforced naturally by the structure of the different cost functions. While [6] naturally biases the mattes to be locally constant, our new cost function pushes the alpha mattes towards 0. By construction, the Matting Laplacian L has the vector with all equal entries, as its trivial null vector. Therefore, [6] is biased towards estimating locally smooth alpha mattes. On the other hand, our cost function L 3 is a positive semi-definite matrix and not necessarily a Laplacian matrix. It has a trivial null vector which has all entries equal to 0, and consequently our algorithm estimates alpha mattes with a bias towards 0. Note that by solving for 1 -α rather than α, we can also bias the alpha mattes towards 1.\n\nResult on toy data. Figure 1 illustrates the advantage of our proposed model. The yellow foreground is a point in RGB space, and the background lies on a color line, varying from light to dark blue. Hence, we have a perfect line-point color model. We add some noise to the composite image in order to slightly perturb it from this model. Notice that [6] produces erroneous alpha mattes due to its larger null space, and our method recovers a much better alpha matte.\n\nAs expected [6] has a bias towards locally smooth mattes, and careful inspection shows that our result has a tiny shift towards 0. Furthermore, note that the trimap is not very tight, and our method correctly recovers those pixels which should be truly 0 or 1.\n\nResults for insufficient user input. We now demonstrate that our algorithm can recover the alpha mattes even when the user provides scribbles for only one of the layers. Recall that since [6] prefers locally constant mattes, it will produce a result with all pixels having α = 0 or α = 1. Therefore, for a fair comparison, we propose a new version of [6], in order to bias the alpha mattes towards 0. In particular, we estimate the alpha mattes by minimizing the cost function\n\nIn this modification, we are biasing the affine models of ( 3) towards (0, 0, 0, 0). It can easily be checked that we can eliminate the unknown affine models in a similar fashion as described earlier, and obtain a closed form solution for the alpha mattes. We hence have a formulation which can potentially estimate the alpha mattes even when the user provides scribbles for one of the layers only.\n\nFigure 2 shows a toy example for the line-point color model where the user marks scribbles for the foreground only. We are able to recover visually pleasing alpha mattes, since our natural bias towards 0 is the desired bias in this case. However, we do not get good results with our proposed modification of [6] even when we increase in (14). As discussed, these resulting alpha mattes are biased to be locally smooth due to the nature of the Matting Laplacian.\n\nWe now consider the case when the colors of both the layers are constant and hence satisfy the color point model. By the hypothesis, ∀j ∈ W i , F j = F and ∀j ∈ W i , B j = B. Therefore, the composite intensity I j of a pixel j ∈ W i can be expressed as ∀j ∈ W i :\n\nFor this scenario, we derive two important results as given by Theorem 2. Theorem 2 Consider an image patch W i around a pixel i ∈ V, such that the RGB intensities of the pixels in the patch, satisfy the point-point color models. Define a matrix G P P i ∈ R |Wi|×3 , whose rows are given as\n\nIf the alpha mattes of all the pixels in the patch are not equal and the color points of the two layers are distinct, then Rk(G LP i ) = 2. 2. If Rk(G P P i ) = 2, there exists a projection Π :\n\nsuch that the alpha matte α j of each pixel j ∈ W i can be expressed as a linear function of the projected intensities Ĩi ∈ R 2 , via unique coeffi-\n\nProof. Please refer to technical report [13].\n\nAs earlier, we define a matrix Gi ∈ R |Wi|×2 , the rows of which are given by Ĩj , j ∈ W i , and also a matrix ᾱi ∈ R |Wi| , whose entries are given by α j , j ∈ W i . The problem of finding the unknown alpha mattes can then be posed as one of minimizing the cost function\n\nRecall that the coefficients v i for each patch W i can be estimated in closed form as\n\nSubstituting the expression for v i from ( 17), we see that the cost function J 2 (α, v) can be reduced to a cost function dependent on the alpha mattes only, as\n\nSince the constructed cost function is quadratic in the alpha mattes, the alpha mattes can be estimated in closed form by solving a linear system. What is the null space? We know that for each small image patch W i , since Gi is of rank 2, the null space of the matrix\n\ni is of rank 2. Now, we can proceed as we did in the rank 3 case, and verify that the column span of Gi is a subset of the column span of the matrix G i employed by [6]. Consequently, the 2 dimensional null space constructed by our framework is a subset of the 4 dimensional null space constructed by [6], and our proposed model for the alpha mattes is more compact than that of [6]. Also, since the locus of a point (x, y) on a line can be represented as c 1 x + c 2 y = 1, we can always find models (a 1 i , a 2 i ) such that our framework admits locally constant solutions. It is also easy to show that, as for the rank 3 case, the Laplacian of [6] is rank 2 for noise free data. Results on toy data. Figure 3 gives a toy example to illustrate the advantage of our proposed model. The yellow foreground and blue background constitute distinct points in RGB space. Therefore, this scenario corresponds to the point-point color model. We add some noise to the composite image. The conclusions are the same as in Figure 1, i.e.\n\n[6] produces a solution which is worse than ours. Again, observe that [6] has biased towards locally smooth mattes, while ours has a small bias towards 0.\n\nIn this section, we present a quantitative and qualitative comparison of our proposed framework with that of [6], and show that our formulation helps to estimate better mattes. First, we give the details of our numerical implementation and then present an analysis of our tests.\n\nLike in [6], we consider image patches of size 3 × 3. Note that we need to estimate the rank of each patch W i , and for this, we first construct a matrix G i , the rows of which are given by I R j I G j I B j 1 , j ∈ W i . We then estimate the singular value decomposition of this matrix as G = U ΣV , where the diagonal entries of Σ are given by σ 1 > σ 2 > σ 3 > σ 4 . Now, we normalize the singular values as Σ = λΣ, where λ = (σ 2 1 + σ 2 2 + σ 2 3 + σ 2 4 ) -0.5 . This normalization ensures that the rank estimation is not sensitive to scale variations in the image. We inspect the normalized singular values σi = λσ i , and estimate the rank as rank(W i )= argmax k [ σk > δ], where δ is a pre-defined tolerance value. We use δ = 0.0025 in all our experiments.\n\nGiven the rank of a patch W i , we choose the appropriate cost function C i for the patch as discussed in Section 3. In particular, if the rank of W i is 2, 3 or 4, we construct the matrix (11), or C = L in (4) respectively, by restricting V = i. In the case of rank 1, we construct C i using the cost function of (4), which essentially forces the alpha mattes in the patch to be equal. We then define a vector ᾱi ∈ R |Wi| , the entries of which are given by {α j }, j ∈ W i . We therefore need to estimate the alpha mattes of the image by minimizing i ᾱ i C i ᾱ = α Lα, where α is the vector containing the alpha mattes of all the pixels in the image. Note that L is a positive semi-definite matrix of size |α| × |α| obtained by aggregating the matrices C i . Now, we need to minimize this cost function subject to the constraints that the set of pixels scribbled as foreground (say F) have α = 1 and the set of pixels scribbled as background (say B ) have α = 0. As shown in [14], the solution to this problem\n\nis equivalent to solving a linear system. Hence, we have a new closed form solution for the alpha mattes of an image.\n\nWe perform our evaluation on the database used in [10], which contains 27 high quality images. For the purpose of testing, we dilate the perfect trimap by 22 pixels.  14), but only for those connected regions in the trimap which have only 1 as boundary conditions. Note, for Levin-mod we tried different values for in eqn. ( 14) and selected the best as = 10 -3 . The performance of each algorithm is evaluated using the following three different metrics. Given the computed α matte and the ground truth α * , we compute the metrics SAD:\n\n2 , and gradient er-\n\nTable 1 shows these errors for different methods (averaged over all test cases).\n\nThe best result for each metric is highlighted in bold.\n\nWe note that Levin-mod obviously outperforms Levin.\n\nInterestingly, Rank-adaptive-mod performs better than Rank-adaptive. Visual inspection shows that the bias towards 0 is more pronounced for the rank 2 case than for rank 3. This points towards the fact that for real images, our rank 3 formulation can account for the rank 2 cases also and has much more stable performance. Note that this is not a drawback of our formulation, since we can have a black box for rank estimation, which always gives values of 3 or 4.\n\nImportantly, the modification of our algorithm Rank-adaptive-mod performs better than Levin as well as Levin-mod in 2 out of the 3 metrics. These improvements can also be observed visually, since these three error metrics may not be representative of the error observed by a human.  -6 show typical results obtained in the above error analysis. We show the results of Levin-mod and Rank-adaptive-mod since these algorithms rank the best in the error metrics. In the images displaying the rank estimated by us, we use the following color-coding: dark blue -marked pixels, light blue -rank 1, green -rank 2, orange -rank 3, and red -rank 4. It is important to note that most of the unmarked pixels in the trimap have rank less than 4. In spite of introducing a bias towards 0 alpha mattes, Levin-mod cannot deal with holes in the trimap. This is due to its inherent bias to estimate locally smooth alpha mattes. Our method, however, has no such problem and is able to recover visually pleasing alpha mattes. Moreover, in spite of an inherent bias of our method towards 0 alpha mattes, our algorithm is able to accurately estimate 1 alpha mattes in several regions of the trimap, such as the boundary of the ball, the girl and the leaves in Figures 456.\n\nWe now address the issue of using scribbles vs. trimap as user interaction. In Figure 7, we see that when we use the same scribbles as used in [6], our framework is able to capture finer details of the alpha matte of the dandelion, as compared to [6]. On the other hand, in Figure 8, we see that when we use the same scribbles used in [6], our method gives suboptimal performance. Specifically, due to the inherent bias, our method tries to fit fractional alpha even though the true alpha matte is 1 in large portions of the bear. However, this can be easily fixed by connecting the scribbles and flood filling them to create a trimap, as shown in Figure 8(d). Our result (Fig. 8(f)) with this trimap is comparable to that of [6] (Fig. 8(e)). In general, our method outperforms [6] when the user input is a trimap, which as exhibited in our experiments, need not be tight. Note that this is not a limitation, since recent methods such as [1,10,9,20] also use the given scribbles to generate a trimap, and then estimate the alpha mattes using this trimap.\n\nIn this work, we have presented new appearance models for the problem of image matting. By construction, these appearance models are more compact than that proposed by [6], and as shown in our analysis, outperform the traditional color line model of [6], without the need of any additional user interaction. Future work entails the need of closed form solvers for the mattes of image patches that have complex intensity variation and hence do not satisfy the color line model or the color point model.\n\n(a) Image (b) Ground truth alpha (c) Trimap (d) Estimated rank (e) Results of Levin-mod (f) Results of Rank-adaptive-mod (a) Image (b) Ground truth alpha (c) Trimap (d) Estimated rank (e) Results of Levin-mod (f) Results of Rank-adaptive-mod Figure 5. Comparison of our framework vs. [6] on an image of a girl (a) Image (b) Ground truth alpha (c) Trimap (d) Estimated rank (e) Results of Levin-mod (f) Results of Rank-adaptive-mod Figure 6. Comparison of our framework vs. [6] on an image of a plant [6] A. Levin, D. Lischinski, and Y. Weiss. A closed-form solution to natural image matting. IEEE Trans. Pattern Anal. Mach. Intell., 30(2):228-242, 2008. [7] A. Levin, A. Rav-Acha, and D. Lischinski. Spectral matting. IEEE (a) Image + scribbles (b) Result of Levin (c) Result of Rank-adaptive-mod (a) Image + scribbles originally used in [6] (b) Result of Levin (c) Result of Rank-adaptive-mod (d) Trimap via connecting scribbles+floodfill (e) Result of Levin (f) Result of Rank-adaptive-mod"
}