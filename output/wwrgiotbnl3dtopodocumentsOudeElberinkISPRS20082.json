{
    "title": "PROBLEMS IN AUTOMATED BUILDING RECONSTRUCTION BASED ON DENSE AIRBORNE LASER SCANNING DATA",
    "publication_date": "2007",
    "authors": [
        {
            "full_name": "Sander Oude Elberink",
            "firstname": "Sander Oude",
            "lastname": "Elberink",
            "affiliations": [
                {
                    "organization": "International Institute for Geo-information Science and Earth Observation (ITC), Commission III",
                    "address": {
                        "city": "Enschede",
                        "country": "The Netherlands",
                        "postcode": "7500 AA"
                    }
                },
                {
                    "organization": "WG III/3",
                    "address": {}
                }
            ]
        }
    ],
    "abstract": "Reconstructing buildings in 3D has been a challenging research topic for at least ten years, and will be in future as long as acquisition systems are improving and model requirements are increasing. Despite the fact that many researchers presented approaches to automatically reconstruct 3D buildings, there are still a significant number of problems to be solved. We discuss a series of remaining problems in automated building reconstruction, related to the lack of information in the laser scanning data and the complexity in the scene. Describing the urban scene, in particular roof faces, becomes more complex when looking at a higher level of detail. In our study we focus on problems related to the reconstruction of building parts larger than 1 m 2 . Examples are shown of airborne laser scanning data with an average point density of 25 p/ m 2 , on buildings of a medium sized city centre in Europe. In order to show perspective in solving the described problems, we conclude with a global direction for future research.",
    "full_text": "Buildings are important objects in several applications, like city planning, noise models and 3D cadastral databases. Therefore reconstructing buildings is a repeatedly appearing topic in photogrammetric research activities, each proposing faster and more detailed production of the 3D building models. Although buildings can appear to be complex, it mostly consists of geometric regularities. Generally, a building contains vertical walls and planar roof parts that cover the total building surface. Many of the approaches presented in the past used this regularity information at some parts in their reconstruction method, (Haala et al., 1998;Rottensteiner and Briese, 2003;Vosselman, 1999). Despite the fact that many progress has been made to automatically reconstruct 3D buildings (Brenner, 2005), there are still a significant number of problems to be solved. Two main problem types can be distinguished: problems finding information from the data, and problems caused by scene complexity.\n\nIn this paper we identify the major remaining problems in the field of automatic building reconstruction using airborne laser scanning data. It is important to have an overview of different kinds of problems, before focussing on methodologies how to solve them in order to reconstruct buildings in 3D. The type and size of problems depend on (a.o.) acquisition methods, availability of additional information, complexity of the scene and the desired level of detail. As laser scan systems nowadays can produce more dense datasets, it is of interest to foresee the problems when reconstruction higher level of detail building models using high density laser data. Problems with image based building reconstructions are not analysed in this paper. We believe the potential of automatic reconstruction in complex scenes is lower using images than using laser data, although the extensive list of problems with laser scanner data in this paper leads to believe otherwise.\n\nProblems are discussed and illustrated by figures showing raw data, processed data or other intermediate results of processing steps. Examples are based on a high point density laser dataset that has been acquired by a forward, downward and backward looking laser scanning system mounted on a helicopter. As we laser data with an average point density of 25 p/m 2 , we focus on the reconstruction of detailed building models. Dormers and other roof parts larger than 1 m 2 are expected to be detected and consequently to be part of the reconstructed building.\n\nIn section 3 we focus on problems related to either the data acquisition or processing steps in building reconstruction. Then we show that scene complexity in section 4 has a major influence on the success of the reconstruction method.\n\nIn this section a selection is made of various approaches that reconstruct buildings. Each of the proposed methods can be used for their purpose. We shortly describe the research problem and the solution for groups of references.\n\nIn (Vosselman, 1999) an approach is presented that solves problems related to the outlining of buildings. First, segments are detected and outlined in dense height data. Planar faces have been detected by Hough-based plane extraction. In a connected components algorithm fragmented planes have been connected. Outlines of buildings have been regularized by forcing them to be either parallel or perpendicular to the main direction of the building. Vosselman and Dijkman (2001) describe the added value of partitioning topographic map data to group segments and reconstruct roof parts. Rottensteiner andBriese, (2002, 2003) discuss problems related to (step) edge detection and how to constrain and group data driven features. They present an approach by analysing the roof segments, looking for an intersection, a step edge, or both an intersection and a step edge. Also, geometric constraints on the consistence of buildings are proposed by performing an overall adjustment including available sensor information, parameters of the planes and vertices. Geometric constraints can be applied on lines, planes or combinations of them. More improvements can be found in Rottensteiner et al. (2005) where step edges and outlines are reconstructed more reliable and building hypotheses are tested and parameters estimated. Rottensteiner (2006) proposes an adjustment approach that can handle data observations, geometric constraint observations and approximate values for the unknown parameters as input. So within this adjustment data and model driven information can be taken as input. Each observation group is given its own weight in the adjustment procedure. The topology of the model is assumed to be known, as being a result of hypotheses tests as described in Rottensteiner et al. (2005).\n\nIn a few situations, the assumption that a building can be built from planar roof parts is not correct. The problems with nonplanar roofs are mention in (Filin et al., 2007). They describe a method, which first detects non-planar roof faces. If such curved roof parts are found, a more elaborative reconstruction method is needed. The authors present a reconstruction approach that can handle curved surfaces by using NURBS.\n\nThe French combination of MATIS (IGN) and INFRA has got a thorough research history in reconstruction 3D buildings from aerial images and DEMs (Taillandier and Deriche, 2004) and (Durupt and Taillandier, 2006). Rectangular footprints are fitted to the DSM and at corners of building blocks a solution is proposed for overlapping or nearby rectangles. Building roofs are shape limited to have two sloped roofs. For their purpose of robust and practical 3D city modelling the method works, but it does not work sufficiently for more detailed roof structures and complex building shapes. Haala and Brenner (1997) propose a method to reconstruct buildings from a skeleton derived from building ground plan. Their initial problem is automatic interpretation of DSMs, which is solved by adding ground plan information and using partitioned parts of the map to propose hypotheses. Inside the regions of the skeleton, roof patches from the DSM are analyzed and accepted or rejected according to a hypothesisand-test algorithm. Brenner (2000) describe the use of segment regions instead of the skeleton regions, and tries to form logical sequences of segment patches. Although this approach is datadriven, the reconstruction possibilities are limited to the acceptance criteria. One of these criteria is the region labeling, where segments are accepted looking at the sequence of regions along the map outline. Complex roof structures where roofs change across the map outlines (e.g. mansard roofs) cannot be labeled correctly. Brenner (2004) describes in a theoretical manner, a combination of model-and data-driven approach, by using weak primitives. These weak primitives have the ability to vary constraints without losing topological information. This approach is of interest if the topological information is known. However, in order to derive this topological information correctly, several problems have to be solved first.\n\nIn section 3 the focus is on problems that are related to the laser scanner data, followed by a section handling complexity issues of the recording scene in section 4.\n\nWith the increasing point density of laser scanners and the increasing resolution of digital imagery, data driven reconstruction techniques produce more accurate and robust models. Smaller roof details can be detected and geometric constraints can be applied with more confidence. Although increasing data density solves many problems, we discuss some of the remaining challenges.\n\nIn general the workflow of data driven approaches contain the following steps: acquisition, segmentation, building detection, feature extraction, grouping, and 3D reconstruction. We discuss problems throughout this chain and will start with the acquisition stage.\n\nThe point density of laser scan data mostly depends on the acquisition configuration, including system properties and flight configuration. Here we discuss some causes of variations in point density, accompanied by potential problems of varying densities.\n\nWorst case in data driven approaches starts with regions without laser points. Two main causes are highlighted here.\n\n• Object properties. Several difficulties in automated 3D mapping have been described in (Vosselman et al., 2005). Some of them are caused by object properties resulting in lower point densities or even gaps in the data. Problems can be found at steep roof parts, roof surfaces that have bad reflectance properties (e.g. wet or dark roofs), and small roof features that contain no or few laser points, see Figure 1.\n\nEven if laser data is acquired with a backward, nadir and forward looking laser scanner, shadow regions exist on or near buildings. It is hard to discriminate between occluded regions next to buildings and roof parts with bad reflectance.\n\nFigure 1 Laser data and outline of topographic map (left), aerial image (right) taken on same time and date.\n\nEvery acquisition project starts with designing the actual flight. Flying height, flight pattern and system properties are designed in order to meet the data requirements. Partly depending on weather conditions (in relation to platform stability) it is possible to estimate the point density and its variability. Here three configuration properties are analysed that influence the actual point density.\n\n• Strip overlap. Laser data is acquired strip-wise and, as a consequence of avoiding data gaps, neighbouring strips overlap each other. Besides the positive result that inside these overlapping areas the original point cloud will contain roughly twice as many points as in single strips, one can argue that the negative result is that there is a large variation (up to 100%) in between the data at a small distance. Automatic approaches should be robust to handle these variations.\n\n• Platform movements. Due to platform movements during the flight the point density will vary within each strip, resulting in an irregular pattern on the ground surface.\n\nScanning pattern. Although the flight configuration will be tuned to the scanning properties in order to get an optimal distribution of points, there will be variations in along or across track directions.\n\nVariations in point density are visualised in Figure 2, where the point density per square meter is shown in greyscale. Data ranges are between 0 points (black) and 180 points (white). We will discuss problems with varying point density in every consecutive step of the reconstruction. A general problem with varying point densities is the choice of correct threshold values. Thresholds can be found in most of the detection steps: detection of planar surfaces, intersection lines and grouping of features.\n\nIn most of the reconstruction approaches data is segmented in order to group points or pixels that belong to the same feature. This grouping is based on similarity properties like proximity, planarity and curvature. The relation between the object feature and how this object is represented by the data is important. In segmentation algorithms a maximum distance threshold and minimum segment size are set to decide if points belong to the same segment and whether they belong to any segment at all. These segmentation parameters should be chosen carefully to minimize over-and (more important) under-segmentation. Over-segmentation means that an object feature is represented by more than one segment. These segments can be grouped in a later stage and is not considered as harmful (Tovari and Pfeiffer, 2005). When a segment is covering multiple object features (called under-segmentation), or if a feature is not represented by any segment at all it is more difficult to reconstruct the object feature in a later stage. Therefore, the choice of segmentation parameters should be based on the lower point density parts and analyse there which object features could be represented by a segment. In case of the dataset in Figure 2, it would be on based on 12 p/ m 2 , although the mean point density of the scene is about 25 p/ m 2 . But even then, segmentation problems remain with missing data at steep, dark and wet object parts, see Figure 3. Figure 3 shows that laser points are missing on one steep side of a mansard roof. Even in this dense laser dataset, data is missing due to reasons due to a combination of acquisition configuration and building properties. Reconstruction techniques therefore not only have to consider laser points or segments but also should take information from the data gap. In terrestrial reconstruction techniques we have seen the use of gap information in (Becker and Haala, 2007) and (Pu and Vosselman, 2007), who detect and reconstruct windows by looking at the absence of terrestrial laser data at a building wall.\n\nFrom an airborne point of view gaps can indicate e.g. wet horizontal parts, steep and/or hidden roof parts. Additional challenge in the airborne case is to detect and reconstruct those object parts that have no laser points and in addition to that are located at the edge of already detected features, instead of inside the feature. This is the case in Figure 3, where the data gap of the missing mansard roof part also might represent a shadow area next to the building. Laser points on four dormers are not segmented, because of missing data Even if dormers and chimneys can be detected and reconstructed roughly, small differences occur due to the varying number and spreading of laser points on parts on dormers. In reality, it is likely that dormers on the same building will have the same shape. Regularization of these objects can be performed by constraining shape and location, using a similar approach of Rottensteiner and Briese (2003).\n\nThe use of ground plans has been described in many papers. Most of the ground plans contain information about the outlines of buildings. Motivations to use them vary from detection of regions of interest (Hofmann et al., 2002), giving hints about the roof structure (Brenner, 2000) to using them as outline of the 3D building (Haala et al., 1998;Hofmann, 2004;Vosselman and Dijkman, 2001). About as many authors reject the idea of using ground plans because of the limiting factors like unavailability of precise GIS data (Maas and Vosselman, 1999;Rottensteiner et al., 2005;Vosselman, 1999). Their approaches are solely based on their primary data source. Each of the two groups has got their motivation whether or not to use the ground plan. In this section we first show problems when using ground plans, followed by a list of problems when not having them.\n\nMost of the topographic maps are acquired by stereo photogrammetry, at some points assisted by additional terrestrial measurements. Normally the outlines of buildings are corrected for roof overhangs, so they represent the walls of buildings. This can also be seen in Figure 4 where laser points and map data are visualised together. Laser points on roofs seem to cover a bigger area than the outline of map data. Another interesting issue is the shape difference between the map outline and roof outline. The map outline represents the walls including small extrusions at the front and backside of the building, where the roof outline approximately is a rectangle without extrusions. However, on top of the roof there are dormers and chimneys, for which no hint was given from the map. Figure 5 Missing laser data (L1), missing segments (L2), shape of map outline does not follow roof shape (M1), map outline does not cover roof area (M2).\n\nIn Figure 5 the strong and weak sides of using map data has been shown. In cases of missing laser data (L1) or not segmented laser points (L2) laser data might be helpful to at least propose a simple building hypothesis later on in the reconstruction. However, in cases where the map outline does not give clear hints about the roof shape (M1) and where map data might be outdated or imprecise (M2) fusion might not be the best option.\n\nMost of the problems described in the literature on approaches that do not use ground plans can be found in the detection part of the reconstruction. Although using multipulse information and full wave form analysis might improve the classification between vegetation and buildings, objects like vehicles and containers might cause several false classifications. Figure 6 shows a relative simple scene, but missing laser data (D1) and objects that geometrically appear as building parts (D2), might cause problems in automatic building detection without using ground plans.\n\nFigure 6 Four problem areas in a simple scene.\n\nFinding the outline of a building is interesting for 2D applications, e.g. for mapping purposes, as well as for intermediate steps in 3D reconstruction algorithms, e.g. to select the laser points on this particular building. Outlining of buildings from point clouds still remains a difficult problem, despite the many papers describing solutions to this task. Solutions have been described to outline non rectangular buildings (Rottensteiner and Briese, 2002) and solutions by combining laser and image data (Rottensteiner et al., 2004;Sohn and Dowman, 2003). The largest remaining problem is to outline building parts that does not contain laser points, for example buildings indicated with D1 in Figure 6. Second type of problem relates to the complexity of the scene, definition of building outline and how this is represented in the laser data. For example, sun awnings and other temporary extrusions might have the same geometric properties as sheds, carports or garages and therefore are hard to automatically eliminate from the building outline.\n\nGiven the problems mentioned in the previous sections, the major problem in 3D reconstruction is creating hypotheses about the 3D building shape. To automatically create hypotheses, the algorithm has to make assumptions based on features found in the laser data and about logics in building shapes. In Figure 7 intersection lines have been derived automatically between two neighbouring building segments. Although the general shape can be indentified by the user, the line segments are not grouped and the step to properly proposing the final topology of the building is not solved yet.\n\nFigure 7 Map outlines and intersection lines.\n\nIn the previous section examples were shown for relatively simple urban scenery. When only looking at those problems, one can argue that using a model driven approach will be the solution to most of the problems. After all, using a model as starting point will solve some of the problems with missing data. Another advantage is that starting with a predefined model, its topology implicitly describes the building hypothesis.\n\nIn this section we focus on problems with finding the right building model automatically.\n\nModel driven approaches are proven robust and popular in rough 3D city modelling. The appearance of these 3D models often look structured and because of the absence of strange shaped reconstructed buildings, one can understand its popularity for visualisation purposes. However, as many authors of data driven approaches mention in their first section, model driven techniques are too generalized to be able to reconstruct complex building shapes, as shown in Figure 8. For interpretability reasons, images are shown instead of point clouds of complex scenes which might be hard to interpret on paper.\n\nEven if approaches can handle combinations of primitives, it cannot be expected that characteristic buildings, like city halls, domes and churches, can be described by an automatically detected combination of primitives. In Figure 8 six situations are shown with unusual topological building parts. Normally, a library of predefined buildings will not contain possibilities to reconstructed scenes as shown in the figure.\n\nFigure 8 Complex building shapes in urban scene.\n\nAs a logic result of looking at the pros and cons of data driven and model driven approaches, many problems can be solved by combining both methods. Filling up the data gaps with model knowledge makes data driven approaches more robust. On the other hand, getting more hints from the data makes model driven approaches more flexible. Good examples of combining model and data driven approaches can be found in (Sohn, 2004) and (Rottensteiner, 2006). Note that enforcing constraints can also be seen as a combination of the two approaches.\n\nRemaining problems can be found at conflict situations between data and model. For example, conflicts occur when applying thresholds concerning the final shape of the model. When is a corner constraint to be a straight angle? Does it depend on evidence found in the data or on the a priori building knowledge? From situation to situation the confidence in either the data or the model varies. Biggest problem remains the decision which model to choose. Even if the building can be described by adaptable primitives, like described in a semiautomatic manner in (Rottensteiner and Schulze, 2003), the problem is to automatically select and connect the right primitives.\n\nFrom photogrammetric research, we can learn how to group linear features, for example using a probabilistic approach as presented in Scholze (2002). In his PhD thesis he describes how to group 3D line segments and uses Bayesian statistics to propose a roof model and completes the missing parts in the model by adding semantical and logical roof parts, (Scholze, 2002). Although, the results are given for relatively simple buildings, it is of interest to see if this probabilistic approach can be proven successful in situations that are more complex. (van Gool et al., 2007) presents another interesting modelling method for proposing shapes of building facades based on shape grammars. These grammars include information about possible repetitive patterns or constrained shapes (e.g. windows are constrained to be rectangles) in the scene. If we want to apply a similar approach to 3D roof shapes, we have to find an appropriate energy function, which combines logical roof shapes with information found in the laser and map data.\n\nAlthough some examples might be exceptions to the rules, which can better be handled in a semi-automatic method, we have shown realistic problems in current automatic reconstruction methods. For many applications, semiautomation might solve most of the problems, as the operator can interpret complex scenes as well as missing building features. However, in most automated reconstruction approaches, the building model is not known. The focus on future reconstruction techniques will therefore be on proposing a set of potential models, before selecting and reconstructing the best approximating model. Each of the models in this set of potential models preferably combines data driven information, e.g. segment outlines and intersection lines, and a model driven component introducing the building knowledge like semantics and topology.\n\nTo aim for automatic reconstruction building knowledge should be integrated in the process of building reconstruction. Building knowledge should take care of the lack of laser scanner information. This knowledge should consist of a proper grammar of building roofs and a logical description of possible building shapes. It can be expected that the variety of these building shapes is too large to make use of a library of predefined models, although this depends on the desired level of detail and the recorded scene. In addition to the grammar, knowledge can be integrated in probabilistic and semantic labelling by giving experience-based weights to possible 3D building shapes.\n\nExisting GIS data can be used if available, but outlines of buildings from the GIS should be handled with care. The 2D outlines do not have to represent the outline of the roof. Changes between GIS data and laser data can have several causes which can not automatically be identified. Proposals using map data as input for model driven information, should be aware of the fact that map information might not give the correct hints about 3D building shapes."
}