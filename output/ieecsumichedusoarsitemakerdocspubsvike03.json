{
    "title": "EXAMPLE-DRIVEN DIAGRAMMATIC TOOLS FOR RAPID KNOWLEDGE ACQUISITION",
    "publication_date": "1999",
    "authors": [
        {
            "full_name": "Douglas J Pearson",
            "firstname": "Douglas J",
            "lastname": "Pearson",
            "affiliations": [
                {
                    "organization": "Dept. of EECS, ThreePenny Software, LLC Seattle",
                    "address": {
                        "country": "USA",
                        "postcode": "98103"
                    }
                }
            ]
        },
        {
            "full_name": "John E Laird",
            "firstname": "John E",
            "lastname": "Laird",
            "affiliations": [
                {
                    "organization": "University of Michigan Ann Arbor",
                    "address": {
                        "country": "USA",
                        "postcode": "48109"
                    }
                }
            ]
        }
    ],
    "abstract": "The last ten years has seen a revolution in the complexity and realism of human behavior models (HBMs). However, the cost of developing realistic HBMs continues to increase as much of the detailed and complex knowledge must be manually encoded to produce realistic behavior. The focus of this project is on reducing the cost of acquiring, validating and maintaining the knowledge used in realistic HBMs. Our approach is to develop tools that allow subject matter experts (SMEs) to visually specify behavior using abstract scenarios represented as diagrams. The SME can graphically describe the conditions under which actions and goals should be pursued, together with the associated reasons for those decisions. The system, guided by the e xpert's choices, analyzes and automatically generalizes from the example scenarios, alerting the SME to inconsistencies and missing knowledge. The system incrementally generates an executable HBM whose behavior the SME can view and modify during development. By moving the language of discourse from symbolic programming languages to annotated diagrams, the SMEs specify knowledge directly without requiring the intervention of a knowledge engineer to translate between the representations.",
    "full_text": "The cost of developing realistic human behavior models (HBMs) continues to increase as much of the detailed and complex knowledge must be manually encoded to produce realistic behavior. The focus of this project is on reducing this cost by developing tools that allow subject matter experts (SMEs) to visual specify behavior using example scenarios represented as diagrams. The distinguishing features of this approach are:\n\n• Changing the language of discourse for developing, validating and maintaining HBMs from symbolic languages to diagrams.\n\n• Driving the development process through example scenarios, where an SME walks through ideal behaviors, recording reasons for decisions and describing appropriate goals, actions and methods to pursue.\n\n• Generalizing the examples through direct guidance from the SME in selecting features for when a particular course of action is appropriate, coupled with heuristics to assist in this selection process. This ensures that general purpose behaviors are acquired rather than simple, scripted scenarios.\n\n• Generating and analyzing rules automatically to determine how well they cover the examples specified by the SME. Where differences arise, the SME is prompted to correct inconsistencies or fill in missing knowledge.\n\n• The tools manage the knowledge during all stages of development from acquisition, through development, validation and maintenance within a single, unified environment.\n\nWe discuss these methods in the context of an ongoing project to develop realistic human behavior models of soldiers engaged in close quarters combat within buildings. To date our work has focused on the challenge of acquiring new behaviors as distinct from acquiring new internal or external representations of the environment, which we will pursue at a later point within this project.\n\nThe typical approach to knowledge acquisition and construction of a human behavior model consists of:\n\n1. Review of relevant domain specific literature by the development team.\n\n2. Interviews with a subject matter expert (SME) describing the overall task domain and then specific example scenarios with descriptions of decisions and actions.\n\nPermission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. The most costly parts of the development process are usually steps 3, 5 and 7--the phases where knowledge engineers encode the behaviors previously described by the SMEs. Based on our experience of building large scale HBMs in the tactical air combat domain [1,2] 75%-90% of the effort was spent developing tactical and missionspecific knowledge. This experience directly motivated our current effort to build visual tools that allow SMEs to more directly encode their knowledge, through examples of behaviors represented as diagrams.\n\nThe core of this approach is to minimize the role of the knowledge engineer as much as possible, to let the SME enter knowledge in a format friendly to his natural thinking, and translating that representation automatically to an executable format.\n\nThe outline of our approach is:\n\n1. The expert (SME) visually lays out a training scenario 2. The expert then walks through the scenario, defining the desired behavior for the entities within this specific scenario 3. The example scenario is automatically generalized to cover more than the specific scenario being described by the SME.\n\n4. Rules are automatically generated from the example scenarios and these rules are analyzed to determine how well they cover the library of training examples.\n\n5. This process is applied to the all stages of development from acquisition, through development, validation and maintenance.\n\nThe overall structure of the system is shown in Figure 1 and in the rest of this paper we will describe these elements in more detail.\n\nThe biggest problem with current approaches is that there is a vast disconnect between the language used by the SMEs for describing behaviors and the language used by the knowledge engineers for building the HBMs. A long tradition of psychological research supports the idea that for some problem solving and thinking, diagrams are essential [3,4]. Our hypothesis is that by visually specifying behavior through diagrams, the SMEs will be able to more directly encode their knowledge greatly reducing the time to develop HBMs.\n\nThe knowledge to be acquired falls into three categories:\n\n• Goal knowledge\n\nAt this stage of our research project, the SME is able to specify new goal and behavior knowledge in terms of the existing state representation. The SME does this, not by directly writing code, but by stepping through diagrammatic representations of the example problems in the task domain.\n\nThe current tools assume that the state representation is largely constant and is developed in collaboration with the SME prior to behavior specification. We hope to relax this assumption in the future.\n\nThe first step in entering new knowledge is for the SME to create a specific scenario. The SME lays out a series of rooms, doors, walls, kitchen appliances etc. The SME can also place participants, including friendly, opponent and neutral forces (see Figure 2).\n\nOnce the scenario is defined, the SME walks all of the entities through the scenario, step by step, demonstrating the correct behavior. At each step, the SME selects the appropriate behavior for the agent for its current task. These tasks can include situations assessment (e.g. determining defensive strong points), high-level tactical goals (e.g. defend a room) or low-level behaviors (e.g. move to a door).\n\nThe majority of the information that the SME must have access to is well suited to visual representations, such as the layout of a room, the positions of individuals, their actions etc. To date, we have focused on representing these physical aspects of the task domain, but it is our intention to progressively represent data structures that are internal to the HBMs, such as abstract situational awareness, current objectives and individuals' attitudes concerning other members of the team. We expect that graphical representations of these concepts, although more difficult to develop initially, will be more natural to use than pure symbolic or numeric representations that developers are currently forced to use.\n\nBehaviors are defined by selecting specific actions from an available palette (e.g. add-new-goal or move-to-location).\n\nThe user then parameterizes this action by clicking in the visual display (e.g. clicking on the room to be cleared or on the door to be moved to). The user can add new goal concepts, together with the parameters they require. The behaviors being defined are not limited to external, physical behaviors. The set of actions can include internal state changes, such as new situational awareness information (e.g. that a particular door is the mo st likely access point for an enemy).\n\nThe SME can summon additional views of the situation. Most notable is the entity's view that shows what the selected entity can sense directly through all modalities. We plan to extend this view to show situational analysis, such as determining lines of fire, escape routes etc. Figure 3 shows an example of this (the lower window is the entity view).\n\nIf the knowledge base included only annotated examples, the knowledge would be very brittle, covering the specific training scenarios but little else. One of the major roles of a knowledge engineer in traditional knowledge acquisition is to generalize from the examples so that the knowledge covers a broader collection of situations.\n\nGeneralization is such a key area that we plan to address it with multiple techniques. We will describe two methods we are using in this section and another proposed method in the future work section.\n\nOur first approach to generalization is to have the SME walk through the scenario marking features in the environment that should be considered in each decision. The more features that the SME selects, the more closely tied the acquired knowledge will be to the specific scenario. If the SME selects only a few features, the knowledge generated from the scenario will be very general and will cover many similar situations.\n\nFor example, when firing at an opponent a subset of the important features might be:\n\nTable 1. Example relevant features Object Feature Value <target> IsThreat true <target> IsAlive true <shooter> CanSee(<target>) true <shooter> Nearest-Threat <target> <shooter> Goal Eliminate-Threats\n\nThe process of selecting these relevant features is potentially time consuming and error prone. Our second generalization technique uses a series of heuristics to reduce both the time spent and errors made. These heuristics attempt to identify features that are likely to be relevant to a decision.\n\nTo continue this example, the heuristic associated with shooting someone might be to include:\n\nTable 2. Approximate list of relevant features Object Feature Value <target> IsThreat true <target> IsAlive true <shooter> CanSee(<target>) true <shooter> Goal <current-goal>\n\nThat is to say that whenever a \"shoot\" command is issued, these features will be included in the default set of relevant features (e.g. to shoot someone you should be able to see them). The set of features to include is domain specific and is developed in consultation with the SME prior to behavior acquisition. The important aspect of these heuristics is that their predictions do not have to be correct, just close. The SME will review and adjust the set of features, remo ving ones that are not in fact relevant or adding others (e.g. the Nearest-Threat condition in this e xample). This initial 'guess' at the feature set reduces the workload for the SME.\n\nThis example also serves to demonstrate how the number of features selected affects the generality of the knowledge that is acquired. If the Goal feature is removed then the knowledge gained will apply any time the entity can see a threat, not just when the current task is to eliminate those threats. Conversely, if additional features are added (e.g. that the shooter is carrying a certain weapon) then the newly acquired knowledge will apply to a smaller range of situations.\n\nA major research issue is how to correctly handle the situation where the important features relevant to a decision are not currently represented within the domain. We have not yet directly addressed this problem although our approach will be to allow the user to define new internal structure that the HBM can then use for its reasoning. For example, the SME might determine that a particular decision relies on the last known location of an enemy. If that property is not currently represented in the task domain, we must present a method for its inclusion together with a method to visualize this new piece of information. We expect that developing such techniques for dynamically extending the set of concepts will be one of the more challenging aspects of our future work on this project.\n\nAfter the SME has defined the scenario, specified the desired behavior and reasons for that behavior the system can then automatically generate a set of rules based on the SMEs choices. This generation process is currently a direct mapping from the important feature sets. The rule generated from the example shown in Table 1 would be:\n\nThese rules are executed within the tool and compared to the behavior that the SME specified. If the SME did not accurately specify the list of important features for each decision then the behavior produced by the rules will not match the desired behavior that the SME specified. For example, if an entity shoots an opponent in a crowded room the SME should indicate that the reason for this was because of the target being an opponent (not a friend or neutral). If the SME forgets to do so, then when the system simulates the entity preparing to shoot it will determine that the entity cannot uniquely decide which target to select and will prompt the SME for further clarification.\n\nThis ability to detect errors in the knowledge base during the creation and storage of examples can save an enormous amount of time. In a traditional knowledge acquisition process, such an error is often not recognized until the knowledge engineers have invested substantial effort and the SME may have to be contacted again to explain what the correct behavior should be.\n\nAn imp ortant problem in any effort to acquire behavior models from experts is how to verify that the acquired knowledge has been accurately encoded in the HBM. By formally capturing the training scenarios as diagrams, we can both validate that the rules generate the desired behavior in all example scenarios as well as tracing the source of each piece of the knowledge base back to the specific diagram drawn by the SME that lead to its inclusion.\n\nThis approach compares very favorably to standard knowledge acquisition processes, where the final knowledge base is validated by running a series of test cases and having the results inspected by the SMEs. This testing can be expensive if the number of test scenarios is large and performing manual comparisons of the results is a potentially error prone process. Worse, when errors are discovered and changes are made to the knowledge base, the only way to reliably validate the new system is to repeat all of the tests and inspections again.\n\nKnowledge acquisition typically focuses on the initial creation of a knowledge base. In practice with large scale HBMs, there is invariably a need to include new knowledge after the delivery of the model. A significant motivation for this project is that the SMEs for one of our behavior models (TacAir-Soar [1,2]) have been frustrated by their inability to add new missions and tactics quickly and cheaply.\n\nOur example-driven approach allows new knowledge to be added through the addition of new example scenarios. We hope that the tools are sufficiently easy to use that in many cases these additions can be made by the SMEs directly, without the involvement of knowledge engineers at all. The SMEs will maintain the library of example diagrams, rather than maintaining the underlying code. As new examples are added or existing examples are modified, the automatic analysis and validation steps described above will help ensure that changes do not break existing behaviors and introduce errors.\n\nWe are still in the relatively early stages of this project and are still developing the suite of tools. Once completed, we will evaluate the impact the system has on the behavior development process through a series of comparative trials.\n\n1. Baseline trial. In order to create a baseline for comparison, we will have an SME specify, in advance, the requirements for a series of tasks in the MOUT Close Quarters Combat domain. This specification will follow the standard model of using written documents to convey the requirements to the knowledge engineer. The engineer will then use their existing development tools to complete as many of the tasks as possible within the available time.\n\n2. Comparison trial. An SME, working in conjunction with a knowledge engineer, will use the new tool set to complete the same set of tasks. We will then compare the time taken to complete the tasks and the quality of the solutions.\n\nWe may also design and conduct additional comparative trials to evaluate how well an SME can function working alone with the tools or how well a novice user performs with the new tools.\n\nAlthough our examples and evaluation domain both focus on the close quarters combat domain, the suite of tools is largely domain independent. The only requirement for a domain is that we can build a visual representation of the task. In physical tasks this representation is typically a two-dimensional top-down view of the problem domain, but the tools only assume that some such visual representation can be found (e.g. a 3-dimensional view or even a purely internal representation would also suffice).\n\nIn order to demo nstrate that the tools are indeed domain independent, we applied the tool to the air combat domain in a matter of hours (see Figure 4).\n\nVisual Programming is the use of graphics to create computer programs [5]. There are a number of visual programming languages (e.g. ARK [6], VIPR [7], Prograph [8]) where the program code is visually represented and modified directly by the user. These languages focus on general purpose programming languages and tasks and therefore the elements represented are basic programming elements like classes, objects, methods, iterations and branches. These visual programming systems do not use inference or learning in the development of the underlying code, instead relying on the user to directly input all of the new knowledge.\n\nProgramming by Demonstration is a variation on visual programming, where the user demonstrates the desired behavior on sample data. For example, Peridot [9] allows a user to draw a desired interface and then \"use\" the prototype interface while the underlying behavior is induced by the system. Mondrian [10], Chimera [11] and Metamouse [12] are all examples of systems where the user demo nstrates a sequence of graphical editing commands and the system learns new compound graphical procedures. The focus of these systems is also to learn general purpose programming languages (such as LISP). Although they use machine learning techniques to generalize from the sample instances, there is very little transfer of the learned knowledge to new situations. Learning how one dialog box functions has, appropriately, little effect on how another dialog box will operate. In the knowledge acquis ition task for our work, transferring knowledge between different related scenarios is an important goal. Soar's rich knowledge representation and complete AI architecture facilitates this transfer.\n\nVisual programming focuses on the internal representations of the agent while programming by demonstration focuses on the external or task domain representations. Our approach combines these by representing both certain elements of the agent's internal goals and sensed state with external representations of the task domain. This combination gives the user greater insight into the agent's behaviors and reasoning allowing for better transfer of knowledge to the system.\n\nVisual programming has also been used for specifying simple robotic behaviors, both in the game MindRover [13] and in the legged robotic toy Wonderborg by Bandai. These systems show that visual programming can be used effectively by consumers to program simple behaviors without having to use computer languages. Our goal is to expand this type of programming to the complex behaviors required in HBMs.\n\nKnowledge acquisition by assembling primitive comp onents (e.g. [14,15]) typically focuses on the acquisition of new concepts in the representation language and constraints between those concepts. Our work can also be seen as the composition of primitive components. But in contrast, we have focused initially on the acquisition of behaviors described in terms of an existing representation language rather than on extending the representation.\n\nThere are many avenues for future research on this project, including:\n\n• During example generalization, the SME may fail to identify all critical features or might include some that aren't really important to the decision to select a particular behavior. To improve the quality of this feature selection process, we will use machine learning techniques to analyze the scenarios. The learner will identify commonalities across scenarios as well as propose possible specializations to the SME. • We currently test for inconsistencies and errors within a scenario. As each scenario is created, the rules generated from that scenario can be tested against all scenarios in the example library (not just the current scenario) to see if they produce contradictory behavior. This extension will allow us to detect interactions between scenarios that are typically difficult and timeconsuming to identify and correct.\n\n• Example behavior specification is currently limited to a single, linear path through each scenario. We will extend this to include support for alternative paths, negations (things not to do) and temporal ordering constraints. We will also present the user with a visual representation of the structure of the behavior over time (currently we show a particular state at a particular time) and allow the user to modify this structure.\n\n• As we have mentioned earlier, the current approach assumes that the state representation is largely constant and developed in advance of behavior specification. A key future goal is to relax this assumption by providing tools to extend the representation language. The tools must be simple enough for the SME to make these additions, while being efficiently represented so the tool scales well to large and complex domains."
}