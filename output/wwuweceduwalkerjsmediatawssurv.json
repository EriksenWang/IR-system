{
    "title": "Tree-adapted wavelet shrinkage",
    "publication_date": "1999",
    "authors": [
        {
            "full_name": "James S Walker",
            "firstname": "James S",
            "lastname": "Walker",
            "affiliations": [
                {
                    "organization": "Department of Mathematics, University of Wisconsin",
                    "address": {
                        "postcode": "54702-4004"
                    }
                }
            ]
        }
    ],
    "abstract": "N/A",
    "full_text": "During the last decade, several new methods have emerged for removing Gaussian random noise from images. These new methods, which use wavelet transform techniques, are generally superior to the classic Wiener filtering method of denoising. The goal of this survey is to describe one of these new wavelet-based techniques, called tree-adapted wavelet shrinkage (TAWS). The basic theory and implementation of TAWS will be explained, and it will be compared to several other algorithms.\n\nAs an introduction to the capabilities of TAWS, in section 1 we compare it with the classic Wiener filtering method. This comparison will show that TAWS is clearly superior.\n\nTo make this survey understandable to as wide an audience as possible, in section 2 we describe the fundamentals of wavelet analysis of images. There are two interrelated approaches to wavelet theory: the wavelet analysis of analog signals and the wavelet analysis of discrete signals. The interaction between these two modes of analysis is a fundamental aspect of wavelet theory. This brief account of wavelet theory will stress those aspects which are needed for understanding the theory behind the various wavelet denoising methods, including TAWS. Readers who are already familiar with wavelet analysis should feel free to skip (or perhaps skim) this section.\n\nIn section 3 we provide a short discussion of three wavelet-based techniques for image denoising: VISUSHRINK, SURESHRINK, and cycle-spin thresholding. TAWS builds upon the basic concepts provided by these three approaches, so it is important to briefly discuss them. We begin by outlining the now classic technique of VISUSHRINK. VISUSHRINK was one of the first methods to provide an alternative to Wiener filtering. In many cases it can outperform Wiener filtering, especially for images with a low signal-to-noise ratio. VISUSHRINK does suffer, however, from the fact that it generally produces images that appear too smooth, that do not have sharp edges. Two superior methods to wavelet shrinkage are SURESHRINK and cycle-spin thresholding. They produce perceptually sharper denoised images and higher signal-to-noise ratios.\n\nTAWS is built upon the foundation provided by these three earlier methods. It provides fundamental improvements to the basic technique of VISUSHRINK, somewhat analagous to SURESHRINK. In addition, there is a TAWS-adapted variant of cycle-spinning, TAWS-SPIN, which provides relatively high SNRs and excellent perceptual denoisings. Unlike cycle-spin thresholding, TAWS-SPIN is a very simple procedure, requiring no complicated coding or memory bookkeeping.\n\nIn section 4, we describe in detail the theory of TAWS and its implementation. TAWS makes use of relations between edges within an image at multiple resolution levels and the image's wavelet transform. By utilizing these relations TAWS is able to ameliorate the problem of blurred edges that is endemic to classical wavelet shrinkage. An important feature of TAWS is its compatibility with image compression. In particular, TAWS was first discovered in relation to a particular image compression algorithm called ASWDR (adaptively scanned wavelet difference reduction) [Walker, 2000]. We shall briefly outline the ASWDR algorithm in section 4 and highlight its connection with TAWS. The TAWS algorithm was first reported in Walker and Chen (2000). Since then, the TAWS algorithm has been improved to the point where all parameters can be chosen automatically. This improvement will be described here.\n\nA detailed comparison of TAWS with other denoising methods is carried out in section 5, which is the final section of this article. The comparison will be based on SNRs for denoising various test images with simulated Gaussian noise, and also on perceptual comparisons of some of the denoised images. The TAWS method will be shown to be competitive with state-of-the-art methods, such as SURESHRINK, cycle-spin thresholding, and hidden Markov tree methods.\n\nBefore we discuss the theory behind TAWS, we shall first illustrate its superiority over Wiener filtering. Wiener filtering is the classic, Fourier-based method of noise removal. We hope that this comparison will provide sufficient motivation for the reader to further study the TAWS method.\n\nThe type of noise we consider here is additive Gaussian random noise. Given a discrete image F, the noisy image G is related to it by the equation G = F + N, where the noise values N j,k are independent random variables with underlying distributions that are all zero-mean Gaussian normal of variance σ 2 . Wiener filtering is well-known to provide the best linear method for removing such noise [see, e.g., Mallat (1998)]. That is, if the denoised image is obtained by applying a linear transformation to G, then Wiener filtering provides the best such denoising. Best in the sense of least error when measured using a sum of squares of differences over all pixels. In this paper we shall follow tradition and use as our objective measure of error between images, the Signal to Noise Ratio (SNR)-which in decibels is 10 log 10 ( F 2 2 / F -G 2 2 ). In other words,\n\nwhere each sum is over all pixels. Thus Wiener filtering is, among all linear transformations of the noisy image G, the one which maximizes SNR. We shall use the commercial implementation of Wiener filtering from the MATLAB TM image processing toolbox [the wiener2 procedure, Lee (1980)].\n\nAs an example of how Wiener and TAWS denoisings perform, consider the standard test image Peppers shown in Fig. 1(a) and the noisy version of it in Fig. 1(b). The noisy image was produced by adding Gaussian noise with σ = 32, and has an SNR of 11.8 db. In Figures 1(c) and (d) we show the Wiener filtering and TAWS-SPIN denoisings of the noisy image. The TAWS-SPIN denoising is superior both in terms of SNR and also perceptually. The TAWS-SPIN denoising has an SNR of 21.6 db, which is 3.0 db higher than the SNR for the Wiener denoising. Perceptually, the Wiener filtering retains a grainy appearance that strikes observers as a noisy image. On the other hand, the TAWS-SPIN denoising appears to be essentially noise-free, albeit slightly out of focus.\n\nIt is important to expand on the remarks just made about the TAWS-SPIN denoised image. Like all wavelet-based denoisings, a TAWS denoising aims to produce an image free of all contamination by random noise and having greatly increased SNR. Different wavelet-based approaches utilize different theoretical models for imaging in order to achieve this goal. Later, we shall briefly outline these models for some of the other wavelet-based methods, and describe in more detail the model used to develop TAWS. We also noted above that the TAWS-SPIN denoising in Fig. 1(d) appears to be a slightly out of focus version of the original image. We shall see that this is a kind of over smoothing that is endemic to all wavelet-based denoising methods, although TAWS suffers from it to a lesser degree than the other wavelet methods discussed below.\n\nWe conclude this comparison by examining the SNR performance of Wiener filtering and TAWS on a suite of test images. Like all the images considered in this paper, these images are grey level images with 256 intensity levels (sometimes called 8-bit grey level images). Gaussian noise of various standard deviations was added to six different test images. All of the original and noisy images are available at the following website: http://www.uwec.edu/academic/curric/walkerjs/denoisings\n\nThe noisy images were denoised using Wiener filtering and TAWS-SPIN. Table 1 contains the results.\n\nThe data in Table 1 provide strong evidence that TAWS-SPIN is far superior to Wiener filtering. Its superiority is particularly great at the lower SNR values, for noise with σ = 32 and 64. It should also be noted that TAWS-SPIN is a relatively fast procedure. The average time for a TAWS-SPIN denoising of a 256 by 256 image is about 3 seconds, while the average time for a 512 by 512 image is about 12 seconds (on a 1 GHz machine with 256 MB RAM). For optimum speed and efficiency, a TAWS denoising (without cycle spinning) is preferable, but at a cost of reduced SNR and more visible noise artifacts. We shall provide more examples of both TAWS and TAWS-SPIN denoisings, and comparisons with other denoising methods, in section 5.\n\nFor those readers who are not familiar with wavelet analysis, we provide a brief summary in the next section. Even if you are already conversant with wavelets, it might be useful to skim this section as we shall make some remarks pertaining to the theory of TAWS.\n\nThe TAWS denoising method, like all wavelet-based denoising methods, depends on first performing a wavelet transform of the noisy image. Wavelet transforms facilitate separating noise from the transformed image. In this section we briefly summarize the principal aspects of wavelet analysis. Thorough treatments can be found in Chui (1997), Daubechies (1992), Meyer (1992), Resnikoff and Wells (1998), Strang and Nguyen (1996), and Vetterli and Kovačević (1995). Particular emphasis on discrete wavelet analysis is given in Walker (1997) and Walker (1999).\n\nWe begin by summarizing the wavelet analysis of one-dimensional analog signals. The notation for that theory is simpler, but the main ideas for 2D images are captured in the simpler 1D setting. Since our aim is to explain denoising of digital images contaminated by random noise, we need to examine the connection between wavelet analysis of analog signals and wavelet analysis of discrete signals. This connection is mediated by an appropriate signal model. The signal model we shall use is that a noise-free signal is a continuous, piecewise smooth function (by piecewise smooth, we mean that pieces of the graph of the function are continuously differentiable to some order). This model has the virtue of simplicity. It is also fairly realistic, since signals are typically obtained via some measuring process. Therefore, a noise-free signal will have any discontinuities averaged out and irregularities smoothed out by the measuring instrument.\n\nA wavelet basis for functions in\n\nwhich are an orthonormal basis for L 2 (R). Each basis function ψ m j is a dilation by 2 -m and translation by j2 -m of the function ψ. This function ψ is the generating wavelet (or simply wavelet) for this wavelet basis. Because {ψ m j } is an orthonormal basis, the following wavelet series expansion holds for each f ∈ L 2 (R):\n\nwith wavelet coefficients {β m j } defined by\n\nFor the given wavelet system {ψ m j }, the map f → {β m j } is the wavelet transform defined by the wavelet system.\n\nThere are many wavelet bases. A classic example is the Haar basis (Haar, 1910). To define the Haar basis, let 1 S (x) denote the indicator function for the set S. That is,\n\nThe wavelet for the Haar basis is ψ\n\n. Because this Haar wavelet ψ is a step function, any partial sum of the series in Eq. (1) will be a step function. Unfortunately, approximation of an analog signal by step functions is not consistent with our continuous, piecewise smooth signal model.\n\nFortunately, there are wavelet bases which are consistent with our signal model. For example, the Daubechies wavelet bases (Daubechies, 1988). A Daubechies wavelet ψ is continuous and compactly supported (0 outside some finite interval). Furthermore, many Daubechies wavelets are smooth; they are continuously differentiable to some order. In order to obtain smoothness, a Daubechies wavelet ψ is required to have a finite number of zero moments:\n\nx n ψ(x) dx = 0, n = 0, 1, . . . , N.\n\n(3)\n\nNote that (3) is satisfied by the Haar wavelet if N = 0. The Daubechies wavelet satisfying Eq. ( 3) for a given N ≥ 1 is supported on the interval [0, 2N + 1]. Each basis function ψ m j is then supported on the interval [j2 -m , (j + 2N + 1)2 -m ]. These intervals vary in length depending on m, and location depending on m and j. The basis functions ψ m j (x) = 2 -m/2 ψ(2 m xj) can zoom in on particular areas of a signal. As m increases, the supports of these basis functions decrease in length, and varying j allows us to examine particular areas of the signal. The wavelet coefficients β m j encode information about local aspects of the signal f by measuring its correlation with ψ m j . Furthermore, the terms in the series in Eq. ( 1) are multiples of the smooth basis functions ψ m j , so partial sums are smooth. When the signal makes rapid transitions-e.g., when transitioning from one smooth piece to another-the wavelet coefficients β m j that reflect this most prominently (have largest magnitude) will be supported in intervals located around the transition region. Since those terms β m j ψ m j (x) are supported around the transition region, a partial sum of the series in Eq. (1) that includes those terms produces a smooth transition between pieces.\n\nFor our signal model, the zero moment requirement (3) implies that there are many smallmagnitude wavelet coefficients. If f is closely approximated by a polynomial of degree N , as in a truncated Taylor expansion for instance, over the support of ψ m j , then the wavelet coefficient β m j will be approximately zero. This leads to many small-magnitude wavelet coefficients located in regions where the signal is smooth. The combination of orthonormality, compact support, smoothness, and zero moments, yields a series in Eq. ( 1) that is well-adapted to our signal model of continuous, piecewise smooth functions. It also produces an excellent system for performing denoising of signals contaminated by Gaussian noise. Since {ψ m j } is an orthonormal system, the wavelet transform f → {β m j } is orthogonal. The combination of an orthogonal transform (conservation of energy) and large numbers of small wavelet coefficients (compaction of energy) is the principal reason that Gaussian random noise can be separated from the signal. We discuss this further in section 3.\n\nThe series expansion in (1) can be viewed as a limit of a sequence of functions f M defined by\n\nEach f M belongs to a subspace V M of L 2 (R) with basis {ψ m j } m<M, j∈Z . For all the wavelet systems we discuss, there exists a function φ such that, for every M , the set {φ M j (x) = 2 -M/2 φ(2 M xj)} j∈Z is an orthonormal basis for V M . The function φ is called the scaling function for the wavelet system. Because {φ M j } is an orthonormal basis for V M , we have the following scaling series expansion of f M :\n\nwith scaling coefficients {α M j } defined by\n\nFormulas ( 4) and ( 5) express f M as an orthogonal projection of f into V M . The scaling function for the Haar system is φ(x) = 1 [0,1) (x). The Haar scaling function and wavelet satisfy the following identities:\n\nSimilar identities hold for Daubechies wavelets and scaling functions. For each Daubechies system, there are two finite sets of constants {c k } 2N +1 k=0 and {d k } 2N +1 k=0 such that\n\nFor example, if N = 1, Daubechies found that the constants\n\nprovide a solution of (7). They define the Daub4 wavelet system. Notice that for the Haar system, the pair of equations in (6) are a special case of those in (7), obtained by setting N = 0. For the Haar case, the constants in (7) are\n\nThere is a close relation between scaling coefficients and wavelet coefficients. From the identities in (7), we obtain\n\nThe second equation in (9) shows how the wavelet coefficients {β m-1 j } are obtained from the scaling coefficients {α m j }. The first equation in (9) allows us to iterate this procedure. By iteration, all wavelet coefficients {β k j } k<m can be obtained from the scaling coefficients {α m j } at scale m. For all wavelet systems, the scaling function φ(x) is supported on the interval [0, 2N + 1] and satisfies\n\nThis equation will prove useful in deriving the discrete version of wavelet theory.\n\nThe scaling coefficients {α M j }, for large enough M , provide a connection between the world of analog signals and the world of discrete signals. For example, given an analog signal f (x), we can generate discrete data {f j } j∈Z by defining each f j to be f (x j ), where x j = j∆x for some fixed step-size ∆x. We refer to {f j } as uniform samples, or just samples, of f (x). Formula (5) yields the following approximation for sufficiently large M (provided f is uniformly continuous):\n\nBecause of Eq. ( 10) we then havefoot_1\n\nThe approximation in (11) is our justification for assuming, in the discrete setting, that α M j = 2 M/2 f j . In practice, the constant factor 2 M/2 is usually dropped, and we just assume that α M j = f j for each j. The reason for dropping the constant factor 2 M/2 is that the equations in (9) then define an orthogonal transformation on the samples {f j }. This orthogonal transformation is a discrete wavelet transform.\n\nThe equations in (9), starting from initial data {α M j = f j }, provide a discrete wavelet transform. To see how this works we first consider the simplest case, the Haar transform.\n\nFor Haar wavelets, N = 0, c 0 = c 1 = 1/ √ 2, and 9) then yields the following transformation:\n\nIn practice, these formulas are applied to a finite set of initial values. We begin with a vector f = (f 0 , f 1 , . . . , f J-1 ), where we assume J is even. Applying (12) to f yields the vector\n\nThe mapping f → (a 1 | b 1 ) is the 1 st level Haar transform of f . The vector a 1 is called the trend of f , and the vector b 1 is called the fluctuation of f . It is easy to see that the 1 st level Haar transform is orthogonal. It preserves the energy of vectors, as measured by sums of squares.\n\nIf J can be divided several times by 2, then several levels of Haar transform can be performed. For example, if J is divisible by 4, then f has a 2 nd level Haar transform. This is done by iterating the 1 st level Haar transform, by applying it to the trend vector a 1 . This is just a special instance of the formulas in (9) for the Haar case.\n\nAs an example of these ideas, consider the following analog signal\n\nThe graph of the vector f , generated by J = 16, 384 samples of the signal f (x) over the interval [0, 1), is shown in Figure 2 . This 2 nd level transform is also displayed in Figure 2(c), where each of the vectors a 2 , b 2 , and b 1 are graphed over the interval [0, 1). Comparing the graph of a 2 with the graph of f , it is clear that they are closely related in form, although a 2 has only a quarter of the values of f , spaced four times as far apart. The 2 nd level trend a 2 contains 99.990% of the energy of f . Notice that the fluctuations b 2 and b 1 , when graphed over the interval [0, 1), provide excellent locaters for the positions of the jump discontinuities of f (x). We will find similar results for images. But with images, instead of jump discontinuities at isolated points, there will be edges along curves.\n\n0 0.25 0.5 0.75 1 0 (a) 0 0.25 0.5 0.75 1 0 0 (b) 0 0.25 0.5 0.75 1 0 0 0 a 2 b 2 b 1 (c) For Daubechies wavelets, there are similar wavelet transformations. For example, using the coefficients in (8), the 1 st level Daub4 discrete wavelet transform is defined byfoot_2\n\nThese equations define an orthogonal transform f → (a 1 | b 1 ). Higher level Daub4 transforms, as with the higher level Haar transforms, are defined by iteration on the trend vectors a 1 , a 2 , etc. One advantage of Daubechies wavelets is that the moment conditions in (3) imply corresponding discrete moment conditions on the constants {d k } used for generating wavelet coefficients in the discrete transform. These discrete moment conditions are (we set 0 0 = 1 to enable a single statement):\n\nGiven our signal model, these discrete moment conditions imply that there will be many smallmagnitude wavelet coefficients. In fact, if the vector f consists of samples from a signal that can be closely approximated over the support of ψ m-1 j by a polynomial of degree N (as in a truncated Taylor expansion), then ( 14) implies that β m-1 j will be approximately zero. Notice how this last statement for wavelet analysis of discrete signals corresponds to a similar statement made above for wavelet analysis of analog signals. Based on this correspondence, we can state the following four basic properties for the discrete Daubechies wavelet transforms (assuming our signal model):\n\nEnergy Conservation. The wavelet transform is an orthogonal transform.\n\nEnergy Compaction. There are large numbers of small magnitude wavelet coefficients. Most of the energy is concentrated in the trend.\n\nTwo Populations. The larger wavelet coefficients are clustered around sharp transition regions (edges in images). Smaller wavelet coefficients reside in smoother regions.\n\nClustering. Large magnitude wavelet coefficients tend to have some large magnitude coefficients located near them.\n\nNote that the Clustering property was not discussed above. It is not difficult to see that it holds, however. It follows from the large amount of overlap of the supports of the Daubechies wavelets. Consequently, when a wavelet coefficient β m j is relatively large, there is a tendency for one of its neighbors β m j-1 or β m j+1 to be large as well.\n\nNow that we have summarized wavelet analysis for 1D signals, we turn to the case of 2D images.\n\nBecause the 2D theory is essentially the same as for 1D, we shall just briefly summarize its new features.\n\nGeneralizing our signal model for 1D, our model for 2D images will be continuous, piecewise smooth functions F (x, y). Discrete images will consist of J by K matrices F = (F j,k ) obtained via samples from these functions.\n\nWavelet series for 2D images are a simple generalization from 1D series. The wavelet basis functions consist of three kinds: ψ m j (x)φ m k (y), φ m j (x)ψ m k (y), and ψ m j (x)ψ m k (y). For these three kinds of basis functions, the zero moment condition (3) generalizes to powers of both x and y. A 2D wavelet series for F (x, y) is expressible as\n\nHere Ψ m I (x, y) stands for any one of the three types of basis functions, and I is the index set needed for labeling all of these basis functions. There is also a scaling series, using {φ M j (x)φ M k (y)} as basis, which is an obvious generalization of (4). The theory of wavelet series for 2D images is essentially the same as the 1D theory above, with only slight notational modifications, so we now turn to a discussion of 2D discrete wavelet transforms. Such transforms will be applied to matrices, just as in 1D they were applied to vectors.\n\nA discrete wavelet transform of a J by K matrix F, where J and K are both even, is obtained in two steps (Mallat, 1989): (1) transform each row of F by a 1D wavelet transform, obtaining a matrix F; (2) transform each column of F by the same 1D transform. Steps 1 and 2 are independent and may be performed in either order.\n\nStep 1 of this transform process produces J rows of 1D transforms:\n\nStep 2 then produces the following 1 st level transform:\n\nand D 1 are each J/2 by K/2 sub-matrices. The trend A 1 consists of scaling coefficients, while the fluctuations V 1 , H 1 , and D 1 consist of wavelet coefficients for each of the three kinds of wavelet basis functions.\n\nThe trend A 1 contains scaling coefficients for the scaling basis {φ M -1\n\nHence, by a 2D version of (11), it is a lower resolution version of F. For example, consider the image of an octagonal ring shown in Fig. 3(a). Its 1 st level Daub4 wavelet transform is shown in Fig. 3\n\nThe trend A 1 occupies the upper left quadrant of the transform, and it is clearly a lower resolution version of the original image. The vertical fluctuation V 1 contains wavelet coefficients for the basis elements ψ M -1 j (x)φ M -1 k (y); i.e., fluctuations along rows and trends along columns. Wherever there are vertical edges in an image, the fluctuations along rows are able to detect these edges. This tends to emphasize vertical edges, or edges containing a vertical component. This can be seen clearly in Fig. 3(b) where V 1 appears in the upper right quadrant. Notice also that horizontal edges, where the octagonal ring image is constant over long stretches, are removed from V 1 . The horizontal fluctuation H 1 is similar to V 1 , except that the roles of horizontal and vertical are reversed. In Fig. 3(b) the horizontal fluctuation H 1 is shown in the lower left quadrant. Finally, there is the diagonal fluctuation D 1 , which contains wavelet coefficients for the basis elements ψ M -1 j (x)ψ M -1 k (y). This fluctuation tends to emphasize diagonal features, as can be seen clearly in Fig. 3(b) where it occupies the lower right quadrant. Diagonal features are emphasized because fluctuations along rows and columns tend to erase horizontal and vertical edges.\n\nIt is interesting to note that this decomposition of the image into a lower resolution sub-image, along with several sub-images reflective of responses to different edge orientations, is analogous to operations performed by mammalian vision systems. Watson (1987) is perhaps the first paper to establish a close connection between wavelets and vision. A precursor to that paper in the field of image processing was Burt and Adelson (1983). Several papers by Field (1993Field ( , 1994Field ( , 1999) ) and by Field and Brady (1997) explore this connection more fully. A good summary of wavelets and vision can be found in Wandell (1995).\n\nAs with 1D transforms, higher levels of 2D wavelet transforms are computed by iterating the 1 st level transform on the trends. For example, in Fig. 3(c) we show a 2 nd level transform of the octagonal ring image. The trend A 1 from Fig. 3(b) has been transformed into a trend A 2 and fluctuations V 2 , H 2 , and D 2 . The trend A 2 is an even lower resolution version of the original octagon image, while the fluctuations reflect edge details in the lower resolution image A 1 . An example of a 3 rd level transform is shown in Fig. 4.\n\nThe transform used in Fig. 4 is based on the Daub 9/7 wavelet system (Cohen et al., 1992). This system is a very popular one in wavelet-based image processing. For instance, it is used in the JPEG 2000 image compression standard (Gormish et al., 2000).\n\nFigure 4 nicely illustrates the four basic properties of wavelet transforms. The Clustering property, for instance, is apparent from both Figures 4(b) and (c). Figure 4(c) also provides a good illustration of the Two Populations property. Comparing it with the image in Fig. 4(a), we see that larger wavelet coefficients are clustered around edges, such as the boat masts and rigging, and smaller coefficients reside in smoother regions, such as the sky and clouds. The Energy Com- paction property is illustrated by the fact that the 3 rd level trend, which is shown in the upper left corner of Fig. 4(b), accounts for 98.7% of the total energy of the transform coefficients. Finally, the Daub 9/7 system provides good Energy Conservation. Although it is not an orthogonal transform, the Daub 9/7 transform preserves 99.7% of the energy of the original boat image. This example illustrates how close it is to being orthogonal-close enough, in fact, that we can use it for all intents and purposes as if it were orthogonal. The Daub 9/7 transform has some important advantages for image processing. For example, its wavelet basis functions used for reconstruction are twice continuously differentiable and symmetric. One advantage of symmetry is that images can be symmetrically extended past their boundaries, resulting in less boundary artifacts in denoised images than with periodic extension (footnote 3). The Daub 9/7 system was used for the TAWS-SPIN denoisings in section 1. The smoothness of its wavelet basis functions is reflected in the smooth appearance of the TAWS-SPIN denoised image in Fig. 1(d), since that image corresponds to a wavelet series partial sum.\n\nIn this section we examine the fundamental concepts underlying wavelet-based denoising. This will provide the right context for our description of TAWS in the next section. TAWS is based upon improvements to two basic denoising techniques: wavelet shrinkage and cycle-spin thresholding.\n\nA major breakthrough in denoising was achieved with the now-classic methods of wavelet shrinkage (Donoho andJohnstone, 1994 and1995). We shall follow them in referring to their methods as VISUSHRINK and SURESHRINK. Because TAWS shares some ideas in common with VISUSHRINK, we shall first describe this method. The 1D theory for VISUSHRINK captures the main ideas and allows us to explain things more easily, so we shall state results for 1D signals. The extension of these results to 2D images is straightforward. All of the results that we state below for VISUSHRINK are proved in Donoho and Johnstone (1994). See also Donoho et al. (1995) and Donoho (1993).\n\nIn our discussion, we assume that the equation g = f + n describes the 1D noisy signal g obtained from the original signal f by the addition of the noise n. The original signal f consists of samples of an analog signal from our piecewise smooth signal model, and the noise values n j are assumed to be realizations of independent zero-mean Gaussian normal random variables with standard deviation σ, i.e., they are i.i.d. of type N (0, σ 2 ). Wavelet transforms of these signals are denoted by g, f , and n. Since wavelet transforms are linear, we have g = f + n. The orthogonality of wavelet transforms implies that the transformed noise values n j are also i.i.d. of type N (0, σ 2 ).\n\nIn VISUSHRINK, the values g j of the transformed noisy signal are subjected to the following shrinkage function:\n\nwhere the threshold τ is assigned the value τ V = σ √ 2 log J. After shrinkage, the inverse wavelet transform is applied to produce the denoised signal. For a J by K image, the VISUSHRINK threshold is τ V = σ √ 2 log M , where M is the larger of J and K. We shall confine our treatment to square J by J images, so τ V = σ √ 2 log J. To be more precise, the shrinkage function is applied only to wavelet coefficients, the scaling coefficients are left unchanged. With an orthogonal transform of L levels, the noise energy in the trend A L is greatly reduced-as a fraction of total noise energy-when L is large enough. In an image, the noise energy reduction is by a factor of 1/4 L , hence L ≥ 3 is usually sufficient to greatly reduce the fraction of noise energy in the trend. This is in stark contrast to the Energy Compaction property for the original image, which greatly magnifies the sizes of image transform values in the trend. Since the scaling functions corresponding to trend coefficients are widely spread out over the image when L ≥ 3, it follows that relatively small amplitude noise terms are much less visible in the reconstructed image. We shall illustrate this with an example later in this section.\n\nIn wavelet shrinkage, all wavelet coefficients g j of magnitude less than some threshold τ are set to zero. This is called thresholding. The fact that the transformed noise values are i.i.d. of type N (0, σ 2 ), combined with the Energy Compaction and Two Populations properties for the original signal transform f , provides the rationale for this thresholding. If τ is several times larger than σ, as it is in VISUSHRINK, then | g j | < τ almost certainly guarantees that g j is noise-dominated. In fact, for the VISUSHRINK threshold τ V , the following limit holds for all indices j corresponding to wavelet coefficients:\n\nHence | n j | is almost certainly less than τ V . Furthermore, the Energy Compaction and Two Populations properties imply that | f j | ≈ 0 for most indices j. Therefore, asymptotically, the threshold τ V guarantees that VISUSHRINK denoised images will be essentially noise-free.\n\nIn order to apply VISUSHRINK, it is necessary to estimate the standard deviation σ of the noise. Fortunately, it can be estimated from the highest level wavelet coefficients via the following median estimate:\n\nσ ≈ (median of highest level coefficients) 0.6475\n\nThis approximation is reasonably accurate, since it is derived from an exact formula for N (0, σ 2 ) random variables and the highest level wavelet coefficients are mostly noise. A median estimate is used, rather than say a mean estimate, because it is relatively insensitive to the existence of a few high-magnitude outliers. Typically there are such outliers, resulting from the high magnitude wavelet coefficients near the edges in the original image.\n\nVISUSHRINK produces nearly optimal denoising results. This optimality can be expressed in terms of its achieving maximum SNRs. Equivalently, VISUSHRINK minimizes the risk error, where the risk R[ f , f ] between two signals f and f is defined by the following expected value:\n\nLetting f V stand for the VISUSHRINK denoising of the noisy signal, the risk R[f V , f ] which compares f V with the original signal f satisfies (for a sufficiently smooth wavelet system):\n\nwhere C is a constant (dependent only on the choice of wavelet system). This asymptotic result is significantly better than for a Wiener filtering f W of the noisy image. For Wiener filtering, the following holds [see Mallat (1998)]:\n\nfor some constant A. Comparing ( 19) and ( 20), we see that VISUSHRINK is asymptotically superior to Wiener filtering as J → ∞. Since VISUSHRINK is a non-linear method, this superiority for VISUSHRINK does not contradict the optimality of Wiener filtering among linear methods.\n\nThe near optimality of VISUSHRINK is expressed by the following asymptotic result:\n\nwhere R[f I , f ] is the risk of an ideal denoising f I of a piecewise polynomial signal. Other optimality results, using different signal models and alternative measures of risk error, are described in detail in Donoho et al. (1995).\n\nAlthough the results we have described provide ample evidence for the near optimality of VISUSHRINK, it is important to examine its performance on denoising actual images. In Fig. 5 we show four different VISUSHRINK denoisings of the noisy Peppers image shown in Fig. 1(b). The wavelet system used for these denoisings was the Daub 9/7 system. The number of levels used for the wavelet transform ranges from 2 levels to 5 levels. The 2 nd level and 3 rd level denoisings both have greater SNRs than the Wiener filtering shown in Fig. 1(c). The 2 nd level VISUSHRINK denoising has a 1 db higher SNR than the Wiener filtering.\n\nBy carefully examining these four typical denoisings, we can learn a lot about VISUSHRINK, both its strengths and weaknesses. First, observe that although the 2 nd level denoising has the highest SNR, it also exhibits a significant amount of \"mottling\" artifacts. This mottling is due to the noise left unaffected in the 2 nd level trend. As we noted above, the reconstruction of this 2 nd level trend noise consists of low amplitude scaling functions spread out over wide areas within the image. Since a noise standard deviation of σ = 32 produces relatively high energy noise (hence relatively low SNR), the reduction of noise energy by a factor of 1/16 in the 2 nd level trend does not reduce the amplitudes of the reconstructed noise terms sufficiently to render them invisible.\n\nIn the 4 th level and 5 th level denoisings, however, the reductions of trend noise energy by factors of 1/256 and 1/1024, respectively, are quite sufficient to render invisible the reconstructed trend noise. The 3 rd level denoising exhibits trend noise that is just barely visible.\n\nThe most striking weakness of the VISUSHRINK denoisings is the over smoothing of the reconstructed images. This over smoothing is particularly extreme in Figures 5(c) and (d), where it is so great that it causes significant reduction in SNRs. Over smoothing is caused by the VISUSHRINK threshold being set too high to capture the higher level wavelet coefficients needed for producing a sharp image. Since successive trends of f are repeated averagings, there is a blurring of edges in successive trends, producing a decrease in amplitudes of significant wavelet coefficients near these blurred edges. Consequently, the single threshold τ V set by VISUSHRINK tends to threshold out some wavelet coefficients at higher levels that are needed for producing sharp edges in the reconstructed image. This is clearly shown in the images in Fig. 5, which become progressively more blurred as higher level transforms are used.\n\nIt is interesting to compare the TAWS-SPIN denoising in Fig. 1(d) with these VISUSHRINK denoisings. The TAWS-SPIN denoising is significantly less blurred and does not exhibit any mottling. A 5 th level Daub 9/7 transform was used for this TAWS-SPIN denoising, but the threshold was equal to τ V /8. By using a much lower threshold than VISUSHRINK, TAWS-SPIN circumvents the over smoothing problem. Thus TAWS-SPIN is able to employ a 5 th level transform, which completely eliminates any mottling in its denoising. Finally, like the VISUSHRINK denoisings, the TAWS-SPIN denoising appears to be essentially free of any random noise-the image appears to be produced from our piecewise smooth image model.\n\nThe defects in VISUSHRINK denoisings, as well as the \"empirical gap\" present in the size of the (log J) 2 factor in ( 21), has led to continuing efforts to improve the performance of wavelet-based denoising. Major improvements over VISUSHRINK were obtained with the SURESHRINK method and cycle-spin thresholding.\n\nThe SURESHRINK method of Donoho and Johnstone (1995) is also based on wavelet shrinkage. But SURESHRINK uses independently chosen thresholds for each fluctuation at each level of the wavelet transform. This typically results in different shrinkage thresholds for each of these fluctuations. By using different shrinkage thresholds for each fluctuation, SURESHRINK is able to include more significant wavelet coefficients-thus alleviating the blurring problem of VISUSHRINK, producing more detailed images. For example, in Fig. 6 we show two SURESHRINK denoisings of the noisy Pepper image in Fig. 1(b). These images show the typical kinds of improvements obtained with SURESHRINK. The denoised images are considerably sharper than the corresponding VISUSHRINK denoisings with much higher SNRs. In particular, notice that the 4 th level SURESHRINK denoising exhibits essentially no loss of detail, and is slightly better perceptually over the 3 rd level denoising. To select the SURESHRINK thresholds, Donoho and Johnstone (1995) make use of an estimator of risk developed by Stein (1981). This risk estimator ensures that a threshold can be chosen for each fluctuation which, on average, minimizes the risk among all shrinkage thresholds. By minimizing these risks, SURESHRINK produces significantly lower total risk (and thus higher SNR) than VISUSHRINK. For instance, in Johnstone (1999) it is shown that the following holds for the risk error of a SURESHRINK denoising f S of a noisy image:\n\nThis asymptotic result compares favorably with (21); the (log P ) 2 factor has been replaced by just log P .\n\nAs we shall see in section 4, the TAWS method builds upon the SURESHRINK method in that different thresholds are used for different levels and fluctuations of the wavelet transform. Unlike SURESHRINK, however, TAWS uses different thresholds for single wavelet coefficients and correlates the choice of threshold with the location of edges within the image. This helps TAWS to better capture edge details, and thus produce better resolved denoisings than SURESHRINK.\n\nBesides SURESHRINK, another significant improvement over VISUSHRINK is the method of cyclespin thresholding. Cycle-spin thresholding was first described in Coifman and Donoho (1995) and in Lang et al. (1995). Although it has not been established on as firm a theoretical foundation as VISUSHRINK-see, however, Chambolle and Lucier (2001) for some initial work-its basic features are fairly well understood and, in practice, it produces far superior denoisings. Cycle-spin thresholding addresses two related shortcomings of VISUSHRINK. One shortcoming is the lack of shift-invariance of wavelet transforms. From formula (2), it is easy to see that the wavelet transform f (x) → {β m j } is not shift-invariant. This lack of shift-invariance carries over to the discrete wavelet transform as well. For example, in Fig. 7 we show V 1 wavelet coefficients for Daub 9/7 wavelet transforms of the boat image in Fig. 4(a) and a shifted version of this image. At the threshold of τ = 32, these wavelet transforms are not simply shifts of each other (as would be the case with a shift-invariant transform). Notice, in particular, that there are many more significant coefficients near the central mast of the boat in Fig. 7(b). The goal of cycle-spin thresholding is to include such new significant coefficients in shifted-image transforms, thus producing a sharper denoised image which includes more edge details. By including these new significant coefficients, cycle-spin thresholding is able to ameliorate the other shortcoming of VISUSHRINK, its over smoothing.\n\nCycle-spin thresholding achieves shift-invariance by averaging all shifts of the noisy image. More precisely, every cycle-shift (G j-j 0 , k-k 0 ), for j 0 = 0, ±1, . . . , ±(J/2 -1) and k 0 = 0, ±1, . . . , ±(K/2 -1), is denoised and all these denoisings are averaged (after reverse shifting) via a simple arithmetic mean. 4 In practice, it has been found that-rather than using shrinkage for denoising-it is better to use simple thresholding because it yields higher SNRs and perceptually sharper denoisings. By simple thresholding we mean that each transform's values are subjected to the thresholding function:\n\nThus, the coefficient is retained if its magnitude is at least as large as τ , otherwise the coefficient is set to zero. Generally, the VISUSHRINK threshold τ V is used. Although carrying out so many denoisings in order to produce the average denoised image may appear to be inordinately time consuming, it has been shown that the whole process can be performed in O(P log P ) operations, where P is the number of pixels in the noisy image. Since all distinct cycle-shifts are used, the operation of cycle-spin thresholding is shift-invariant.\n\nAs an example of how well cycle-spin thresholding performs, consider the two images shown in Fig. 8. These are cycle-spin thresholdings of the noisy image in Fig. 1(b). These images show the typical kinds of improvements that cycle-spin thresholding provides over VISUSHRINK. The SNR in each case is significantly higher than the SNR for the same level VISUSHRINK denoising.\n\nThere is also much less degradation of quality, and less over smoothing. Consequently it is feasible to use 4 th level and 5 th level transforms with cycle-spin thresholding.\n\nThe TAWS method of denoising also benefits from cycle-spin averaging. The cycle-spin version of TAWS, called TAWS-SPIN, was used for the denoisings described above in section 1. TAWS-SPIN will be described in the next section, where we explain the theory and application of Tree-adapted wavelet shrinkage.\n\nIn this section we describe the theory of TAWS and the details of its implementation. TAWS is designed to exploit, in a computationally simple way, the four basic properties of wavelet transforms that we discussed in section 2. We shall elaborate on these four properties in this section, and show how they lead to the TAWS approach to separating image-dominated wavelet coefficients from noise-dominated coefficients. TAWS performs this separation via three selection principles. These selection principles enable TAWS to select image-dominated wavelet coefficients at much lower thresholds than the VISUSHRINK threshold; thus supplying more details, especially near edges. Capturing more image details gives TAWS denoisings a particularly sharp, focused appearance.\n\nAfter providing a theoretical justification for TAWS, we then provide a detailed description of its algorithm. The TAWS algorithm is a modification of an image compression algorithm, called ASWDR [adaptively scanned wavelet difference reduction, Walker (2000)]. Improvements to ASWDR were made by Walker and Nguyen (2000a). These improvements led to corresponding improvements in TAWS, described in Walker (2001a). This newer version of TAWS is discussed here, instead of the older version introduced in Walker and Chen (2000).\n\nThe close relationship between TAWS and the image compression algorithm ASWDR has allowed for the development of a combined image compressor plus denoiser, called TAWS-COMP. Since combining image compression with denoising is tangential to our main subject, we shall only briefly examine it here. More details concerning TAWS-COMP can be found in Walker (2001a) and Walker (2001b).\n\nThe TAWS method of removing random noise from images is based on the four properties of wavelet transforms-Energy Conservation, Energy Compaction, Two Populations, and Clustering-which we discussed above in section 2. In section 3 we discussed how Energy Compaction implies that noise can be effectively removed from trend coefficients. We also discussed how VISUSHRINK essentially removes all noise-dominated wavelet coefficients by rejecting all coefficients having magnitude less than the threshold τ V . To improve VISUSHRINK denoisings, the TAWS method makes use of the Two Populations and Clustering properties to distinguish image-dominated from noisedominated wavelet coefficients at thresholds that are smaller than τ V . TAWS uses three selection principles to perform this identification of image-dominated wavelet coefficients.\n\nIn order to state these selection principles, we first need to discuss the concepts of child coefficients (children) and parent coefficients (parents). For 1D signals, the wavelet coefficient β m j , corresponding to ψ m j (x) = 2 -m/2 ψ(2 m xj), has two child coefficients β m+1 2j and β m+1 2j+1 . These children correspond to the wavelets ψ m+1 2j (x) and ψ m+1 2j+1 (x). The dilation and translation structure of a wavelet system implies that the support of ψ m j contains the supports of both ψ m+1 2j and ψ m+1 2j+1 . In other words, the children β m+1 2j and β m+1 2j+1 encode information about the signal within the same spatial region as the parent β m j . For example, if the signal is smooth over the support of ψ m j , then the parent and its children will all have small magnitudes (we shall make this more precise below). By applying the parent and child definitions to all levels, we obtain a binary tree structure connecting parents and children.\n\nThe generalization of the notions of parents and children to 2D images is simple. For instance, a vertical coefficient V m j,k is the parent of four children V m+1 2j,2k , V m+1 2j+1,2k , V m+1 2j,2k+1 , and V m+1 2j+1,2k+1 . Similar definitions apply to the horizontal and diagonal coefficients. Thus we obtain a 4-leaved tree connecting parents with children. As for the 1D case, the supports of the 2D wavelets corresponding to children are contained within the supports of the 2D wavelets corresponding to their parents. Hence, if an image is smooth over the support of a wavelet corresponding to a parent, then it will be smooth over all the wavelets corresponding to its children. Consequently, over smooth regions, away from edges, both parents and children will have small magnitude.\n\nWavelet coefficients of small magnitude are less significant, contributing less energy to the image, than wavelet coefficients of larger magnitude. To make this notion of significance preciseand to relate it to the multi-resolution, parent-child tree structure of image transforms-we introduce the following definitions of insignificant and significant coefficients. Given a threshold T > 0, we say that a parent is insignificant if its magnitude is less than T , and a child is insignificant if its magnitude is less than the half-threshold T /2. Likewise, a parent is significant when its magnitude is greater than or equal to T , and a child is significant when its magnitude is greater than or equal to T /2. It is important to note that insignificance and significance are relative notions which depend on the size of the given threshold T . Furthermore, the half-threshold T /2 is used for testing for significance of children. We will show below that, with piecewise smooth images, it is correct to use this half-threshold for children. Moreover, we shall see that using these different thresholds for parents and children closely corresponds to the tree-based coding structure of the ASWDR image compression algorithm. By using the coding structure of this algorithm, it is possible to determine significance of parents and children in a logically consistent manner.\n\nWe have now provided all of the background needed for stating the TAWS selection principles. For wavelet coefficients having magnitudes below the VISUSHRINK threshold, TAWS uses the following three principles to distinguish image-dominated coefficients from noise-dominated coefficients:\n\nA. Only accept significant children with significant parents.\n\nReject a significant parent if all its children are insignificant.\n\nA good illustration of these Selection Principles can be seen in Fig. 9. In Figures 9(b) and (c) we show the locations of significant parents and children, using threshold T = 24, for a Daub 9/7 transform of the Peppers test image. The grey pixels in both these images indicate insignificant coefficients, and the white pixels indicate significant coefficients. The similarity of the regions made\n\n(a) Peppers (b) Parents, T = 24 (c) Children, T = 12 up of grey pixels in the two images indicates that insignificant parents tend to have insignificant children, which implies Selection Principle A. Likewise, the similarity of the regions made up of white pixels indicates that significant parents tend to have some significant children, which implies Selection Principle B. Finally, the clustering together of significant coefficients (in either image) illustrates the validity of Selection Principle C. We shall now show how these Selection Principles are derived from basic ideas of wavelet analysis. Selection Principle A follows from the fact that, in most instances, the children of an insignificant parent will all be insignificant. More precisely, within a smooth region of an image, the implication |parent| < T =⇒ |child| < T /2 (23)\n\nholds for thresholds T that are not too small. To see why (23) holds, let's consider the 1D case. Suppose that the wavelet ψ has K ≥ 1 zero moments, and that the 1D signal f (x) has an n-term Taylor expansion (for 1 ≤ n ≤ K) about the point x j = j2 -m . That is,\n\nwhere t x lies between x and x j . Equation ( 24) is consistent with our piecewise smooth signal model, provided x lies within a smooth region of the image. It is also consistent with our model to assume that |f (n) (x)| is bounded by a constant B, for all x within a smooth region and lying a fixed distance from the transition points between different smooth regions. We may also suppose that the wavelet ψ is supported within the finite interval [-a, a]. 5 The wavelet coefficient β m j is then bounded as follows (using zero moments, and the bound on |f (n) (x)|):\n\nUsing the Schwarz inequality on the last integral above yields\n\nInequality ( 25) is the key to proving (23).\n\nTo use (25) to prove (23), we first note that the right side of (25) decreases towards zero at an exponential rate, as n increases and as m increases. Therefore, if the threshold T is not too small, we may assume that\n\nInequality ( 26) will hold under a range of conditions: (1) if T is moderately large, (2) if n is sufficiently large (sufficient smoothness of the signal), (3) if m is sufficiently large (coefficients in lower levels). From ( 25) and ( 26) we obtain\n\nBecause some mixture of conditions (1) to (3) will generally hold for large numbers of wavelet coefficients-provided they are isolated from sharp transition regions between different smoothness regions-it follows that ( 23) is valid in a statistical sense (valid for most cases, provided sharp transition regions are avoided and the threshold T is not too small). The general validity of (23) establishes Selection Principle A.\n\nWe have established the general validity of Selection Principle A for 1D piecewise smooth signals. Similar reasoning applies to the 2D case of piecewise smooth images. As long as the support of the wavelets corresponding to parent coefficients lie within a smoothness region (away from sharp transitions near edges) and the threshold T is not too small, then (23) will be valid; hence Selection Principle A will also be valid. Notice that our argument for Selection Principle A was based on smoothness of the image, and does not apply to random noise.\n\nIn demonstrating Selection Principle A, we established the validity of the implication in (23). In other words, an insignificant parent has all of its children insignificant. Applying this last statement to all descendants of an insignificant parent, we obtain a zero-tree of insignificant coefficients. These zero-trees have been used extensively in image compression algorithms, such as the EZW algorithm of Shapiro (1993) and the SPIHT algorithm of Said and Pearlman (1996a). 6Selection Principle B can be verified using statistics assembled from natural images. In the TAWS algorithm described below, Selection Principle B is used as a criterion for choosing newly emergent significant children when the threshold T is decreased to a half-threshold T /2. If a parent coefficient was significant when the threshold is T , then we define the conditional probability P (new | old) by\n\nThus P (new | old) is the probability that a new significant child, whose magnitude satisfies T > |child| ≥ T /2, has an old significant parent, whose magnitude satisfies |parent| ≥ T .\n\nIn Table 2 we give the fraction of new significant children having old significant parents at several Daub 9/7 transform levels for four test images and for random noise. The values for the random noise were obtained by averaging five realizations of Gaussian random noise with mean 0 and standard deviation 28. (Although only five realizations were used, the results in Table 2 for the noise were quite stable showing deviations of no more than ±0.01 for all values.) The data in this table clearly show that the probability in ( 28) is much greater for moderately high threshold values for the test images than for the random noise. In other words, for the random noise only, it is highly unlikely that a newly significant child value will have an old significant parent when the threshold is greater than the standard deviation for all the child coefficients. This provides a statistical validation of Selection Principle B as a criterion for choosing newly emergent significant children when the threshold T is decreased to a half-threshold T /2. Selection Principle B is a consequence of using wavelets that are continuous and have compact support. Consequently, sharp transitions in image values near edges produce relatively higher values for the inner products of the image with wavelet basis functions supported in regions overlapping these edges. Thus relatively higher transform values occur near edges. Detailed theoretical verifications of this fact are described in Mallat and Hwang (1992), Mallat (1998), andWang (1995). Furthermore, since the support of the wavelet corresponding to a parent contains the supports of the wavelets corresponding to its children, it follows that a significant value of a parent occurring near an edge will, at least statistically, imply that some of its children will also be significant. Table 2 provides supporting data for this last assertion.\n\nFinally, we give a brief discussion of the validity of Selection Principle C. Our argument relies on statistical data compiled by other researchers. Selection Principle C follows from the large amount of overlap of supports of adjacent wavelet basis functions. Because of this overlap, if a wavelet coefficient is large near an edge, then there is a high probability that adjacent wavelet coefficients will also be large. Huang and Mumford (1999) have assembled statistics, for a large number of test images, which show a high correlation between magnitudes of adjacent coefficients. They have also developed theoretical models explaining this correlation. Liu and Moulin have analyzed the degree of mutual information contained in neighboring coefficients versus parent-child coefficients. They found that neighboring coefficients are, in general, slightly more closely correlated than parent-child coefficients. Buccigrossi and Simoncelli (1999) report similar findings. Since correlation between parent-child coefficients is expressed by the validity of Selection Principles A and B, it follows that Selection Principle C must be valid as well.\n\nThe TAWS algorithm combines the three TAWS Selection Principles together with the ASWDR image compression algorithm. Because TAWS is an adaptation of ASWDR, we shall first summarize ASWDR. The TAWS-COMP procedure for simultaneous compression and denoising is also based on ASWDR, hence we have a second reason for describing ASWDR.\n\nThe ASWDR image compression algorithm consists of five parts, as shown in Fig. 10. In the Initialization part of ASWDR, a wavelet transform of the image is computed. An initial threshold value T 0 is chosen so that all transform values have magnitudes that are less than 2T 0 and at least one has magnitude greater than or equal to T 0 . The purpose of the loop indicated in Fig. 10 is to encode significant transform values by the method of bit-plane encoding. A binary expansion, relative to the quantity 2T 0 , is computed for each transform value. The loop constitutes the procedure by which these binary expansions are computed. As the threshold is successively reduced by half, the parts labeled Significance Pass and Refinement Pass compute the next bit in the binary expansions of the transform values. 7 We shall see below that the replacing of the threshold T by its half-value T /2, along with the looping through the Significance Pass, results in a logically consistent method for testing the significance of parents and children.\n\nWe shall now describe each part of the ASWDR algorithm in more detail. The Initialization part, as described above, involves wavelet transforming the image and choosing an initial threshold T = T 0 . One other task in Initialization is the assigning of a scan order. For an image with P pixels, a scan order is a one-to-one and onto mapping, g i,j = x k , for k = 1, . . . P , between the transform values ( g i,j ) and a linear ordering (x k ). This initial scan order is a zigzag from higher to lower levels (Shapiro, 1993) scanning through the vertical coefficients, and zigzag scanning through the diagonal coefficients.\n\nThe next part of the algorithm is the Significance Pass. In this part, new significant transform values x m satisfying T ≤ |x m | < 2T are identified. Their index values m are encoded using the difference reduction method of Tian and Wells (1996). The difference reduction method essentially consists of a binary encoding of the number of steps to go from the index of the last significant value to the index of the present significant value. More details can be found in Tian and Wells (1998) or Walker and Nguyen (2000b). The quantized value q m = T sgn(x m ) is assigned to the index m at this point.\n\nFollowing the Significance Pass, there is a Refinement Pass. The Refinement Pass is a process of refining the precision of old quantized transform values q n , which satisfy |q n | ≥ 2T . Each refined value is a better approximation of an exact transform value. The precision of quantized values is increased to make them at least as accurate as the present threshold. For example, if an old significant transform's magnitude |x n | lies in the interval [32,48), say, and the present threshold is 8, then it will be determined if its magnitude lies in [32, 40) or [40, 48). In the latter case, the new quantized value becomes 40 sgn(x n ), and in the former case, the quantized value remains 32 sgn(x n ). The Refinement Pass adds another bit of precision in the binary expansions of the scaled transform values {x k /(2T 0 )}.\n\nFollowing the Refinement Pass, the New Scan Order part is performed. This is the part of the ASWDR algorithm where ideas similar to the TAWS Selection Principles are employed. A new scan order is created by a bootstrap process proceeding from higher to lower levels of the wavelet transform. We call this bootstrap process the ASWDR New Scan Order Procedure: ASWDR New Scan Order Procedure At the highest level (which contains the trend coefficients), use the indices of the remaining insignificant values as the scan order at that level. Assuming that the new scan order is already created at level r, a new scan order is created at level r -1 in the following way. Use the old scan order to scan through the significant wavelet coefficients at level r in the transform. The first part of the new scan order at level r -1 contains the insignificant children of these significant wavelet coefficients. Rescan through the insignificant wavelet coefficients at level r. The second part of the new scan order at level r -1 contains the insignificant children, at least one of whose siblings is significant, of these insignificant wavelet coefficients. Rescan a second time through the insignificant wavelet coefficients at level r. The third part of the scan order at level r -1 contains the insignificant children, none of whose siblings are significant, of these insignificant wavelet coefficients. (Although this description is phrased in terms of a three-scan process, it can be performed in one scan by linking together three separate chains at the end of one scan.) Use this new scanning order for level r -1 to create the new scanning order for level r -2, until all levels are exhausted.\n\nThe rationale for the creation of a new scan order is to reduce the number of steps between the new significant values which emerge when the threshold T is reduced to T /2. For example, consider Figures 9(b) and (c). If the value of the threshold T is 24 for the Peppers image, then the first part of the new scan order for the transform coefficients in Fig. 9(c) will be the insignificant children of the significant parent locations shown as white pixels in Fig. 9(b). This will capture a high percentage of new significant children within the first part of the new scan order-thus greatly reducing the number of steps, and hence the number of bits needed for encoding. Notice also how the locations of significant values are highly correlated with the locations of edges within the Peppers image. The scanning order of ASWDR dynamically adapts to the locations of these edge details in an image, and this enhances the resolution of these images in ASWDR compressed images. 8 Since the TAWS algorithm makes use of a similar dynamically adapted scanning order, it also enjoys high resolution of edges. Consequently, as we shall see in section 5, TAWS denoised images are sharper, more in focus, than denoisings obtained with other wavelet methods.\n\nThe ASWDR procedure continues until either the threshold T is less than some preassigned value τ , or until a preassigned number of bits (a bit budget) has been used for encoding. The first stopping criterion is used by the TAWS algorithm, while the second stopping criterion is used by the TAWS-COMP simultaneous compression and denoising algorithm.\n\nThe TAWS denoising algorithm combines the three TAWS Selection Principles with the ASWDR image compression method summarized above. In order to achieve this combination, three parameters are used.\n\nOne parameter is the descent index D, which is a non-negative integer. The TAWS threshold τ T is then set at α τ V /2 D , where the height index α satisfies 1 ≤ α ≤ 2. For all of the TAWS denoisings reported on in this survey, the value of this second parameter α was set as √ 2. Note that if D = 0 and α = 1, then τ T = τ V and TAWS reduces to the VISUSHRINK method. The third parameter is a depth index D, which is an integer lying between 1 and L, where L is the number of levels in the wavelet transform. We shall clarify below the nature of the depth index D.\n\nThe basic structure of TAWS is diagrammed in Fig. 10. We now describe in detail the implementation of TAWS.\n\nStep 1 (Initialization). As described above for the ASWDR algorithm, in this step the image is transformed, a scanning order {x k } is defined for searching through the transformed image, and an initial threshold T = T 0 is chosen. For later use, the integer K is defined via the equation (2T 0 )/2 K = ατ V . That K is an integer can be arranged by a rescaling of transform values. This rescaling of transform values is needed to ensure that T = τ T after K + D cycles through Steps 2 to 5.\n\nStep 2 (Significance pass). Determine new significant index values, those indices m for which x m has a magnitude satisfying T ≤ |x m | < 2T . If T ≥ τ V , then assign q m = T sgn(x m ) as the quantized value corresponding to x m .\n\nStep 3 (Refinement pass). Refine the quantized transform values corresponding to old significant transform values. Each refined value is a better approximation to an exact transform value. The refinement process corresponds to computing the bits in the binary expansions of the scaled transform values {x m /(2T 0 )}.\n\nStep 4 (New Scan Order). Create a new scanning order as follows. For the first K cycles through Steps 2 to 5, during which T ≥ τ V , produce a new scanning order by following the ASWDR New Scan Order Procedure.\n\nFor cycles K + 1 to K + D, the threshold T satisfies T < τ V . For these cycles, proceed as follows. If the level r is larger than D, then use the ASWDR New Scan Order Procedure to produce the new scan order for level r -1. For each level r from D to 2, produce the new scan order at level r -1 as follows. Use the old scan order to scan through the significant wavelet coefficients in level r. Include in the new scan order all of the insignificant children of x m . (This implements Selection Principle A, and implements Selection Principle B as a searching procedure for new significant coefficients.)\n\nStep 5 (Divide Threshold by 2). Replace the threshold T by 1/2 of its value and repeat Steps 2 to 4 until this new threshold T is less than τ T .\n\nWhen the procedure is finished, Selection Principle C is invoked by setting to zero all quantized transform values of magnitude less than τ V which do not have a non-zero adjacent value. Furthermore, in order to ensure greater accuracy of non-zero quantized transform values, the refinement pass is executed several times more (five further refinements usually provide sufficient increase in SNR). Finally, shrinkage is applied using τ = τ T , and an inverse transform is performed on the quantized transform to produce a denoised image.\n\nAn important feature of the TAWS algorithm is its fast execution. The whole procedure can be performed in O(P ) operations, where P is the number of pixels in the noisy image. In fact, it takes only 1.3 seconds to denoise a 512×512 image on a 1 GHz machine with 256 MB RAM. Moreover, this speed was attained without any coding optimizations (such as expressing the rescaled transform in pure binary form to allow for replacing divisions by bit-shifts and for faster comparisons).\n\nIn the original description of TAWS in Walker and Chen (2000), the choices of the parameters L, D, and D, were not automatically specified. With the improvements of TAWS described here, it is now possible to specify choices for these parameters which are automatically set, independently by the algorithm. For all images tested, the following parameter values have been found to generally produce the best denoisings (highest SNRs and good visual characteristics). The level parameter is set as L = 5. Using 5 levels in the Daub 9/7 transform greatly reduces the fraction of noise energy in the 5 th level trend. The descent index is set as D = 3. The lowest possible threshold is then √ 2τ V /8 which is slightly above the standard deviation σ of the noise. The depth parameter D is given one of two values, depending on the size of σ. If σ ≤ 25.6, then the depth parameter is set as D = 2; and if σ > 25.6, then the depth parameter is set as D = 3. The reason for the difference is that when σ is fairly large (> 25.6), then more noise values contribute significant energy at higher levels of the transform. Using D = 3 instead of D = 2 allows for a more stringent application of the TAWS Selection Principles, including at one higher level of the transform. Consequently, more noise is generally removed and a higher SNR is generally obtained, when D = 3 is used with higher values of σ. As an illustration of the effectiveness of the TAWS algorithm, consider the images shown in Figures 11 and 12. In Fig. 11(a) we show the Boats test image. A portion of the Daub 9/7 transform of this image is shown in Fig. 11(b). To be precise, the 1 st level vertically oriented coefficients are shown. Only significant coefficients, those whose magnitude is at least as large as τ T = √ 2 τ V /8, are shown in Fig. 11(b) and in Figures 11(c) through 11(f). The grey background in those images corresponds to insignificant coefficients, darker pixels indicate negatively valued significant coefficients, and lighter pixels indicate positively valued significant coefficients. Consequently, the TAWS denoised image in Fig. 12(d), resulting from the transform in Fig. 11(f), is a sharper, more focused image than the VISUSHRINK denoising and yet it does not contain residual noise like Fig. 12(c). The TAWS denoising is superior, both perceptually and in terms of SNR, to both the VISUSHRINK denoising and the denoising obtained by shrinkage with τ T . This example illustrates the superiority of TAWS over VISUSHRINK. Much higher performance denoisers, however, have superseded VISUSHRINK. In section 5, we shall compare TAWS with such state of the art denoisers.\n\nSince it utilizes thresholding, the TAWS algorithm can be improved by an averaging of shifted versions of the noisy image, just as we discussed in section 3 for cycle-spin thresholding. This averaging algorithm, called TAWS-SPIN, simply consists of averaging TAWS denoisings of a finite number of cyclic shifts of the noisy image: (G i-k,j-m ) for k, m = 0, ±1, . . . , (N/2) -1. It is important to remember that although cycle-spin thresholding is an O(P log P ) method, it still requires considerable memory resources-and fairly complicated bookkeeping-to store parts of previously computed transforms of shifted images. The TAWS-SPIN method requires only a modest increase in memory resources-just two extra arrays equal in size to the image array for holding the image shifts and for storing partial averages-and there is no extra bookkeeping needed, since complete denoisings are performed to create the averages.\n\nExperiments with TAWS-SPIN show that SNR values rapidly converge as the number of shifts increases, and that N = 1 yields a good compromise between increased SNR values and increased time and memory consumption needed to perform averages. For N = 1, just 9 denoisings are averaged, hence TAWS-SPIN still performs with O(P ) complexity. As mentioned in section 1, the time for a TAWS-SPIN denoising with N = 1 of a 512 by 512 image is about 12 seconds. Using N = 2 provides almost the highest possible SNR values (at about 3 times higher cost in calculation time than for N = 1). The TAWS-SPIN denoisings in section 1 were obtained using N = 1, while those in section 5 were obtained with N = 2. Experiments have also determined that a height index of α = 2, a descent index of D = 4, and a depth index of either D = 2 (when σ ≤ 25.6) or D = 3 (when σ > 25.6), provide excellent TAWS-SPIN denoisings. All of the TAWS-SPIN denoisings reported on in this survey used these parameter settings. By using higher values for α and D, the TAWS-SPIN algorithm applies the TAWS Selection Principles over a greater range of threshold values (beginning with a higher value of ατ v ), and is thus able to select out more residual noise values than TAWS alone.\n\nA major attribute of TAWS is its close connection to the image compression procedure ASWDR. This close connection allows for the TAWS algorithm to be transformed into a simultaneous compressing and denoising algorithm, called TAWS-COMP. The essential idea is to simply transmit bits during the Significance Pass and Refinement Pass-as described above for the ASWDR compression algorithm-which encode index values for new significant coefficients and how to refine old significant coefficients. These bits constitute the compressed image. They describe how to rebuild the denoised image transform. When compressing, however, any noise-dominated transform values that would be removed by Selection Principle C (which is invoked after Steps 1 through 5 in TAWS) should not be encoded. Therefore, Selection Principle C must be invoked during Steps 1 through 5. Moreover, by removing isolated noisy transform values-which contribute to isolated noisy artifacts in TAWS denoised images-both the perceptual quality and compression ratio of the denoised images can be improved. Most of these isolated noisy transform values can be removed by using Selection Principle B to remove significant parents without significant children as part of Step 4.\n\nWe now give a description of the TAWS-COMP simultaneous compression and denoising algorithm. In this description we highlight the compressing parts of the algorithm by using italics.\n\nStep 1 As described above for the ASWDR algorithm, in this step the image is transformed, a scanning order {x k } is defined for searching through the transformed image, and an initial threshold T = T 0 is chosen.\n\nStep 2 (Significance pass). Determine new significant index values, those indices m for which x m has a magnitude satisfying T ≤ |x m | < 2T . If T ≥ τ V , then assign q m = T sgn(x m ) as the quantized value corresponding to x m . Encode these new significant indices using the difference reduction method described by Tian andWells (1996, 1998) or Walker and Nguyen (2000b).\n\nStep 3 (Refinement pass). Refine quantized transform values by successively computing the bits in the binary expansion of scaled transform values {x[m]/(2T 0 )}. Encode the next bit in the binary expansion for each pass.\n\nStep 4 (New Scan Order). Create a new scanning order as follows. For the first K cycles through Steps 2 to 5, during which T ≥ τ V , produce a new scanning order by following the ASWDR New Scan Order Procedure.\n\nFor cycles K + 1 to K + D, the threshold T satisfies T < τ V . For these cycles, proceed as follows. If the level r is larger than D, then use the ASWDR New Scan Order Procedure to produce the new scan order for level r -1. For each level r from D to 2, produce the new scan order at level r -1 as follows. Use the old scan order to scan through the significant wavelet coefficients in level r. If such a significant coefficient, x m , satisfies |x m | < τ V and has no significant children, then set x m = 0 and q m = 0. (Thus invoking Selection Principle B.) On the other hand, if |x m | < τ V and x m has some significant children, or if |x m | ≥ τ V , then include in the new scan order all of the insignificant children of x m that have at least one significant sibling. (This implements Selection Principle A, and partially implements Selection Principle C, for these lower levels.)\n\nStep 5 (Divide Threshold by 2). Replace the threshold T by 1/2 of its value and repeat Steps 2 to 4 until this new threshold T is less than τ T .\n\nEither integer-to-integer (Calderbank et. al, 1998), or floating point wavelet transforms, can be used with the TAWS-COMP procedure. When an integer-to-integer transform is used, then a rescaling of the transform is performed during the Initialization Step which approximates an orthogonal transform (Said and Pearlman, 1996b). (When an integer-to-integer transform is used with TAWS, then the rescaling of transform values in the Initialization Step of TAWS is replaced by the rescaling just described for TAWS-COMP.)\n\nWhen the TAWS-COMP procedure is finished, then decompression can be performed on the compressed data. This decompression consists of the following 5 steps:\n\n1. Recapitulate Steps 1-5 above in order to obtain the quantized transform.\n\n2. Round quantized transform values to the midpoints of their quantization bins (to improve accuracy).\n\n3. Set to zero all quantized transform values having magnitude less than τ V which do not have a non-zero adjacent value (this implements selection principle C).\n\n4. Apply shrinkage to the quantized transform using threshold τ T .\n\n5. Invert the quantized transform (and round to 8-bit precision).\n\nThe description of TAWS-COMP given above makes it appear as if the only exit point of the compression procedure is when T < τ T occurs in Step 5. However, TAWS-COMP also allows for checking the cumulative total of bits output throughout the compression process, and exiting may occur when this bit total exhausts a prescribed bit budget. Thus TAWS-COMP can match preassigned bit rates. A similar exiting criterion within the decompression process allows TAWS-COMP to decompress at any bit rate up to the total compressed rate.\n\nA more complete description of TAWS-COMP can be found in Walker (2001b). An example of a TAWS-COMP compression plus denoising will be given below in section 5. This example will illustrate that TAWS-COMP can perform denoising nearly as well as TAWS while simultaneously compressing the image.\n\nThe TAWS procedures can be used with a variety of different transforms. In this survey, we employed the Daub 9/7 transform exclusively. Other transforms that can be used are: (1) complex wavelet transforms [Kingsbury, 1998], (2) steerable wavelet transforms [Simoncelli and Freeman, 1995], (3) integer-to-integer wavelet transforms [Calderbank et al., 1998], and (4) the GenLOT transforms [de Queiroz et al., 1996] when mapped to a four-leaved tree structure [Tran, 1999, andTran andNguyen, 1999].\n\nFurther research is needed on the effectiveness of these transforms for TAWS denoising and how they compare. The complex and steerable wavelet transforms have already proven themselves to be quite effective in other denoising algorithms [Choi et al. (2000), and Strela et al. (2000)].\n\nIn this last section of our survey, we compare TAWS with other prominent denoising methods. This comparison will be done in two ways. First, we shall make an objective comparison using SNR. We compare the increases in SNR, obtained using TAWS and other denoising methods, on a suite of test images contaminated with Gaussian random noise having a range of standard deviations. This comparison will show that TAWS produces SNRs essentially equal to those produced by SURESHRINK, and that TAWS-SPIN produces the highest SNRs of all of the methods examined. Second, because SNR does not always accord well with human visual perception, we shall also make a subjective, visual comparison of several denoisings. This visual comparison will illustrate the superior ability of TAWS to produce denoisings that are sharply focused with well-defined edges.\n\nIn Table 3 we list the SNRs for denoisings of five standard test images, known as Lena, Goldhill, Boats, Barbara, and Peppers. These images were contaminated with Gaussian random noise having standard deviations of σ = 8, 16, 32, and 64. These standard deviations range from fairly low (σ = 8) to moderate (σ = 16), to moderately high (σ = 32) and extremely high (σ = 64). Seven different denoising methods were used to produce the SNRs in Table 3. These methods include Wiener filtering, SURESHRINK, TAWS, cycle-spin thresholding, and TAWS-SPIN, which were discussed above. In addition to these methods, Table 3 also includes SNRs from two other prominent denoising methods, the HMT method (Romberg et al., 1999a) and the HMT-SPIN method (Romberg et al., 1999c). These HMT methods use a Bayesian probabilistic approach in connection with Markov relations for the significance states, relative to thresholding, of the nodes in trees of wavelet coefficients. Complete details can be found in the papers cited above. HMT methods bear some similarity to the TAWS procedure, but they are based on a probabilistic decision theory, while the decision theory for TAWS is deterministic. Columns 2 to 5 in Table 3 contain the SNRs for denoisings using Wiener filtering, the HMT method, SURESHRINK, and TAWS, respectively. These methods do not employ spin-averaging. Among these non-spin averaged methods, the data in Table 3 clearly indicate that SURESHRINK generally produces the highest SNRs. TAWS produces higher SNRs than SURESHRINK for onequarter of the denoisings. The differences in SNRs, however, between the three wavelet-based methods (HMT, SURESHRINK, and TAWS) are not very significant-generally less than 0.5 db. In terms of SNRs, these three methods provide roughly equivalent performance. These wavelet-based methods all outperform Wiener filtering, particularly at the higher noise levels (σ = 32 and 64).\n\nThe remaining columns in Table 3, columns 6 to 8, contain the SNRs for spin-averaged denoisings. These spin-averaged denoisings are cycle-spin thresholding, HMT-SPIN, and TAWS-SPIN. All of these methods are averages of denoisings of cyclic shifts, (G i-k,j-m ) for k, m = 0, ±1, . . . , (N/2) -1, of the noisy image. In each case, a certain type of denoising method-either thresholding, or HMT, or TAWS-is applied to each cyclic shift, and then all denoisings are averaged (after reverse shifting). For each method, it is possible to carry out this work in O(P log 2 P ) operations.\n\nIt is important to remember, however, that although cycle-spin methods have O(P log 2 P ) complexity, it still requires considerable memory resources to store parts of previously computed transforms of shifted images. Experiments show that SNR values rapidly converge as the number of shifts increases, and that N = 2 (averaging 25 different shiftings) yields a good compromise between increased SNR values and increased time and memory consumption needed for performing averages. The results reported in Table 3 for each of the three spin-averaged methods are for the case of N = 2. These results show that TAWS-SPIN generally produces the highest SNRs, and sometimes its SNRs are significantly higher (at least 0.5 db higher) than one or both of the other spin-averaged methods. TAWS-SPIN also generally provides the highest SNR values of all seven of the denoising methods.\n\n(a) Boats image (b) Noisy image (c) SURESHRINK (d) TAWS (e) HMT (f) Wiener\n\nAlthough SNR provides an objective standard for measuring the effectiveness of denoising, it does not always accord well with human visual perception. For example, although the VISUSHRINK denoisings in Fig. 5 all have much higher SNRs than the noisy image in  There is an important point to consider here. Human visual perception has been refined over millions of years of evolution, thus producing an excellent system for distinguishing image details from noise. Distinguishing image details is vitally important-the survival of individual humans, and our mammalian ancestors, has depended upon it. Our perceptual ability to separate image details from noise explains the VISUSHRINK example discussed in the previous paragraph. When a denoising appears blurred, and many image details are lost, human observers will prefer the original noisy image. The ability of TAWS to retain edge details, and the importance of such details for the focused appearance of images in our visual perception, enables TAWS denoisings to appear more sharply focused than denoisings with other methods. The examples discussed below will confirm this last statement. Our first example is a denoising of the noisy Boats image shown in Fig. 13(b). This noisy image was obtained by adding random noise with σ = 20 to the Boats image in Fig. 13(a). In Figures 13(c) to (f), we show denoisings of this noisy image using SURESHRINK, TAWS, HMT, and Wiener filtering. Although the SURESHRINK denoising has the highest SNR, the TAWS denoising is slightly more focused than any of the other denoisings (excepting, perhaps, the Wiener filtering). The HMT denoising appears particularly blurred. Although the Wiener filtering might appear slightly more focused than the other denoisings, it retains considerable amounts of residual noise. These observations are even more clearly evident in the magnifications shown in Fig. 14.\n\nAs a second example, we used these same denoising methods on the Barbara image, contaminated with random noise having σ = 16. Because it is nearly impossible to distinguish between the full-size denoisings,foot_8 we show in Fig. 15 magnifications of the various denoisings. Although SURESHRINK has a slightly higher SNR, it retains some annoying isolated noise artifacts. The HMT denoising is somewhat blurred and also exhibits some isolated noise artifacts. The Wiener filtering, as with the last example, contains a large amount of residual noise (hence we shall not consider any more examples of Wiener filtering). Finally, we note that the TAWS denoising appears the sharpest of all the wavelet-based denoisings. Note, in particular, the sharpness of the stripes in Barbara's scarf and the faithful reconstruction of Barbara's lips. The TAWS denoising also seems the most free of noise artifacts. We now consider an example of spin-averaged denoising. In Fig. 16, we show a cycle-spin thresholding, a TAWS-SPIN, and a HMT-SPIN denoising of the noisy Boats image with σ = 20. In this case, the TAWS-SPIN denoising has the highest SNR and appears the sharpest, most clearly focused of the denoisings. The magnifications of these images in Fig. 17 confirm the superiority of the TAWS-SPIN denoising. In particular, the letters in the boat's name and the boat's masts and rigging are more sharply defined for the TAWS-SPINdenoising than for either of the other spin denoisings.\n\nWe conclude our comparisons with an example of denoising a real image. The previous examples used test images which were then contaminated by adding random noise. In our final example,\n\n(a) Underwater image (b) Histogram we consider the denoising of an image acquired from an undersea camera under very noisy conditions. This image is shown in Fig. 18  19. It is interesting that for this real example, the SURESHRINK denoising is clearly the worst, due to its very blurred appearance. The TAWS denoising is much less blurred, and retains far more structure in the seaweed on the lower right. There are, however, some isolated noise artifacts in the TAWS denoising. These artifacts are removed in the TAWS-SPIN denoising, which is also more sharply defined than either the HMT or HMT-SPIN denoisings.\n\nIn this undersea camera application, it is necessary to transmit the acquired image over a very low-capacity channel. The low-capacity necessitates transmitting a compressed image. In Fig. 19(c) we show a TAWS-COMP denoising which has been simultaneously compressed at a rate of 32:1. This TAWS-COMP denoising is not as good as the TAWS or HMT denoisings, but does retain more details than the SURESHRINK denoising, even though it is compressed at the rate of 32:1. Further examples and more detailed discussion of TAWS-COMP can be found in Walker (2001b).\n\nIn this survey we have described the theory behind TAWS, and compared it with other denoising methods both in terms of SNR and perceptually. The TAWS method is particularly good at preserving edge details and thus producing sharply resolved denoisings. Such sharply resolved denoisings have not been previously achieved with other wavelet-based methods.\n\nFuture research will be needed to examine the properties of TAWS denoisings using different wavelet transforms, such as the complex wavelet transforms which have been shown to improve the performance of other wavelet-based denoisers. An important, and long unsolved, problem is to find a measure of error which is better in accord with human visual perception than SNR. Perhaps such a measure would objectively demonstrate that TAWS is superior to competing methods.\n\n1\n\nHere we are alluding to convolution by a measuring instrument. Discussion of wavelet-based techniques for deconvolution can be found inMallat (1998) and references therein.\n\nFurther discussion of (11) can be found inWalker (1997).\n\nThe equations in (13) do not apply when j = J/2 -1, since the values f 2j+2 and f 2j+3 are undefined. In this case, the values of f 0 and f 1 , respectively, are substituted for these undefined values. This corresponds to a periodic extension of the vector f .\n\nThe term, cycle-shift, is used because when jj 0 or kk 0 fall outside the range of indices for the rows or columns of the image matrix, then a wrap-around is used to define G j-j0, k-k0 .\n\nA symmetric interval about 0 is needed for Daub 9/7 wavelets, but this assumption is also valid for all the Daubechies wavelets and all other compactly supported wavelets.\n\nSee alsoWalker and Nguyen (2000b) for a description of both algorithms.\n\nSeeWalker and Nguyen (2000b) for a more complete description of bit-plane encoding.\n\nThe importance of edges for human vision was emphasized byMarr (1982). A wavelet analysis of the key role played by edges in image formation was developed byMallat and Zhong (1992).\n\nThe full-size denoisings can be found at the following webpage: http://www.uwec.edu/academic/curric/walkerjs/denoisings"
}