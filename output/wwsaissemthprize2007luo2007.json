{
    "title": "N/A",
    "publication_date": "2005",
    "authors": [],
    "abstract": "Vision-based place recognition is a desirable feature for an autonomous mobile system. In order to work in realistic scenarios, a visual recognition algorithm should have two key properties: robustness and adaptability. This thesis focuses on the latter, and presents a discriminative incremental learning approach to place recognition. We propose a solution based on incremental extensions of support vector machine classifier. Since computational and memory efficieny are crucial for mobile robot platforms aim to continoulsy work in real-world settings, we put emphasis on these properties. We use a recently introduced memory-controlled incremental technqiue, which allows to control the memory requirements as the system updates its internal representation. At the same time, it preserves the recognition performance of the batch algorithm and runs online. In order to assess the method, we acquired a database capturing the intrinsic variability of places over time. Extensive experiments show the power and the potential of the approach.",
    "full_text": "A fundamental requirement for an autonomous mobile system is the ability to localize itself within a known environment, i.e, to know its position in the world. The common take on the problem is to use metric geometric models or discrete topological ones. Semantics has rarely been associated with such models. However, as robots break down the fences and come closer and closer to our home, the interaction with people becomes more important. Thus, it is necessary to include semantics in the models and to enable the use of place information as a way to introduce contextual knowledge into the system.\n\nThe current trend in robot localization and mapping community is to try to use vision instead of more traditional range sensors, such as laser and sonar. We see two main reasons behind this trend: (1) vision potentially offers more portable and cost effective solutions, as new mass market for camera technology result in significantly reduced price and increased performance; (2) vision can provide information unavailable to other sensors: for instance, it can provide semantic information on a scene through the understanding of its visual appearance, not just the geometric aspect of it. This would open various opportunities in term of flexibility and use of context.\n\nCurrent research on vision-based localization systems faces several issues, of which robustness and adaptability are probably the most challenging. The system should be robust to many types of variations such as changes in illumination conditions, people moving around, or objects being used and moved. Moreover, the visual appearance of indoor environments changes continuously in time. This poses serious problems for recognition algorithms trained off-line on data acquired once and for all during a fixed time span. At the same time, when used on a robot, the system must run in real-time on hardware with limited processing and memory resources.\n\nThe inability to adapt to changes in the environment would prevent any systems from working in most realistic environments. Here we study the problem of adaptability of a visual place recognition system, that is, its ability to detect changes and adapt to them in an indoor environment, thus maintaining a level of robustness over a long period of time. Our starting point is the visual place recognition system presented by Pronobis et al. [50], which used the Support Vector Machine classifier. It is a purely appearance-based system able to cope with illumination and pose changes, and it could achieve satisfactory performances when considering short intervals between the training and testing data acquisition. Nevertheless, a room's appearance is doomed to change dramatically in time because it is used: chairs are pushed around, objects are taken in/out of drawers, furniture and paintings are added, or changed, or re-arranged; and so forth. As it is not possible to predict a priori how a room is going to change, the system is unable to acquire beforehand training data for representing all these possible visual variations. Thus, the only possible strategy for a visual place recognition algorithm aiming to work in realistic setting is to update its internal representation in time, learning incrementally from the new data recorded during use.\n\nIn this thesis, we focus on the ability of the recognition algorithm to adapt to changes over a long period of time. We argue that the adaptation should be performed in an incremental fashion. The internal representation should be updated (rather than rebuilt from scratch) without the need to keep all the previously acquired training data in memory. Moreover, the updating process should gradually forget unnecessary information and keep the model compact, fast, and free from redundancy.\n\nTo achieve these goals, we applied several Support Vector Machine incremental learning algorithms, from the machine learning community, to the domain of visual recognition. Additionally, in order to test their effectiveness on this scenario, we extended the database used in [50] 6 months later to add variations over long time spans as a supplement to illumination and pose changes of the old sequences. Extensive experiments clearly show the power of our approach, while illustrating the need for incremental solutions in real-time vision-based robot localization. Although the incremental learning algorithms proposed in this thesis were only be applied to recognition system using Support Vector Machine classifier, several concepts regarding an incremental system, introduced here might still be valuable for many different incremental applications.\n\nThe research on place recognition has been mostly conducted in the mobile robotics community, where the problem is referred to as topological localization. Vision based systems have gained popularity recently, and several approaches have been proposed. These methods employ either regular cameras [56,54] or omnidirectional sensors [27,58,10,44,1] to acquire images. The major difference between the approaches relates to the method the scene is perceived, and thus the way to extract features from the scene. The visual features extracted from the images served as landmark to give information about the position. Local image features may be regarded as natural landmarks. The SIFT descriptor was successfully used by Se et al. in [52]. Tamimi et al. [54] employed Kernel PCA to extract features from local patches. Global features are also commonly used. Pronobis et al. [47,50] suggested to use composed receptive field histograms [38], which are able to cope with small illumination and pose variations. In [58] color histograms are extracted from panoramic images to define and recognize places.\n\nUnstructured and dynamic environments pose a crucial challenge to many realworld applications. Since the parameters of the robot system will require tuning in order to work properly in the new environment and it is impossible to predict and model every possibilities, robots can only interact with the environment and work upon the new information extracted from the sensors. Consequently, learning and adaptive robot have been a much research topic in different technical sections, such as robot control, humanoid robotics and navigation, of the robotics community during the last years. Only some relevant examples on robot localization and navigation will be discussed here. In [20], Jose Millan proposed a reinforcement connectionist learning architecture that allows the robot to acquire efficient navigation strategies in a rapid, safe, and incremental way. Beeson et al. [8] introduced a new action model and show that by adapting the action model parameters over time could improves the localization result. Incremental learning approaches had been so far mostly used for constructing the geometrical map, or the environment representation, online. Brunskill et al. [12] proposed a model using incremental PCA for simultaneous localization and mapping (SLAM). A similar approach was used in the only work we are aware of that uses an incremental method in the context of visual place recognition. In [2] incremental PCA was used to update low-dimensional representations of images taken by a mobile robot as it moved around in an environment. They also tested repetitive learning of their model with the same training images several times. Note that their work was not addressing the problem of environment variations and of its complexity in real-world data.\n\nThe rest of the thesis is organized as follows: Chapter 2 presents the architecture of the adaptive visual place recognition system, and defines the problem of incremental learning for adaptive place recognition. Chapter 3 will review the theoretical background of the Support Vector Machine classifier and its incremental learning extensions. Chapter 4 gives a description of the KTH-IDOL2 database as well as the scenario of the experiment using the database. Chapter 5 reports the extensive experiments results that prove the concept and show the effectiveness of our approach. The thesis concludes with a summary and possible future direction of the research in Chapter 6.\n\nThe thesis provides a description on an incremental learning system for adaptive visual indoor place recognition. The system is able to update its internal representation from the new input data, and adapt to the changes in the environment. Furthermore, our system places strong emphasis on controlling the memory requirements, paving the way towards real-time, continuous learning. To the knowledge of the author, this is the first attempt to employ incremental learning for solving variations and building adaptive model in the context of visual place recognition.\n\nBeside the primary contribution, we also identified several other desirable properties for incremental learning system implemented on robotic platform, such as reducing memory requirements, forgetting mechanism for discarding unnecessary information to free the memory space, self-detection of knowledge/ignorance and speed. We are not aware of any systems using incremental extension of support vector machines which have a forgetting mechanism, neither of any incremental models being able to perform self-detection of knowledge/ignorance. Although the proposed solution is only a first elementary step, it might attract interest in further research.\n\nThe presented system was tested with extensive set of experiments. For this purpose, an image database consisting of image sequences acquired using robot platforms in a real environment was built. The database captured natural variability that occurred in real-world environments introduced by both illumination and human activity and could be used for various testing of vision-based robot localization. Detailed description of the database can be found in Chapter 4 and in [43].\n\nPart of the work presented in this thesis has appeared in the following paper and technical report:\n\nThe introduction gave a brief overview of the place recognition problem and underlined the most important issues in designing an adaptive vision system. This chapter introduces the fundamental ideas that shaped the architecture of the adaptive visual place recognition system. First, in Section 2.1, we will formulate the problem and define a few key terms. In Section 2.2 we will briefly review relevant concepts in the human memory. Then, in Section 2.3, we will present the framework of our adaptive system, and describe the modules used to assemble the architecture, based on which, in Section 2.4, we will provide a more detailed description of the feature extraction methods used in the system. Finally, in Section 2.5, we will enumerate several properties we identified for an effective learning system and give a theoretical overview on incremental learning. In this section, our exploration of the adaptive recognition system will be associated with a study on human perception and memory system.\n\nVisual Place Recognition could be considered as a Pattern Recognition problem on the visual representation of the environment. The word pattern needs to be briefly defined here. Pattern is a quantitative or structured description of an object or some other entity of interest [29]. According to this definition, a digital representation of an image of a place is a pattern, because it contains a visual description of the place. Patterns are grouped into pattern classes with respect to some common properties they share. In case of place recognition, the common properties are the physically separated rooms with different functionalities. These pattern classes are denoted ω 1 , ω 2 . . . ω W , where W is the number of classes. Solving a pattern recognition problem involves designing a classifier for assigning patterns to their classes. We, as designers, need to select the model for the classifier underlying the patterns, which could describe those features that are common within one class and different from other classes. Again, in the place recognition problem, we could build models of rooms using their distinct features, for instance, the special objects that occur within different rooms.\n\nDue to the complexity of most of the practical pattern recognition problems, it is nearly impossible to guess the parameters, rules of classification models ahead of time. The recognition system need to be given a representative set of samples (training patterns), and use them to learn and estimate the unknown parameters of the model. The concept of \"learning\" refers to some form of an algorithm for generalizing the training data and reducing the error on classifying them. Typically, the training patterns are labeled with their classes. This approach is referred to as supervised learning, as opposed to unsupervised learning. In this thesis, supervised learning will be used to train the place recognition system. Of course, we hope that after training, the system will be able to properly recognize not only those training samples but also novel ones which will encounter in the future. This is known as generalization ability. Conversely, if the classifier is adopted to the special training set so well, it may never predict any examples outside the training set correctly. This phenomenon is known as overfitting. The generalization performance is a crucial issue for the place recognition system. This is due to the fact that, in realistic conditions, the environment changes continuously and identical viewpoints are difficult to retrieve.\n\nAfter building a sophisticated model, the system is able to achieve satisfactory performance when the environment is relatively stable. However, in the real world, the environment is bounded to change with time. Often, these changes make the model built on old data inconsistent with the new data. This problem, known as concept drift [57,62], complicates the task of learning to build model from data.\n\nTo endow the capability of handling concept drift, the system must be able to update its model regularly as new instances are processed. Among different approaches proposed in the machine learning community [57,24,63], incremental learning is considered as a very suitable method for handling this problem. Hence, we apply an incremental learning method which allows the system to build adaptive model. More detailed issues about adaptive learning will be discussed in Section 2.5.\n\nThe most successful recognition and learning system was designed by nature -most particularly humans. While designing an artificial learning system, the designers' work may in fact be influenced by knowledge of how these problems are solved in nature. For this reason, it is also of particular interest to study how the memory is processed in then human brain. Since that memory process in the human brain is very complex, we will only provide a brief review of the relevant concepts that are widely accepted in cognitive psychology. More specific properties will be studied in association with with the learning system in Section 2.5.\n\nThe task of perceiving and recognizing a scene, determining its semantic category, as well as extracting its general structural information, requires only one eye fixation and can be completed in less than 100ms, while learning it would demand more effort. An influential model presented by Atkinson and Shiffrin [3] in the late 60s proposed that the visual, auditory and haptic information perceived from the environment through perceptual systems would be stored into a limited capacity shortterm sensory memory. They also proposed that the longer an item resides in this storage, the greater probability of its transfer to long term memory. However, later research suggested that merely holding an item in short term memory did not guarantee learning. Craik and Lockhart [18] proposed the levels-of-processing framework which emphasized the processing that a item underwent in order to learn and recognition.\n\nCognitive psychologists separated out three common stages of different memory systems [5]: encoding, the processes whereby information is registered; storage, the maintenance of information over time; and retrieval, which refers to the accessing of the information by recognition, recall or implicitly by demonstrating that a relevant task is performed more efficiently as a result of prior experience.\n\nAnother related topic is the theory of forgetting, which is a fundamental question in the psychology of memory. Numerous theories have been proposed so far. Early theories [4] suggested that we forgot from disuse. One good example is that we become less proficient in a foreign language learned in high school if we do not use it for a long while. Later, it was suggested that forgetting may simply be a matter of decay, that is memory traces simply fade with time [4]. One of the most widely accepted theories of forgetting is interference theory [4], that people forget some target material because it is interfered with by other material in memory. Interference takes two forms: retroactive interference and proactive interference. Retroactive interference is that newer learning interferes with earlier learning. In contrast, proactive interference is that earlier learning interferes with new learning [4].\n\nAs any other pattern recognition system [23,55], our system could be considered as an assembly of specialized modules cooperating by exchanging data. The framework of the system is presented in Figure 2\n\nInformation is flowed from the environment through a series of sensors, which could be regarded as the perceptual organs of the machine system. For visual perception, digital cameras are used to capture images from the environment. The input images vary depending on the type of the cameras. There are two types of cameras commonly used for a visual place recognition system: a regular perspective camera and an omni-directional camera. The omni-directional cameras are commonly applied for mobile robot localization, because they provide a horizontal field of view of nearly 360 • which simplifies recognition. The perspective camera is the most common visual sensor and is widely applied in many different recognition systems. In the visual system presented in this thesis, perspective cameras mounted on two robot platforms were used. Detailed information about the cameras and sample images will be given in Chapter 4. To automatically label the images for the supervision, the range sensors, such as laser and sonar, were used to estimate the pose of the robot during the acquisition process.\n\nWhen an image instance is collected by the visual sensor, it is temporarily stored in the memory before being processed and placed for long-term storage if it is considered as useful sample by the learning algorithm. Due to the computational cost, the system usually does not perform training every times a new instance comes. Once a certain number of instances are collected, the updating will begin. The difference between Short-Term Memory (STM) and Long-Term Memory (LTM) has been investigated in cognitive science for a long time. LTM takes from STM only those pieces of information that are considered relevant and useful [62]. In our case, the temporary storage memory represents STM and the model of the classifier represents LTM.\n\nThe aim of the feature extraction is similar to the encoding stage of memory process. It is to provide a new representation of the input pattern, that would simplify the learning and classification problem. The effect of levels of processing could be a good example, simply processing the visual characteristics of a word leads to a much poorer subsequent recall or recognition than processing it in terms of its meaning. The performance of the whole recognition system highly depends on the quality of the selected feature descriptor. This leads to the idea of finding distinguishing features, which should be insensitive to within-class variability and emphasize properties that are different from other classes. At the same time, this representation should also be invariant to irrelevant transformations of the input. For example, in case of place recognition, the ideal descriptor should be invariant to translation, scale, as well as to variations introduced by illumination changes and movement of small objects. Features employed in our system are described in detail in section 2.4.\n\nAccording to the supervised learning scheme, \"learning\" is the process of using labeled sample patterns collected by the sensor to determine the model of a classifier, which is also referred to as training process. For different training algorithms and models, the learning paradigm would be completely different. No universal method has been found for solving all the pattern recognition problems in every domain.\n\nIn our system, we employ the Support Vector Machine classifier which has been proved successful for the place recognition problem in previous work [50]. In case of the support vector machine classifier, the model is composed of support vectors (a selection set of training samples which summarize the data space) and a few corresponding parameters. More details about Support Vector Machine can be found in Chapter 3. Interestingly, this learning process somewhat resembles how humans remember a place -selecting a few landmarks and weighting them in the memory. Those selected training samples will be stored in the system memory until they are updated or \"forgotten\". Unlike a typical recognition system with a fixed model, the new learning process involves interactions with the knowledge of the prebuilt model. These interactions include updating the old model with new incoming instances, and \"forgetting\" out-of-date knowledge. A benefit from this incremental learning mechanism is that the system is able to adapt to the changes in the environment. Section 2.5 will provide a detailed analysis of these properties.\n\nThe classifier is the module which performs the actual recognition task. It assigns the input pattern to one of the classes on the basis of the previous built model and feature extracted from the pattern. Again, the design of a classifier varies for different problems. Moreover, its performance depends on the choice of the model as well as the presented training samples. The degree of difficulty of the classification problem depends on the variability of features within each class in comparison to the difference between classes. As we can see, place recognition is a quite complicate problem due to its large within class variability. Another important issue is the speed of prediction for each pattern, as a system usually demands real-time performance. More about these topics will be explored in Chapter 3.\n\nIn this section, we will describe the methods employed in our place recognition system for extracting the distinguishing features from the images. As already stated in the previous section, the feature extraction process aims to give a new representation of the input pattern that is able to convey the distinct features of the category and is invariant to irrelevant transformations of the input pattern class. In case of visual information processing, such representation could either be extracted from the whole image (global features) without any loss of information of the scene, or computed from its salient parts (local features). Both approaches have been tried on place recognition and localization applications [58,52,54,47,50].\n\nIn this thesis, we assessed the performance of both global descriptor and local image descriptor. The system uses the Composed Receptive Field Histograms (CRFH) [38] as global features and the Scale-Invariant Feature Transform (SIFT) [41] for extracting local features. In the remaining part of this section, we will introduce both feature types separately. Interested readers not familiar with the basic theory of digital image processing, such as scale-space theory and basic image operators, are referred to [30] and the references cited therein.\n\nComposed Receptive Field Histograms of Higher Dimensionality [38] are a multidimensional statistical representation of the occurrence of responses of several image descriptors applied to the image. The use of view-based representation in terms of Receptive field response [34] has emerged as a promising paradigm for visual recognition. Schiele and Crowley [51] summarized receptive fields into histograms, and computed histograms of either magnitude or the laplacian operator at three scales, which are shown highly effective for recognition of objects. The idea behind CRFH is that histograms of very high dimensionality features could capture more of the visual information contents in the image structure. Each dimension corresponds to one image descriptor and the cells of the histogram count the pixels sharing similar responses of all descriptors. The histograms could be computed from several types of image descriptors and various combinations of these, thus it allows to capture various properties of the image as well as the relations between them. Several basic descriptors are given below:\n\n• Normalized Gaussian derivatives, obtained by computing partial derivatives (L x , L y , L xx , L xy , L yy ) from the scale-space representation L(•, •; t) = g(•, •; t) * f obtained by smoothing the original image f with a Gaussian kernel g(•, •; t), and multiplying the regular partial derivatives by the standard deviation σ = √ t raised to the order of differentiation [39].\n\n• Differential invariants, invariant to rotations in the image plane, mainly the normalized gradient magnitude |∇ norm L| = t(L 2 x + L 2 y ), the normalized Laplacian ∇ 2 norm L = t(L xx + L yy ), the normalized determinant of the Hessian det(∇ norm ∇ T norm L) = t 2 (L xx L yy -L 2 xy ). • Chromatic cues obtained from RGB-images according to C 1 = (R -G)/2 and\n\nA simple example using first-order derivatives computed at one scale illustrating the idea is show in Figure 2.2.\n\nWhen using histograms of such high dimensionality, computational problems would easily occur. For example, a 16-dimensional histogram with 16 quantization levels per dimension contains 16 16 cell. However, in practice most of the cells will be empty in practice. Due to this fact, Linde and Lindeberg [38] suggested to store only those cells that are non-zero. Thus, a histogram, H, with n non-zero cells c 1 , . . . , c n , with values v 1 , . . . , v n , respectively, can be stored as an array of size 2n,\n\nThe index c i for a D-dimensional histogram with the quantization levels q 1 , . . . , q D can be computed as follows: where the values m i1 , . . . , m iD , 0 ≤ m ik < q k denote the coordinates of the cell. Such approach largely reduces the memory requirement and makes it possible to define efficient operations on them. Extensive experiments showed that CRFH features are robust to viewpoint rotations [38] and variations in illumination and minor scene changes [50].\n\nIn contrast to global features, local features represent the appearance of the image around a set of characteristic points called interest points. Local feature extraction takes two steps: interest point detection and description. The interest point detector aims to identify those characteristic points in the image and the descriptor extracts robust features from the local patches located at these detected points. In our system, we employ the Harris-Laplace detector [46] and the SIFT descriptor [40,41]. The Harris-Laplace detector [46] employs the scale-adopted Harris detector [31] in order to identify the interests points in the scale-space and the Laplacian measure for automatic scale selection. The original Harris function based on the second moment matrix has shown its good performance in handling image rotations, illumination changes and perspective deformations; however, it is sensitive to variations in scaling. To cope with this problem, the scale-adopted second moment matrix is used:\n\nwhere t I = σ 2 I is the integration scale, and t D = σ 2 D is the differentiation scale. The Gaussian derivatives are computed at the scale t D and the result is smoothed with the Gaussian window g(x, y,t I ) of width σ I . The scale parameters are usually related by the equation σ D = sσ I , where s is a constant factor. The scale-adopted Harris interest function yields det(µ)(x, y,t I ,t D )α(trace(µ)(x, y,t I ,t D )) 2 .\n\n(2.\n\n3)\n\nThe function could be considered as a measure of the cornerness at the point (x, y) of the image and the scale t D . Consequently, the interest points corresponding to corners can be detected by finding its local maxima. The Harris-Laplace detector computes the Harris function at multiple scales and searches for local maxima. Then, the maxima are thresholded to get rid of those small cornerness. Finally, the algorithm will check whether the detected points correspond to the extremum of the Laplacian of Gaussian computed over scale. The points whose LoG attain no maximum and whose the Log is below some threshold are also rejected. Examples of points detected by the Harris-Laplace detector are illustrated in Figure 2.3. The SIFT descriptor devised by Lowe [40,41] represents the features of local patches characterized by coordinates in the scale-space in the form of histograms of gradient direction. The features share similar properties with neurons in inferior temporal cortex that are used for object recognition in primate vision. They are invariant to image scaling, translation, rotation and partially invariant to changing viewpoints and changes in illumination.\n\nThe algorithm transforms image data into scale-invariant coordinates relative to local features. First, the algorithm assigns a characteristic orientation to the interest point, by detecting peaks in a gradient direction histograms. For each interest point, in a 16x16 window, histogram is computed in a way that the contribution of each pixel belonging to the local patch is weighted by the gradient magnitude and a Gaussian window of width equal to 1.5 times the scale of the interest point. Then, the orientation of the point is determined by the highest peak in the histograms. Plus, the other peaks whose height are at least 80% of the highest peak will be used to generate new interest points. All further measurements are stored relatively to this orientation, which provides invariance to rotation. In order to increase the robustness to illumination variations, the feature vectors are normalized and the large values exceed threshold in the vector are rejected.\n\nIn this part, we will describe the elementary similarity measure for comparing histograms (for comparing CRFH feature) and local features (for matching SIFT feature).\n\nThe χfoot_0 measure [9] is proposed by mathematical statistics for comparison of histograms. It calculates the \"distance\" between two histograms h 1 and h 2 for any pair of images:\n\nComparing image representations based on local features is done by matching. The best candidate match for each keypoint is found by identifying its nearest neighbor in the database of keypoints from sample images. The nearest neighbor is defined as the keypoint with minimum Euclidean distance for the invariant descriptor vector. An effective way presented by Lowe [41] applied a nearest neighbor algorithm, followed by a Hough transform [6] for object recognition problem.\n\nIdeally, we could recognize the images by comparing or matching them with the training images stored in the database. However, when the number of training images is large, especially for complex problem such as place recognition, this method will become costly. In our system, we applied support vector machines, which are based on a thorough mathematical foundation and have powerful generalization capability. Additionally, the kernels used in support vector machines employ the above measures, which have been proved to be quite effective in visual recognition task. Introduction of the support vector machines will be given in Chapter 3.\n\nA crucial issue when design an adaptive system is its learning ability. The ability to learn is a hallmark of intelligence. Humans can rapidly and reliably learn different kinds of regularities and generalizations. Although we still do not know how to make computers learn nearly as well as people learn, machine learning systems that are effective for certain types of learning tasks have been invented. Our particular system design draws concepts and results from different incremental and adaptive learning paradigms in the literature of the machine learning community [36,62,21]. Meanwhile, we think naturally in term of memory and computational complexity, which are desired properties for system running on robotic platforms. We identified several properties of learning systems that could allow it to flexibly react to variations in the environment and be implemented on mobile robots with limited processing and memory resources. The general approach underlying the learning algorithms consists of:\n\n• The system should regularly update the model with current examples and hypotheses;\n\n• The system should forget invalid and outdated information to free the memory space;\n\n• The model should converge fast if the environment is relatively stable;\n\n• The model should possess means to control these functions by monitoring the system behavior.\n\nThe unstructured and dynamic environments pose serious troubles to recognition systems with fixed model, because of their inability to adapt to the changes. An effective learner should be able to track the changes and quickly adapt to them. The fundamental ability of an adaptive system is to incrementally update its internal representation, so that it could maintain a certain level of robustness over time.\n\nIncremental learning is considered a quite suitable approach for handling environment changes. Batch learning, as opposed to incremental learning, is much simpler when a large collection of new instances is available. However, it would be a waste of effort to relearn an old concept from scratch every time, especially for a visual place recognition system. First, normally, an indoor environment would not be totally changed. The system only needs to update the representation of the changed regions. Second, in order to build a robust model, it will need to acquire a huge collection of training instances including different illumination conditions and as much potential scenes as possible at once. Conversely, an incremental learning paradigm allows for deleting the training instances immediately after updating the model and for separating the learning task, which is more memory and computational efficient. Last but not least, given the advantage of storing knowledge descriptions in a long time span, the system can deal with recurring contexts: furniture are put back to their old locations, objects are taken out from the drawers again, or illumination and weather conditions reappears.\n\nHuman beings adapt to different kinds of changes by actively interacting with their environment. This is known as active learning [17]. Towards an autonomous agent with the capability of on-line and continuous learning, there are several other desirable properties for the incremental learning system.\n\nBeing able to deal with recurring contexts is a merit of an incremental system. On the other hand, one has to take into account the memory limitation. In general, learning systems seldom forget about past cases, which reduce the effectiveness of the learning process. The idea of introducing a forgetting operator to enhance learning has been investigated in previous adaptive systems. Kubat applied a window of fixed size in the FLORA system [36] and later on a practical computer network problem [37]. This window keeps track of the new arrived examples, and only those examples stay in the window are trusted by the learner for making decisions. The old examples dropped out from the window will be \"forgotten\". This work was inspired by the idea of memory decay: any piece of information that enters memory tends to slowly fade out. However, it turns out to be only sufficient for some particular applications. The premise of using a window as a means of controlling forgetting is that the distribution of data changes dramatically in times. Obviously, visual recognition data do not belong to this category.\n\nMoreover, memory does not simply decay with time, pieces of information which are important and useful in the future might stay longer. For instance, in a realistic indoor environment, knowledge about those scenes which may reappear should be preserved. While for permanent changes such as replacing wallpaper or furniture, these old pieces of memory are no longer helpful. Additionally, they will consume unnecessary memory space and may even act as noisy data. It is a common human experience that these permanent changes interfere with the invalid memory. However, implementing this function in machines presents a challenge. An alternative to the window method was used in the concept formation system FAVORIT [35]. In the system, each example is assigned a weight which slowly decays with time. If the same example reappears, the weight is incremented. Examples whose weight drops below some threshold are forgotten. However, due to the complication of real world visual information, this method is not applicable in a vision-based system. Therefore, our design effort will be put on finding incremental algorithm that privileges newest information at the expenses to oldest one, and preserves discriminative information longer.\n\nImagine a daily routine in your work environment, you step inside the laboratory in the morning, open the door of your office, turn on your computer, and go to the kitchen to get yourself a cup of coffee. Perhaps the coffeepot was not on exactly the same table as last morning or they take one of the chairs from the kitchen, but it does not take you any mental effort to recognize it and your cognitive system does not signal alarm. Not much new memory fraction has been added so far. It may happen that when you try to reconstruction the lab in your brain, it will be made up by what you see today. How about the yesterday's lab? You will have difficult to rebuild it without interfering by today's scenes, since you did not notice any difference between them. This is in consistent with the retroactive interference theory [11].\n\nAny incremental or on-line learning theory must prevent memory explosion in continuous processing, if it aims to work in a real-world environment. Different from the forgetting scheme, we want the memory model to be compact and free from redundancy. That is, the model should be fast to converge or even maintain the same space, if the environment is relatively stable. The idea is that when a new collection of training instances comes, the system should consult its store of old instances to see whether some of these new collections describe similar visual information as the old one. Then it should delete those redundant instances. Furthermore, when a stable model has been reached, it might be worthwhile to store the current instances rather than the old one.\n\nRegardless of the algorithm complexity, employing regular model updates as new data arrives can be extremely costly as the amount of arriving data may be overwhelming. Ideally, the algorithm should try to save computational resources by limiting the number of expensive updating episodes. Previous applications inspect the classification rate as a quantitative indicator for triggering updating. But the feedback system also requires time and other resources. Effective learning requires the system that can detect environments changes without being explicitly informed about them. Suppose that the system could successfully identify a plateau in memory growth, this behavior could be translated into measurable quantities for switching on/off the incremental update.\n\nThe idea of the dynamic control of forgetting is similar to the FLORA2 [62] system which flexibly adjusts of size of the window during learning. It allows for faster recovery after an environment change by getting rid of outdated and maybe disturbing information. We suggest the speed of memory decay should be associated with the dynamic state of the environment. If the environment changes very fast, the forgetting rate could be high, and vice versa.\n\nAs well as human being, a programmed learning system is intrinsically based on the notion of error and mistake. Learning is triggered by the occurrence of an error, since it manifests the weakness of the current knowledge. Error-driven learning systems have been studied in many different domains [26,21,45]. However, some basic issues rise up when apply an error-driven approach on a recognition problem. When a mistake happens, a new \"case\" is added. But those old samples which are incorrect or conflicting may still be kept in the model, because they are almost impossible to target in many cases. Plus, overfitting is another common phenomenon which exists in an error-driven learning system. In this thesis, we will also examine this issue through experiments.\n\nTo recapitulate briefly, this chapter discussed the main issues related to place recognition and adaptive learning with respect to both artificial systems and humans. We started with defining the problems of pattern recognition and learning and a brief review of related theory on human memory process. Then, we introduced the structure of our adaptive place recognition system in term of different modules and their relationship. Following that, we described in detail the image descriptors used in the feature extraction module of our recognition system. Finally, the core of this thesis, the learning scenario, was presented, and we explicitly enumerated several desirable properties of an incremental learning system running on robotic platforms. Experiments investigating these properties are reported in Chapter 5.\n\nIn this chapter we will show how to solve the pattern recognition problem using Support Vector Machines (SVM) [59,19,13] and their incremental learning extensions [53,21]. Because of their good performance and well developed statistical theoretical background, Support Vector Machines are now receiving increasing attention. In many different cases, their generalization performance either matches or is significantly better than that of other methods. In the visual recognition domain [38,32], it was successfully applied to many applications including visual place recognition [50]. Inspired from Vapnik's statistical learning theory [59], support vector machines have good generalization performance to summarize the data space in a very concise manner, which also makes them well-suited for an incremental learning framework. Details will be given in successive sections of this chapter.\n\nThis chapter is organized as follows: in Section 3.1 we will introduce the principle of Support Vector Machines, and in Section 3.2 we will describe the incremental SVM learning framework and several popular incremental learning algorithms. Next, in Section 3.3 we will present a new, modified memory-controlled version of incremental SVM. We will conclude with a summary in Section 3.4.\n\nThis section aims to introduce the main concepts and properties of SVM. For this purpose, the fundamentals of linear discriminant classifier are given in Section 3.1.1. On foundation of this knowledge, the algorithm for finding the optimal separating hyperplane for a linearly separable and non-separable case will be explained in Section 3.1.2. Next, Section 3.1.3 describes a method for constructing a non-linear SVM classifier by non-linearly mapping the input vectors to a high-dimensional feature space and constructing the linear decision surface in that space. All solutions given in these sections are solving a two-class problem, we will present the multi-class extensions in Section 3.1.4.\n\nIn case of supervised learning, the learning machine is given a set of labeled training instances. Usually these instances are in the form of attribute vectors, which could be considered as a point in an N-dimensional feature space. Once these attribute vectors are available, many hypotheses could be used for the problem. Among these, linear functions are one of the simplest solutions. In classification, the aim is to find a discriminant function f : ℜ N → ℜ distinguishing between the points belonging to the different classes.\n\nLet us start with the simplest case: linear machines trained on two-class separable data. In this case, the instances can be denoted as {(x x x i , y i )} n i=1 , where x x x i ∈ ℜ N is a feature vector, and y i ∈ {-1, 1} determines the class. Since this is a linearly separable case, suppose that we have some hyperplane which could separate the positive from the negative instances. The points x x x which lie on the hyperplane satisfy w w w T x x x + b = 0, where w w w is the weight vector and the b is the bias or threshold weight. This problem is illustrated in Figure 3.1. For the linearly separable case, all the training instances should satisfy the following constraints:\n\nThe linear discriminant function can be written as\n\nIf f (x x x) > 0, then the vector point x x x is classified to the class +1, and if f (x x x) < 0, it is classified to the class -1. The equation f (x x x) = 0 defines the decision surface that separate these vectors. Now let us consider the properties of the discriminant function f (x x x). It gives an algebraic measure of the distance of the point x x x to the hyperplane [23]. For example, the coordinates of the point x x x o could be expressed using its normal projection to the hyperplane x x x p and the unit vector w w w w w w :\n\nThe algebraic distance is positive if the point lies on the positive half-space and negative if it lies on the negative half-space. In order to obtain a measure that is always positive the algebraic distance may be multiplied by the class label y i . A geometric illustration of this results is also given in Figure 3.1. Therefore, the problem of classifying linearly separable data into two classes is to find the separating hyperplane. However, the separating hyperplane is not unique. We may also want to choose the hyperplane that may more accurately classify the newincoming point. Intuitively, it should be the hyperplane with the maximum distance to the closest data point from both classes -this distance is called margin will give lower expected risk (Empirical Risk Minimization [19]), -because its separation between the two classes is the greatest. This hyperplane is clearly of interest and is known as the maximum-margin hyperplane or the optimal hyperplane. Classifiers trying to find the large-margin hyperplane are known as large-margin classifiers.\n\nThe Support Vector Machines belong to the class of so-called large margin classifiers, because in the linearly separable case Support Vector Machines obtain the optimal separating hyperplane with the maximal margin. The optimal hyper plane for a typical two dimensional case have the form shown in Figure 3.2. The margin ρ can be expressed as ρ = min i=1,...,n y i f (x x x i ) w w w = min i=1,...,n y i (w w w T x x x i + b) w w w . (3.6)\n\nwhere x x x 1 , x x x 2 , . . . , x x x n are the closest points to the optimal hyperplane, which is known as Support Vectors, they are indicated in Figure 3.2 by red points. We see that the margin may be maximized by either maximizing the absolute value of the discriminant function at the nearest point (min i=1,...,n y i f (x x x i )) or by minimizing the length of the weight vector w w w . The function associated with the hyperplane (w w w, b) does not change if we rescale or normalize the hyperplane. Hence, we can fix the functional margin at the nearest point to be equal to 1. In this case, the linear separability condition can be rewritten as\n\nThe problem of finding the optimal hyperplane now can be formulated by solving the following optimization problem: find the optimal value of the weight vector w w w o and the bias b o such that they satisfy the constraints\n\nand the weight vector w w w o minimizes the cost function:\n\nw w w T w w w (3.9)\n\nSolving this problem using Lagrange multipliers a i (i = 1, 2, . . . , n) results in a discriminant function\n\nwhere α i and b o are found by using an SVC learning algorithm [59,19]. Usually, only a small fraction of the Lagrange multipliers α i coefficients are non-zero. Their corresponding x x x i are the \"support vectors\". From the discriminant function, we could notice that the knowledge of the classifier (model) is represented in form of support vectors, the corresponding Lagrange multipliers and the bias. All the remaining training examples that do not contribute to the discriminant function could be regarded as redundant.\n\nIn many real-world situations, non-linearly separable case is quite common. Although the training samples can not be discriminated using a hyperplane, we could try to formulate the solution that will allow to minimize the classification error on the training set. This method is known as soft margin hyperplane. The solution is identical to the separable case except for a modification of the Lagrange multipliers into 0 ≤ α i ≤ C, i = 1, 2, . . . , n, where C is a parameter controlling the trade-off between the complexity of the classifier and the amount of errors and it has an influence on the generalization performance. This soft margin idea is useful not only for non-linearly separable problems, but also able to avoid situations where the hyperplane is optimal with respect to the errors on the training set but does not generalize well to the novel samples, i.e. overfitting situation. An example of the soft margin hyperplane for solving the non-separable problem is illustrated in Figure 3.3.\n\nIn many practical application, a non-linear classifier is more appropriate for solving the problems. In this section, we will describe a method which obtain a non-linear SVM classifier by mapping the input vectors from the input space ℜ N to a highdimensional feature space H, such that the mapped data points of the two classes are linearly separable in the feature space. This mapping could be done efficient by exploiting the fact that it is possible to compute the inner product of the input vectors in the feature space using a kernel function without explicitly determining the highdimensional representation of the vectors. As illustrated in Figure 3.4, it is possible to increase the separability of the points in ℜ N by mapping them to some space H through a non-linear function φ . The function φ can be written as:  As a result, the discriminant function of the SVM classifier in the feature space H becomes:\n\nThis representation requires computing the inner product of the vectors in the feature space. However, doing computation in this high-dimensional space could be extremely computational cost. Now if there is a \"kernel function\" K such that K(x x x i , x x x) = φ (x x x i ) • φ (x x x), we would only need to use K in the training and avoid de-termining the feature space representation of the vector. By substitute the kernel function into Eq. 3.12, we could obtain\n\nThe kernel function could be considered as a similarity measure between the vector x x x i and x x x. However, in order to ensure that there exist a space in which the measure corresponds to an inner product, the function must satisfy the Mercer's condition. The subject is comprehensively studied in [19]. Note it is not guaranteed that there exist a space, if the kernel function does not satisfy the Mercer's condition.\n\nMany practical examples have demonstrated that it is still possible to use those kernel functions and achieve very good performance.\n\nMany specialized kernels have been proposed for classifying different types of input data (e.g. see [60,16,7]). In our experiments, we employed two kernels for different image feature's input data: the χ 2 kernel [16,7] for classifying the Composed Receptive Field Histograms, and the local kernels [60] performing matching of the local image features. Both of them were proved to be effective for the given task through experiments (for χ 2 kernel, see [16,38]; for local kernel, see [60]). The kernel functions are given as follows:\n\nwhere the χ 2 measure is given by\n\n• local kernel\n\nwith\n\nwhere\n\ni=1 is a vector of local features extracted from one image, and K l (x x x, y y y) is a kernel used as a measure of similarity between the local descriptors x and y. In our experiments, we used the Gaussian kernel K(x x x, y y y) = e -γ x x x-y y y as K l . This is due to the fact that the Gaussian kernel employs the Euclidean distance which is the most commonly used measure for comparing the SIFT descriptors. This kernel is a non-Mercer's kernel, but performs well in practice.\n\nThe parameters in the kernel functions are specified by the user. In usually, optimal parameters values can be found through experiments.\n\nSupport Vector Machines were designed for binary classification. For classification problem whose number of classes is greater than two, several extensions were proposed in the literature [61,33]. In this section, we will describe two algorithms: the one-against-one method and the one-against-all method, which employ several binary SVM classifiers for multi-class problem. Considering a c-class problem for classes {ω i } c i=1 , the algorithms are given as follow:\n\nOne-against-all\n\nThe one-against-all method employs c classifiers. The i-th classifier is trained to discriminate between the class ω i and all the other classes. During the test phase, the sample is classified using all classifiers and the final decision is made on the basis of the values of the discriminant functions as follows:\n\nOne-against-one\n\nIn the case of the one-against-one approach, c(c-1) 2 classifiers are trained to discriminate between each pair of classes. In order to make the final decision, each classifier votes on one class depending on the sign of its discriminant function. Consequently, the class which collects the highest number of votes is selected.\n\nAs introduced in the previous section, the support vector machines have the appealing properties of summarizing the data space in a very concise manner by only preserving the support vectors. Since the number of support vectors is typically much smaller than the number of training examples, it suggests that SVM can be an effective tool for incremental learning. In Section 3.2.1 we will introduce the basic approximate incremental training framework. Following that, two incremental techniques using SVM will be described in Section 3.2.2. And a new modified version of the old algorithm which would lead to a controlled growth of the memory requirement for incremental SVM will be presented in Section 3.3.\n\nGiven that the generalization property of support vector machines does not depend on the complete training data, but only those instances which become support vectors, we could partition a huge dataset and then incrementally train SVM classifier with the partitions. The training would preserve only the support vectors of previous model and add them to the new input data for the next training step, as illustrated in Figure 3.5. This framework has been previously introduced in [53], and proven to obtain well comparable results to their non-incremental training equivalent. As been pointed out in [53], this is because the SVM algorithm will preserve the essential class boundary information regarding the data seen so far in a very compact form as support vectors. This information would contribute properly to derive the new concept in the next iteration. There exist several extensions of incremental techniques based on this given framework: once a new incoming batch of data is loaded, the data is filtered at first according to some fixed criteria [21], which might discard a part of the new data, then incorporated with the support vectors of the current model for updating. The methods where at each step only the learned model from the previously seen data (preserved as support vectors), are kept in memory are known as approximate methods. They seem to be the most suitable for visual recognition: firstly -as opposed to exact method like [14] -they discard a significant amount of the training data at each incremental step. Second, they are expected to achieve performances not too far from the complete data set (batch algorithm). In all the experiments, we would only use the approximate methods.\n\nDifferent incremental learning techniques using SVM has been so far mainly explored in machine learning community for data mining problems [53,21]. In the thesis, we use two methods for the visual place recognition problem, the fixed-partition technique [53] and the error-driven technique [21].\n\nIn this method the training data set is partitioned in batches of fixed size k:\n\nwith T T T i = {(x x x i j , y i j )} k j=1 . At the first step, the model is trained on the first batch of data T T T 1 , obtaining a classification function\n\nAt the second step, a new batch of data is loaded into memory; then, the new training set becomes\n\nwhere S S SV 1 are the support vectors learned at the first step. The new classification function will be:\n\nThus, as new batches of data points are loaded into memory, the existing support vector model is updated, so to generate the classifier at that incremental step. This method is exactly the same as the proposed basic framework.\n\nAs opposed to the fixed-partition method, the error-driven technique makes a filtering on the new data at each incremental step: given the model SV M t at the step t, the new data are loaded into memory and classified using SV M t . If the data is misclassified it is kept, otherwise it is discarded. The support vectors of SV M t , together with the misclassified points, are used as training data to obtain the new model SV M t+1 .\n\nA common problem to both incremental technique, and in general to all incremental extensions of SVM, is that in principle there is no limitation to the memory growth. Indeed, several experimental evaluations show that, while approximate methods generally achieve classification performances equivalent to those of batch SVM, the number of SVs tends to grow proportionally to the number of incremental steps [49]. This is of course a very serious issue as it will lead to memory explosion and influence the performance efficiency. Therefore, it crucially demands a method which is able to decrease the memory requirements as well as keep a satisfactory performance.\n\nIn this section, we will introduce a new, modified incremental SVM algorithm, which is able to reduce the memory requirements and control the memory growth during the incremental process. This algorithm was invented by Pronobis and Caputo [49].\n\nIt combines the fixed-partition technique for incremental SVM with a simplification method that reduces the number of support vectors needed to build the decision function by detecting the linear dependence between them. Here we propose to use this method on image sequences data to obtain an adaptive model.\n\nThe rest of this section is organized as follows: Section 3.3.1 provides a brief description of the original exact simplification method [22] and the algorithm used to control the trade-off between the complexity of the classifier and the classification performance. Section 3.3.2 present the incremental algorithm, and how to control storage and growth of the memory.\n\nThe core idea behind the simplification algorithm [22] is that the set of support vectors {x x x i } m i=1 in the standard discrimination function Eq. 3.13 is not guaranteed to be linearly independent. Suppose that support vector x j are linearly dependent on the other support vectors in the feature space. More specifically, these support vectors could be sorted so that the first r are linear independent, and the remaining mr depend linearly on those in the feature space:\n\nEq. 3.23 can be substituted into Eq. 3.13. The discriminant function can now be rewritten as\n\nWe could see the function is not represented by the linearly dependent support vectors anymore. If we define the coefficients γ i j , such that α j y j c i j = α i y i γ i j and γ i = ∑ m j=r+1 γ i j , then the above equation can be further derived as\n\nwhere\n\nThus, the resulting classification function requires mr less kernel evaluations than the original function. Note that the number r of linearly independent support vectors depends on the definition of linear independence. This is, again, a nice property that allows to control the range of simplification according to requirement. In [49], Pronobis and Caputo employed QR factorization algorithm with column pivoting [28] for identifying the linearly dependent support vectors and to determine the coefficients c i j .\n\nThe QR factorization with column pivoting algorithm is a widely used method for selecting the independent columns of a matrix. It allows to reveal the numerical rank of the matrix with respect to a parameter τ, which is a threshold value defining the measure criteria of linear dependence. Plus, the algorithm performs a permutation of the columns of the matrix so that they are ordered according to the degree of their relative linear independence. As a result, if the rank of the support vector matrix is r for a given threshold value τ, the linearly independent columns will occupy the first r places. As the value of τ grows, the discrimination function will become more and more an approximation of the original one. For details about the algorithm as well as its usage on support vector matrix, we refer the reader to [28,47].\n\nA simple example (from Pronobis [47]) of the method is presented in Figure 3.6. As shown in the figure, the algorithm is able to achieve 90% reduction on the number of support vectors without any loss in generalization performance compared to the original solution (compare Figure 3.6 upper left and upper right). Further reduction can be achieved by increasing τ. But, in this case, we could notice small variations on the decision surface. Thus, the classification performance may slightly drop compared to the exact solution.\n\nOn the bias of these properties, the threshold τ could be considered as a parameter of the algorithm that allows the user to control the number of stored support vectors, which can be regarded as linearly independent in the feature space. When the user accepts a certain decrease in classification performance, it could obtain even greater reduction on memory requirements by representing the discrimination function approximately. Extensive experimental evaluation indicated that a small decrease in performance may lead to a larger reduction in the number of support vectors [49]. Therefore, the threshold τ could be used effectively to trade performance for memory requirements and speed, depending on the task at hand.\n\nThe approximate incremental techniques, such as fixed-partition incremental learning algorithm, described in Section 3. [49]. However, its inability to control the memory growth is a serious issue for many applications. By combining the reduction algorithm with the approximate techniques, it is possible to obtain an incremental SVM with a mechanism which reduces the memory growth in a principled way. The new algorithm applies the reduction scheme at each incremental steps. Thus, the new representation of the data is then built from the remaining support vectors. We could expect that the new algorithm is quite suitable for applying on a robot or mobile platform and handling continuous sequences data: first, a robot platform usually has limited resources and it may demand real-time performance. As it was shown in the previous section, the number of support vectors is a crucial factor influencing the memory requirement and the speed of the classifier. The memory-controlled algorithm allows to control the memory requirements. Consequently, it also increases the speed in both the incremental training and the testing phase of the Support Vector Machine classifier. Second, usually, image sequences contain a large amount of redundant information, even if they are acquired in a highly dynamic environment. The reduction algorithm is able to identify this redundant information by examining the linear dependence between the support vectors, keeping the model compact, fast and free from redundancy. Experiments, reported in Chapter 5, prove these assumptions.\n\nMoreover, as previously pointed out, the algorithm is flexible in tuning the tradeoff between the amount of reduction and the classification rate. Therefore, this amount of reduction could be decided based on the dynamic of the input data. As it was stated in Chapter 2.5, adaptive incremental learning system aims to maintain an updated representation of recent data, while preserving discriminative previous knowledge. For instance, in a highly dynamic environment, the out-of-date representation could decay sooner by increasing the amount of reduction before updating. Results reported in Chapter 5, revealed that the algorithm preserves important and discriminate data. Additionally, experiments also investigate the results of using different thresholds to control the speed of reduction.\n\nIn this chapter we provide a brief review of the Support Vector Machines classifier, as well as its approximate incremental extensions. Firstly, we studied the separating hyperplane in a linearly separable case and its optimal solution. Then we derived the discriminant function of the SVM classifier and showed how to perform a nonlinear mapping for solving non-separable problem. This lead us to the using of kernel functions as well as the definition of those will be used in the experiments. Secondly, we described the incremental SVM extensions proposed in the machine learning literature [53,21], which were shown to be suitable for visual recognition. Finally, we introduced a new, memory-controlled incremental SVM technique. This modified version of old incremental techniques can conquer the memory growth problem of the old techniques and is expected to handle image sequences data efficiently.\n\nThe previous chapters presented the architecture of our adaptive place recognition system as well as the theory behind it. Now let us imagine a scenario, where a guide robot begins to work in a lab, consisting of several rooms with different functionalities. First, as the robot is guided into different rooms and introduced to these places by the administrator, it takes the robot a while to \"learn\" the visual appearance of the whole house recorded during the initial supervision. After that, the robot is able to localize itself in the lab during the work. Once in a while, parts of the house are redecorated. The robot might feel lost while entering these regions. Instead of starting over a full training tour, the equipped adaptive system allows the robot to acquire new images of that place and replace its visual localization knowledge with the new information.\n\nMotivated from the above scenario, we created an image sequences database using two mobile robot platforms for the experimental evaluation. Named KTH-IDOL2 database, this database is an extension of the KTH-IDOL1 presented and used in [50]. Information about the database will be elaborated: Section 4.1 presents general information of the database. Section 4.2 provides information about the office environment where the database was acquired. Section 4.3 introduces the employed robot platforms, and Section 4.4 describes the acquisition procedure. Then, Sections 4.5 and 4.6 present interesting examples illustrating attributes of the database and captured the variability. Finally, a summary is given in Section 4.7. Additional details such as the file naming conventions, file format and structure of the database appearing in the guide can be found in the appendix of the technical report [43]. The whole database is freely available on the Internet and can be obtained at http://cogvis.nada.kth.se/IDOL/.\n\nThe name IDOL is an acronym which stands for Image Database for rObot Localization. The KTH-IDOL2 Database contains 24 image sequences accompanied by laser scans and odometry data acquired using two mobile robot platforms. The acquisition was performed within an indoor laboratory environment consisting of five rooms with different functionality (one-person office, two-persons office, corridor, kitchen, and printer area), under various illumination conditions (cloudy weather, sunny weather, and night), across a span time of six months. As a result, the data capture the natural variability that occurs in real-world environments, introduced by both illumination and human activities (people appear in the rooms, furniture and objects change location etc.).\n\nAs it was stated at the beginning, the KTH-IDOL2 database is an extension of the KTH-IDOL1 database and as such consists of the following parts: a The twelve original sequences taken from the KTH-IDOL1 database, which can be seen as an extension of the KTH-INDECS database [48] on mobile robot platforms. The sequences were acquired under various illumination conditions, over a span of two weeks, capturing natural variability of an office environment.\n\nThe purpose for collecting those database was to evaluate the robustness of a visual place recognition system. b Additional sequences were acquired six months later, using the same procedure.\n\nThe motivation for this extension was to obtain data for experiments testing the ability of our algorithms to adapt to a wider spectrum of variability that occurs within dynamic environments over a long period of time.\n\nAll the image sequences included in the database were acquired at the Computational Vision and Active Perception laboratory (CVAP), at the Royal Institute of Technology, Sweden. The part of the environment under consideration consists of five rooms with different functionality, located on the same floor: the corridor, the printer area, the kitchen , a two-persons office and a one-person office. Example pictures captured in each of the rooms are shown in Figure 4.1. A general map of the environment is presented in Figure 4.2. These rooms are physically separated by sliding glass doors. However, there is one exception. The printer area is in fact a continuation of the corridor, and was treated as a separate room due to its different functionality. Therefore, the boundary between these two rooms can be regarded as arbitrary marked.\n\nAs it was stated previously, the rooms fulfill different functions which determines the furniture layout, objects inside as well as the activity that is likely to occur. Places like the corridor, the printer area, and the kitchen can be regarded as public, which implies that various people may be present. On the other hand, the offices were imaged when they are empty or with their owners at work. In the corridor and the printer area, the furniture is mostly fixed and objects are less moveable. As a result, these areas were less susceptible to variations compared to the kitchen and the offices in which the furniture (e.g, chairs) is moved more often, objects (e.g, cups) were taken in/out, and decoration was also changed by the owner. Moreover, the whole environment, especially the regions close to windows, is heavily influenced by external illumination and weather conditions. For instance, in sunny weather, the shadows and reflections caused by sunlight will affect the visual appearance of the rooms.\n\nIt is also worth pointing out that the database was recorded only in part of the laboratory. However, because of the transparent glass door, some additional offices could still be visible in the images taken in the corridor.\n\nThe image sequences, laser scans and odometry data were acquired using two mobile robot platforms, the PeopleBot Minnie and the PowerBot Dumbo (see Figure 4.3). The robots were controlled manually using a wireless joystick. Both robots were equipped with a perspective camera, a SICK laser scanner and wheel encoders. (a) Minnie (b) Dumbo Platform Minnie Dumbo Frame Rate 5fps Resolution 320×240 Exposure Auto Focus Auto Filed Angle Horizontal:45 • Vertical:35 • Height 98cm 36cm Tilt 0 • 13 • (Up)\n\nTable 4.1. Parameters and settings of the cameras.\n\nThe images were taken using a pan-tilt-zoom Cannon VC-C4 camera mounted on the robots, and acquired at a speed of 5 frame per seconds. As shown on the images, the cameras were mounted at different heights. All the images were acquired using the same camera settings. Detailed parameters and settings of the cameras on both robots can be found in Table 4.1. As noted in the table, the camera on Dumbo was tilted up in order to reduce the amount of floor captured in the images.\n\nFor the purpose of labeling, the position and orientation, i.e. the pose, of the robot was tracked using a laser-based localization method [25]. The robot platforms were equipped with wheel encoder, odometry, which could be used to measure the relative motion of the robot. Therefore, it could be used to keep track of the pose of the robot when its initial pose was given, under ideal conditions. However, it was not the case in reality, where imperfections in the kinematic model of the robot, wheel slippage during driving, etc. cause errors that would accumulate. To bound the error in the pose estimation, a laser scanner was used together with a map of the environment.\n\nThe SICK laser scanner is a non contact active measurement system which can measure the distances to its surroundings in a plane. By matching the laser data with the environmental model, the pose of the robot can be estimated and tracked efficiently.\n\nEach image sequence was continuously acquired at a rate of 5-fps using the perspective camera, while the robot was manually driven (average speed around 0.3-0.35m/s) along a roughly planned path (see Figure 4.4) in the lab. The path was designed in a way allowing the robots to capture the visual appearance of all the rooms. As it was already mentioned, a similar path was followed during the acquisition of all the sequences. However, due to manual control, obvious differences in viewpoints still existed between different sequences. To illustrate the differences, a comparison of two paths is presented in Figure 4.5a. Additionally two sets of images from two sequences, recorded at the closest points, are shown in Figure 4.5b. Plots showing acquisition paths for all the sequences are attached to the database.\n\nThe artificial light was always on in all rooms during acquisitions. However, it was not fixed or specially adjusted before the acquisition process, which meant the light condition was the same as everyday working environment, and it would not eliminate the influence of external illumination and weather changes.\n\nFour sequences were recorded, for each robot platform (Minnie and Dumbo) and for each weather condition (sunny, cloudy, and night). Of these four sequences, the  first two (inherited from KTH-IDOL1) were acquired six months before the last two. Therefore, 24 image sequences were recorded in total. An image sequence usually contains 800 -1100 frames. Each image was automatically labeled with a timestamp, robot's pose, and the room in which it was acquired. The labeling was based on the position and direction of the camera given by the aforementioned laser-based localization system. This pose was represented in a defined global coordinate system. Then, the estimated coordinates were used to determine in which room the image was acquired.\n\nThe image sequences were acquired in a real-world setting, over a span of 6 months, and under different illumination and weather conditions. Consequently, different vi-sual variations in a indoor environment were captured in the sequences. These variations could be categorized into the following categories:\n\nVery significant changes were caused by the illumination. To capture this variability and intrinsic properties of the environment, sequences were acquired under three illumination and weather conditions: in cloudy weather, in sunny weather, and at night. The influence could be easily observed from the exemplary images presented in Figure 4.6. Especially, because of the unpredictability of the sunlight, the shadows and reflections caused by the sunlight heavily influenced the visual appearance of the captured scenes. And due to the fact that auto-exposure model of the cameras was turned on, the images became dark when acquired in front of the window in sunny days.\n\nNight Sunny\n\nThe visual appearance of the indoor environment was changing over time since it was being used. The following variations introduced by human activity can be observed in the images:\n\n• People appeared in different rooms during working time (Figure 4.7a).\n\n• Objects were moved and taken in/out of the drawers (Figure 4.7b).\n\n• Pieces of furniture, such as chairs, were pushed around (Figure 4.7c).\n\n• Decoration of one of the rooms was changed by the owner: new articles and painting were added/removed, computers and chairs were replaced (Figure 4.7d).\n\n(a) People appeared in different areas during working time.\n\n(b) Objects were moved and new objects appeared.\n\n(c) Pieces of furniture were moved around.\n\n(d) Decoration was changed.\n\nDuring the acquisition, we encountered several problems which may also occur in a real-world case. The images in the database were labeled according to the position of the robot at the moment of acquisition. As a result, when the robot faced a transparent glass door of one of the offices or was positioned in the transition region between two rooms, the visual information captured in the image was not consistent with its label. Moreover, during the acquisition, the robots also acquired images which contained very little visual cues (e.g. images of blank walls).\n\nAnother difficulty was caused by the motion of the robots. Part of the images were blurred due to the fact that the robot was shaking while driving and the autofocus function of the camera could not react fast enough during rotations. This makes the database suitable for testing applications that should operate on a mobile platform where such problems are common.\n\nThe chapter provided a description of the image sequences database we acquired within an indoor environment. This database captures the natural variability that occurs in real-world environments, introduced by both illumination and human activity. It could be used to evaluate various vision-based robot localization and place recognition algorithm and method. Our extensive experimental evaluations were entirely based on this database.\n\nWe conducted a series of experiments to evaluate the effectiveness of our system on the KTH-IDOL2 database. In the experiments, we compared the three incremental technique presented in Chapter 3 as well as the batch algorithm.\n\nIn this chapter, we report the results of the performed evaluation. The chapter starts with a description of those parts of the experimental procedure that were common for all experiments. Then, in Section 5.2, we demonstrate the adaptability of the system using the basic incremental learning paradigm, revealing the potential memory problem of that method. Section 5.3 reports results of experiments exploiting the memory-controlled incremental techniques on different image descriptors in cascade of complexity levels , based on which, one image descriptor is chosen for further experiments. In section 5.4, we will present experiments using the three incremental learning techniques on simplified environment setting to examine their properties. Next, in Section 5.5, each of the incremental techniques is tested in a real-world scenario. Finally, the chapter concludes with a discussion of the results in Section 5.6.\n\nFor space reasons, this chapter presents only a summary of the available experimental results. Detailed results can be found in [42]. Experimental result plots presented in this chapter could also be found in Appendix A in larger size.\n\nAll the experiments reported in this thesis were performed on the KTH-IDOL2 database. For each experiment, the database was divided into training and test sets with respect to the robot platform used to acquire the image sequences, as well as the illumination conditions. It is important to note that, for each sequence in KTH-IDOL2, there is always a corresponding sequence acquired under similar illumination condition, within short time span, and by the same robot platform. Consequently, once the system learned one sequence, it is supposed to achieve acceptable perfor- mance on classifying the test sequence corresponding to the training one. This makes the database useful for various kinds of tests of the adaptability of the system. In case of training, in order to reveal the various properties of interest of the incremental algorithm, we needed a reasonable number of incremental steps. Thus, we split every sequence into five subsequences, so that each subset contained one of the five images acquired by the robot every second. Since during acquisition the camera's viewpoint was changing continuously, the sub-sequences could be considered as recorded separately in a static environment but under varying poses. In order to get a feeling of the variations of the frame images in a sequence, Figure 5.1 shows eight sample images acquired within a time span of 1.6 sec.\n\nAn extended version of the libsvm [15] library, including implementation of different kernels and the support vector reduction algorithm, was employed in the experiments. During all the experiments, we set cost C = 100, and use χ 2 kernel (for global features) and local kernels [60] (for local features). Optimal kernel parameters were determined via cross validation. As stated in Chapter 3.3, for memory-controlled incremental algorithm, the threshold τ could be used as an operator to trade the performance for memory requirement and speed during classification, depending on the task at hand. Here, we introduce a new symbol Θ , which denoted the percentage of the original classification rate that is guaranteed to be preserved after the reduction. Thus, the threshold parameter was adjusted so to allow, at most, a reduction in recognition rate of (100% -Θ ) of that obtained with the fixed-partition method. Note that, in support vector reduction algorithm, the classification rate of the resulting solution could be considered as a constraint on the amount of reduced support vectors [49]. In other words, the parameter Θ decides the amount of discarded support vectors at each incremental step. Thus, the results of the memory-controlled incremental algorithm will be reported with the parameter Θ as explicit quantity, rather than an implicit threshold quantity.  Average results obtained using fixed-partition incremental techniques and the batch algorithm. The order of the training sequences was chosen in such way that the first two sequences were acquired six months before/after the testing sequence. The third sequence was recorded under roughly similar conditions as the testing sequence. The incremental method adapts to the environment variations by updating the model with recent training data, while obtaining the same performance as batch method. Large-size figures could be found in Appendix A.1.\n\nWe performed a set of pilot experiments to evaluate the adaptability of the basic fixed-partition incremental algorithm. The system was trained incrementally on three sequences acquired under similar illumination conditions with the same robot platform; the fourth sequence was used for testing. The order of the training sequences was chosen so that the first two sequences were acquired six months before/after the testing sequence. The third sequence was recorded under roughly similar conditions as the testing sequence. Training on each sequence was performed in five steps, using one subsequence at a time, resulting in fifteen steps in total. We considered 12 different permutations of training sequences; here we report average results with standard deviations. Figure 5.2, a, shows the recognition rates obtained, at each step of the incremental procedure as well as using the batch method on the whole training data. Figure 5.2, b, shows the number of support vectors stored by both the incremental and batch method in the model at each step. We can see that the performance of the system was not satisfactory, when it was trained only on the old (first ten steps) acquired long time before/after the test set. When the system began to learn a \"recent\" sequence, the classification rate increased significantly. At the same time, there was no loss in classification performance of the incremental algorithm compared to the batch one. It is also interesting to observe that, while the system was consecutively trained on the first and second sequences acquired at similar conditions, the increase in classification rate was less pronounced. However, this behavior was not reflected in the size of the model, the number of stored support vectors grew continuously with the number of training step.\n\nThese results provide a clear evidence that the fixed-partition incremental method performs as well as the batch algorithm, and is able to update representation of the model to adapt to variations. Although the memory requirement is less than the batch method and the growth is slower, there is still no correlation between the classification rate and the number of support vectors. A significant drawback of the method is that it does not guarantee a control on the growth of memory, which would eventually lead to a memory explosion. For a system applied on a robot platform, this is a serious issue.\n\nThe fixed-partition technique has shown its good performance on handling environment variations. However, because that the method does not provide a mean to control the memory growth and removing old knowledge, it is inapplicable for a mobile platform aiming to work in real-world setting. Accordingly, we put efforts on finding an incremental algorithm capable of controlling the memory growth. In Chapter 3.3, we presented a recently introduced modified version of the fixed-partition method, which is able to reduce the storage requirements while maintaining a statistically equivalent performance. As the support vector reduction algorithm, applied at each step of this incremental procedure, examines the linear relationship between support vectors and eliminates those considered as linearly dependent, it is reasonable to assume that this linear relationship between support vectors identified by the algorithm varies depending on the complexity of the image descriptors.\n\nAs already stated, the CRFH features were built on the basis of several combinations of basic image descriptors at different scales. The complexity of the CRFH descriptor could be measured by the total number of cells of the histograms, which depends on the number of image descriptors and scale levels used as well as the number of quantization levels per dimension. For instance, a histogram with 28 quantization levels per dimension, computed from normalized second order Gaussian derivatives at scales 2 and 8, denoted as L xx L xy L yy (2, 8) with 28 bins, is 6-dimensional and contains 28 6 cells. Similarly, the complexity of the local feature descriptor can be defined as the average number of corners per image identified by the Harris-Laplace interest point detector and can be controlled by adjusting the minimal threshold.\n\nWe tried several combinations of image descriptors for building CRFH features within different levels of complexity (from approximate 10 3 to 10 10 cells) and two levels of complexity of local descriptors (average number of corners per images equals 40 and 80). The experimental procedure was similar to the previous one: we used four sequences acquired at similar illumination conditions and using the same robot platform, three of them as training set and the remaining one as test set.  Results of experiment with the memory-controlled incremental method and the CRFH features in different levels of complexity. The results were obtained using the fixedpartition incremental method, and the memory controlled incremental algorithm, for three values of the parameter Θ (99%, 95% and 90%). The left column reports the classification rates. The right column reports the number of support vectors stored at each incremental step. Large-size figures could be found in Appendix A.2. At this time, the training order is not specified, but random. In the experiments, we benchmarked the memory-controlled algorithm using different values of the parameter Θ (Θ = 99%, 95% or 90%) against the fixed-partition incremental method. For each image descriptor, we performed experiments for 12 different permutations of training sequences.\n\nThe average results for the CRFH features built from various combination of image descriptors, are presented in Figure 5.3. On the left, it shows the recognition rates achieved for different value of Θ ; on the right, the figure presents the number of support vectors stored at each incremental step. Results for the local features, are reported in a similar fashion in Figure 5.4. While selecting features to implement on a mobile system, efficiency is another important point which needs to be considered. In order to give a better analysis of the efficiency of all tested feature types, we present the result for the final incremental step for one of the experiments, in context of the training and recognition time as well as the size of the model in Table 5 technique (Figure 5.3, right and Figure 5.4, right). Especially, when we accept a certain percent of reduction in classification rate (e.g. Θ = 95% or 90%), the memory requirement decreased dramatically. Moreover, we can see that the gain in memory compression is much greater than the overall decrease in performance, especially for the results obtained using Θ = 95% or 90%. This trade-off between performance and memory reduction would be a potentially useful function for applications working in a highly dynamic environment and with limited memory resources, particularly for systems equipped with multiple sensors. For a mobile robot working in an indoor environment, since in an indoor environment the space and structure are constrained and the amount of variations is lower than outdoors environment, we would like it to maintain a level of robustness. Therefore, memory-controlled method with Θ = 99% was accepted in our further experiments. Figure 5.3, right, and Figure 5.4, right, compare the competence of the memorycontrolled method on identifying linear relationship between support vectors represented by image descriptors of different complexity. As we expected, the support vector reduction algorithm implemented in the memory-controlled incremental technique does not work as effectively as it does on image descriptors of low complexity (Figure 5.3c&d, right and Figure 5.4b, right), when applies on high complexity image descriptors (Figure 5.3a&b, right and Figure 5.4a, right). This can be explained by the fact that most vectors are considered as linear independent under strict criteria of linearly dependence (i.e. Θ = 99%), when using a highly redundant representation such as CRFH of very high dimensionality and large number of quantization levels per dimension. Interestingly, Figure 5.3d, is an characteristic example. Due to their simple representation, most support vectors were identified as linearly dependent. After analyzing these results together with computational efficiency and memory requirement reported in Table 5.1, we could conclude that those complicated and redundant image descriptors 1 are additionally very computationally expensive, which make them less suitable for mobile robot applications. As shown in the table, although the CRFH built from L xx L xy L yy (2, 8) with 28 bins achieves a few percents higher accuracy than the other two CRFH features below, the computational and memory costs are many times higher than those of the low complexity feature representation.\n\nAs we can see, the histogram with 8 quantization levels per dimension, computed from normalized first-order Gaussian derivatives at scale 1 and 4, achieves good performance on bias of both performance and efficiency, and the reduction algorithm could perform effectively on this descriptor. Thus, we would only use this combination of descriptors and we set memory-controlled parameter Θ to be 99% in further experiments.\n\nIn this section, we will compare the performance of different incremental methods: fixed-partition, error-driven and memory-controlled. The experimental process was the same as the previous experiments setup, but we considered 36 permutations. The reason for doing experiments under such relatively stable environmental setup (exempt from illumination variations) was that it is easy to examine and interpret the properties of the employed incremental methods accordingly. Figure 5.5, a, shows the recognition rates obtained at each step using the three incremental algorithms as well as the batch method on the whole training data. Figure 5.5, b, reports the number of support vectors stored in the model at each step of the incremental procedure.\n\nSimilarly to the results reported in previous sections, we can still observe that the fixed-partition incremental algorithm could achieve an identical performance as the batch one, but fails to limit the memory growth. It shows plateaus in the classification rate whenever the model is trained on similar data coming from consecutive 1 CRFH feature presented in very high dimensions (high levels of complexity) captures more contents from the images. Thus, it is supposed to achieve better performance on dealing with illumination and small variations. This performance has been evaluated in [47] and [50], which could also be interpreted from the average results reported in Fig. 5.3a, left. However, we find that the desire robustness on handling types of variations still can not be achieved. Plus, the high computational cost impedes it from being applied in practice, which was the main motivation for the work conducted in this thesis. We show that incremental learning methods provide a simple solution with low cost while achieving robust performance. For interested readers, we refer the readers to the cited reference.  subsequences. However, the size of the model grows continuously at a similar rate, which is not proportional to what the system gains in performance. The other two incremental extensions (memory-controlled and error-driven) seems to be better suited for continuous learning. We see that for these methods, both the classification rate and the number of stored support vectors show plateaus every five incremental steps (Fig. 5.5), and the growth is synchronized with the performance obtained by the classifier. The error-driven technique is the model with the smallest memory growth and requirements; however, it also delivers the worst recognition performance. At the same time, the memory-controlled algorithm performs comparably to the batch SVM, with memory requirements twice smaller. Furthermore, the memory growth slows down over time (Fig. 5.5, b). This may indicate that the model becomes more and more representative and a larger amount of incoming data can be considered redundant. We therefore conclude that the memory-controlled incremental SVM is the best algorithm, with respect to the properties considered (Chapter 2.5), for the problem at hand. In order to gain a better understanding of behavior of the methods, we performed an additional analysis of the results. Fig. 5.6e shows, for the three incremental techniques, the average amounts of training vectors (originating from each of the three training sequences) that remained in the model after the final incremental step. The figure illustrates how the methods weight instances, learned at different time, when constructing the internal representation. We see that both fixed-partition and memory-controlled algorithms privilege new data, as the support vectors from the last training sequence are more represented in the model. This phenomenon is stronger for the memory-controlled algorithm, while it is not shown by the errordriven method, which seems more conservative.  To get a feeling of how the forgetting mechanism works in case of the memorycontrolled method, we plotted the positions where the support vectors were acquired. Figure 5.6 reports results obtained for a model built after the final incremental step. The positions were marked on three maps presented in Figure 5.6a,b,c so that each of the maps shows the support vectors originating from only one training sequence. As already shown in Figure 5.6e, most of the vectors in the model come from the last training sequence. Moreover, the number of support vectors from the previous training steps decreases monotonically, thus the algorithm gradually forgets the old knowledge. These support vectors could be considered as landmarks selected by the visual system for the recognition task. It is interesting to observe how the vectors from each sequence distribute along the path of the robot. On each map, the places crowded with support vectors are mainly transition areas between the rooms, regions of high variability, as well as places at which the robot rotated (thus providing a lot of different visual cues without changing position). It exhibits that the algorithm preserves those images which we human also consider as visually informative. To illustrate the point, Figure 5.6d shows sample images acquired in the corridor, for which the support vectors decay quickly, and one of the offices, for which they are being preserved much longer. The results indicate that the forgetting is not performed in a random way. On the contrary, the algorithm tends to preserve those training vectors that are most crucial for discriminative classification. As it will be shown in the next section, such behavior allows the recognition system to squeeze its internal representation and still properly classify many of the old views of places in case they recur in the future.\n\nIn this section, we performed the final evaluation of each incremental method in a real-world scenario, variations introduced by both illumination and human activity over a long time spans. For this purpose, we considered a case where the algorithms had to incrementally gain robustness to variations introduced by changing illumination and natural activity, but also to use their adaptation abilities to handle longtime environment changes. We first trained the system on three sequences acquired at roughly similar time but under different illumination conditions. After that, we repeated the same training procedure on sequences acquired 6 months earlier/later. Since IDOL2 data consists of pairs of sequences acquired under roughly similar conditions, each training sequence have a corresponding sequence which could be used for testing. Again, each sequence was divided into five subsequences. In total, for each experiment we performed 30 incremental steps. The experiment procedure is illustrated in Figure 5.7.\n\nthat the fixed-partition method performs as batch SVM, but it is unable to control the memory growth. We also found that the error-driven method could get a reasonable accuracy while minimizing the memory requirements. Still, even if for this last algorithm the number of stored SVs increases slowly, the growth is not predictable nor controllable. Moreover, none of these two methods has shown to possess an effective forgetting mechanism. On the contrary, they can be described as conservative, and we can expect that they would adapt slowly in highly dynamic environments. As opposed to this, the memory-controlled algorithm is able to achieve performances statistically equivalent to those of batch SVM, while at the same time providing a principled and effective way to control the memory growth. The experiments show that this has induced a forgetting mechanism which privileges newly acquired data to the expenses of oldest one, while reaching a memory plateau whenever new data are similar to those already processed.\n\nVarying environment poses a crucial challenge to vision-based place recognition systems. An incremental learning system continuously updating its internal representation is able to adapt to these changes. In spite of that, in order to implement this system on a mobile robot platform with limited memory and processing resources, we as designers need to put strong efforts on the efficiency of the system.\n\nIn this thesis, we proposed a discriminative incremental learning approach to the place recognition problem, using a novel version of incremental support vector machine extension, which allows to control the memory growth as the new data arrives in an intelligent way. Extensive experiments show that this method could achieve recognition performances statistically equivalent to those of the batch case, while obtaining a dramatic memory reduction. As a first step toward the goal of building an autonomous agents capable of on-line, continuous learning, we showed experimentally that (a) the method tends to forget old knowledge in favor of the new data when updating, and discriminative knowledge tends to be preserved longer in this \"memory decay\" episode; (b) it reaches a plateau in performance and memory when the environment is relatively stable, which could be translated into measurable quantity to trigger/pause the updating process; and (c) the speed of forgetting could be controlled by adjusting a threshold value of the incremental algorithm. This could lead to a system that controls its speed of forgetting according to the dynamic state of the environment.\n\nThe work presented in this thesis can be extended in many directions, two major issues will be investigated in the future:\n\n• Update Room by Room/Frames by Frames The possibility to do the incremental learning, room by room or frames by frames. Doing updating and learning in a more natural way would make this work very interesting. Pilot experiments demonstrate the result to be quite promising.\n\nAs pointed out in the previous chapter, due to limitations of current state-of-art of visual feature representations and the ambiguities between visual information and semantics, the place recognition system still face many difficulties in a realist setting. A cue-integration scheme can be incorporated into the system. Because audio information will not suffer from the occlusion and viewpoint limitation, and current speech recognition system can achieve very accurate and robust results on identifying speakers and special sound events, we plan to combine audio as a secondary cues to improve the robustness of current system.  0 2 4 6 8 10 12 14 16 1000 1100 Training Step Number of Support Vectors Batch Incremental(Fixed-partition)    0 2 4 6 8 10 12 14 16 100 Training Step Classification Rate (%) Fixed-partition Memory-controlled(99%) Memory-controlled(95%) Memory-controlled(90%) (a) Classification Rate.   0 2 4 6 8 10 12 14 16 Training Step Classification Rate (%) Fixed-partition Memory-controlled(99%) Memory-controlled(95%) Memory-controlled(90%) (a) Classification Rate.   0 2 4 6 8 10 12 14 16 45 50 55 60 65 70 Training Step Classification Rate (%) Fixed-partition Memory-controlled(99%) Memory-controlled(95%) Memory-controlled(90%) (a) Classification Rate.  A.3 Figure 5.4 2 4 6 8 10 12 14 16 65 70 75 80 85 90 95 100 Training Step Classification rate (%) Batch Fixed-partition Memory-controlled(99%) (a) Classification Rate.   0 2 4 6 8 10 12 14 16 Training Step Classification rate (%) Batch Fixed-partition Memory-controlled(99%) (a) Classification Rate.   A.4 Figure 5.5 0 2 4 6 8 10 12 14 16 65 70 75 80 85 90 95 Training Step Classification Rate (%) Batch Fixed-partition Memory-controlled(99%) Error-driven Fig. A.9.    Fixed-partition Memory-controlled(99%) Error-driven Number of Support Vectors 213 244 292 108 140 211 128 81 68 Tr. sequence 1 Tr. sequence 2 Tr. sequence 3 Fig. A.14. Figure 5.6e\n\nAdaptive Visual Place Recognition Architecture\n\nIncremental Support Vectors Machine Learning\n\nScenario and the KTH-IDOL2 Database\n\nExperimental Setup and Results"
}