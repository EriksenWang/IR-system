{
    "title": "A Framework to Support Spatial, Temporal and Thematic Analytics over Semantic Web Data",
    "publication_date": "2007",
    "authors": [
        {
            "full_name": "Matthew S Perry",
            "firstname": "Matthew S",
            "lastname": "Perry",
            "affiliations": []
        },
        {
            "full_name": "P Sheth",
            "firstname": "P",
            "lastname": "Sheth",
            "affiliations": []
        },
        {
            "full_name": "Prateek Jain",
            "firstname": "Prateek",
            "lastname": "Jain",
            "affiliations": []
        }
    ],
    "abstract": "Spatial and temporal data are critical components in many applications. This is especially true in analytical applications ranging from scientific discovery to national security and criminal investigation. The analytical process often requires uncovering and analyzing complex thematic relationships between disparate people, places and events. Fundamentally new query operators based on the graph structure of Semantic Web data models, such as semantic associations, are proving useful for this purpose. However, these analysis mechanisms are primarily intended for thematic relationships. In this paper, we describe a framework built around the RDF data model for analysis of thematic, spatial and temporal relationships between named entities. We present a spatiotemporal modeling approach that uses an upper-level ontology in combination with temporal RDF graphs. A set of query operators that use graph patterns to specify a form of context are formally defined. We also describe an efficient implementation of the framework in Oracle DBMS and demonstrate the scalability of our approach with a performance study using both synthetic and real-world RDF datasets of over 25 million triples.",
    "full_text": "Analytical applications are increasingly exploiting complex relationships among named entities as a powerful analytical tool. Such \"connect-the-dots\" applications are common in many domains including national security, drug discovery, and medical informatics. Semantic Web Technologies [Herman et al. 2001] are well suited for this type of analysis. It is often necessary that the analysis process spans across multiple heterogeneous data sources, and ontologies and semantic metadata standards help facilitate aggregation and integration of this content. In addition, standard models for metadata representation on the web, such as Resource Description Framework (RDF) [Klyne and Carroll ], model relationships as first class objects making it very natural to query and analyze entities based on their relationships. Researchers have consequently argued for graph-based querying of RDF [Angles and Gutierrez 2005], and fundamentally new analytical operators based on the graph structure of RDF have emerged (e.g., semantic associations [Anyanwu and Sheth 2003] and subgraph discovery [Ramakrishnan et al. 2005]). These operators allow querying for complex relationships among named entities where an ontology provides the context or domain semantics. We use the term semantic analytics to refer to this process of searching and analyzing semantically meaningful connections among named entities. Semantic analytics has been successfully used in a variety of settings, for example identifying conflict of interest [Aleman-Meza et al.\n\n• 2006], detecting patent infringement [Mukherjea and Bamba: 2004] and discovering metabolic pathways [Kochut and Janik 2007].\n\nSo far, semantic analytics tools have primarily focused on thematic relationships, but spatial and temporal data are often critical components in analytical domains. In fact, most entities and events can be described along three dimensions: thematic, spatial and temporal. Consider the following event: Fred Smith moved into the house at 244 Elm Street on November 16, 2007. The thematic dimension describes what is occurring (the person Fred Smith moved to a new residence). The spatial dimension describes where the event occurs (the new residence is located at 244 Elm Street). The temporal dimension describes when the event occurs (the moving event occurred on November 16, 2007). Unfortunately, integrated semantic analytics over all three dimensions is not currently possible because of the following gaps in the state of the art:\n\n-Current GIS and spatial database technology does not support complex thematic analytics operations. Traditional data models used for GIS excel at modeling and analyzing spatial and temporal relationships among geospatial entities but tend to model the thematic aspects of a given domain as directly attached attributes of geospatial entities. Thematic entities and their relationships are not explicitly and independently represented, making analysis of these relationships difficult. -Current semantic analytics technology does not support analysis of spatial and temporal relationships. Semantic analytics research has focused on thematic relationships between entities. Thematic relationships can be explicitly stated in RDF graphs, but many important spatial and temporal relationships (e.g., distance and elapsed time) are implicit and require additional computation. Semantic analytics tools depend on explicit relations and must be extended if they are to use implicit spatial and temporal relations.\n\nThis paper describes a framework that aims to bridge these gaps. In [Anonymous 2006] a modeling approach was presented that tries to overcome the limitations described above by modeling spatial, temporal and thematic (STT) data using ontologies and temporal RDF graphs. A variety of query operators that combine thematic relationships with spatial and temporal relationships are possible with this modeling approach. In [Anonymous 2007], initial definitions and a prototype implementation of a core set of query operators were presented. We further develop the ideas presented in these papers and describe a framework to support STT analytics over Semantic Web data.\n\nWe propose a framework that extends current semantic analytics technology so that spatial and temporal data is supported in addition to thematic data. We address problems of data modeling, data storage and query operator design and implementation. Specifically, we make the following contributions:\n\n-An ontology-based spatiotemporal modeling approach using temporal RDF.\n\n-A formalization of a set of spatial, temporal and thematic query operators for the proposed modeling approach that builds on a notion of context and supports computation of implicit spatial and temporal relations.\n\n• 3 -A SQL-based implementation of the proposed query operators that involves a storage and indexing scheme for spatial and temporal RDF data and an efficient treatment of temporal RDFS inferencing.\n\n-A detailed performance study of the implementation using large synthetic and real-world RDF datasets.\n\nThe initial ideas underlying this framework appeared in the proceedings two conferences [Anonymous 2006, Anonymous 2007]. We have further developed, refined and extended the material presented at these conferences. Our new contributions include (1) a revised formalization of a core set of query operators that generalizes from path templates to graph patterns, (2) a deeper discussion of the RDF serializations used in the framework, the algorithms used for implementation and the relevant related work in the literature and (3) a more complete and extensive evaluation of our implementation that involves not only synthetically-generated RDF datasets but also a real-world RDF dataset of over 25 million triples. Our implementation demonstrates excellent scalability for very large RDF datasets in this evaluation (e.g., execution time of less than 500 milliseconds for a 10-hop graph pattern query over a 28 million triple dataset).\n\nThe remainder of the paper is organized as follows. Section 2 presents motivating examples. Our modeling approach is discussed in Section 3, and query operators over this model are formalized in Section 4. Section 5 presents an implementation of this framework in Oracle DBMS. An experimental evaluation of our implementation is presented in Section 6. Section 7 discusses related work in spatial and temporal data management and management of RDF data, and Section 8 gives conclusions and discusses future work.\n\nWe will motivate this work with a set of examples from the environmental sciences domain. Suppose a hydrology researcher is investigating the effects of human activities on rainfall-runoff relationships. Through some initial work using a GIS system, the researcher has noticed an increase in home-owner's insurance claims related to water damage within a certain geographic region. A possible reason for this could be a reduction in ground vegetation in the area due to human activities, as this vegetation helps prevent flash flood events. An interesting search would be find any factories with manufacturing processes that may adversely affect nearby ground vegetation and only return those factories within the identified zone of houses. We may pose the following SQL query involving the spatial restrict table function for such a search: SELECT f as factory FROM TABLE (spatial restrict(' (?f uses manufacturing process ?m) (?m has by product ?p) (?p negatively affects <Ground Vegetation>) (?f located at ?l)', <Houses Region>, 'GeoRelate(mask=inside)');\n\n• With this query, we are using the spatial restrict operator to specify a thematic connection (context) between factories and substances that negatively impact ground vegetation, and we are then using a spatial relationship to limit the results to those factories inside the spatial feature (i.e., polygon) formed from the boundary of the region of homes in question. We also provide a spatial extent operator that allows retrieving the spatial geometry associated with a given thematic entity with respect to a given context, and a spatial eval operator that computes the spatial relationship between two thematic entities with respect to a given context.\n\nWe provide analogous temporal extent, temporal restrict and temporal eval operators to query temporal aspects of connections between entities. The temporal extent operator returns the temporal properties of a given relationship and the temporal restrict operator allows optional filtering based on these temporal properties. For example, find all flood insurance claims occurring after a given factory became operational and return the dates of the claims.\n\nSELECT c as claim, start date, end date FROM TABLE (temporal restrict(' (?o files claim ?c) (?c related to <Flood Damage>) (?c for policy ?p) (?p type <Homeowners>)', 'AFTER ', '2006', ' -03-02', '2006-03-03', 'INTERSECT'))-03-03', 'INTERSECT'));\n\nIn this query, we are specifying a graph pattern that identifies a particular type of insurance claim. We are additionally limiting the results to those that are valid after the input time interval. The INTERSECT keyword indicates the type of temporal interval to use for a given result subgraph. In this case, we are interested in the time interval during which each edge (RDF statement) in the subgraph is valid. Our final operator, temporal eval, acts as a temporal join for thematic subgraphs.\n\nOur implementation allows multiple operators to be used in a single SQL query. We can therefore execute spatio-temporal-thematic queries that combine spatial and temporal operators. These possibilities are discussed in Section 5.1. Though we refer to our queries as spatial, temporal or spatiotemporal in the paper, all our queries involve a significant thematic component due to the graph patterns used in the queries.\n\nWe use the running scenario of historical analysis of battlefield events of World War II to illustrate concepts in the remainder of the paper. We chose this scenario because it is easy to understand and because we have generated large synthetic datasets corresponding to this scenario that are used in our evaluation.\n\nOur ontology-based modeling approach is presented in this section. We give preliminary descriptions of RDF, RDFS and Temporal RDF and present the core ontologies used in our modeling approach.\n\n3.1.0.1 RDF:. RDF has been adopted by the W3C as a standard for representing metadata on the Web. The RDF data model is defined as follows. Let U , L and B be pairwise disjoint sets of URIs, literals and blank nodes, respectively. The , Vol. , No. , 20.\n\n• 5 union of these sets U ∪ B ∪ L is referred to as the set of RDF Terms RT . An RDF triple is a 3-tuple (s, p, o) ∈ (U ∪B)×U ×RT where s is the subject, p is the property and o is the object. A set of RDF triples is referred to as an RDF Graph, as RDF can be represented as a directed, labeled graph where a directed edge labeled with the property name connects a vertex labeled with the subject name to a vertex labeled with the object name.\n\n3.1.0.2 RDFS:. RDF Schema (RDFS) [Brickley and Guha ] provides a standard vocabulary for describing the classes and relationships used in RDF graphs and consequently provides the capability to define ontologies. Ontologies serve to formally specify the semantics of RDF data so that a common interpretation of the data can be shared across multiple applications. Classes represent logical groups of resources, and a member of a class is said to be an instance of the class. The RDFS vocabulary offers a set of built-in classes and properties. Two of the most relevant classes are rdfs:Class and rdf:Property, and some of the most relevant properties are rdf:type, rdfs:domain, rdfs:range, rdfs:subClassOf and rdfs:subPropertyOf. The rdf:type property is used to define class and property types (e.g., the triple (S, rdf:type, rdfs:Class) asserts that S is a class). rdf:type is also used to denote instances of classes (e.g., (s, rdf:type, S ) asserts that s is an instance of S ). rdfs:domain and rdfs:range allow us to define the domain and range for a given property, and rdfs:subClassOf and rdfs:subPropertyOf allow us to create class and property hierarchies.\n\nA set of entailment rules are also defined for RDF and RDFS [Hayes 2004]. Conceptually, these rules specify that an additional triple can be added to an RDF graph if the graph contains triples of a specific pattern. Such rules describe, for example, the transitivity of the rdfs: subClassOf property (i.e. (x, rdfs:subClassOf, y) (y, rdfs:subClassOf, z ) ⇒ (x, rdfs:subClassOf, z )).\n\n3.1.0.3 Temporal RDF:. In order to analyze the temporal properties of relationships in RDF graphs, we need a way to record the temporal properties of the statements in those graphs, and we must account for the effects of those temporal properties on RDFS inferencing rules. Gutierrez et. al. introduced the notion of temporal RDF graphs for this purpose [Gutierrez et al. 2005;2007].\n\nTemporal RDF graphs model linear, discrete, absolute time and are defined as follows [Gutierrez et al. 2007]. Given a set of discrete, linearly ordered time points T , a temporal triple is an RDF triple with a temporal label t ∈ T . A statement's temporal label represents its valid time. The notation (s, p, o) : [t] is used to denote a temporal triple. The expression (s, p, o)\n\nThe following example illustrates these concepts. Consider a soldier s1 assigned to the 1st Armored Division (1stAD) from April 3, 1942, until June 14, 1943, and then assigned to the 3rd Armored Division (3rdAD) from June 15, 1943, until October 18, 1943. This would yield the following triples: (s1, assigned to, 1stAD) : [04:03:1942[04:03: , 06:14:1943[04:03: ], (s1, assigned to, 3rdAD) : [06:15:1943[04:03: , 10:18:1943]].\n\nWe must also account for the effects of temporal labels on RDFS inferencing rules (see Section 5.2.2). To incorporate inferencing into temporal RDF graphs, a basic arithmetic of intervals is needed to derive the temporal label for inferred statements. For example, interval intersection would be needed for rdfs:subClassOf (e.g., (x, rdfs:subClassOf, y) : [1, 4] ∧ (y, rdfs:subClassOf, z ) : [3, 5] ⇒ (x, rdfs:subClassOf, z ) : [3, 4]).\n\nHere we discuss our ontology-based approach for modeling theme, space and time.\n\nWe present an upper-level ontology defining a general hierarchy of thematic and spatial entity classes and associated relationships connecting these entity classes (see Figure 1). We intend for application-specific domain ontologies in the thematic dimension to be integrated into the upper-level ontology through subclassing of appropriate classes and relationships. Temporal information is integrated into the ontology by labeling relationship instances with their valid times. A unique aspect of this approach is that we do not require the spatial properties of each thematic entity to be explicitly recorded. Instead, we utilize relationships in the thematic domain to indirectly provide spatial properties. This gives the benefit of greater flexibility in the integration of thematic and spatial information.\n\n3.2.0.4 Thematic Dimension:. Our upper-level thematic ontology consists of a fundamental class hierarchy and a few basic relationships. In developing the class hierarchy, we first follow the approach of Grenon and Smith's Basic Formal Ontology [Grenon and Smith 2004] and distinguish between Continuants and Occurrents. Continuants are those entities that persist over time and maintain their identity through change. Examples from our historical battlefield analysis scenario could include a soldier, an aircraft or a city. Occurrents represent events and processes; they happen and then no longer exist. Examples are the bombing of a target or the execution of a training exercise. A second division of entities concerns spatial properties. Some Occurrents are inherently spatial such as a battle; others are not, such as the assignment of a solider to a division. We therefore explicitly represent , Vol. , No. , 20.  Spatial Occurrents and Non-Spatial Occurrents. Continuants also have varying spatial properties. We distinguish a special type of Continuant that we refer to as a Named Place. Named Places are entities that serve as locations for other physical entities and Spatial Occurrents. They have very static spatial behavior over time and are distinguished by a strong association with their spatial location. Examples of Named Places include a city, a zip code, a building, or a lake. In contrast to a Named Place, we distinguish another subclass of Continuant: Dynamic Entity. Dynamic Entities are those entities with dynamic spatial behavior whose identities are not as strongly associated with space. Examples include a person or a vehicle. We do not make further philosophical distinctions between these two types of Continuants as the final decision depends upon the domain and application.\n\n3.2.0.5 Spatial Dimension:. The spatial portion of our upper-level ontology consists of a top-level class and two corresponding relations. Spatial Regions represents basic spatial geometries (i.e. georeferenced points, lines and polygons). The occurred at relation connects Spatial Occurrent to Spatial Region, and located at connects Named Place to Spatial Region. These relations allow us to associate a thematic concept, such as the city of Berlin or the Battle of the Bulge, with its geospatial properties. Spatial properties of thematic entities can consequently be derived using the associated Spatial Regions.\n\nThe spatial features represented by the Spatial Region class are complex types that need to be fully modeled with a spatial ontology. Fortunately, there is movement towards standard ontologies for spatial geometries, for example work done • as part of the Open Geospatial Consortium (OGC) Semantic Web Interoperability Experiment [Open Geospatial Consortium 2008] and the W3C geo incubator group [Lieberman 2006]. The existing OGC Geographic Markup Language (GML) specification serves as an excellent basis for these ontologies as discussed in [Abdelmonty et al. 2005;Kolas et al. 2005]. We propose a spatial ontology based on the GeoRSS GML specification [Singh et al. 2008]. The ontology models 2-dimensional spatial geometries and associated spatial reference system information. Figure 2 illustrates the RDF representation of this ontology.\n\n3.2.0.6 Temporal Dimension:. We use temporal RDF graphs [Gutierrez et al. 2007] to incorporate the time dimension into our model. Temporal information is represented by associating time intervals with relationship instances in the ontology. The time interval on the relationship denotes the times at which the relationship is valid. These time intervals are grounded to a discrete, linearly-ordered timeline. RDF reification is used to associate time intervals with RDF statements to realize temporal RDF graphs. We use a portion of the OWL-Time ontology [Hobbs and Pan 2004] to model the time intervals themselves, and a new property temporal asserts that the reified statement is valid during the given time interval. Figure 3 illustrates this approach.\n\nOur approach for querying over this ontology-based model utilizes the graph-centric structure of RDF data. For spatial aspects, we use subgraphs in the RDF graph to connect thematic entities (e.g., Dynamic Entities) to Spatial Regions. A given thematic entity can be connected to various Spatial Regions through a variety of different subgraphs, yielding a many-to-many mapping. Associated domain ontologies clarify the semantics of these subgraphs, and we refer to a given subgraph as a context. That is, a thematic entity has spatial properties with respect to a given context. Using a military ontology, for example, a soldier could be associated with the spatial properties of his residence in one context (Solider, lives at, Residence) (Residence, located at, Spatial Region) or with the locations of his training facilities using a different context (Soldier, member of, Military Unit) (Military Unit, trains at, Base) (Base, located at, Spatial Region). For temporal aspects, we derive temporal intervals for these subgraphs through computations over the temporal values of the edges (temporal RDF triples) that make up the subgraph.\n\nIn this section, we introduce and formalize a set of query operators that follow the basic approach outlined above. We introduce spatial operators that allow (1) retrieving the spatial properties of an entity with respect to a given context (spatial extent), (2) retrieving the set of entities whose associated Spatial Regions satisfy a spatial predicate (spatial restrict) and (3) retrieving pairs of entities whose associated spatial regions satisfy a given spatial relation (spatial eval). We introduce temporal operators that allow (1) deriving a temporal interval for a subgraph in the RDF graph (temporal extent), (2) filtering a set of subgraphs by evaluating a temporal predicate over their derived time intervals (temporal restrict), and (3) retrieving pairs of subgraphs whose time intervals satisfy a given temporal relation (temporal eval). We will use the example temporal RDF graph G t 1 shown in Figure 4 to illustrate each query operator.\n\n, Vol. , No. , 20. Our framework differs from traditional approaches to querying RDF data in that computation of implicit relationships are supported. We do not rely on the existence of explicit RDF statements asserting spatial and temporal relationships such as inside and after. Instead, we perform computations at query time to establish the existence of these relationships that are implicit in the RDF dataset.\n\nOur querying approach relies on specifying a type of connection between resources in an RDF graph. We use SPARQL-like graph patterns to express these connection types. Conceptually, a graph pattern is a set of RDF triples where the subjects, properties and/or objects may be replaced with variables. In general, a graph pattern query against an RDF graph G returns a set of mappings between the variables in the graph pattern and terms (URIs, Blank Nodes and Literals) in G such that replacing variables with their corresponding terms results in a set of triples actually present in G. Figure 5 illustrates an example graph pattern query. A formal syntax for SPARQL graph patterns and formal semantics for SPARQL graph pattern queries is given in [Perez et al. 2006]. We present a fragment of this formalization to define the general concept of a graph pattern, which we use to formally define our proposed query operators.\n\nLet U L denote the union U ∪ L (recall that U is the set of URIs and L is the set of Literals) and let V N be a set of variables disjoint from the set of RDF Terms RT .\n\nA graph pattern is defined recursively as follows:\n\n-\n\n-If P 1 is a triple pattern, then P 1 is a graph pattern.\n\n, Vol. , No. , 20.\n\n• Fig. 5. Example graph pattern from historical analysis of WWII scenario with resulting variable bindings.\n\n-If P 1 and P 2 are graph patterns, then (P 1 AND P 2 ) is a graph pattern.\n\nThe semantics of a graph pattern are defined in terms of a function [[•]], which takes a graph pattern expression and returns a set of mappings where a mapping µ : V N → RT is a function from V N to RT . For a triple pattern tp, we denote the set of variables in tp as var(tp), and we denote the triple obtained by replacing the variables in tp according to the mapping µ as µ(tp). For a graph pattern GP , we denote the set of triples obtained by replacing the variables in GP according to µ as µ(GP ), and we refer to this set of triples as an instance of GP . For a mapping µ, the subset of V N where it is defined is called its domain dom(µ). Two mappings µ 1 and µ 2 are compatible if for all x ∈ dom(µ 1 ) ∩ dom(µ 2 ), it is the case that µ 1 (x) = µ 2 (x). In other words the union µ 1 ∪ µ 2 is also a mapping. In addition, for two sets of mappings M 1 and M 2 , the join is defined as:\n\nand µ 2 ∈ M 2 and µ 1 and µ 2 are compatible mappings} Let G be an RDF graph, tp a triple pattern and P 1 , P 2 graph patterns. The evaluation of a graph pattern over G, denoted [[•]] G , is defined recursively as:\n\n-\n\nWe define our spatial operators using what we term a spatial context. Conceptually, a spatial context specifies a type of connection between a thematic entity and a spatial entity. Given a temporal RDF graph G t , a spatial context is defined as a 2-tuple (GP, v) where GP is a graph pattern and v ∈ var(GP ) is a variable in GP identifying a Spatial Region instance. That is, for each mapping µ ∈ [[GP ]] T RIP LES(Gt) with µ(v) = x, there exists a triple (x, rdf:type, Spatial Region) in T RIP LES(G t ). Note that G in the previous section refers to a plain RDF graph, and here G t refers to a temporal RDF graph. Also recall that T RIP LES(G t ) denotes the plain RDF graph created by removing the temporal information from G t . As an example, consider the spatial context below that connects a soldier (?x ) to a Spatial Region (?s).\n\n('(?x assigned to ?y) (?y participates in ?z ) (?z occurred at ?s)', '?s') , Vol. , No. , 20.\n\nIn the following, for a Spatial Region URI sr, we use geom(sr) to refer to the actual spatial geometry (i.e. point, line, polygon) represented by sr according to the spatial ontology described in Section 3.2. We use S to denote the set of all possible spatial geometries.\n\nThe first spatial operator we define, spatial extent, is intended to find the spatial properties of a thematic entity with respect to a given spatial context. The query \"what are the spatial properties of the 101st Airborne Division with respect to battle participation\" (Example 1) illustrates an example search using this operator. We can think of this operator as retrieving the spatial features corresponding to the identified Spatial Region in the result subgraphs of a graph pattern query.\n\nT RIP LES(Gt) and s = geom(µ(v))} Example 1: ANS ← spatial extent('( 101st Airborne Division participates in ?x ) (?x occurred at ?v )', '?v ') Gt1 Example 1 Result: Result Variable Value µ 1 x Siege of Bastogne v Polygon 1 s 1 -Polygon((5.43 50.00, ... , 5.43 50.00)) µ 2 x Operation Market Garden v Polygon 3 s 2 -Polygon((5.51 51.59, ... , 5.51 51.59))\n\nThe next two spatial operators focus on spatial relationships. As a prerequisite, we define a spatial formula, which is used to express conditions on spatial relationships. Spatial formulas are built from qualitative spatial functions and metric spatial functions. A qualitative spatial function is a Boolean function qsf : S × S → B. Any of the following topological spatial relations identified by Egenhofer and Herring [Egenhofer and Herring 1994] may be used as qualitative spatial functions in our formalization: disjoint, touch, overlap boundary disjoint, overlap boundary intersect, equal, contains, covers, inside, covered by.\n\nWe define a qualitative spatial expression, qse, as follows, where s 1 , s 2 ∈ S ∪ V S .\n\nqse ::= qsf (s 1 , s 2 )\n\nA metric spatial function is a function msf : S × S → R. We use one metric spatial function distance : S × S → R, which returns the distance between two spatial geometries. Let V S be a set of variables disjoint from V N and RT . We define a metric spatial expression, mse, as follows, where s 1 , s 2 ∈ S ∪ V S and r ∈ R.\n\nA spatial formula sf evaluates to a Boolean value for a given graph and is defined , Vol. , No. , 20.\n\n• in terms of metric spatial expressions and qualitative spatial expressions. A spatial formula takes the following form.\n\nThe spatial formulas used in our formalization are expressions containing exactly one free variable $s or exactly two free variables $s 1 and $s 2 and are denoted as sf ($s) and sf ($s 1 ,$s 2 ).\n\nThe next spatial operator, spatial restrict, is designed to retrieve thematic entities based on their spatial relationships with a given location in a given context. An example of this type of search is \"which military units have spatial extents that are within 20 miles of (50.00 N, 6.00 E) in the context of battle participation?\" Note that the variable $s used in the spatial formula is different from the variable v in the graph pattern that represents a Spatial Region instance, as v corresponds to a URI and $s corresponds to a spatial geometry. (Example 2).\n\na spatial context (GP, v), a spatial formula sf defined over S and a variable $s, a temporal RDF graph G t Find:\n\nand sf evaluates to true for $s = s} Example 2:\n\nANS ← spatial restrict('(?x participates in ?y) (?y occurred at ?v )', '?v ', distance($s, (50.00N, 6.00E)) ≤ 20 miles)\n\nGt1 Example 2 Result: Result Variable Value µ 1 x 101st Airborne Divison y Siege of Bastogne v Polygon 1 s 1 -Polygon((5.43 50.00, ... , 5.43 50.00)) µ 2 x 10th Armored Divison y Siege of Bastogne v Polygon 1 s 2 -Polygon((5.43 50.00, ... , 5.43 50.00)) µ 3 x 82nd Airborne Divison y Battle of the Bulge v Polygon 2 s 3 -Polygon((6.04 50.32, ... , 6.04 50.32))\n\nThe final spatial operator, spatial eval, investigates how thematic entities are related in space. We can think of this operator as a spatial join between thematic entities with respect to a given context. As an example, consider the query \"which military unit's operational area is inside the operational area of the 82nd Airborne Division?\" (Example 3).\n\n• 13\n\na spatial context (GP 1 , v 1 ), a spatial context (GP 2 , v 2 ), a spatial formula sf defined over S and variables $s 1 , $s 2 , a temporal RDF graph G t Find:\n\nANS ← spatial eval('(? x 1 participates in ? y 1 ) (? y 1 occurred at ? v 1 )', '? v 1 ', '( 82nd Airborne Division participates in ? y 2 ) (?\n\nDivison y 1 Siege of Bastogne v 1 Polygon 1 s 11 -Polygon((5.43 50.00, ... , 5.43 50.00)) µ 12 y 2 Battle of the Bulge v 2 Polygon 2 s 12 -Polygon((6.04 50.32, ... , 6.04 50.32)) µ 21 x 1 10th Armored Divison y 1 Siege of Bastogne v 1 Polygon 1 s 21 -Polygon((5.43 50.00, ... , 5.43 50.00)) µ 22 y 2 Battle of the Bulge v 2 Polygon 2 s 22 -Polygon((6.04 50.32, ... , 6.04 50.32))\n\nThe basic idea behind our temporal operators is that we derive a time interval for a graph pattern instance using the time intervals associated with the triples in the graph pattern. These derived intervals are used to restrict graph pattern query results and to perform temporal joins between graph pattern instances. We will first give some initial definitions. Let T be a set of totally ordered time points. Let G t be a temporal RDF graph defined over T . For each statement e\n\nConsider the following example: 2,3,4,5,6,7,8,9, 10}, T = {2, 3, 4, 7, 8}\n\nGiven a set of temporal triples E = {e 1 , e 2 , ..., e n }, we define the interval expan-, Vol. , No. , 20.\n\nsion of E, int expansion(E), as the set contig intervals(temporal(e 1 ))× contig intervals(temporal(e 2 )) × ... contig intervals(temporal(e n ))\n\nConsider the following example:\n\nSuppose:\n\nGiven a set of time intervals I = {(s 1 , t 1 ), (s 2 , t 2 ), ..., (s n , t n )} defined over T , let s min = min 1≤i≤n s i , s max = max 1≤i≤n s i , t min = min 1≤i≤n t i , and t max = max 1≤i≤n t i . We define two values, intersect and range, as follows:\n\nConceptually, intersect(I) is the largest time interval that intersects each interval in I, and range(I) is the smallest interval that contains each interval in I.\n\nWe will now extend these definitions from a set of intervals to a set of sets of intervals (e.g., what is returned from int expansion). Given a set of sets of time intervals I S = {I 1 , I 2 , ..., I n }, we define intersect S and range S as follows:\n\nThe first temporal operator we define, temporal extent, is intended to compute and return the derived time intervals for the results of a graph pattern query. This operator can return one of two time intervals: (1) the intersect interval that represents the time interval during which all statements in the graph pattern instance are valid and (2) the range interval that represents the time interval during which any statement in the graph pattern instance is valid. As an example consider the query \"find all members of the 101st Airborne Division that participated in battles and the valid times of those battles\" (Example 4).\n\na temporal RDF Graph G t , a graph pattern GP , an interval type IT ∈ {intersect, range} , Vol. , No. , 20.\n\nFind:\n\nT RIP LES(Gt) and i ∈ intersect S /range S (int expansion(µ(GP )))} Example 4: ANS ← temporal extent ('(?x assigned to 101st Airborne Division ) ( 101st Airborne Division participates in ?y)', 'intersect') Gt1 Example 4 Result: Result Variable Value µ 1 x Soldier 1 y Siege of Bastogne i 1 -[12:19:1944,01:15:1945] µ 2 x Soldier 2 y Siege of Bastogne i 2 -[12:19:1944,01:15:1945] µ 3 x Soldier 1 y Operation Market Garden i 3 -[09:17:1944,09:25:1944] µ 4 x Soldier 2 y Operation Market Garden i 4 -[09:17:1944,09:25:1944]\n\nThe remaining temporal operators examine temporal relationships. To specify conditions on these relationships, we define a temporal formula which is constructed from qualitative and metric temporal expressions. For a given temporal RDF graph G t over time domain T , let I denote the set of all time intervals over T . A qualitative temporal function is a Boolean function qtf : I × I → B. Any of the thirteen interval relations identified by Allen [Allen 1983] can be used in qualitative temporal functions in our formalization. We define a qualitative temporal expression, qte, as follows, where i 1 , i 2 ∈ I ∪ V T .\n\nqte\n\nA metric temporal function is a function mtf : I × I → Z. We use one metric temporal function elapsed time : I × I → Z, which is defined for two disjoint time intervals as the duration of time between the end of the earliest interval and the start of the latest interval. The function returns zero if the intervals are not disjoint.\n\nLet V T be a set of variables disjoint from V N , RT and V S . We define a metric temporal expression, mte, as follows, where i 1 , i 2 ∈ I ∪ V T and z ∈ Z.\n\nA temporal formula tf evaluates to a Boolean value for a given graph and is constructed from qualitative temporal expressions and metric temporal expressions. It takes the following form, where\n\nThe temporal formulas used in our formalization are expressions containing exactly one free variable $t or exactly two free variables $t 1 and $t 2 and are denoted as tf ($t) and tf ($t 1 ,$t 2 ).\n\nThe first relationship-based temporal operator, temporal restrict, is concerned with the temporal properties of a single entity. This operator inquires about the properties of an entity at a given time. For example, one may ask \"which members of the 10th Armored Division participated in battles during the time interval from January 1 1944 to December 31 1945? \" (Example 5). The basic idea behind this operator is that we specify a graph pattern query and then restrict the set of results based on the temporal extents of the graph pattern instances.\n\na temporal RDF Graph G t , a graph pattern GP , an interval type IT ∈ {intersect, range}, a temporal formula tf defined over I and a variable $t Find:\n\nT RIP LES(Gt) and i ∈ intersect S /range S (int expansion(µ(GP ))) and tf evaluates to true for $t = i)} Example 5: AN S ← temporal restrict('(?x assigned to 10th Armored Division ) ( 10th Armored Division participates in ?y)', 'intersect', during($t, [01:01:1944, 12:31:1945]) = true) Gt1 Example 5 Result: Result Variable Value µ 1 x Soldier 3 y Siege of Bastogne i 1 -[12:19:1944,01:15:1945]\n\nThe final temporal operator, temporal eval, allows for querying temporal relationships between entities. This operator can be thought of as a temporal join between graph pattern instances. This operator is designed for a query such as \"which speeches by President Roosevelt were given within 1 day of a major battle? \" (Example 6).\n\na temporal RDF Graph G t , a graph pattern GP 1 , an interval type IT 1 ∈ {intersect, range}, a graph pattern GP 2 , an interval type IT 2 ∈ {intersect, range}, a temporal formula tf defined over I and variables $t 1 , $t 2 Find:\n\nand tf evaluates to true for $t 1 = i 1 and $t 2 = i 2 } , Vol. , No. , 20.\n\n• 17 Example 6: ANS ← temporal eval('( Franklin Roosevelt gives ?x )', 'intersect', '(?y used in ?z )', 'intersect', temporal distance($i 1 , $i 2 ) ≤ 1 day) Gt Example 6 Result: Result Variable Value µ 11 x Day of Infamy speech i 11 -[12:07:1941, 12:07:1941] µ 12 y USS Enterprise z Attack on Pearl Harbor i 12 -[12:08:1941, 12:08:1941]\n\nThe computational complexity of our operators is dominated by the complexity of the thematic component (i.e. the evaluation of the graph pattern query). The evaluation of a graph pattern p over an RDF graph G is equivalent to the subgraph isomorphism problem where the task is to determine if p is isomorphic to a subgraph of G. The subgraph isomorphism problem is known to be NP-complete [Garey and Johnson 1979]. [Gutierrez et al. 2004] also discuss the simpler problem of testing the emptiness of a query answer set for a graph pattern query over an RDF graph in two forms, where q(G) denotes the set of mappings returned for a query q over an RDF graph G:\n\n-Query complexity version: For a fixed graph G, given a query q, is q(G) nonempty? -Data complexity version: For a fixed query q, given a graph G, is q(G) nonempty?\n\nThe authors showed that this problem is NP-complete for the query complexity version and polynomial for the data complexity version. In addition, [Gutierrez et al. 2005;2007] showed that the asymptotic complexity of this problem is the same for both temporal and nontemporal RDF graphs.\n\nIn this section, we describe the implementation of our spatial and temporal RDF query operators using Oracle's extensibility framework [Oracle 2005a]. The implementation builds on Oracle's existing support for RDF storage and inferencing and support for spatial object types and indexes. The existing support for these features is the main reason we chose Oracle database for our implementation. We create SQL table functions for each of the previously discussed query operators. Additional structures are created to allow for spatial and temporal indexing of the RDF data for efficient execution of the table functions.\n\nOur implementation uses procedural and declarative SQL and the built-in index structures of the DBMS. We do not depend on any lower-level interfaces of the DBMS, and no modifications to the database kernel are required. Our implementation could therefore be extended to another DBMS and is not restricted to Oracle.\n\nWe will first give definitions of the table functions that correspond to the query operators defined in the previous section. This is followed by a discussion of our storage and indexing scheme and finally our query processing strategies.\n\nWe define four table functions: two spatial and two temporal. The following descriptions use the term spatial geometry to refer to an SDO GEOMETRY object that would be stored in Oracle Spatial. We can think of a spatial geometry as the implementation of the class Spatial Region.\n\nThe spatial extent table function implements the spatial extent query operator described previously, and optional parameters are used to give the filtering functionality of the spatial restrict operator. The signature for the table function is shown below: spatial extent (graphPattern VARCHAR, spatialVar VARCHAR, ontology RDFModels, <geom SDO GEOMETRY>, <spatialRelation VARCHAR>) returns AnyDataSet;\n\nThe graphPattern and spatialVar parameters represent the spatial context for the query, and ontology determines the temporal RDF graph to search against. This function returns a table with rows containing one column for each distinct variable in the graph pattern and one column for the spatial geometry. Each row contains the URI bound to each variable and the spatial geometry corresponding to the Spatial Region bound to spatialVar. Two optional parameters, a spatial geometry and a spatial relationship, can be used to filter the graph pattern instances. In this case, the table would only contain those graph pattern instances whose associated spatial geometries satisfy the specified spatial relation with the input spatial geometry. Our implementation currently supports the following spatial relationships: disjoint, touch, overlap boundary intersect, overlap boundary disjoint, equal, contains, covers, inside, covered by, anyinteract and within distance.\n\nThe spatial eval\n\ntable function implements the spatial eval query operator defined previously. The signature for this table function is shown below: spatial eval (graphPattern VARCHAR, spatialVar VARCHAR, graphPattern2 VARCHAR, spatialVar2 VARCHAR, spatialRelation VARCHAR, ontology RDFModels) return AnyDataSet; graphPattern and spatialVar specify the first spatial context, and graphPattern2 and spatialVar2 specify the second spatial context. spatialRelation identifies the spatial relation for joining the two graph pattern instances. This function returns a table containing a column for each variable in graphPattern and graphPattern2 and a column for each associated spatial geometry (s 1 and s 2 ). For each row in the resulting table, s 1 spatialRelation s 2 evaluates to true. The temporal extent table function implements both the temporal extent and temporal restrict operators discussed previously. Optional parameters are used to perform filtering based on temporal properties. The signature for the table function is shown below. , Vol. , No. , 20. • 19 temporal extent (graphPattern VARCHAR, intervalType VARCHAR, ontology RDFModels, <start DATE>, <end DATE>, <temporalRel VARCHAR>) return AnyDataSet; This function takes three parameters as input, specifically a graph pattern, a String value specifying the interval type (INTERSECT or RANGE ), and a parameter specifying the temporal RDF graph to search against. The table returned contains a column for each variable in the graph pattern and two DATE columns that specify the start and end of the time interval computed for the graph pattern instance. Three optional parameters, two DATE values to identify the boundaries of a time interval and a temporal relationship, can be used to filter the found graph pattern instances. In this case, assuming the DATE columns in the returned table are named stDate and endDate, each row in the result satisfies the condition [stDate, endDate] temporalRel [start, end]. Our implementation currently supports seven temporal relationships: before, after, during, overlap, during inv, overlap inv and anyinteract. The temporal eval table function implements the temporal eval operator described previously. It has the following signature: temporal eval (graphPattern VARCHAR, intervalType VARCHAR, graphPattern2 VARCHAR, intervalType2 VARCHAR, temporalRel VARCHAR, ontology RDFModels) return AnyDataSet; graphPattern and intervalType specify the left hand side of the join operation, while graphPattern2 and intervalType2 specify the right hand side. temporalRel identifies the join condition. This function returns a table containing a column for each variable in graphPattern and graphPattern2 and four DATE columns (start 1 , end 1 , start 2 , end 2 ) to indicate the derived time interval for each found graph pattern instance. For each row in the resulting table, [start 1 , end 1 ] temporalRel [start 2 , end 2 ] evaluates to true.\n\nMultiple functions can be used in a single SQL query. This allows us to join the tables that result from a function execution and thus provides a mechanism for spatio-temporal-thematic queries. For example, the following query selects all soldiers who were on the crew of a vehicle that was used in a military event that occurred within an input bounding box and also returns the times at which this particular spatial relationship holds. s.x, t.start date, t.end date FROM TABLE (spatial extent( '(?x <on crew of> ?y) (?y <used in> ?z) (?z <occurred at> ?l)', 'l', SDO RDF Models('military'), SDO GEOMETRY(2003, 8265, NULL, SDO ELEM INFO ARRAY(1, 1003, 3), SDO ORDINATE ARRAY(-81.970263, 41.061209, -80.518693, 41.964041)), 'GEO RELATE(mask=inside)')) s, TABLE (temporal extent( , Vol. , No. , 20. '(?x <on crew of> ?y) (?y <used in> ?z) (?z <occurred at> ?l)', 'INTERSECT', SDO RDF Models('military'))) t WHERE s.x = t.x AND s.y = t.y AND s.z = t.z AND s.l = t.l;\n\nThis section presents our storage and indexing scheme for spatial and temporal RDF data. We will first give an overview of existing Oracle capabilities for storing spatial geometries and RDF data and then present our spatial and temporal indexing schemes.\n\nTechnologies. Oracle's Semantic Data Store [Oracle 2005b] provides the capabilities to store, inference over, and query semantic data, which can be plain RDF descriptions and RDFS-based ontologies. To store RDF data, users create a model (ontology) to hold RDF triples. The triples are stored after normalization in two tables: an RDFValues table that stores RDF terms and a numeric id and an RDFTriples table that stores the ids of the subject, predicate and object of each statement. Users can optionally derive a set of inferred triples based on user-defined rules and/or RDFS semantics. These triples are materialized by creating a rules index and stored in a separate InferredTriples table. These storage structures are illustrated in Figure 6. A SQL table function is provided that allows issuing graph pattern queries against both asserted and inferred RDF statements.\n\nOracle Spatial [Oracle 2005c] provides facilities to store, query and index spatial geometries. It supports the object-relational model for representing spatial geometries. A native spatial data type, SDO GEOMETRY, is defined for storing vector data. Database tables can contain one or more SDO GEOMETRY columns. Oracle Spatial supports spatial indexing on SDO GEOMETRY columns, and provides a variety of procedures, functions and operators for performing spatial analysis operations.\n\n5.2.2 Indexing Approach. In order to ensure efficient execution of graph pattern queries involving spatial and temporal predicates, we must provide a means to index portions of the RDF graph based on spatial and temporal values. Basically, this is done by building a table mapping Spatial Region instance URIs to their SDO GEOMETRY representation and by building a modified RDFTriples table , Vol. , No. , 20.\n\n• 21 that also stores the temporal intervals associated with a triple. In order to build these indexes, users first load the set of asserted RDF statements into Oracle Semantic Data Store and build an RDFS rules index. After this step, users can run our indexing procedures to build spatial and temporal indexes for the RDF data. 5.2.2.1 Spatial Indexing Scheme. We provide the procedure build geo index () to construct a spatial index for a given ontology. This procedure first creates the table SpatialData (value id NUMBER, shape SDO GEOMETRY ) for storing spatial geometries corresponding to instances of the class Spatial Region in the ontology. value id is the id given to the URI of the Spatial Region instance in Oracle's RDFValues table, and shape stores the SDO GEOMETRY representation of the Spatial Region instance (see Figure 6). This table is filled by querying the ontology for each Spatial Region instance, iterating through the results and creating and inserting SDO GEOMETRY objects into the spatial indexing table. Finally, to enable efficient searching with spatial predicates on this table, a spatial index (R-Tree) is created on the shape column. 5.2.2.2 Temporal Indexing Scheme. Our temporal indexing scheme is a bit more complicated, as it must account for temporal labels on statements inferred through RDFS semantics. However, we only need to handle a subset of the RDFS inferencing rules. Only a subset is required because we are not interested in handling temporal evolution of the ontology schema. What we need to handle are temporal properties of instance data. Specifically, we need to account for temporal labels of inferred rdf:type statements and statements resulting from rdfs:subPropertyOf. rdf:type statements result from the following rules:\n\n(1) (x, rdf:type, y) : i 1 ∧ (y, rdfs:subClassOf, z) : i 2 ⇒ (x, rdf:type, z) : i 1 ∩ i 2 (2) (x, p, y) : i 1 ∧ (p, rdfs:domain, a) : i 2 ⇒ (x, rdf:type, a) :\n\nWe infer instance statements from rdfs:subPropertyOf using the following rule:\n\nIn each case, the temporal label of an inferred statement s is the intersection of the valid time intervals of the statements used to infer s. A statement s may be inferred in many different ways, which may result in multiple valid time intervals for s (e.g. i 1 , i 2 , ..., i n ). The final valid time for s will be the union of each of these valid time intervals (e.g.,\n\nThis temporal inferencing serves an important purpose in our scheme. Consider the example of a Battle event (b 1 ) that three platoons (p 1 , p 2 , p 3 ) participate in at different times:  After taking the union of these intervals, we get the following result for the overall valid time:\n\n(b 1 , rdf:type, Battle) : [1,5] In this case, [1,5] represents the overall duration or lifetime of b 1 . Note that we are using relationships between entities and an event to automatically infer the overall duration of the event.\n\nWe provide the procedure build temporal index (ontology, rules index name, min start time, max end time) to construct a temporal index for a given ontology and rules index. The ontology parameter identifies the temporal RDF graph stored in Oracle; rules index name identifies the RDFS rules index associated with the ontology; min start time and max end time specify the earliest date and the latest date in the associated time domain. The purpose of these boundary parameters is to act as the start time and end time of statements that are eternally valid. All schemalevel statements in the ontology are considered eternally valid. All asserted instance level statements with missing or incomplete temporal properties are also considered eternally valid. The build temporal index procedure executes in three phases.\n\nThe first phase creates the temporary table asserted temporal triples (subj id NUMBER, prop id NUMBER, obj id NUMBER, start DATE, end DATE ). The ontology is then queried to retrieve all temporal reifications. The subject, property, and object ids of each temporally reified statement and the start time and end time are inserted into this temporary table. Next, those statements with incomplete or missing temporal reifications are added to the asserted temporal triples table using min start time and max end time as a substitution for any missing temporal values. The final step of this phase scans the asserted temporal triples table and ensures that all asserted schema-level statements have [min start time, max end time] as their valid time.\n\nAt this point, we have recorded the temporal values for each asserted statement, and the second and third phases perform the temporal inferencing process and create the final TemporalTriples table (see Figure 6). Algorithm 1 shows the temporal inferencing procedure. We first compute and store the transitive closure of the class and property hierarchy of the ontology. Next, we create a second temporary table redundant triples (subj id NUMBER, prop id NUMBER, obj id NUMBER, start DATE, end DATE ). Then, we iterate through the asserted temporal triples table and add any inferred statements to the redundant triples table. In this step, the temporal label of the asserted statement is directly assigned to the corresponding inferred statements. This procedure results in possibly redundant and overlapping intervals for each statement, so a third phase, shown in Algorithm 2, iterates through this table and cleans up the time intervals for each statement. The cleanup phase first sorts redundant triples by (subj id, prop id, obj id, start date) and then makes a single pass over the sorted set to merge overlapping intervals having the same (subj id, prop id, obj id ) values. The final result of this process is a table Tem-poralTriples (subj id NUMBER, prop id NUMBER, obj id NUMBER, start DATE, end DATE ) that contains the complete set of asserted and inferred temporal triples.\n\n, Vol. , No. , 20.\n\n• 23 Algorithm 1 TemporalInference 1: compute and store transitive closure of rdfs:subClassOf and rdfs:subPropertyOf 2: create temporary table redundant triples (subj id, prop id, obj id, start, end ) 3: for each row r ∈ asserted temporal triples do 4: if (r.prop = rdf :type) then 5: for each Class C ∈ SuperClasses(r.obj) do 6: insert row (r.subj, rdf :type, C, r.start date, r.end date) into redundant triples 7: end for 8: else 9: for each property P ∈ SuperProperties(r.prop) do 10: insert row (r.subj, P , r.obj, r.start date, r.end date) into redundant triples 11: end for 12:\n\nx ← domain(r.prop)\n\nfor each Class C ∈ SuperClasses(x) ∪ {x} do The complexity of the temporal inferencing procedure is as follows. Assume we have n asserted triples in the dataset and c classes and p property types in the ontology schema. The transitive closure of the class and property hierarchy can be obtained in O(c 3 + p 3 ). In the worst case, every property would be a subclass of every other property; every class would be a subclass of every class, and each property would have every class in its domain and range. In this case, we would add 2c+p triples for every asserted triple, yielding O(c 3 +p 3 +n(c+p)) for Algorithm 1. In Algorithm 2, we must sort this set of statements and then make a single pass over the sorted set, yielding O(n(c + p) log(n(c + p)) + n(c + p)). This gives an overall complexity of O(n(c + p) log(n(c + p))) for the temporal inferencing procedure, assuming that the number asserted triples n is much larger than the number of classes c and properties p.\n\nIn this section we discuss the implementation of the SQL table functions defined previously. The table functions were implemented using Oracle's ODCIT able interface methods. With this scheme, users implement a start(), f etch() and close() method for the table function. In start(), the query parameters are parsed; a SQL query is prepared and executed, and a handle to the query is stored in a scan context parameter. The f etch() method\n\n• Algorithm 2 MergeTemporalIntervals 1: create table TemporalTriples (subj id, prop id, obj id, start, end) 2: sort redundant triples by subj id, prop id, obj id, start 3: r ← first row of redundant triples 4: curr row ← r 5: for each row r remaining in redundant triples do 6: if (r.subj id = curr row.subj id and r.prop id = curr row.prop id and r.obj id = curr row.obj id) then 7: if (r.start ≤ curr row.end and r.end > curr row.end) then 8: curr row.end ← r.end 9: end if 10: if (r.start > curr row.end) then 11: insert row (curr row.subj id, curr row.prop id, curr row.obj id, curr row.start, curr row.end) into T emporalT riples 12: curr row.start ← r.start 13: curr row.end ← r.end 14: end if 15: else 16: insert row (curr row.subj id, curr row.prop id, curr row.obj id, curr row.start, curr row.end) into T emporalT riples 17: curr row ← r 18: end if 19: end for 20: insert into T emporalT riples SELECT (subj id, prop id, obj id, min start, max end) FROM Inf erredT riples WHERE (subj id, prop id, obj id) NOT IN T emporalT riples\n\nfetches a subset of rows from the prepared query and returns them. This method is invoked as many times as necessary by the kernel until all result rows are returned. The close() method performs cleanup operations after the last f etch() call. We also implement an optional describe() method, which is used notify the kernel of the structure of the data type to be returned (i.e., columns of the table). This method is necessary because the number of columns in the return type depends on the graph pattern and cannot be determined until query compilation time.\n\nGraph Pattern to SQL Translation:. Each of the table functions takes a graph pattern and ontology as input. The conversion of a graph pattern to a SQL query is therefore a central component of each function. The graph pattern is transformed into a self-join query against the T emporalT riples table corresponding to the input ontology. The graph pattern translation algorithm is shown in\n\nAlgorithm 3. The algorithm first parses the graph pattern and builds a mapping between tokens (i.e., variables and URIs) and a list of their occurrences in the graph pattern. To denote an occurrence, we record the triple pattern number and the position within the triple pattern (i.e. subject, predicate or object). We also build a mapping from URIs to their ids in the RDF V alues table. We then use these mappings to build a self-join query over the T emporalT riples table with two sets of conditions in the where clause: (1) restrictions based on the ids of the URIs in the graph pattern and (2) join conditions based on variable correspondences between triple patterns. We must also join with the RDF V alues table to resolve the ids of URIs bound to variables to actual URI Strings.\n\nThe example below illustrates the transformation process. The resulting SQL query assumes that the ids of on crew of and used in are 1 and 2, respectively.\n\n(?a <on crew of> ?b)(?b <used in> ?c) SELECT rv1.uri, rv2.uri, rv3.uri FROM TemporalTriples tt1, TemporalTriples tt2, RDFValues rv1, RDFValues rv2, RDFValues rv3 WHERE tt1.prop id = 1 and tt2.prop id = 2 and tt1.obj id = tt2.subj id and rv1.id = tt1.subj id and rv2.id = tt1.obj id and rv3.id = tt2.obj id;\n\n5.2.3.2 Spatial Functions:. Spatial functions are implemented by augmenting the base graph pattern query discussed in the previous section.\n\nAlgorithm 4 shows the query processing procedure for spatial extent function. We modify the base query as follows. First we identify the appropriate column (i.e., subj id, prop id, or obj id ) in the RDFTriples table that corresponds to the position of the spatial variable parameter. Then we add an additional join matching ids from the TemporalTriples table with value ids in the SpatialData table to select the id of the SDO GEOMETRY object. We must return the id, rather than the SDO GEOMETRY object, from SpatialData because object types cannot be returned from table functions. In the case of optional result filtering, we need to modify the where clause so that we filter the spatial features from SpatialData according to the input spatial feature and spatial relation. This is done by adding the appropriate sdo relate or sdo within distance predicate available in Oracle Spatial. For example, given the query: spatial extent (..., sdo geometry (...), 'geo relate (inside)')\n\nwe would modify the query as follows: WHERE ... AND sdo relate (geo.shape, sdo geometry (...), 'mask=inside') = 'true'.\n\nAlgorithm 5 shows the query processing procedure for the spatial eval function.\n\nWe implement what is essentially a nested loop join (NLJ) using the basic spatial extent and filtered spatial extent operators. We first construct and execute a basic spatial extent query in the start() routine. Next, in the f etch() routine, we consume a row from the spatial extent query and then construct and execute the , Vol. , No. , 20.\n\n• Algorithm 3 Graph Pattern Translation Input: GP : graph pattern G t : temporal RDF graph Output: selectStr: select portion of SQL query f romStr: from portion of SQL query whereStr: where portion of SQL query varM ap: mapping between variables and a list of their occurrences in GP 1: selectStr ← 'SELECT' 2: f romStr ← 'FROM' 3: whereStr ← 'WHERE' 4: declare mapRecord as 2-tuple (triple pattern num, pos) 5: declare Map uriM ap (String, List of mapRecord) 6: declare Map varM ap (String, List of mapRecord) 7: declare Map uriIdM ap (String, Integer) 8: parse GP and populate uriM ap, varM ap 9: for each var v ∈ varM ap do 10: currList ← varM ap(v) 11: add 'tt <currList(1).triple pattern num>. <currList(1).pos> as <v>' to selectStr 12: end for 13: for i = 1 to numT ripleP atterns do 14: add 'TemporalTriples tt <i>' to f romStr 15: end for 16: for i = 1 to numV ars do 17: add 'RDFValues rv <i>' to f romStr 18: end for 19: populate uriIdM ap from RDF V alues 20: for each URI u ∈ uriM ap do 21: currList ← uriM ap(u) 22: for i = 1 to length(currList) do 23: add 'tt <currList(i).triple pattern num>. <currList(i).pos> = <uriIdMap(u)>' to whereStr 24: end for 25: end for 26: for each var v ∈ varM ap do 27: currList ← varM ap(v) 28: for i = 1 to length(currList) -1 do 29: add 'tt <currList(i).triple pattern num>. <currList(i).pos> = tt <currList(i+1).triple pattern num>. <currList(i+1).pos>' to whereStr 30: end for 31: end for , Vol. , No. , 20. • 27 Algorithm 4 spatial extent Input: GP : graph pattern svar: spatial variable identifier G t : temporal RDF graph f ilterP arams: optional filtering parameters Output: rows: query results 1: GraphP atternT ranslation (GP , G t , selectStr, f romStr, whereStr, varM ap) 2: add 'SpatialData.id as geom' to selectStr 3: add 'SpatialData' to f romStr 4: currList ← varM ap(svar) 5: add tt <currList(1).triple pattern num>. <currList(1).pos> = SpatialData.value id' to whereStr 6: if (f ilterP arams are present) then 7: parse f ilterP arams and add appropriate sdo relate or sdo within distance predicate to whereStr 8: end if 9: sctx ← parse (selectStr + f romStr + whereStr) 10: while sctx.results remaining() do 11: rows ← sctx.f etch rows() 12:\n\nreturn rows 13: end while appropriate filtered spatial extent query using the second pair of graph pattern and spatial variable parameters and the spatial relation parameter. This is repeated until all rows in the outer spatial extent query are consumed. 5.2.3.3 Temporal Functions. The implementation of the temporal functions does not translate directly to a SQL query. We must do some extra processing of the base query results in the f etch() routine to form a single time interval for each found graph pattern instance.\n\nAlgorithm 6 shows the query processing strategy for the temporal extent function. We first augment the basic graph pattern query in start() to also select the start and end values for each temporal triple in the graph pattern instance. In the f etch() routine, to compute the final temporal interval for each graph pattern instance, we examine the start and end times for each triple and select the earliest start and latest end (RANGE) or the latest start and earliest end (INTERSECT). In the case of INTERSECT, if the final start value is later than the final end value then the computed interval is not valid and is not included in the final result. When the optional filtering parameters are specified, we must perform additional checking of the found graph patterns to ensure they satisfy the filter condition. In addition to these extra computations in f etch(), we augment the base query in start() with a series of predicates involving the start and end times of each statement in the graph pattern. This is done to filter the results as much as possible in the base query to reduce subsequent overhead in f etch(). To illustrate these additional predicates,\n\n• Algorithm 5 spatial eval Input: GP 1 : graph pattern var 1 : spatial variable identifier GP 2 : graph pattern var 2 : spatial variable identifier spatialRel: spatial relation G t : temporal RDF graph Output: rows: query result 1: sctx ← parse (spatial extent(GP 1 , var 1 , G t )) 2: while sctx.results remaining() do 3: outer rows ← sctx.f etch rows() 4: for each row r 1 ∈ outer rows do 5: inner rows ← execute(spatial extent(GP 2 , var 2 , G t , r.geom, inverse of spatialRel)) 6: for each row r 2 ∈ inner rows do 7: add r 1 .vars, r.geom, r 2 .vars, r 2 .geom to rows 8: end for 9: end for 10:\n\nreturn rows 11: end while consider the following temporal extent query and corresponding base query: SELECT ... FROM TABLE(temporal extent('(?x <on crew of> ?y) (?y <used in> ?z)', 'range ', 1942, 1944, 'during')); SELECT ... FROM ..., TemporalTriples t1, TemporalTriples t2 WHERE ... and t1.start > 1942WHERE ... and t1.start > and t2.end < 1944WHERE ... and t1.start > and t2.start > 1942WHERE ... and t1.start > and t2.end < 1944;; Algorithm 7 shows the query processing strategy for temporal eval. The implementation of the temporal eval operator is similar to the implementation of spatial eval. We first build a basic temporal extent query involving the first pair of graph pattern and interval type parameters, which is executed in the start() routine. Next, in f etch(), we consume a row from the basic temporal extent query and execute an appropriate filtered temporal extent query using the second pair of graph pattern and interval type parameters. This query uses the time interval from the current outer temporal extent result and the inverse of the temporal relation parameter from the original temporal eval query.\n\nThe experimental evaluation of our implementation is described in this section. All code was written in PL/SQL, and all experiments were conducted using Oracle 10g Release 2 running on a Sun Fire V490 server with four 1.8 GHz Ultra Sparc\n\n• 29 Algorithm 6 temporal extent Input: GP : graph pattern IT : interval type G t : temporal RDF graph f ilterP arams: optional filtering parameters Output: rows: query result 1: GraphP atternT ranslation (GP , G t , selectStr, f romStr, whereStr, varM ap) 2: for each i in 1 to graphP atternLen do 3: add 'tt <i>.start as st <i>, tt <i>.end as ed <i>' to selectStr 4: end for 5: if (f ilterP arams are present) then 6: parse f ilterP arams and add appropriate constraints to whereStr 7: end if 8: sctx ← parse(selectStr + f romStr + whereStr) 9: while sctx.results remaining() do 10: rows ← sctx.f etch rows() 11: for each row r ∈ rows do 12: if (IT = 'RANGE') then 13: curr interval ← [min(r.st), max(r.ed)] 14: end if 15: if (IT = 'INTERSECT') then 16: if max(r.st) ≤ min(r.ed) then 17: curr interval ← [max(r.st), min(r.ed)] 18: end if 19: end if 20: if (curr interval is defined) then 21: if (f ilterP arams are present and curr interval, t interval satisfies filter condition) then 22: add r.vars, curr interval to rows 23: end if 24: if (f ilterP arams are not present) then 25: add r.vars, curr interval to rows 26: end if 27: end if 28: end for 29: return rows 30: end while , Vol. , No. , 20. • Algorithm 7 temporal eval Input: GP 1 : graph pattern IT 1 : interval type GP 2 : graph pattern IT 2 : interval type temporalRel: temporal relation G t : temporal RDF graph Output: rows: query results 1: sctx ← parse (temporal extent(GP 1 , IT 1 , G t )) 2: while sctx.results remaining() do 3: outer rows ← sctx.f etch rows() 4: for each row r 1 ∈ outer rows do 5: inner rows ← execute( temporal extent(GP 2 , IT 2 , G t , r 1 .interval, inverse of temporalRel)) 6: for each row r 2 ∈ inner rows do 7: add r 1 .vars, r.interval, r2.vars, r2.interval to rows 8: end for 9: end for 10:\n\nreturn rows 11: end while IV processors and 8GB of main memory. The operating system used was 64-bit Solaris 9. The database used an 8 KB block size and was configured with a 512 MB buffer cache and a pga aggregate target size of 512 MB. The times reported for each query were obtained as follows. The query was run once initially to warm up the database buffers and then timed for 10 consecutive executions. We report the mean execution time over these 10 consecutive executions. Times were obtained by querying for systimestamp before and after query execution and computing the difference.\n\nWe conducted experiments using two RDF datasets. One consisted of synthetically generated RDF data corresponding to historical analysis of WWII (SynHist), and the other (GovTrack) consisted of real-world RDF data from the political domain that we obtained from http://www.govtrack.us/data/rdf/. Table I shows the characteristics of these datasets.\n\n6.1.0.4 SynHist Dataset. Five synthetically generated datasets (SH1 -SH5) were used in our experiments. The datasets correspond to a historical battlefield analysis ontology schema that we created. The ontology schema defined 15 class types and 9 property types. Each dataset was created in three phases. First we populated the thematic portion of the ontology. Second we added spatial information, and in the final step we generated temporal labels for the statements in the populated ontology.\n\nTo populate the thematic portion of the battlefield analysis ontology, we used the , Vol. , No. , 20.\n\nTable I. Characteristics of GovTrack and SynHist datasets Dataset Num Triples Size of Num Avg Num Size of (Asserted + TemporalTriples Spatial Points per SpatialData (Inferred) Table (MB) Features Polygon Table (MB) SH1 120,665 6 3,470 98 3 SH2 1,623,404 66 28,488 63 17 SH3 7,002,389 227 77,440 67 50 SH4 19,152,364 754 169,722 56 94 SH5 28,905,693 1,144 244,653 61 145 GT1 5,994,841 264 3,433 2,352 2 GT2 10,471,121 448 3,433 2,352 2 GT3 25,918,237 1,156 3,433 2,352 2\n\nontology population tool described in [Perry 2005]. This tool inputs an ontology schema and relative probabilities for generating instances of each class and property type. Based on these probabilities, it generates instance data, which, in effect, simulates the population of the ontology. We integrated these RDF graphs with the upper-level ontology described in Section 3.2 by adding a handful of rdfs:subClassOf statements to each RDF dataset.\n\nTo add spatial aspects to this dataset, we randomly assigned a spatial geometry to each instance of Spatial Region in the ontology. We used year 2000 census block group boundary polygons from the US Census Bureau [United States Census Bureau 2001] for the spatial geometries. Differently-sized sets of contiguous US States were chosen in proportion with the ontology size.\n\nThe final phase of dataset generation assigned temporal labels to statements in the ontology. Temporal intervals were randomly assigned to each asserted instance statement. Start times and end times for each interval were randomly selected with uniform probability from two overlapping date ranges. We ensured that each interval was valid (i.e., start time earlier than end time) before adding it to the dataset.\n\n6.1.0.5 GovTrack Dataset. The GovTrack RDF dataset contains data about activities of the US Congress. More specifically, it contains data describing politicians, bills, voting records, political organizations, political offices, and terms held by politicians. The ontologies used for this dataset contained 74 classes and 139 properties. 22 classes and 47 properties were actually used in the instance data.\n\nSome transformations and enhancements of the dataset were needed to make it appropriate for experimentation. We integrated the ontologies used with the upper-level ontology described in Section 3.2 using rdfs:subClassOf statements. The GovTrack data contained a significant amount of temporal information. However, this information was encoded using separate properties rather than as temporal RDF. For example, an instance of the class Term would have a start date property and an end date property. A preprocessing step was therefore needed to transform the dataset into a temporal RDF graph. This step would, for example, remove the existing start date and end date statements for a Term and then add the temporal\n\n• Table II. Execution time for RDFS rules index creation and temporal inferencing Dataset Num Triples Time (HH:MM:SS) Asserted Inferred RDFS Idx Temporal Inference SH1 70,640 50,025 00:02:52 00:00:26 SH2 980,253 643,151 00:06:35 00:06:27 SH3 4,294,783 2,707,606 00:26:35 00:22:48 SH4 11,593,162 7,559,202 01:02:46 01:00:34 SH5 17,615,502 11,290,191 01:30:57 01:29:29 GT1 2,959,281 3,035,560 00:13:40 00:21:29 GT2 5,245,453 5,225,668 00:24:08 00:27:46 GT3 12,819,641 13,098,596 01:49:06 01:52:03 label [start date, end date] to all statements involving the Term. To enhance the dataset with spatial data, we linked Congressional District instances with their corresponding boundary polygons available from the US Census [United States Census Bureau 2001]. We used boundary files for the 106th -110th Congress.\n\nWe created three differently-sized subsets of the GovTrack data (GT1 -GT3). GT1 contained information on bills and voting from the 106th Congress. GT2 used the 106th and 107th Congress, and GT3 used the 106th -110th Congress.\n\nOur experiments were designed to characterize the overall performance of our approach with respect to (1) dataset size and (2) graph pattern complexity.\n\nFor testing, B + -Tree indexes were created on each column of the TemporalTriples table and on the value id column of the SpatialData table, and an R-Tree index was created on the shape column of SpatialData. We also created four composite B + -Tree indexes on the TemporalTriples table to allow for efficient index-based joins: (prop id, subj id, obj id ) and (prop id, obj id, subj id ) for spatial operators and (prop id, subj id, obj id, start, end ) and (prop id, obj id, subj id, start, end ) for temporal operators.\n\nTable II shows the execution time for creating RDFS rules indexes using Oracle Semantic Data Store and for executing our temporal inferencing procedure. Times were obtained using the timing option of SQLPlus. The results show that the time required for temporal inferencing is comparable to the time required for RDFS rules index creation. In addition, the procedures take longer on the GovTrack dataset due to its larger ontology schema. The larger schema is also responsible for the greater number of inferred statements relative to the number of asserted statements.\n\nIn the following, we refer to two different graph pattern types: unselective and selective. An unselective graph pattern contains constant URIs in the predicate position in each triple pattern and variables in each subject and object position, for example:\n\n(?x <usgov:cosponsor> ?y)(?x <usgov:sponsor> ?z) (?x <usgov:inCommittee> ?c)\n\nA selective graph pattern has constant URIs in each predicate position and addi-, Vol. , No. , 20.\n\n• 35 6.2.1.1 Basic temporal extent. Queries G1 -G4 and H1 -H4 tested the scalability of the temporal extent operator for the GovTrack and SynHist datasets. Query G1, G2 and H1, H2 measure the response time (i.e. time to return the first 1000 rows) for an unselective graph pattern query, and G3, G4 and H3, H4 tested the execution time for a selective graph pattern query. For both query types and both datasets, query execution time is near constant as the dataset size grows. This is a result of the index-based nested loop join (NLJ) strategy used by the DBMS, which tends to have execution times proportional to the result set size. The 5-triple queries are slower than the 3-triple queries as a result of the additional joins needed to evaluate the query. 6.2.1.2 Filtered temporal extent. Query G5, G6 and H5, H6 tested the scalability of the temporal extent operator with filtering. These queries used an unselective graph pattern in combination with very selective temporal conditions. The queries show relatively constant execution time for the GovTrack dataset but show more of a linear growth for the SynHist dataset. In each case, the DBMS uses an indexbased NLJ strategy over the composite indexes containing start date and end date information.\n\nThese particular queries represent a challenging case for the temporal extent operator. Because the INTERSECT / RANGE interval derived for a graph pattern instance is constructed dynamically from the temporal labels of each edge in the graph pattern instance, we cannot directly index these derived values. We must instead apply the temporal filtering condition to each graph pattern instance as it is being constructed, which can lead to a very large set of intermediate results that are later discarded. The unnecessary intermediate results are generated because, in many cases, we cannot exclude a graph pattern instance until it is fully constructed and the final derived time interval is known. We try to alleviate this problem by placing limited temporal constraints on each triple pattern in the graph pattern. These initial constraints can reduce the number of intermediate results generated, but the amount of reduction depends on the specific interval type and temporal relation used. This issue is further explored in Section 6.2.3.\n\nThe difference in the scalability of the queries over the GovTrack dataset is a result of the characteristics of the time intervals in each dataset. The triples in the SynHist dataset have much longer time intervals with respect to the maximum start and end times of the whole dataset as compared to the GovTrack dataset. As a result, the temporal filtering conditions that can be placed on each triple in the graph pattern are ultimately less selective, leading to larger growth in intermediate results as the dataset size increases. 6.2.1.3 temporal eval. Queries G7, G8 and H7, H8 tested the scalability of the temporal eval operator. Selective graph patterns were used for both the left hand side (LHS) and right hand side (RHS) graph pattern in G7, G8 and H7. H8 used a LHS graph pattern and an unselective RHS graph pattern. The results show that execution times for G8 and H7 are relatively constant across each dataset, but queries G7 and H8 show a linear growth in execution time. The growth in execution time for H7 is a result of the larger sets of intermediate results generated by the unselective RHS graph pattern as the dataset size grows. The results for G7 are a • result of the DURING temporal relation. This particular relation only allows weak temporal constraints on each triple pattern, leading to a growth in intermediate results. This is explored further in Section 6.2.3. 6.2.1.4 Basic spatial extent. Queries G9 -G12 and H9 -H12 tested the scalability of the spatial extent operator. G9, G10 and H9, H10 measured the response time (first 1000 rows) for unselective graph pattern queries, and G11, G12 and H11, H12 measured the execution time of selective graph pattern queries. For both query types and both datasets, query execution time is near constant as the dataset size grows. This is a result of the index-based NLJ strategy used by the DBMS, which tends to have execution times proportional to the result set size. The 5-triple queries are slower than the 3-triple queries as a result of the additional joins needed to evaluate the query. The query execution times are roughly equivalent to those for basic temporal extent queries, as the extra join with the SpatialData table needed for the spatial queries is offset by the extra overhead of deriving INTERSECT / RANGE time intervals for the temporal queries. 6.2.1.5 Filtered spatial extent. Queries G13 -G16 and H13, H14 tested the scalability of the filtering capability of the spatial extent operator. Each query used an unselective graph pattern in combination with a selective spatial predicate. For each query, execution times are relatively constant across each dataset, which is a result of the index-based NLJ strategy used by the DBMS. The slower times reported in G13 and G14 are a result of the very complex spatial geometries used to represent congressional districts, which increase the time needed to perform the spatial filtering using the R-Tree index. Queries G15 and G16 used the same graph patterns and filtering parameters but were run over a modified dataset substituting random census block group polygons for the congressional district polygons. The execution times are significantly faster using these spatial geometries.\n\nIn the SynHist dataset, we see that the spatial filtering queries scale better than temporal filtering queries. Unlike INTERSECT/RANGE intervals, the spatial geometries can be indexed because they are not dynamically created. The spatial filtering queries consequently scale better because we can consistently reduce the search space using the spatial index and do not get as much growth in intermediate results as the dataset size increases. 6.2.1.6 spatial eval. Queries G17 -G20 and H15, H16 tested the scalability of spatial eval. G17, G19 and H15 used selective LHS graph patterns and unselective RHS graph patterns. G18, G20 and H16 used selective RHS and LHS graph patterns. In each case, execution times are relatively constant across each dataset due to the index-based join strategy and the consistent filtering from the spatial index. The execution times of G17 and G18 are much slower due to the complexity of the congressional district polygons. To evaluate a spatial eval query over the GovTrack dataset, we must compute spatial relations between two complex spatial geometries, which is an expensive operation. We had better performance with filtered spatial extent queries because we were computing spatial relations between a complex spatial geometry in the dataset and a simple spatial geometry specified in the query. G19 and G20 are the same spatial eval queries using census block group polygons, which yield much faster execution times. 6.2.2 Scalability with respect to Graph Pattern Size. Our next experiments are designed to test the scalability of various operators with respect to query complexity: that is, the size of the graph pattern used. We have focused on temporal extent and spatial extent operators, as their functionality forms the basis of our implementation.\n\n6.2.2.1 Filtered temporal extent. Experiment GP1 tested the scalability of a filtered temporal extent query as the complexity of the graph pattern used in the query increased. We used unselective graph patterns and very selective temporal predicates in each case. We ran one set of queries over the SH5 dataset and one set of queries over the GT3 dataset.\n\nThe key to the performance of filtered temporal extent queries is the amount the search space can be reduced by placing partial temporal constraints on each triple pattern in the graph pattern. As we noted earlier, the effectiveness of these partial temporal constraints depends on the particular interval type and temporal relation used in a query.\n\nThe objective of this experiment was to characterize the performance of filtered temporal extent queries in both the worst-case scenario (very limited initial temporal filtering) and the best-case scenario (complete initial temporal filtering). An INTERSECT interval type in combination with a DURING temporal relation represented the worst-case. In this situation, we can only enforce that the valid time interval of each triple does not end before the query interval starts or start after the query interval ends. In contrast, with a RANGE interval type and a DURING temporal relation, we can enforce that each triple starts after the query interval starts and ends before the query interval ends. These conditions completely filter out any unwanted graph pattern instances, and this query represents a best-case. Figures 7(a) and 7(b) show the execution times for a best-case and worst-case query for unselective graph patterns varying in size from one triple to seven triples. We can see that execution time grows roughly linearly in each case, but performance is significantly worse with the INTERSECT temporal relation. The performance is better for the GovTrack dataset because of the nature of the temporal intervals in each dataset as we discussed in Section 6.2.1. The execution time for queries over the SynHist dataset tends to grow more rapidly at first and then taper off as the graph pattern gets more complex. This trend is a result of the selectivity of the graph pattern itself. In this dataset, there are fewer instances of the more complex graph patterns. This slows the growth in intermediate results, so not as much additional temporal filtering is needed in the fetch() method. 6.2.2.2 Filtered spatial extent. Experiment GP2 tested the scalability of filtered spatial extent queries. The graphs in Figures 7(c) and 7(d) show the execution times for queries involving unselective graph patterns and selective spatial filtering conditions. As the graph pattern size grows, the query execution times show linear scalability on both datasets and are much faster than the worst-case temporal queries. Because the spatial values in our dataset are not dynamically derived, we can effectively index them. The faster execution times result from the more effective spatial indexing. The spatial index is used initially to select the nodes satisfying the spatial filtering condition, which reduces the search space for evaluating the , Vol. , No. , 20.\n\n• 39 rest of the graph pattern. The queries over the GovTrack dataset have slower execution times because spatial computations are more expensive for the complex spatial geometries in the GovTrack dataset.\n\n6.2.2.3 Basic temporal extent. Experiment GP3 tested the scalability of basic temporal extent queries using selective graph patterns. Figures 7(e) and 7(f) show query execution time for basic temporal extent queries as graph pattern size ranges from 1 triple to 10 triples. The number of result rows returned from the query is also shown in the graphs. These graphs show that performance is quite good for selective graph pattern queries even as the graph patterns grow relatively large. In each case, the execution times grow roughly linearly as the graph pattern size increases when the effects of the result set size are taken into account. The DBMS starts with the most selective triple pattern and uses an index-based join to construct the rest of the graph pattern instance. The initial selection dramatically cuts down the search space and results in the fast execution times for these queries. 6.2.2.4 Basic spatial extent. Experiment GP4 tested the scalability of basic spatial extent queries using selective graph patterns. Figures 7(g) and 7(h) show the execution time of basic spatial extent queries as graph pattern size ranges from 2 to 10 triples. The result set size of each query is also shown in the figure. Execution time grows linearly as graph pattern size increases when the result set size is taken into account. Again, the DBMS starts with the most selective triple pattern and grows the graph pattern instance from there using an index-based NLJ strategy. The initial selection reduces the search space and is responsible for the good performance that we see. The times reported in this experiment are a bit slower than those in GP3 due to the larger result set sizes. 6.2.3 Scalability of Spatiotemporal Queries. We performed some basic experiments to demonstrate the scalability of spatiotemporal queries that combine a spatial operator and a temporal operator in a single SQL query. 6.2.3.1 Spatiotemporal Queries w.r.t. Dataset Size. Our first spatiotemporal experiment tested scalability with respect to dataset size. Table V shows the execution times for a query involving both a filtered temporal extent operator and a filtered spatial extent operator. Each query used one filtered spatial extent operator invocation and one filtered temporal extent operator invocation. The same unselective graph pattern was used in each operator invocation, and the results of each operator invocation were joined based on equality of variable values (i.e. along the lines of the spatiotemporal query example in Section 5.1). The results show that execution times are significantly slower than queries involving a single operator because the results for each individual function invocation must be retrieved and then joined based on variable correspondences to form the final result. This slowdown occurs for both datasets. However, the queries show good scalability with respect to dataset size. Execution time is near constant as the dataset size increases for the GovTrack dataset, but the execution time grows linearly for the SynHist dataset. The growth in execution time for the SynHist dataset is due to the scalability of queries involving a filtered temporal extent operator on this dataset as discussed previously.\n\n6.2.3.2 Spatiotemporal Queries w.r.t. Graph Pattern Size. Experiment ST1 tested the scalability of a spatiotemporal query with respect to graph pattern complexity. The spatiotemporal queries involved both a spatial extent operator invocation and a temporal extent operator invocation. Within a spatiotemporal query, the same selective graph pattern was used for each operator and the results of the two operator invocations were joined on equality of variable values. Figures 7(i) and 7(j) show the execution times for one such spatiotemporal query of each graph pattern size. The results of this experiment show that execution time tends to grow linearly with graph pattern complexity when result set size is taken into account. Execution times are roughly twice as long as a query involving a single operator (i.e. as in experiments GP3 and GP4), as results for both function invocations must be retrieved and then joined.\n\nWe divide related work into two categories: (1) data modeling and (2) query languages and query processing.\n\nWe first discuss the use of ontologies in Geographic Information Science (GIS) and then cover spatiotemporal modeling approaches. 7.1.0.3 Ontologies and GIS. There has been significant work regarding the use of geospatial ontologies in GIS. Ontologies in GIS are seen as a vehicle to facilitate interoperability and to limit data integration problems both from different systems and between people and systems [Agarwal 2005]. Fonseca et al. [Fonseca et al. 2002] present an architecture for an ontology-driven GIS in which ontologies describe the semantics of geographic data and act as a system integrator independent of the data model used (e.g., object vs. field).\n\nOn the Web, the use of ontology for better search and integration of geospatial data and applications is embodied in the Geospatial Semantic Web [Egenhofer 2002]. From a Web context, Kolas et al. [Kolas et al. 2005] outline specific types of geospatial ontologies needed for integration of GIS data and services: base geospatial ontology, feature data source ontology, geospatial service ontology, and geospatial filter ontology. The base geospatial ontology provides core geospatial knowledge vocabulary while the remaining ontologies are focused on geospatial web services.\n\nOur work is complementary to the work on geo-ontologies. The geo-ontologies above would be mapped to (i.e., subsumed by) the spatial classes in our upperlevel ontology (presented in Section 3.2). Our work provides a means to further incorporate non-spatial thematic knowledge and analysis with the geospatial knowledge and analysis provided through geo-ontologies and GIS. That is, we provide a framework that allows analysis of thematic and temporal relationships in addition to spatial relationships. 7.1.0.4 Spatiotemporal Models. Spatiotemporal data models have received considerable attention in both the GIS and Database communities, and many good surveys exist (e.g., [Pelekis et al. 2004;Peuquet 2001]). In a recent survey, Pelekis et. al identify 10 distinct spatiotemporal data models [Pelekis et al. 2004]. In • general, our modeling approach differs through its extensive use of thematic relationships. We not only conceptually separate thematic entities from spatial entities, but we also utilize indirect thematic relationships to link thematic entities to spatial entities in a variety of ways (i.e. different contexts). A review of each distinct model is outside the scope of this paper, but we will review some of the most similar.\n\nOf the models discussed in the literature, the three domain model is conceptually the most similar to our RDF-based approach. The three domain model, introduced by Yuan, is described in [Yuan 1994;1996]. This model represents semantics, space and time separately. To represent spatiotemporal information in this model, semantic objects are linked via temporal objects to spatial objects. This provides temporal information about the semantic (thematic) properties of a given spatial region. This is analogous to temporal located at and occurred at relationships in our upper-level ontology. The three domain model is quite similar to our approach in that it represents thematic entities as first class objects rather than attributes of geospatial objects. The key difference is that the three domain model relies on direct connections from thematic entities to spatial regions whereas our model allows more flexibility through indirect connections composed of sequences of thematic relationships.\n\nOur modeling approach also has similarities with object-oriented approaches. A recent proposal by Worboys and Hornsby [Worboys and Hornsby 2004] combines the object-oriented and event-based modeling approaches to model dynamic geospatial domains. They define an upper-level ontology similar to the one we present in Section 3.2. They model the concept of a setting and a situate function that maps entities and events to settings. Settings can be spatial, temporal, or spatiotemporal. In contrast to our work, the authors focus on geospatial objects and events and model what we would consider a thematic entity (e.g., an airplane) as a geospatial entity. That is, the separation between the thematic and spatial domains is not as strongly emphasized. Our RDF-based modeling approach provides a means to assign spatial properties to those entities not directly connected to a spatial setting and allows deeper analysis of purely thematic relationships.\n\nGeneral modeling approaches and languages have also been extended for spatiotemporal data. Tryfona and Jensen extended the entity-relationship model to create the spatiotemporal entity-relationship model (STER) [Tryfona and Jensen 1999;2000]. Price et. al extended the Unified Modeling Language (UML) to create spatiotemporal UML [Price et al. 2002]. RDF is similar to these modeling languages in the sense that it is a general purpose ontology language and can model entities and relationships for a given domain. Our approach could therefore be seen as an extension of RDF (i.e. spatial types in combination with temporal triples) to allow for modeling spatial and temporal entities and relationships. RDF is different from these other languages in that it also serves as a model for storing and querying data in the form of RDF triples whereas UML and ER are primarily for conceptual modeling. We can thus query relationships directly as first class objects in RDF graphs, and we utilize this capability to design and implement relationship-based query operators. Furthermore, RDF statements carry well-defined semantics, and corresponding inferencing mechanisms must be supported.\n\n• 43\n\nWe first review approaches to querying thematic RDF data and then discuss querying spatial and temporal data on the Semantic Web. This is followed by a review of querying spatial and temporal data using traditional database technology. 7.2.0.5 Querying RDF. Many RDF query languages have been proposed in the literature. These include SQL-like languages (e.g., SPARQL [Prud'hommeaux and Seaborne 2008], RDQL [Seaborne 2004]), functional languages (e.g., RQL [Karvounarakis et al. 2002]), rule-based languages (e.g., TRIPLE [Sintek and Decker 2002]) and graph traversal languages (e.g., RxPath [Souzis 2004]). For a detailed comparison of these languages, see [Haase et al. 2004;Angles and Gutierrez 2005].\n\nRecently, SPARQL has emerged as a W3C recommendation. As an alternative to defining a new query language, an approach for querying RDF data directly in SQL has been proposed [Chong et al. 2005]. This facilitates easy integration with other SQL queries against traditional relational data and saves the overhead of translating data from SQL to the RDF query language data format. Our implementation described in Section 5 follows this approach and introduces new SQL functions for spatial and temporal querying of RDF data.\n\nA variety of systems for management of persistent RDF data have been presented in the literature. These systems usually rely on an underlying relational database representation. Three main types of storage schemes are commonly used [Theoharis et al. 2005]: (1) schema-aware -one table per RDF(S) class or property (e.g., Sesame using PostgreSQL [Broekstra et al. 2002], the vertical partitioning scheme described in [Abadi et al. 2007]), (2) schema-oblivious -a single three-column (subject, predicate, object) table storing all statements (e.g., Jena [Wilkinson et al. 2003], 3Store [Harris and Gibbins 2003], Sesame using MySQL [Broekstra et al. 2002], Oracle Semantic Data Store [Oracle 2005b]) and (3) hybrid -one table storing class membership information and one table for each group of properties with the same range type such as Resource or integer (e.g., RDFSuite [Alexaki et al. 2001]). Efficient evaluation of queries using these systems typically involves transformation into a SQL query against the underlying RDBMS representation, and traditional relational indexes are used to speed up query processing.\n\nAlternate approaches persistently store RDF data using lower-level structures such as Hash Tables (Redland [Beckett 2002]) and B + -Trees (YARS [Harth and Decker 2005]) and traverse these structures to evaluate queries.\n\nAll the previously mentioned techniques index RDF data based on a \"collection of triples\" conceptualization. The GRIN index proposed by Udrea, et al. [Udrea et al. 2007] exploits the graph structure of the RDF data. A GRIN index is a tree structure where leaf nodes represent a set of triples in the RDF graph and interior nodes are represented by a vertex, radius pair (v, r) that represents all vertices in the RDF graph within r hops of vertex v. Graph pattern queries are evaluated by traversing the tree to find all triples that may contain an answer to the query. A subgraph matching algorithm is then run over the identified portion of the RDF graph. The initial implementation of GRIN used a main-memory representation, which was followed by a disk-based implementation using PostgreSQL [Pugliese et al. 2008].\n\nOur approach uses an underlying relational database representation of RDF data\n\n• that follows the schema-oblivious storage scheme. This storage scheme is augmented with additional structures for more efficient searching over spatial and temporal data. We utilize traditional spatial and temporal indexes in our query processing strategies and use composite B + -tree indexes for efficient evaluation of graph pattern queries.\n\n7.2.0.6 Spatial and Temporal Data on the Semantic Web. Work is somewhat limited with regards to incorporating spatial and temporal relationships into queries over Semantic Web data. Examples of querying geospatial RDF data are mostly seen in Web applications and semantic geospatial web services [Kammersell and Dean 2006;Tanasescu et al. 2006]. In general, this work mainly focuses on interoperability, and query processing proceeds by translating RDF representations of spatial features into geometric representations on the fly and then performing spatial calculations. In contrast, we look at how the relationship-centric nature of the RDF model can enable new query types and also address issues related to efficient query processing.\n\nResearchers have proposed querying web documents that are annotated with spatial and temporal semantic metadata. The SPIRIT spatial search engine [Jones et al. 2004] combines an ontology describing the geospatial domain with the searching and indexing capability of Oracle Spatial for the purposes of searching documents based on the spatial features associated with named places mentioned in the document. In contrast, our searching operators are intended for general purpose querying of ontological and spatial relationships. Visser and Hubner [Visser and Hubner 2003] describe a \"spatio-temporal-terminological\" query that they refer to as concept@location in time. With this type of search, users can retrieve documents related to a given concept that contain references to a given time period and geographic location (e.g., \"find documents that contain something about fishing in the North-Sea region since 1990\"). In contrast to Visser and Hubner's work, we focus on querying and analyzing an RDF graph rather than retrieving web documents, and we therefore support a more expressive graph-pattern-based querying paradigm.\n\nSimple temporal data can be stored in RDF graphs using typed literals such as xsd:date, and corresponding query languages support filtering results based on literal values. However, this is far from supporting full temporal RDF as graphs discussed in his paper.\n\nGutierrez et al. introduced the concept of temporal RDF graphs and formally defined them in [Gutierrez et al. 2005;2007]. In addition, the authors briefly discussed aspects of a query language for temporal RDF graphs, but a through investigation of such a language has not been completed, and no implementation issues were mentioned. To the best of our knowledge, our work in [Anonymous 2007] is the first to investigate efficient schemes for storing and querying temporal RDF and implementation of RDFS inferencing that incorporates the concept of valid time for RDF statements. In [Pugliese et al. 2008], Pugliese et al. present tGRIN an extension of the GRIN index for temporal RDF data. The tGRIN extension factors in the temporal distance between vertices in addition to the graph distance (number of edges). The authors' approach using tGRIN, however, supports a more limited form of temporal RDFS inferencing than we do. Specifically, they only support inferences related to rdfs:subPropertyOf. Pugliese et al. also support a different form of temporal RDF queries than we support. Their queries involve temporal conditions on single edges of a graph pattern. In contrast, our queries involve temporal conditions on time intervals derived from multiple edges in a graph pattern (e.g., the intersection of the time intervals of each edge in a graph pattern).\n\nSemantic Web researchers have proposed incorporating past work on qualitative spatial and temporal reasoning into the Semantic Web reasoning framework as an alternative to adding spatial and temporal capabilities to query languages. Hobbs and Pen translated a subset of Allen's interval calculus [Allen 1984;Allen and Ferguson 1994] to OWL to create the OWL-Time ontology [Hobbs and Pan 2004]. In [Abdelmonty et al. 2005], Abdelmonty et al. demonstrated that OWL is insufficient to fully support the spatial reasoning required for a geo-ontology (e.g., it is very hard to define a class of HousesNearMotorways made up of individuals of type house that are within a specific distance of motorways). In a follow-on paper, Smart et al. showed how to use additional rules and specialized tools to help overcome the shortcomings of OWL [Smart et al. 2007]. Our approach differs in that our implementation does not involve reasoning over relative spatial and temporal relations (e.g., (x before y) ∧ (y before z ) ⇒ (x before z )). Instead we support the computation spatial and temporal relations using time values that are grounded to a timeline and spatial features that are grounded to a coordinate system. 7.2.0.7 Spatial and Temporal Query Processing. Management of spatial and temporal data has long been an area of interest [Guting 1994;Guting et al. 2000;Ozsoyoglu and Snodgrass 1995].\n\nProcessing temporal queries over relational data is well covered in the literature. Usually temporal information is stored as time intervals. Selection queries generally retrieve all intervals that intersect a given query interval. Various structures have been proposed for efficient execution of such queries [Salzberg and Tsotras 1999]. Another important task is interval join queries that join two relations based on overlapping intervals. Many approaches to evaluate these joins exist in the literature [Gao et al. 2005].\n\nProcessing spatial queries is also a well-researched topic. Spatial selection queries return a set of spatial objects that satisfy a spatial predicate [Aref and Samet 1991]. Various types of spatial index structures have been developed for such queries (e.g., the R-Tree [Beckman et al. 1990;Guttman 1984] and quadtree [Samet 1984]). Also important are spatial join queries, which join sets of spatial objects based on a spatial predicate. A variety of methods for evaluating spatial joins have been proposed [Arge et al. 2000;Brinkhoff et al. 1993;Gunther 1993].\n\nWork on indexing and querying spatiotemporal data or moving objects is also of interest [Guting et al. 2000]. Indexing approaches usually optimize queries about future positions of spatiotemporal objects or queries about past states of the spatiotemporal objects [Hadjieleftheriou et al. 2002]. Various approaches to indexing spatiotemporal objects appear in the literature [Mokbel et al. 2003].\n\nA key difference of the query types addressed here is our focus on thematic relationships. Rather than querying a set of spatial or temporal objects, we are querying thematic objects associated to spatial objects via a chain of thematic relationships (i.e. in a specific context). For example, the following relationships • could represent a battle participation context: (Soldier, on crew of, Vehicle) (Vehicle, used in, Battle) (Battle, occurred at, Spatial Region). In other words, the spatial object associated with an entity is determined dynamically at run time. Therefore, we cannot create direct spatial indexes for these thematic entities. Similarly, we compute a temporal interval for a subgraph connecting multiple entities, also dynamically generated at run-time, making it infeasible to directly index the derived intervals. Rather than trying to improve upon existing indexing techniques for traditional queries over spatial and/or temporal objects, we focus on how to incorporate these indexing techniques into our query processing procedures.\n\nThis paper discussed an approach for realizing spatial and temporal query operators for Semantic Web data. Our work was motivated by a lack of support for spatial and temporal relationship analysis in current semantic analytics tools. Spatial and temporal data is critical in many analytical applications and must be effectively utilized for semantic analytics to reach its full potential. In addition, a framework that allows integrated analysis of spatial, temporal and thematic information is needed to realize many visions of the next generation World Wide Web, such as the Event Web [Jain 2008], and the framework presented in this paper can help realize such a vision.\n\nOur approach built upon existing support for storage and querying of RDF data and spatial geometries in Oracle DBMS. A set of experiments using both synthetic and real-world RDF datasets of over 25 million triples showed that our implementation exhibited good scalability for a large populated ontology. Basic temporal extent and spatial extent queries were quite fast in all circumstances. The worst performance was seen with filtered temporal extent queries using low selectivity graph patterns with highly selective temporal predicates. However, the resulting execution times were manageable.\n\nA possible limitation of this work is that Oracle Semantic Data Store does not support incremental maintenance of RDFS rules indexes. Consequently, our indexing scheme inherits this limitation. However, incremental maintenance of a materialized set of inferred triples upon updates of asserted triples is possible (e.g., [Volz et al. 2005]), and existing algorithms could be extended to incorporate temporal information.\n\nIn the future, we plan investigate this incremental maintenance issue and to investigate extensions of the SPARQL query language that support the types of operations discussed in this paper.\n\n,Vol. , No. , 20\n\n,Vol. , No. , 20."
}