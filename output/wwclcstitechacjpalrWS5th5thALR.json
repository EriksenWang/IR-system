{
    "title": "Domain Knowledge Engineering Based on Encyclopedias and the Web Text *",
    "publication_date": "2005-10-14",
    "authors": [
        {
            "full_name": "Ramada Plaza",
            "firstname": "Ramada",
            "lastname": "Plaza",
            "affiliations": []
        },
        {
            "full_name": "Jeju ( Korea",
            "firstname": "Jeju (",
            "lastname": "Korea",
            "affiliations": []
        },
        {
            "full_name": "Nicoletta Calzolari",
            "firstname": "Nicoletta",
            "lastname": "Calzolari",
            "affiliations": []
        },
        {
            "full_name": "Shuichi Itahashi",
            "firstname": "Shuichi",
            "lastname": "Itahashi",
            "affiliations": []
        },
        {
            "full_name": "Donghong Ji",
            "firstname": "Donghong",
            "lastname": "Ji",
            "affiliations": []
        },
        {
            "full_name": "Qin Lu",
            "firstname": "Qin",
            "lastname": "Lu",
            "affiliations": []
        },
        {
            "full_name": "Nguyen Thi",
            "firstname": "Nguyen",
            "lastname": "Thi",
            "affiliations": []
        },
        {
            "full_name": "Minh Huyen",
            "firstname": "Minh",
            "lastname": "Huyen",
            "affiliations": []
        },
        {
            "full_name": "Hae-Chang Rim",
            "firstname": "Hae-Chang",
            "lastname": "Rim",
            "affiliations": []
        },
        {
            "full_name": "Kiyoaki Shirai",
            "firstname": "Kiyoaki",
            "lastname": "Shirai",
            "affiliations": []
        },
        {
            "full_name": "Jane Tsay",
            "firstname": "Jane",
            "lastname": "Tsay",
            "affiliations": []
        },
        {
            "full_name": "Sui Zhifang",
            "firstname": "Sui",
            "lastname": "Zhifang",
            "affiliations": []
        },
        {
            "full_name": "Cui Gaoying",
            "firstname": "Cui",
            "lastname": "Gaoying",
            "affiliations": []
        },
        {
            "full_name": "Ding Wansong",
            "firstname": "Ding",
            "lastname": "Wansong",
            "affiliations": []
        },
        {
            "full_name": "Qinlong Zhang",
            "firstname": "Qinlong",
            "lastname": "Zhang",
            "affiliations": []
        },
        {
            "full_name": "Tomoya Noro",
            "firstname": "Tomoya",
            "lastname": "Noro",
            "affiliations": [
                {
                    "organization": "Graduate School of Information Science and Engineering, Tokyo Institute of Technology",
                    "address": {
                        "city": "Tokyo"
                    }
                }
            ]
        },
        {
            "full_name": "Chimato Koike",
            "firstname": "Chimato",
            "lastname": "Koike",
            "affiliations": [
                {
                    "organization": "Graduate School of Science and Engineering, Tokyo Institute of Technology",
                    "address": {
                        "city": "Tokyo"
                    }
                }
            ]
        },
        {
            "full_name": "Taiichi Hashimoto",
            "firstname": "Taiichi",
            "lastname": "Hashimoto",
            "affiliations": [
                {
                    "organization": "Graduate School of Information Science and Engineering, Tokyo Institute of Technology",
                    "address": {
                        "city": "Tokyo"
                    }
                }
            ]
        },
        {
            "full_name": "Takenobu Tokunaga",
            "firstname": "Takenobu",
            "lastname": "Tokunaga",
            "affiliations": [
                {
                    "organization": "Graduate School of Information Science and Engineering, Tokyo Institute of Technology",
                    "address": {
                        "city": "Tokyo"
                    }
                }
            ]
        },
        {
            "full_name": "Hozumi Tanaka",
            "firstname": "Hozumi",
            "lastname": "Tanaka",
            "affiliations": []
        },
        {
            "full_name": "Yan Zhang",
            "firstname": "Yan",
            "lastname": "Zhang",
            "affiliations": []
        },
        {
            "full_name": "Hideki Kashioka",
            "firstname": "Hideki",
            "lastname": "Kashioka",
            "affiliations": []
        },
        {
            "full_name": "Meng-Chien Yang",
            "firstname": "Meng-Chien",
            "lastname": "Yang",
            "affiliations": []
        },
        {
            "full_name": "D Victoria Rau",
            "firstname": "D Victoria",
            "lastname": "Rau",
            "affiliations": []
        },
        {
            "full_name": "Shingo Kato",
            "firstname": "Shingo",
            "lastname": "Kato",
            "affiliations": []
        },
        {
            "full_name": "Shigeki Matsubara",
            "firstname": "Shigeki",
            "lastname": "Matsubara",
            "affiliations": []
        },
        {
            "full_name": "Yukiko Yamaguchi",
            "firstname": "Yukiko",
            "lastname": "Yamaguchi",
            "affiliations": []
        },
        {
            "full_name": "Nobuo Kawaguchi",
            "firstname": "Nobuo",
            "lastname": "Kawaguchi",
            "affiliations": []
        },
        {
            "full_name": "Xin Li",
            "firstname": "Xin",
            "lastname": "Li",
            "affiliations": []
        },
        {
            "full_name": "Xuan-Jing Huang",
            "firstname": "Xuan-Jing",
            "lastname": "Huang",
            "affiliations": []
        },
        {
            "full_name": "Li-De Wu",
            "firstname": "Li-De",
            "lastname": "Wu",
            "affiliations": []
        }
    ],
    "abstract": "Our workshop and symposium would not have been succeeded without the hard work of the program committee. Also, we would like to express our great thanks to the arrangement of the IJCNLP-05 organizing committee and the secretariat. Finally, we wish that all the participants can benefit a lot and enjoy themselves in the workshop and symposium.\nBo Xu (chair) Chu-Ren Huang (co-chair) Takenobu Tokunaga (co-chair) Jun Zhao (co-chair)\nPROGRAMME COMMITTEE Bo Xu (chair)\nChinese Academy of Sciences Chu-Ren Huang (co-chair)\nAcademia Sinica Takenobu Tokunaga (co-chair)\nTokyo Institute of Technology Jun Zhao (co-chair)\nChinese Academy of Sciences",
    "full_text": "It is increasingly convinced that language resources, as well as corpus-based, stochastic, and learning approaches, play a significantly important role in Natural Language Processing (NLP) research. There have been several reports on the success of constructing and using corpora in many dimensions. How to effectively re-organizing the existing resources into a unified framework and establishing the guideline for corpus development has become more and more important, which will be highly helpful for sharing resources and coping with cross-language problems. Motivated by this background, the 5th Workshop on Asian Language Resources (ALR) and 1st Symposium on Asian Language Resources Network (ALRN) are organized under the auspices of the Asian Language Resources Committee of Asia Federation of Natural Language Processing (AFNLP) in conjunction with IJCNLP2005.\n\nThe purposes of the workshop and symposium are as follows.\n\n(1) To investigate the situation of Asian Language Resources, and to make a catalog of the result of this investigation;\n\n(2) To investigate and discuss the problems related to the standards and specification on creating various kinds of language resources; (3) To promote communications between developers and users of various language resources in order to fill the gap between language resources and practical applications; (4) To launch a roadmap for Asian Language Resources. ALR-05 accepts 10 regular papers. We are so sure that the selected papers for presentation are informative and can gain much potential for further research.\n\nWe hope to meet worldwide active researchers working on Asian languages to promote the research on linguistic resources and related fields. We are sure that the workshop and symposium will fruitfully contribute to construct a unifying architecture and mechanism for Asian Language Resources development, management and sharing.\n\nDomain knowledge is the indispensable resource for an intelligent information processing system. With the upsurge of technology, more and more new technology, new product and new techniques come into being. The manual construction and updating domain knowledge base can hardly meet the real needs of application systems, in terms of coverage or effectiveness. In order to improve the robust of an information system, we need to study a computer-aided method to solve the bottleneck of domain knowledge acquisition.\n\nThe Institute of Computational Linguistics, Peking University, now cooperates with Encyclopedia of China Publishing Hall on the project of human-machine interactive encyclopedia knowledge engineering. We want to study how to exploit, use and update encyclopedia resource properly. We will use the technique of natural language processing, machine learning and text mining to acquire domain knowledge semi-automatically from both encyclopedia and the Web text. Furthermore, we set up an open platform for domain knowledge acquisition, so that common network users and domain experts can work together to contribute new domain knowledge. Based on this technology, we can build domain knowledge base on each domain. This technology can be used as an important method of constructing and updating the domain knowledge base for the intelligent information retrieval and extraction systems. In the same time, it can also provide help for the knowledge updating of encyclopedias.\n\nThe researches on knowledge acquisition can be divided into three parts: artificial construction, semi-automatic construction and automatic construction.\n\nArtificial methods are usually used in constructing the common sense knowledge base, such as CYC [1], WordNet [2], EuroWordNet [3], HowNet [4], and CCD [5] etc. That's because common sense is steady comparatively and it can not be affected by the task, also it can be reused by various kinds of system when constructed. For instance, since the WordNet was established in 1985, it had been widely used in IR, Text categorization, QA system etc. Similarly, the HowNet is being used in many Chinese information procession systems. It's worthy of large-scale devotion for long-time using.\n\nOn the contrary, domain knowledge is tied with some concrete domain. Once the application domain changed, we need to reconstruct the domain knowledge base. Furthermore, domain knowledge updates continually, so that the domain knowledge base should be updates frequently. So it's unrealistic to construct the domain knowledge base manually.\n\nIn the way of constructing domain knowledge base, the semi-automatic method is mainly used. [6][7][8][9][10] established the platform of human-computer interactively working for the construction of domain knowledge base. They use various kinds of text processing and language analysis tools, which have the functions of morphological analysis, partial syntactic analysis, partial semantic analysis, with the mode of online cooperation, helping knowledge engineers or domain experts to find the domain concepts and the relations among them. The acquired knowledge can be added into the domain knowledge base. All these methods try to use pattern matching or various layers of NLP technology to acquire domain knowledge from large-scale free text. Free text is easy to get, however, it comes from different kinds of domain, including complicated language phenomenon hence is hard to understand. It's difficult to extract knowledge reliably using current technology of NLP and machine learning from such free text. If there not exists a pre-defined basic domain knowledge architecture, it is difficult to acquire the concepts and the relations relative to the domain. Also, among the above-mentioned methods, the construction of domain knowledge base depends on the expert's point of view and opinions. However, it's very difficult to let experts to construct the \"real-time\" domain architecture objectively and roundly and hence express it clearly in the given time.\n\nIn this paper, we propose a technology of domain knowledge engineering based on encyclopedias and the web text. Encyclopedia is the embodiment of the systematization and centralization of existed domain knowledge. The knowledge has been compiled and modified by many experts. Compared with free text, there are more canonical and NLP technologies can be used comparatively easily to extract knowledge from it. Since the knowledge in encyclopedia is more systematic, we can easily construct the basic frame of domain knowledge. So we will use NLP technology and machine learning method to construct the kernel of domain knowledge based on the analysis of the encyclopedia. Then based on the kernel of domain knowledge base, we can extract domain knowledge from other text resources.\n\nThere exist some researches on extracting knowledge from the encyclopedia [11] [12] [13] [14]. These researches use the encyclopedias as the only source to acquire knowledge. However, with the high-speed improvement in each domain, there is severe knowledge lag in encyclopedias. So it is inadequate to use encyclopedias as the only source for knowledge acquisition. We need to learn more domain knowledge from other text resource besides encyclopedias.\n\nWith the surge of Internet, information in it is increasing exponentially. Abundant knowledge lies in this huge Web resource. If we can extract knowledge from the Web, we could update and expand domain knowledge base most efficiently. Standing in the computational linguistics' point, we focus on retrieving information from the content rather than from the structure of the Web. This paper studies the technology of domain knowledge engineering. Using encyclopedia resource and text information resource on the Web, we focus on the method of constructing domain knowledge base through technologies in natural language text analysis and machine learning. Moreover, an open network platform will be developed, through which common users can work together with domain experts to contribute domain knowledge.\n\nThe compilation of encyclopedias always follows some specified compilatory model.\n\nEncyclopedias have the relatively formal diction and different compilatory model for different kinds of entries. Because of that, the paraphrasable text in encyclopedias has clearer model to express the relation among concepts in most cases. For instance, \"X is a kind of …Y\", \"X is composed of A, B, C and D\", \"A, B and C make up D\", \"X can be divided into A, B and C\". Through recognizing the terms and partial parsing for the paraphrasable text in the encyclopedia, we could learn the patterns, which express the relations among concepts. Furthermore, we could learn the styles of knowledge dense text based on those patterns.\n\nNext step, we will follow the styles and combine the HTML target set to acquire more knowledge dense text fragments from the web. Based on such knowledge-dense text, some deeper natural language processing technologies could be used to extract domain knowledge reliably.\n\nThrough analyzing the characters and expression forms of Chinese terms, we learn term knowledge from large-scale domain corpus and term bank. Using natural language processing method combing rule and statistics, we can automatically extract Chinese terms from corpus.\n\nA term is a kind of phrases, whose components are close related. Further more, it has strong domain feature. The close relation of the components in a term can be captured through calculating the static association rate between the words that compose a term candidate. The linguistic feature can be captured through analysis the grammatical structural information of the terms. While the domain feature of a term can be captured through the domain component that has the possibility of composing a term. For example, \"movable terminal\" and \"social economy\" are both composed by the close related components. While, the former is a term in the domain of information science and technology, and the latter is just a common phrase instead of a term. The reason lies in that the former has the domain feature comes from one of its components\" terminal\", while the latter has not the domain feature.\n\nWe will use the above characteristic and representation forms of a term to perform automatic term extraction. The system of automatic term extraction includes two phases: learning stage and application stage.\n\nIn the stage of learning, we use a series of machine learning methods to get various kinds of integrated knowledge for automatic term extraction from a large-scale corpus and a term bank. These knowledge includes the inner structural knowledge of terms, the statistical domain features of term component, the statistical mutual information between the components of terms, the outer environment features of terms and the distinct text-level features of term recognition etc... In the stage of application, through an efficient model, we use all these various types of knowledge into automatic term extraction.\n\nThe knowledge-dense text fragments (including encyclopedia and the Web text segments whose style is similar to encyclopedias) is relatively simple. Therefore, it's possible to implement deeper analysis on it using the natural language processing technology.\n\nWe use comprehensive language knowledge and statistical technique together to design language analysis method oriented for knowledge-dense text. We will use the comprehensive language knowledge resource, such as The Grammatical Dictionary-base of Contemporary Chinese, Chinese Semantic Dictionary, Chinese Concept Dictionary (CCD), and Termbank of Information Technology, which was developed by Institute of Computational Linguistics (ICL) of Peking University. Moreover, we will design a natural language partial parsing and understanding technology combining statistic technology base on the 80,000,000 words IT corpus. Concretely, on the base of the developed software such as word segmentation, POS tagging, term extraction and identification, skeletal dependency analysis of sentence, we will combine semantic restrict information with syntax rules, so that during syntax analysis we can get the semantic restrict information between syntax components at the same time. We will label semantic roles for predicate-head and its central valency components using Chinese Semantic Dictionary. So we can get shallow case frames of sentences after natural language partial parsing and understanding for text sentences. And domain knowledge will be extracted in the later stage from this analysis result.\n\nThe knowledge of encyclopedia is relatively systematic, mature and intensive. On this foundation, it is easier to set up a basic domain knowledge base which includes the kernel of domain knowledge. In the encyclopedia, every subject is described by attributes, and different subjects are organized hierarchically.\n\nFigure1: An example of the fragments of domain knowledge framework For example as showed in Figure1, aiming at the subject \"Input equipment\" in the domain of computer hardware, the encyclopedia describes the basic knowledge around the subject from many of point of views such as components, function, classification etc, which we call attributes here. On the other hand, \"Input equipment\", \"Output equipment\", \"Terminal unit\" constitute the subject \"computer I/O equipment\"; furthermore, \"Input equipment\", \"Computer storage equipment\", \"Network equipment\" are also components of the \"Computer hardware\". This paper will make the \"classification + Attribute\" as the basic knowledge description method for constructing the basic domain knowledge base. When the basic knowledge description method is set up, we take every entry in the encyclopedia as a subject, through analyzing the correlative sentence and recognizing the key terms in the paraphrase text and the relations among the terms, we can describe the basic knowledge on this subject. In the next step, we may couple several subjects in the same domain gradually in order to construct the basic domain knowledge base in this domain.\n\nThe structure of the web text is incompact, and the diction is not canonical enough. However, the web text is easy to get and contains a great amount of new knowledge. So based on the basic domain knowledge base, we can select the knowledge dense text fragments from the web resource as the source to acquire more new knowledge. We collect language patterns, which are known showing some kind of domain knowledge from encyclopedia. Using the language patterns as the seed set, we could learn more language patterns from the web text using boot strapping machine learning method. Using the expanded seed set, we could learn more language patterns from the larger text. This technique can expand domain knowledge base iteratively. The system structure is as Figure2. Figure2: The system structure for domain knowledge acquisition.\n\nWith the rapid development of Internet, people could communicate and collaborate without face to face. They can share work and collaborate through the web. So we constructed an open human-computer interactive platform to call on domain knowledge experts and spacious common network users to collaborate together and contribute new domain knowledge. This platform could also assist the experts of encyclopedia in editing and managing new domain knowledge.\n\n5 Current result\n\nWe have exploited a term extraction system, including term extraction, human-computer interactive updating etc. The system is made up of basic source layer, learning layer, application layer and service layer. We select the texts from 16 representative Chinese journals in the field of science and technology to construct the testing set.\n\nFirst of all, we manually tagged the terms in the testing texts. The principles we used in term tagging is very strict, that is, we only tag the longest terms in the texts, while ignore any of the term fragments in a longest term. For example, for the word sequence \"接口 技术 规 范 (Interface Technology Specification)\", we only select \" 接 口 技 术 规 范 (Interface Technology Specification)\" as a term, while ignore \" 接 口 技 术 (Interface Technology\", although it may be also a term in other context.\n\nSimilarly, for word sequence \"数字 电视 信 号 (Digital Television Signal)\", we only select \"数字 电视 信号 (Digital Television Signal)\" as a term, while ignore \" 数 字 电 视 (Digital Television)\".\n\nThe above testing principles may result in a great decrease of the precision and recall of term recognition. However, through these principles, we can find more problems existed in the term recognition algorithm.\n\nBased on the above testing principles, we get the precision and recall of term recognition as Table 1. Therefore, what the automatic term recognition system find can only be taken as the term candidates attached with the confidences. We still need the human terminology experts to give a final confirmation of the terms.\n\nOur software includes human-computer interactive updating interface besides automatic term extraction. The interactive updating interface is as Figure3:\n\nFigure3: The interactive updating interface after term extraction\n\nA lot of key concepts in the encyclopedia are well-marked with hyperlinks, titles, bookmarks and other Html tags according to different kinds of information respectively in the paraphrasable text. Using the information supplied by \"China encyclopedia\" e-press, we put encyclopedia subject information, relationship between subjects and term hierarchy into database to form an encyclopedia database for a primary domain knowledge base.\n\nThe core structure of encyclopedia database is presented as (main entry, relation term, relationship). Main entry is the entry that is listed in the encyclopedia. Relation terms are the hyperlink, bookmark, subtitle and so on. The relationship between main term and these elements now is null that need to be added with human assistance.\n\nFor example, the paraphrasable text of term \"frequency divider\" is showed in the database as Table2.\n\nMain entry Relation term Relationship Frequency divider Crystal oscillator Unknown Frequency divider Impulse frequency divider Unknown Frequency divider Trigger Unknown Frequency Regenerate Unknown divider frequency divider Frequency divider Trigger Unknown Frequency divider Regenerate frequency divider Unknown Table2: the database fragment for the term \"frequency divider\" 5.3 Attribute relation template extraction attribute relation type template example definition xxx 家/学者/专家/奠 基人/发明人/创始人/ 先驱 substitutable name mark xxx，/。字/号 xxx country xxx(国名)xxx 家 nationality xxx 族/族人 native place or home place 诞生地/生于 xxx/xxx 人 experience 毕业于 xxx；或 xxx 学位 literature 所著/著有/著作/发表 xxx/代表作 xxx/出版 了 xxx/主要著作 xxx working experience xxx 年任 xxx；xxx 起 任 xxx；任 xxx；兼 任 xxx；历任 xxx； 曾作过 xxx；曾任 xxx；被聘为 xxx achievement and influence 被誉为 xxx/获 xxx 称 号/xxx 创始人 Table3: The examples of the attribute relation template of human entry We have semi-automatically extracted several attribute relation templates for human entries from encyclopedia text. The attribute relation template of human entry examples are as Table3.\n\nThe construction of domain knowledge base is a kind of high intelligent knowledge engineering.\n\nSince there is still have big gap between current level of technological development and real need, it is unrealistic to build domain knowledge base using automatic method or manual method only. However, in the human-computer interaction process, how to sufficiently absorb the knowledge resource which human being has already mastered and use it to supervise automatic acquisition of new knowledge? How to call together knowledge engineers, domain experts and common network users and realize multi-member collaboration during the updating and extending process of domain knowledge base? These are the key problems to be settled in the knowledge engineering domain. This paper tries to do some exploration on these aspects.\n\nParsing is one of the important processes for natural language processing and, in general, a largescale CFG is used to parse a wide variety of sentences. Although it is difficult to build a largescale CFG manually, a CFG can be derived from a large-scale syntactically annotated corpus. For many languages, large-scale syntactically annotated corpora have been built (e.g. the Penn Treebank (Marcus et al., 1993)), and many parsing algorithms using CFGs have been proposed. However, such a syntactically annotated corpus has not been built for Japanese as of yet. De-pendency analysis is preferred in order to analyze Japanese sentences (dependency relation between Japanese phrasal unit, called bunsetsu) (Kurohashi and Nagao, 1998;Uchimoto et al., 2000;Kudo and Matsumoto, 2002), and only a few studies about Japanese CFG have been conducted. Since many efficient parsing algorithms for CFG have been proposed, a Japanese CFG is necessary to apply the algorithms to Japanese.\n\nWe have been building a large-scale Japanese syntactically annotated corpus to derive a Japanese CFG for syntactic parsing (Noro et al., 2004a;Noro et al., 2004b). According to the result, a CFG derived from the corpus can parse sentences with high accuracy and coverage. However, as mentioned previously, dependency analysis is usually adopted in Japanese NLP, and it is difficult to compare our result with results of other dependency analysis since we evaluated our CFG with respect to phrase structure based measure. Although we evaluated with respect to dependency measure as a preliminary experiment in order to compare, the scale was quite small (evaluated on only 100 sentences) and the comparison was unfair since we did not use the same evaluation data.\n\nIn this paper, we show an evaluation result of a CFG derived from our corpus and compare it with results of other Japanese dependency analyzers. We used the Kyoto corpus (Kurohashi and Nagao, 1997) for evaluation data, and chose KNP (Kurohashi and Nagao, 1998) and CaboCha (Kudo and Matsumoto, 2002) for comparison.\n\nAnalyzing Causes of Ambiguity, Deciding on an Annotation Policy\n\nFigure 1: Procedure of building a syntactically annotated corpus\n\nIn this section, we start by introducing our policy for annotating a Japanese syntactically annotated corpus briefly. The details are given in (Noro et al., 2004a;Noro et al., 2004b) Although a large-scale CFG can be easily derived from a syntactically annotated corpus, such a CFG has a problem that it creates a largenumber of parse results during syntactic parsing (i.e. high ambiguity). A syntactically annotated corpus should be built so that the derived CFG would create less ambiguity.\n\nWe have been building such Japanese corpus by using the following method (Figure 1):\n\n1. Derive a CFG from an existing corpus.\n\n2. Analyze major causes of ambiguity.\n\n3. Determine a policy for modifying the corpus.\n\n4. Modify the corpus according to the policy and derive a CFG from it again.\n\n5. Repeat steps ( 2) -( 4) until most problems are solved.\n\nWe focused on two major causes of ambiguity:\n\nLack of Syntactic Information: Some syntactic information which is important for syntactic parsing might be lost during the CFG derivation since CFG rules generally represent only structures of subtree with the depth of 1 (relation between a parent node and some child nodes).\n\nNeed for Semantic Information: Not only syntactic information but also semantic information is necessary for disambiguation in some cases.\n\nTo avoid the first cause, we considered which syntactic information is necessary for syntactic parsing and added the information to each intermediate node in the structure. On the other hand, we considered ambiguity due to the second cause better be left to the subsequent semantic processing since it is difficult to reduce such ambiguity without recourse to semantic information during syntactic parsing. This can be achieved by representing the ambiguous cases as the same structure. We assume that syntactic analysis based on a large-scale CFG is followed by semantic analysis, and the second cause of ambiguity is supposed to be disambiguated in the subsequent semantic processing.\n\nThe main aspects of our policy are as follows:\n\nVerb Conjugation: Information about verb conjugation is added to each intermediate node related to the verb (cf. \"SPLIT-VP\" in (Klein and Manning, 2003) and \"Verb Form\" in (Schiehlen, 2004)).\n\nCompound Noun Structure: Structure ambiguity of compound noun is represented as the same structure regardless of the meaning or word-formation as Shirai et al. described in (Shirai et al., 1995).\n\nStructure ambiguity of adnominal phrase attachment is represented as the same structure regardless of the meaning while structure ambiguity of adverbial phrase attachment is distinguished by meaning.\n\nIn case of a phrase like \"watashi no chichi no hon (my father's book)\", the structure is same whether the adnominal phrase \"watashi no (my)\" attaches to the noun \"chichi (father)\" or the noun \"hon (book)\". On the other hand, in case of a sentence\n\nInput Producing Possible Parse Trees Using a CFG Top-n Possible Parse Trees Using PCFG, PGLR model, etc. Final Interpretation Disambiguation of Adnominal Phrase Attachment One Parse Tree Disambiguation of Adverbial Phrase Attachment Segmentation Accuracy # sentences segmented into bunsetsu correctly # all sentences Dependency Accuracy # correct dependency relations # all dependency relations Sentence Accuracy # sentences determined all relations correctly # sentences segmented in bunsetsu correctly Figure 3: Dependency measures\n\nlike \"kare ga umi wo egaita e wo katta\", we distinguish the structure according to whether the adverbial phrase \"kare ga (he)\" attaches to the verb \"egaita (paint)\" (it means \"I bought a picture of a sea painted by him\") or the verb \"katta (buy)\" (it means \"he bought a picture of a sea\").\n\nConjunctive Structure: Conjunctive structure is not specified during syntactic parsing, instead their analysis is left for the subsequent processing (contrary to (Kurohashi and Nagao, 1994)).\n\nWe have decided to deal with adnominal phrase attachment and adverbial phrase attachment separately in our policy since we believe that a different algorithm should be used to disambiguate them. In the subsequent processing, we assume that adverbial phrase attachment would be disambiguated by choosing one parse tree among the results at first, and adnominal phrase attachment would be disambiguated by choosing one interpretation among all of interpretations which the parse tree represents (Figure 2). We used the EDR corpus (EDR, 1994) for developing our annotation policy, and annotated 8,911 sentences in the corpus and 20,190 sentences in the RWC corpus (Hashida et al., 1998).\n\nIn the following evaluation, we used the latter one.\n\nAs mentioned previously, in general, analyzing dependency relations between bunsetsu is preferred in Japanese, which makes it difficult to compare the result by the CFG with the result by dependency analysis. In order to compare with other dependency analysis, we evaluated our derived CFG with respect to dependency measures shown in Figure 3. Note that sentences which are not segmented into bunsetsu correctly are dropped from the evaluation data when we evaluate dependency accuracy and sentence accuracy.\n\nA CFG is derived from all sentences in our corpus, with which we parsed 6,931 sentences (POS sequences) in the Kyoto corpusfoot_0 by MSLR parser (Shirai et al., 2000). The Kyoto corpus has an- notation in terms of dependency relations among bunsetsu, and it is usually used for evaluation of dependency analysis. The parser is trained according to probabilistic generalized LR (PGLR) model (Inui et al., 2000) (all sentences are used for training), and parse results are ranked by the model.\n\nThe experiment was carried out as follows (Figure 4):\n\n1. Convert POS tags automatically to the RWC tag set.\n\n2. Parse the POS sequence using a CFG derived from our corpus.\n\n3. Rank the parse results by PGLR model and pick up the top-Ò parse results.\n\n4. Extract dependency relations among bunsetsu for each result.\n\nChoose the result which is closest to the gold-standard and evaluate it.\n\nSince the tag set of the Kyoto corpus is different from that of the RWC corpus, a POS conversion in step ( 1) is necessary. It is a rule-based conversion, and the accuracy is about 80%. It seems that the low conversion accuracy would damage the evaluation result. We will discuss this issue in the next section.\n\nIn the 4th step of the experimental procedure, we determine boundaries of bunsetsu and dependency relations among the bunsetsu in a sentence with the CFG rules included in the phrase structure of the sentence. Some CFG rules in our CFG indicate positions of bunsetsu boundaries. For example, a CFG rule \"NP AdnP NP\" (\"NP\" and \"AdnP\" stand for a noun phrase and an adnominal phrase respectively) indicates that there is a boundary of bunsetsu between the two phrases in the right-hand side of the CFG rule (i.e. between the noun phrase and the adnominal phrase), and that a bunsetsu including the head word of the adnominal phrase depends on a bunsetsu including the head word of the noun phrase. An example of \"Nihon teien no nagame ga subarashii (The view of the Japanese garden is wonderful)\" is shown in Figure 5.\n\nStructure ambiguity of adnominal phrase attachment needs to be disambiguated in extracting dependency relations in step (4) since it is represented as the same structure according to our policy 2 . We disambiguate adnominal phrase attachment based on one of the following assumptions: NEAREST: Every ambiguous adnominal phrase attaches to the nearest noun among the nouns which the phrase could attach to.\n\nBEST: Choose the best noun among the nouns which could be attached to (assume that disambiguation of adnominal phrase attachment was done correctly) 3 .\n\n2 Since dependency relations are not categorized in the Kyoto corpus, it is difficult to know how many relations representing adnominal phrase attachment are included in the evaluation data. On the other hand, among the top parse results ranked by PGLR model (i.e in case of Ò ½ in section 4), about 34.1% of all dependency relations represent adnominal phrase attachment, and about 23.4% of them (i.e. about 8.0% of all relations) remain ambiguous. 3 We choose the best noun automatically by referring to\n\nNihon (Japanese) teien (garden) no nagame (view) ga subarashii (wonderful) n n p n p a d j <comp.n> <NP> <AdnP> <NP> <NP> <PP> <AdjP> <AdjP> <S> bunsetsu #1 bunsetsu #2 bunsetsu #3 Bunsetsu No. Word Sequence Bunsetsu Which is Depended on 1 nihon teien no 2 2 nagame ga 3 3 subarashii -Figure 5: Extracting Dependency Relations from a Pharse Structure \"NEAREST\" is a quite simple way for disambiguation, and it would be the baseline model.\n\nOn the other hand, since we assume that structure ambiguity of adnominal phrase attachment is supposed to be disambiguated in the subsequent semantic processing, \"BEST\" would be the upper bound and we could not overcome the accuracy even if the disambiguation was done perfectly in the subsequent processing.\n\nTo take two noun phrases \"watashi no chichi no hon (my father's book)\" and \"watashi no kagaku no hon (my book on science)\" as examples (the correct answer is that the adnominal phrase \"watashi no (my)\" attaches to the noun \"chichi (father)\" in the former case, and attaches to the noun \"hon (book)\" in the latter case), \"NEAR-EST\" attaches to the adnominal phrase \"watashi no\" to the nouns \"chichi\" and \"kagaku (science)\" regardless of their meanings. \"BEST\" attaches the adnominal phrase to the noun \"chichi\" in the former case, and attaches to the noun \"hon\" in the latter case.\n\nAlthough structure ambiguity of compound noun is also represented as the same structure rethe Kyoto corpus. If the noun which is attached to in the Kyoto corpus is not in the candidates, we choose the nearest noun (i.e. \"NEAREST\"). gardless of the meaning or word-formation, we have nothing to do with the structure ambiguity since a bunsetsu is a larger unit than a compound noun. Furthermore, since dependency relations are not categorized, we do not have to care about whether two bunsetsu have conjunctive relation with each other or not.\n\nIn order to compare our result with that of other dependency analyzers, we used two wellknown Japanese dependency analyzers, KNP and CaboCha, and analyzed dependency structure of the sentences in the same evaluation data set. In both cases, POS tagged sentences are used as the input. Since CaboCha uses the same tagset as the RWC corpus, we converted POS tags in the same way as step (1) in our experimental procedure. On the other hand, since KNP uses the tagset adopted by the Kyoto corpus, POS tags do not have to be converted in case of analyzing by KNP.\n\nTable 1 shows the results when Ò ½, which means the top parse result of each sentence is used for evaluation. In this case, \"NEAREST\" means only PGLR model was used for disambiguation without any other information (e.g. lexical infor-  1, accuracy is still lower than KNP and CaboCha even if disambiguation of adnominal phrase attachment was done correctly in the subsequent processing. However, in this case, we do not use any information but PGLR model for disambiguation of any relations except adnominal phrase attachment (i.e. adverbial phrase attachment).\n\nNext, assuming that disambiguation of other relations, we carried out another evaluation changing Ò from 1 to 100. The result is shown in Figure 6. Dependency accuracy could achieve about 95.24% for \"BEST\", which exceeds the dependency accuracy by KNP and CaboCha, if choosing the best result among top-100 parse results ranked by PGLR model would be done correctly in the subsequent processing 4 . From the results, we can conclude the accuracy will increase as soon as lexical and semantic information is incorporated in the subsequent processing 5 .\n\nHowever, segmentation accuracy is still significantly lower. The main reasons are as follows:\n\nPOS Conversion Error: As mentioned previously, we converted POS tags automatically since the POS system of the Kyoto corpus is different from that of the RWC corpus. However, accuracy of the conversion is not high (about 80%). Since we used only POS information and did not use any word information for parsing, the result can be easily affected by the conversion error. Segmentation accuracy by CaboCha is also a little lower than accuracy by KNP. Since POS tags were converted in the same way, we think the reason is same. However, the difference between the accuracy by KNP and CaboCha is smaller since CaboCha uses not only POS information but also word information.\n\nThere is difference in bunsetsu segmentation policy between the Kyoto corpus and our corpus.\n\nFor example:\n\n1.\n\n3 gatsu 31 nichi gogo 9 ji 43 fun goro, jishin ga atta (An earthquake occurred at around 9:43 p.m., March 1st.) 2. gezan suru no wo miokutta (We gave up going down the mountain.)\n\nIn the former case, the underlined part is segmented into 5 bunsetsu (\"3 gatsu\", \"31 nichi\", \"gogo\", \"9 ji\", and \"43 fun goro,\") in the Kyoto corpus, while it is not segmented in our corpus. On the other hand, in the latter case, the underlined part is segmented into 2 bunsetsu (\"gezan suru\" and \"no wo\") in our corpus, while it is not segmented in the Kyoto corpus. By correction of these two types of error, segmentation accuracy improved by 4.35% (76.53% 80.88%) and dependency accuracy improved by 0.61% (95.24% 95.85%).\n\nWe have been building a large-scale Japanese syntactically annotated corpus. In this paper, we evaluated a CFG derived from the corpus with respect to dependency measure. We assume that parse results created by our CFG is supposed to be re-analyzed in the subsequent processing using semantic information, and the result shows that parsing accuracy will increase when semantic information is incorporated.\n\nWe also compared our result with other dependency analyzers, KNP and CaboCha. Although dependency accuracy of our CFG cannot reach those of KNP and CaboCha if only PGLR model is used for disambiguation, it would exceed if disambiguation in the subsequent processing was done correctly.\n\nAs future work, since we assume that the parse results created by our CFG are re-analyzed in the subsequent processing, we need to integrate the subsequent processing into the current framework. Collins proposed a method for reranking the output from an initial statistical parser (Collins, 2000). However, it is not enough for us since we represent some ambiguous cases as the same structure (we need to consider the ambiguity included in each parse result). Our policy has been considered with several types of ambiguity: structure of compound noun, adnominal phrase attachment, adverbial phrase attachment and conjunctive structure. We are planning to provide each method individually and integrate them into a single process.\n\nAlthough we attempt to re-analyze after parsing, it seems that some problem should be solved before parsing. For example, ellipsis often occurs in Japanese. It is difficult to deal with ellipsis (especially, postpositions and verbs) in a CFG framework, resulting in higher ambiguity. It would be helpful if the positions where some words are omitted in a sentence were detected and marked in advance.\n\nThe First International Conference on Language Resource and Evaluation, pages 457-461. Kentaro Inui, Virach Sornlertamvanich, Hozumi Tanaka, and Takenobu Tokunaga. 2000. Probabilistic GLR parsing. In Harry Bunt and Anton Nijholt, editors, Advances in Probabilistic and Other Parsing Technologies, pages 85-104. Kluwer Academic Publishers. Dan Klein and Christopher D. Manning. 2003. Accurate unlexicalized parsing. In the 41st Annual Meeting of the Association for Computational Linguistics, pages 423-430. Taku Kudo and Yuji Matsumoto. 2002. Japanese dependency analysis using cascaded chunking. In CONLL 2002. Sadao Kurohashi and Makoto Nagao. 1994. A syntactic analysis method of long Japanese sentences based on the detection of conjunctive structures. Computational Linguistic, 20(4):507-534. Sadao Kurohashi and Makoto Nagao. 1997. Kyoto university text corpus project. In the 3rd Conference for Natural Language Processing, pages 115-118. In Japanese. Sadao Kurohashi and Makoto Nagao. 1998. Building a Japanese parsed corpus while improving the parsing system. In the first International Conference on Language Resources and Evaluation, pages 719-724. Mitchell P. Marcus, Beatrice Santorini, and Mary Ann Marcinkiewicz. 1993. Building a large annotated corpus of English: The Penn Treebank. Computational Linguistics, 19(2):313-330. Tomoya Noro, Taiichi Hashimoto, Takenobu Tokunaga, and Hozumi Tanaka. 2004a. Building a large-scale japanese CFG for syntactic parsing. In The 4th Workshop on Asian Language Processing, pages 71-78. Tomoya Noro, Taiichi Hashimoto, Takenobu Tokunaga, and Hozumi Tanaka. 2004b. A large-scale japanese CFG derived from a syntactically annotated corpus and its evaluation. In The 3rd Workshop on Treebanks and Linguistic Theories, pages 115-126. Michcael Schiehlen. 2004. Annotation strategies for probabilistic parsing in German. In the 20th International Conference on Computational Linguistics, pages 390-396. Kiyoaki Shirai, Takenobu Tokunaga, and Hozumi Tanaka. 1995. Automatic extraction of Japanese grammar from a bracketed corpus. In Natural Language Processing Pacific Rim Symposium, pages 211-216.\n\nResearch and development work on spoken language systems for special domains has been gaining more attention in recent years. Many approaches to spoken language processing require a grammar system for parsing the input utterances in order to obtain the structures, especially for rule-based approaches.\n\nManually developing grammars based on linguistics theories is a very difficult task. Language phenomena are usually described as being symbolic systems such as lexical, syntactic, se-mantic and common sense. Grammar development has to depend on linguistic knowledge and the characteristics of the corpus to explicate a system of linguistic entities. However, it is expensive and time-consuming to maintain a robust grammar system by manual writing.\n\nRecently some researchers (H. Meng et al., 2002;S. Dipper, 2004 andY. Ding, 2004) have presented a methodology to semi-automatically capture different grammar inductions from annotated corpora within restricted domains. A corpus-oriented approach (Y. Miyao, 2004) provides a way to extract grammars automatically from an annotated corpus. The specific language knowledge and knowledge relations need to be constructed and oriented to different corpora and tasks (K. Chen, 2004). The Chinese treebank is a useful resource for acquiring grammar rules and the context relations. Currently there are several Chinese treebanks on a scale of size. In the Penn Chinese Treebank (F. Xia, 2000), each structural tree is annotated with words, parts-of-speech and syntactic structure brackets. In the Sinica Treebank (CKIP), thematic roles are also labeled in the CKIP to provide deeper information.\n\nIn this paper, we discuss the extraction of Chinese grammar oriented to a restricted corpus. First, probabilistic context-free grammars (PCFG) are extracted automatically from the Penn Chinese Treebank and are regarded as the baseline rules. Then a corpus-oriented grammar is developed by adding specific information including head information from the restricted corpus. We then describe the peculiarities and ambiguities, especially between the phrases \"PP\" and \"VP\" in the extracted grammar. Fi-nally, the parsing results of the utterances are used to evaluate the extracted grammar. The outline of this paper is as follows: Section 2 gives the process of acquiring the baseline Chinese grammar and the extension of the current grammar oriented to the corpus. Section 3 explains the grammar properties in our corpus and our approach to disambiguating some special phrase rules, such as \"PP\" and \"VP\" and the word \"在(ZAI)\" in different categories. Section 4 describes the evaluation results of the extracted Chinese grammar. Finally section 5 offers some concluding remarks and outlines our future work.\n\nThere are two parts to acquiring grammar in our system. The baseline grammar is extracted automatically from the Penn Chinese Treebank.\n\nWe define a suitable parts-of-speech and phrase categories and extend them by introducing specific information from our corpus.\n\nThe University of Pennsylvania (Upenn) has released a scale of Chinese treebanks as a kind of resource since 2000 (Xia Fei et al., 2000). Each structural tree includes parts-of-speech and syntactic structure brackets, which provides a good way to extract Chinese probabilistic context-free grammars (PCFG). There are a total of 325 files collected from the Xinhua newswire in this treebank. The majority of these documents focus on economic development and are organized in written formats as opposed to spoken utterances, so the grammars extracted from it are seen as the baseline bank.\n\nThe probabilistic context-free grammars have proven to be very effective for parsing natural language. The produced rules are learnt by matching the bracketed structures automatically from the trees, and the rule probabilities are calculated based on the maximum likelihood estimation (MLE), presented in the following formula (Charniak, 1996):\n\nThe baseline grammar includes about 400 PCFG rules after cleaning and merging some rules with low probabilities (Imamula et al., 2003).\n\nDifferent corpora produce different grammars that have some specific information. In baseline grammars, many grammars are not suitable for spoken corpora. Therefore, we need to build an appropriate grammar by using specific information in our corpus to improve the parsing results and machine translation systems that operates in a restricted field. The data we used in this system is from the ATR Basic Travel Expression Corpus (BTEC) in which the format of utterances is different from the sentences in Upenn. Consequently, an appropriate phrase category is required to be constructed by analyzing the knowledge characteristics in BTEC. We define it by comparing three Chinese structure category systems: Sinica, University of Pennsylvania, and HIT (Harbin Institute of Technology). A phrase category should be not too complicated as but cover language phenomenon in the corpus. Our phrase category is defined and explained in table 1. Categories Explanation NNP Noun Phrase TNP Temporal Noun Phrase LP Localizer Phrase NSP Location Phrase VP Verb Phrase AP Adjective Phrase DP Adverbial Phrase QP Quantifier Phrase PP Preposition Phrase VBAP Phrase with \"把 (BA)\" DENP Nominal Phrase Ending by \"的 (DE)\" DEP Attributive Phrase formed by \"的 (DE)\" Table 1 Phrase Categories In BTEC, Chinese utterances are segmented and labeled as parts-of-speech. We not only construct corpus-oriented grammar rules differently from the baseline grammars but also add head information for each rule. In the above Table 1, the phrase category \"VBAP\" is a phrase name including the preposition \"把(BA)\" and its following noun or verb phrase. The phrase \"DENP\" is a special nominal phrase which has no word after the auxiliary word \"的 (DE)\", and it is usually put at the end of the utterance. Following are some examples of our grammars. 1. PP p(sem\"和\") (head)n 2. DENP (head)a y(sem\"的\") 3. PP p(sem\"用\") (head)r 4. DEP (head)DP de In above rules, the mark \"sem\" means its following word is a terminal node.\n\nAbove constructed Chinese grammars sometimes bring out conflicts when parsing utterances because of the ambiguity phenomenon.\n\nGrammar annotation is done to make the grammatical relations of an utterance more explicit. Thus, some ideas are proposed to deal with these ambiguities that are tightly related to Chinese language.\n\nPlenty of prepositions are rooted in verbs in Chinese language, and most of them still keep the function of verbs. This phenomenon produces ambiguous problems not only between categories preposition \"p\" and verb \"v\" but between the phrases \"VP\" and \"PP\" in the structures of the utterances. PP-attachment ambiguity is a big problem related to the construction of grammar (S. Zhao. 2004). Firstly, we extract a lexicon of Chinese prepositions, which have other categories at the same time, such as the category 'v', adjective 'a', and so on. The following We construct some particular grammar rules for these preposition words showed in Table 2 in order to deal with the conflicts among these words. For example, following rules are related to the word \"给\". PP p(sem\"给\") (head)n VP p(sem\"给\") (head)V VP v(sem\"给\") NNP (head)VP In order to represent the function of the extracted grammar, we compare the coverage of the grammar in different layers between a terminal node and a phrase layer. The different structural trees of the same utterance in Figure 1 are listed as follows.\n\n1.Sentence (这里/r 的/de 鞋/n 哪/r 双/q 是/v1 特价/n 商品/n ？/w ) Figure 1 Annotation of Different trees in the same sentence The same utterance obtains different structural trees from different levels of grammar rules by parsing results, although these two trees are cor-rect and acceptable. The grammar plays an important role in the machine translation system when we build the mapping relations with the goal languages by transform rules. This problem is also called Granularity (K. Chen, 2004). Symbol '**' in Figure 1 denotes that the phrase \"NNP\" is produced by the rule \"NNP n (head)n\" rather than \"NNP NNP (head)NNP\".\n\nA grammar inevitably includes ambiguities among its rules. To some extent, certain kinds of ambiguities are produced by the same ambiguous problems found among part-of-speech tags.\n\nAs with the expression in Section 2, the ambiguity between the phrases \"PP\" and \"VP\" is partly produced by the multiple categories 'p' and 'v' of the words. This is a common case where the phrases \"PP\" and \"VP\" are nested against each other. For example, the rule \"PP p (head)v\" and \"VP PP (head)VP\". This situation is described in the following two utterances in Figure 2.\n\nFigure 2 The Correct Trees of Utterances Including phrases \"PP\" and \"VP\" In sentence 1 of figure 2, the phrase \"PP\" (在/p 规定/v 的/de 路线/n) contains the verb \"规定\", and is produced by the rule \"DEP v de\" and \"NNP DEP n\" firstly. Likewise, in sentence 2, the phrase \"VP(送杯咖啡)\" is produced firstly rather than phrase \"给我送\" is got by rule \"VP PP v\". That is to say, the phrase \"VP\" has higher priority to be produced than \"PP\". The Chinese word \"在\" is a special individual word in our corpus. Its correlative disambiguation rules are constructed by the knowledge relations listed in the following table:\n\nThe order of rules Ambiguity parts bracketed in utterance P (preposition)\n\nTable 3 The characteristics of word \"在\"\n\nThe following steps are used to identify the ambiguities between the phrases \"PP\" and \"VP\": 1. The first step is to look up the preposition lexicon based on the category of the word and find the relative rules from the extracted grammar. 2. When the \"PP\" rules conflict with the \"VP\" rules, we firstly consider the verb and then select an appropriate rule by comparing the relationship to neighboring preposition words. 3. Long distance rules have priority. For instance, rule \"PP p v nd\" is preferred to rule \"PP p v\". 4. It is clear that the fine-grained rules have less representational ambiguity than the coarse-grained grammar rules in relation to the tree presentations. 5. The head information in the rules is viewed as being types of reference knowledge because of their own ambiguities.\n\nWe use the extracted grammar described in section 3 to parse Chinese utterances in BTEC and to evaluate the roles of the grammar.\n\nThe parser adopts a bottom-up parsing algorithm in order to obtain the phrase structures of utterances. There are 200 Chinese utterances selected in our experiment. The number of rules totals 682 that are constructed manually except baseline rules from Upenn Chinese treebank.  4 The number of rules with different leftside phrases\n\nIn our current experiment, the evaluation is limited to obtaining several special phrase structures including \"NNP\", \"VP\", \"PP\", and \"DENP\" by using the extracted grammar. Therefore, the parsing results are calculated using the precision of these phrases in the following formula (2) and are listed in Table 5. We give the evaluation results of the word \"在\" separately in Table 6.\n\nwhere denotes the number of correct phrases in the parsing results, and is the total number of the phrases in the utterances.\n\nc N t N Phrase Precision without disambiguation Precision with disambiguation Prec(NNP) 70.03 70.43 Prec(PP) 81.51 84.17 Prec(VP) 69.01 70.13 Prec(DENP) 82.61 82.81 Table 5 The evaluation results Phrase with \"在\" Precision without disambiguation Precision with disambiguation Prec(PP) 79.12 83.67 Prec(VP) 89.34 91.72 Prec(DP) 87.71 88.02 Table 6 The evaluation results of \"在\" From the evaluation results, we found that the precisions of the phrases \"NNP\" and \"VP\" were not high due to the diversity and complexity. We only processed the ambiguity between \"VP\" and \"PP\" and improve the precision of phrase \"PP\". From the condition of the word \"在\", it is very useful for the grammar extraction to construct information on high-frequency words and wordto-word collocation relations.\n\nThe Chinese language is one of the most difficult languages to process. There is still no uniform standard for acquiring Chinese grammar that covers all domains. Hence, a grammar should be constructed from the view of point of real research requirements in real corpora. It is the most important to maintain consistency and satisfy the actual requirements of a real corpus. One of the main purposes in constructing a Chinese grammar is to improve its validity and robustness to machine translation in a restricted corpus. The development of a robust grammar based on linguistics is difficult because of the complexity of deep linguistic analysis. For example, how many annotated grammars are suitable for the parsing system and a real machine translation? What is the balance between the granularity of grammar structures and grammar coverage including the ambiguities? In general, the coarse-grained grammar rules have a higher coverage rate compared with fine-grained rules, which contain more terminal nodes. There is also the major problem of determining which Treebank size is required to acquire the grammar rules.\n\nCorpus-oriented grammar extraction is conducted for the purpose of constructing more explicit grammar knowledge and improving the machine translation system in a restricted corpus. Treebanks provide a useful resource for acquiring grammar rules. However, it is time consuming to construct a much larger size Treebank, which is better for grammar extraction. It would be better if the knowledge extraction process could be carried out iteratively. The parser could use the initial grammar to produce a large amount of structural trees. These new trees would provide more information on the grammar to improve the robustness of the grammar and the power of the parsing system. This whole process can be regarded as an automatic knowledge learning system. The principal idea in this paper was to acquire Chinese grammar from a restricted corpus for a machine translation system. The extracted grammar was not only from the Penn Chinese treebank but also from new information added to our experimental corpus. The corpus-oriented Chinese grammar was evaluated by parsing the phrase structures that includes \"NNP\", \"VP\", \"PP\", \"DENP\", and the phrases relative to the word \"在\". Currently, we only focus on a few limited phrases, and the disambiguation process has been explored with specific rules manually. Therefore, to improve grammar extraction in the future, we will aim at increasing the robustness and coverage of the rules and try to automatically reduce the ambiguity rate by constructing more knowledge relations. The word-to-word collocation relations provided useful information on grammar extraction for the detailed processing.\n\nsources and Evaluation (LREC-2000), Athens, Greece. Rashmi Prasad, Elini Miltsahaki, Aravind Joshi and Bonnie Webber. Annotation and Data Mining of the Penn Discourse Treebank. In Proceedings of the ACL 2004 Workshop on Discourse Annotation, Barcelona. 2004. Yusuke Miyao, Takashi Ninomiya and Jun'ichi Tsujii. Corpus-oriented Grammar Development for Acquiring a Head-driven Phrase Structure Grammar from the Penn Treebank. In Proceedings of the First International Joint Conference on Natural Language Processing (IJCNLP2004). March, Sanya, pp. 390-397, 2004 E. Charniak. 1996. Treebank Grammars. Technical Report CS-96-02, Department of Computer Science, Brown University.\n\nHe Tingting Huazhong Normal University tthe@mail.ccnu.edu.cn\n\nHuazhong Normal University Xu_xiaoqi@hotmail.com\n\n\"Metadata\" is first defined in computer science. It plays an important role in the management of electronic resources, especially the huge information from Internet. By cataloguing the web pages, we can obtain a better search more efficiently. Nowadays, metadata becomes a popular tool to describe administrative information about all kinds of resources. It defines schemes for resource description, and also provides universal mechanism for resource retrieval.\n\nIn corpus linguistic, metadata description has existed for a long time, and is generally referred to heading information. By defining metadata, more accurate and profuse annotation contents can be provided for corpus, such as, information about time, area, author and etc. However, there is no uniform specification for processing metadata in Chinese corpus at present. Thus, we define a core metadata set for Chinese corpus and normalize the description of set element. Basing on the Dublin Core metadata, which is widely accepted in philology, the definition takes much attention on the linguistic characteristics of Chinese corpus, and is compatible to the OLAC metadata standards as well. Both creator and users of the corpus can get regulations of textual description and annotation strategy from this standard.\n\nIn section 2, we discuss some referenced standards and resources, including DC and OLAC metadata. Section 3 presents a framework within which we design our metadata, and lists the main problems to be solved. Section 4 summarizes our metadata description and reports some further development of the standard. Conclusion is drawn in section 5.\n\nDublin Core Metadata has been present in OCLC ／ NCSA ( National Center for Supercomputer Applications ) Meta Workshop in 1995.It's a standard for cross-domain information resource description, and has no fundamental restrictions to the types of resources to which the metadata can be assigned. DC metadata defined 15 core elements, which are maintained and managed by DCMI (Dublin Core Metadata Initiative). The core elements are listed in table 1.\n\nIn DC metadata, each element is described in 10 property items that defined in ISO/IEC 11179.They are: \"Name\", \"Identifier\", \"Version\", \"Registration Authority\", \"Language\", \"Definition\", \"Obligation\", \"Datatype\", \"Maximum Occurrence\" and \"Comment\". However, 6 items among them have settled value for each element as following:\n\nVersion:1.\n\n1 Registration Authority: Dublin Core Metadata Initiative Language:en Obligation: Optional Datatype: Character String Maximum Occurrence: Unlimited Elements about Resource Content Elements about Copyright Elements about External Attribute description Title Creator Date Subject Publisher Type Description Contributor Format Language Rights Identifier Source Relation Coverage Table 1 Fifteen core elements in DC, which are divided into 3 classes. DC metadata is an important reference for the definition of Chinese corpus metadata. There are at least two reasons for this.\n\n(1) Both DC and corpus metadata are designed for large-scale users, who are not always professional catalogue person. Thus apprehensible and general are two pivotal aims to achieve. (2) DC metadata has been mostly assigned to electronic text from Internet webs, which are primary source of linguistic material as well. Therefore, it's expected that the corpus can be used directly without reannotation if they are annotated with DC metadata before.\n\nThe OLAC ( Open Language Archives Community Metadata)metadata set is based on the Dublin Core metadata set. In order to meet the specific needs of the language archiving community, the OLAC metadata set qualifies with three kinds of qualification: element refinement, encoding scheme, and content language. With these three attributes, an element in OLAC can indicate more information than the same one in DC does. Take the element \"Date\" in OLAC for example, with the element refinement, it can represent either date of create, or date of issue, or date of modification in different occasions The elements in OLAC are listed in table 2,and we can see that it uses all the 15 elements in DC. Element in OLAC are described in 5 property items which are \"Name\", \"Definition\", \"Comments\", \" Attributes\" and \" Examples\".\n\nResource Content Elements about Copyright Elements about External Attribute description Title Creator Date Coverage Publisher Identifier Description Contributor Format Language Rights Format.cpu Source Format.markup Relation Format.os Subject Format.sourcecode Subject.language Format.encoding Type Type.data Type.function Table 2 Elements in OLAC, this set uses all fifteen elements in DC. Genre= Prose Style= narrative Mode= Written Topics= Literature Medium= Textbook Name= Sex= Nationality= Language=Chinese Publish House= National Institute for Compilation and Translation Publish Place=Taiwan Publish Data= Title= starlight Table 3 Example of metadata describing in Sinica corpus 2.3 Research on large-scale corpus metadata 2.3.1 Sinica corpus metadata Sinica corpus is developed and maintained by Institute of Information Science and CKIP group in Academia Sinica. It's designed for analyzing modern Chinese. Texts are collected from different areas and classified according to five criteria: genre, style, mode, topic, and source.\n\nTherefore, this corpus is a representative sample of modern Chinese language. Metadata in Sinica corpus lays special emphasis on describing the linguistics information of linguistic material, such as \"Mode\", \"Style\", \"Medium\", and \"Topic\". An example of metadata describing in Sinica corpus is given in table 3.\n\nNational modern Chinese corpus is the largest balance corpus in China at present. The selection of linguistic material follows the principles of commonality, description and practicability. In order to reflect the panorama of modern Chinese, a lot of work has been done on designing balance gene. And the finally selected samples have a wide span on time, domain and medium.\n\nMetadata in National modern Chinese corpus pay much attention on copyright information and publish information of linguistic material. Furthermore, both a global serial number and a category number are designed to identify a certain sample.\n\nThe British National Corpus (BNC) is a 100 million word collection of samples of written and spoken language from a wide range of sources, designed to represent a wide crosssection of current British English, both spoken and written. Each text in BNC has a TEI header to indicate the identification and classification of individual text, special details such as speakers', and the housekeeping information. The definition of text classification is meticulous. For spoken text material, age, sex, and class of respondent are all make sense as well as the domain, region and type of the content. And for written text material classification, age, sex, type of author, audience, circulation, status, medium, and domain are laid emphasis on. However, some classification were still poorly defined and partially populated, such a \"dating\"(date of copy or date of first publication?) and \"domain\" (has something different with text-type?).\n\nIn recent years, the awareness that text is not just text, but that texts comes in several forms, has spread from more theoretical and literary subfields of linguistics to the more practically oriented information retrieval and natural language processing fields. As a consequence, several test collections available for research explicitly attempt to cover many or most wellestablished textual genres, or functional styles in well-balanced proportions\n\nIn practice, choosing balance gene is a professional work that needs a scientific programming strategy. Sinclair suggested a minimum set of balance gene for general corpus in 1991 that indicates a popular classify principle for linguistic: the style of linguistic (on-the-spot record or literature); the form of linguistic (formal or informal); the medium type of linguistic (from book or magazine or paper); and the age, sex of the author. From the Sinica corpus and National modern Chinese corpus we've discussed above, we can see that the gene of time, style, area and subject are most in frequent use, which become our crucial reference for metadata designing.\n\nISO1179 is an international standard about developing metadata. There are 6 parts in this standard, which are considered as our basic rule to follow.\n\nWe describe metadata information from three aspects, which we consider as: content structure, syntax structure and semantic structure. Content structure is used to decide the elements in a metadata set. Syntax structure introduces a model or syntax to represent metadata, while semantic structure declares the signification concourse of elements.\n\nA consistent strategy is essential when these three structures are used to define metadata. Our research is to solve three problems especially.\n\nElements in metadata set are used to describe a resource from different aspects. Thus, the selection or designing of elements becomes an important issue. When the selection depends on the experience of corpus creator rather than a normative rule, it's hard for the metadata to assert the resource sufficiently.\n\nWe referenced a lot from DC and OLAC metadata. For the universal use of these two metadata standards and the similarity between DC metadata and corpus metadata we discuss above, we finally used all the fifteen elements defined in DC standard. However, some elements are refined or splitted into several new elements on the basis of the old definition. For example, the elements \"Date\" is extended as \"Indite Date\", \"Issued Date\", \"Created Date\" and \"Modified Date\", thus more detailed and definite information of date can be obtained for either a single sample or the whole corpus. And the same case for the element \"Language\" from DC. We defined three kinds of information about language to describe both creator information and content information.\n\nTo fully consider the linguistic characteristics of Chinese corpus, we've introduced several popular metadata elements in balanced corpus, such as style, mode, medium and so on, which are also important balance gene for corpus designing.\n\nTherefore, we define 46 elements in all, which can be divided into 6 classes. They are: information about copyright, information about background of linguistic material creator, information about medium of linguistic material, information about the content of linguistic material, information about collecting linguistic material, and information about management of linguistic material. Most elements we defined are intellectual metadata, while some structural metadata, access control metadata and critical metadata are included as well.\n\nMetadata is structured data about data. It's usually expressed with several property fields or subsections, which is regarded as its own data structure or syntax. Different metadata system may use different way to describe and naming its elements, thus it's hard for metadata communion or understanding the same element from two dissimilar systems.\n\nA unified method for description is helpful, and it's expected to be succinct, general and distinguished. Our standard has provided 10 fields for a metadata description. Some are obligatory, that is to say you must give a value to such fields in order to confirm an element. And some are optional for the individuation use. This seems to do a better work than DC, while 6 fields in it always have settled value. We specially introduce two subsections for naming an element, thus elements can be distinguished exactly from either \"Name\" or \"Long Name\" field. We have exhibited such format in XML (eXtensible Markup Language), and created the DTD (Document Type Definition) file for it as well.\n\nSemantic structure defines the detailed value of metadata, and finally affirms how to use it. Value land should be carefully considered to avoid confusion use. Many famous metadata standards have formed a maturity definition of elements. For example, DC use ISO 8601 to define element \"date\", Dublin Core Types for element \"Resource Type\" and URL or ISBN to define element \"Identifier\". We took much account of the linguistic characteristics of Chinese corpus and some value are assigned refer to linguistics literature.\n\nOur corpus metadata set is based on the Dublin Core metadata set and uses all fifteen elements defined in that standard. We've summarized some annotation items in other large-scale corpus and developed an element set listed in table 4.There are 46 elements in all. They are expected to describe the resources from six aspects.\n\nThe intellectual property right of corpus is copyright. According to the copyright law, corpus must show clearly its copyright information when being published or promulgated. Metadata in this class is about corpus' created or issued information, mainly including: Title: the title of original linguistic material, such as books, articles, webs and so on. Source Identifier: the tag of source linguistic material, such as ISBN for books and URL for webs. Indite Date: is used to describe the writing time of original linguistic material, or the recording time of the oral linguistic material.\n\nIssued Date: describe the publish time of a given linguistic material.\n\nCopyright: show the composer, publishing company or the web site of the original linguistic material.\n\nResource Type: resource's physical type can be various, such as papery, electronic, recordy, or kinescope.\n\nWe pay some attention on the individual information of corpus' creator, because it's helpful for analyzing linguistics characteristic about corpus. Such information includes native language, born place, age, sex as well as creator's name. For corpus' creator is not always a single person, we define \"Agent Type\" to clarify such instance, and introduce other creators in \"Contributor\".\n\nInformation about medium of linguistic material provides detailed data of publish region, influence area, circulation extent and so on, which are all important to evaluate the corpus' balance gene.\n\nMedium Type: linguistic material is usually selected from different published medium including paper, book, magazine, web or else. Publish Type and Publish Area: respectively indicate the geographical area type or size, such as national or local, and the idiographic cantons the area covers. Publish Period and Amount: respectively show the publish frequency and copies of the publication.\n\nguistic material Information about the content of linguistic material describe corpus from the point of view of linguistics, such as mode and style. And other elements in this class focus on two things, that is what the material expressed and how it expressed. For example: Subject: is used to express the theme of the linguistic material, while \"Description\" gives some further detail of what is talk about. Markup Language: is especially defined to indicate the coding language of electronic resources. 4.1.5 Information about collecting linguistic material Corpus is not a simple set of corpus. When select linguistic material, many factors are considered. We discuss the information about collecting linguistic material in written corpus and oral corpus respectively.\n\nIn written corpus, elements mostly describe the information of material sample, such as how to abstract the sample or how long the sample linguistic material should be. Oral corpus has its particular way to collect materials, so we describe them from the scene character of the interlocution.\n\nguistic material Information about management of linguistic material record data for corpus management and further-processing. Most elements are designed for system administrator and it's recommended that the data is user-sightless. Such as Tag information of linguistic material:\n\nIdentifier: defined for system to identify each linguistic material from this unique identifier. Sample Name: the material title in the corpus .It can either be the original title of the material, or new name the corpus' creator gives afterward if it has. Log information of linguistic material processing are defined for corpus updating and backup, such as input type, annotate type, create date and modified date. And system information, such as operation system (format.os) and CPU (format.cpu) are defined to describe the running environment of the corpus.\n\nTo distinguish one element from another, or our elements from someone else's, we provide a potent description method. Ten subsections are defined as mutual attribute field. Each metadata element can be described with these subsections selectively or whole.\n\nUnique for each element. Used as identifier when preserve data. Name is a sting of English letter.\n\nDisplayed as full name in Chinese.\n\nSemantic content of an element.\n\nExtra or special explanations are put in comments.\n\nSpecify the possible value land of metadata.\n\nA \"Type\" subsegment can be either \"basic element\" or \"file citation\", while \"file citation\" denotes that the element's definition has referenced some content from another file.\n\nIndicate where the metadata has been ever defined. It may be from DC, OLAC or userdefined.\n\nElements could be either obligatory or optional. When a metadata is obligatory, it must be used in corpus.\n\nIndicate the publish date of the metadata 4.2.10 Publish File Indicate the name of file in which the metadata first defined.\n\nThe way to describe a metadata element is to assign semantic content to each subsection we\n\nformation about col information about copyright information about background of linguistic material creator information about medium of linguistic material information about the content of linguistic material Written corpus Oral corpus information about management of linguistic material Title Agent Type Medium Type Mode Abstraction Type Environment Identifier Source Identifier Creator Publish Type Style Position Event Sample Name Indite Date Sex Publish Area Subject Words Amount of Resource Place Input Type Issued Date Native Place Amount Description defined before. There are 46 elements in all, and we give description of two elements to show the model. Description 1: Name: Agent Type Long Name: 创 建者形式 Definition: The way in which corpus' creator organized. Comments: The creator of a corpus may be one person, several persons or an organization. Value Land: Defined as {sole, multiple, corporate, unknown, unclassified } according to the design of BNC corpus. \"unknown\" represent this property has not been obtained, while \"unclassified\" indicate the organized form has not been defined in our value land (equivalent to NULL in relation database). Type: basic element DefinedIn: user-defined Obligation: commendatory Publish Date: 2005.1. Publish File: Standard of corpus metadata Description 2: Name: Mode Long Name: 语 体 Definition: Type of writing Comments: Value Land: {kouyupingshi, kouyuyishu, shumianpingshi, shumianyishu} Type: basic element DefinedIn: user-defined Obligation: commendatory Publish Date: 2005.1. Publish File: Standard of corpus metadata\n\nXML is a widely used language for defining data formats. It provides a very rich system to define complex documents and data structures. As long as a programmer has the XML definition for a collection of data (often called a \"schema\"), they can create a program to process any data format according to those rules. We've defined our metadata format by using XML in several schema files.\n\nThe following codes define the element \"Style\", which is proposed to describe the style of article material in corpus. We defined four types of mode in our standard: narrative writing, exposi-tory writing, argumentative writing and practical writing. In the schema, they are represented as \"jixuwen\", \"shuomingwen\", \"lunshuwen\", and \"yingyongwen\" respectively. <?xml version=\"1.0\" encoding=\"GB2312\"?> <schema xmlns=\"http://www.w3.org/2001/XMLSchema\"> <annotation> <documentation> CMD Schema for Article Style, seiga, 1/7/05 </documentation> </annotation> <simpleType name=\"CMD-Style-Code\"> <restriction base=\"string\"> <enumeration value=\"jixuwen\"/> <enumeration value=\"shuomingwen\"/> <enumeration value=\"lunshuwen\"/> <enumeration value=\"yingyongwen\"/> </restriction> </simpleType> </schema> Code1.define element \"Mode\" in a schema\n\nMetadata is \"data about data\". In our norm, a lot work has been done to describe such data. We normalized data item, naming regulation, data type and data width.46 metadata elements have been defined to register information of resource, within which 15 belong to DC Metadata, 3 belong to OLAC Metadata, 15 belong to both DC and OLAC Metadata, and 28 are user-defined. According to this, we tag each metadata by its \"DefinedIn\" item. Corpus designers are able to choose element during the annotation. They can also add new elements to satisfy various requirements basing on this standard.\n\nThe standard use English string when denominating metadata element, because some software cannot support Chinese variable. We develop DTD files and an assistant software (FIG. 2-FIG. 4) for the convenient of corpus annotation. By filling blanks with some metadata information in this software, users can directly get the XML code of an annotated corpus. We are to do some further experiment on corpus annotation and corpus management. With various information the metadata interpreted, more works may lead to resources discovery and content rating. FIG.3Interface to input information about the content of linguistic material and collecting linguistic material The impact of globalization and urbanization has caused many aboriginal languages on our planet to go extinct. This language death process not only reduces the number of native languages but also wipes out the cultural heritage connected with those languages (Xu 2001). Therefore, preservation and archiving of these endangered native languages is vital and critical. Many projects around the world are seeking to preserve these endangered native languages (e.g., Lublinskaya 2002;Psutka 2002).\n\nThe attempt to preserve an endangered language includes several steps: documenting and recording the oral and written literature, compiling the grammar and a dictionary of the language, and annotating the documentation related to this language. It is also important to find an effective approach to teach the endangered language to the ethnic group using the language, particularly to members of the younger generation, who often live in urban areas without any connection to their place of origin.\n\nAccording to a study by Whaley (2003), the factors required to help an endangered language survive include:\n\n1. a well developed preservation and maintenance program for the language; 2. use of information technology in the preserving project; 3. a new world order, especially economic and political shifts; 4. an environment for learning and exploring the language.\n\nBased on the above discussion, it is important that an endangered language preservation and documentation project should be comprehensive and carefully planned. This project needs to take advantage of state-of-the-art technologies and establish an environment for learning.\n\nIn order to successfully document and preserve a Batanic language, Yami, we propose an approach of archiving and development of an environment that fosters learning of the language. The Yami language, used by the Yami tribe on Orchid Island, is an oral language in which most of the content is closely connected to the traditional life style and cultural heritage. However, many Yami people have moved to cities in Taiwan and have lost their connection to the Yami society on Orchid Island. The death of the older generation has hastened the decline of the Yami language. According to Rau's (1995) sociolinguistic survey on Orchid Island, Iraralay is the only community of the six villages on the island where children still use some Yami for daily interaction. Although Yami has been offered as an elective in elementary school since 1998, Yami is gradually being replaced by Mandarin Chinese. Among the junior high school students on the island, 60% either believed Yami would die eventually or were uncertain about the fate of the language.\n\nThe approach proposes a comprehensive series of steps to collect and record the Yami language. In addition, the work includes development of a learning method that will be effective with Yami youngsters who live in urban areas. Although the complete work of documentation will take many years, the Yami language is in danger of being lost due to rapid urbanization. Therefore, we have developed a strategy to make language items available in learning materials as soon as they have been collected, taking advantage of information technology and computer networking. Using these technologies we have developed an integrated platform for documenting, processing and learning that will help both Yami youngsters and other students taking Yami as a second language.\n\nThe integrated platform is built on a main web server with several supporting servers. The main server is designed as the server for resource management and the supporting servers are designed for different purposes. The purpose of this design is to effectively edit the oral recording of the Yami language and to make the language learning materials. The proposed platform includes three subsystems:\n\n1. a subsystem to manage and edit the digital archiving of the Yami language, 2. a subsystem to handle the workflow of collecting oral recordings of the Yami language, 3. a subsystem to create and manage the Yami language learning materials. Each subsystem is installed on one or two servers. All these subsystems will be described in detail in Section 3.\n\nAlthough most ideas in the proposed integrated framework has been used for other language documentation and learning, the proposed framework is an initiative for archiving and teaching an endangered language. The attempt of our study is not only to use technologies to preserve an endangered language but also to develop a well-accepted platform for this language. Hence, people can learn and appreciate this language and its cultural heritage.\n\nThe proposed framework is used in an ongoing grant-supported project for archiving and documenting the Yami language (ELDP, MDP0114). The collection of Yami language materials began in 1994. Currently, we are implementing the computer systems and database in this integrated framework. In the later section, we will report on our current progress.\n\nThe remainder of this paper is organized as follows. Section 2 is a description of the process of collecting the material for archiving. Section 3 shows the proposed integrated framework and a brief description of related methodologies. Section 4 illustrates the current development of the system, followed by conclusion and future directions in Section 5.\n\nIn addition to digitally archiving the 20 narratives, reference grammar, trilingual dictionary with 2000 entries (Rau & Dong, 2005), and multimedia pedagogical materials (Rau et al. 2005), we also collaborated with local consultants to document daily conversations, business transactions, festivals, and ceremonies.\n\nThe topics were selected based on consultation of previous research on Yami ethnography, and are designed to meet the standards stipulated by the R.O.C. Ministry of Education for developing Austronesian teaching materials in Taiwan. The topics are closely related to those selected for inclusion in four volumes of Yami multimedia teaching materials the second author is currently developing.\n\nIn this section, we will describe our design and the theoretical framework behind the design. The project is divided into four major steps:\n\n(1) field recording: recording the oral sound data of the Yami language, (2) archiving: editing the sound data and annotating the data using the metadata, (3) multimedia transformation: analyzing the original data and creating a multimedia Yami dictionary and text description, (4) e-Learning: creating online Yami language learning materials. The framework is designed to meet two requirements of our Yami language archiving project:\n\n(1) to build a complete and original archiving database for Yami language including speech of various genres, grammar, vocabulary and cultural artifacts. ( 2) to create learning materials in an easyto-learn environment via internet and computer.\n\nFirst of all, the existing records collected by the research team since 1994 will be organized and digitalized, along with new field recordings. In our project, we will develop an oral speech archiving database to store these oral recordings. Each recording will be scanned to find the basic sound characteristics and transferred to digital data. The sound characteristics are used for comparing and tracking these recordings. Following a study by Chen (1996) about tone and stress patterns in Asian languages, we will extract information on intonation and stress from the field recording. This information will later be used to create the learning material. The field recordings are arranged by segments, ranging from words in isolation to \"idea units\" or \"tone units\" (Chafe 1979) in continuous speech.\n\nOnce a segment of the field recording has been completed, the original data is stored in the computer and two different types of digital data are created. These include MP3 data that will be used for creating the learning materials and the annotated digital data in which the recordings are separated into phrases with Chinese and English translations. All these data are stored in a relational database with the recording date used as the searching key.\n\nThe processing of field recordings is considered to be the preparation and preprocessing stage of the Yami language documentation project. The voice database is used to create the archived data and learning materials.\n\nThe archiving step begins with editing the voice database and construction of the OLAC metadata for each entity in the voice database. The original sound tracks in the field recording database are edited to improve clarity of the sound by using sampling techniques (Kientzle 1998). The edited sounds are stored as the new sound records in the voice database.\n\nThe metadata used for describing Yami language is the OLAC metadata, an extended Dublin Core set with basic elements of language resources. To meet the requirement of the linguistic community, certain new extension elements are put in the OLAC set following DCMI guidelines (DCMI 2000). To build a proper OLAC metadata for the Yami language, we have chosen to adopt the OLAC set proposed by Bird and Simons (Bird et al. 2001, Bird & Simons 2003) for this project. Because Yami is primarily an oral language, we use a subset of this OLAC set. The OLAC elements used in this project are: {Title, Creator, Subject, Subject language, Description, Publisher, Contributor, Date, Type, Format, Identifier, Source, Language, Relation, Rights}. The reason for selecting these elements is to create a common description of the Yami language. Furthermore, after reviewing the field study materials, we can show that the above OLAC subset can meet the basic requirement for describing the Yami language. The rules to apply these OLAC elements to each recording of the Yami language are:\n\n(1) Each OLAC element can be optional and repeatable;\n\n(2) Each OLAC element can describe only one single identification or one single range;\n\n(3) Data format of each OLAC element follows the rules in DCMI (DCMI 2002). Each OLAC element used in describing the Yami language is given following the OLAC and ELDP guidelines. Suppose there is a Yami language sound track to be described, the OLAC element set of this sound track is shown as follows: Title: the Chinese name of the Yami language sound track. A second Title element is used to store English translation. Creator: the Yami speaker who uttered this speech. A second Creator element is used to store his/her Chinese name. Subject: the keyword used to classify the content of the Yami language sound track. The keywords and controlled vocabularies are being collected. Subject language: the Chinese linguistic description of the Yami language. A second element is the corresponding English description. Description: the usage and the multimedia data related to this Yami language sound track. Some multimedia data are collected using the Multimedia Transformation step described in Section 3.3. Publisher: the research teams and the sponsoring institutions. Contributor: the research teams and the person who recorded this sound track. Date: the date this sound track was recorded and the date the archiving process was completed. Type: the genre of the content of the Yami language sound track. We are transferring many Yami language linguistic and anthropological terms into DC-type. These DC-type terms will be used as the Type element. Format: the digital data type of the Yami language sound track. Identifier: the ELDP identifier for this Yami language sound track. We will follow ELDP guidelines to create identifiers for the archived sound track. Source: the location of the archiving database and the location for storing the field study draft. Language: English and Chinese (traditional and simplified characters) Relation: the related Yami language sound tracks. Rights: copyright information of this sound track.\n\nIn the archiving step we will also consider how to build a database of the controlled vocabularies for the Yami language. We will use three sources for the controlled vocabulary in this project: lexicon, primary text and language description.\n\nThe table of OLAC metadata is created in two forms, one XML text table format and one relational table format. The voice database from the first step is edited and connected to the metadata table.\n\nAnother goal of this step is to build a Yami language online phrase dictionary. The OLAC metadata are used for parsing and editing with the voice database to create a Yami language online phrase dictionary. We will develop an auto dictionary-generating program that can process the OLAC metadata and find suitable terms. In addition, we use the grammar and course materials of Yami language multimedia courseware created by Rau et al. (2005) to build our on-line multimedia Yami language phrase dictionary.\n\nWhen the metadata of a set of the Yami language sound tracks are completed, the results will be published online on our web site. This year, our focus is aligning the OLAC metadata of the Yami language sound tracks with the multimedia courseware by Rau et al. (2005). Later, we will try to use ontology to determine rules for creating metadata automatically and to develop an automatic metadata generator for the Yami language.\n\nThe Yami language is basically a spoken language, although an orthography is being developed and standardized as texts are collected. To preserve the Yami language, we will use an image database to annotate the language. In addition, each word in Yami is annotated with its orthography stored in a sound database. The purpose of this transformation is to build an image for each Yami word. Therefore, the meaning of the word can be related directly to a picture. The reasons why we have chosen to use this approach to annotate the Yami language are as follows:\n\n(1) The Yami language, like all other languages, has culture-specific words and expressions, of which pictures are direct representations.\n\n(2) The annotated pictures help learners understand the traditional lifestyle on Orchid Island and give them more incentive to learn the language. (3) The pictures include many Yami cultural artifacts. The annotated pictures can thus preserve descriptions of their cultural heritage.\n\nThe steps for multimedia transformation of the Yami language are as follows:\n\n(1) Collect suitable images for building the annotated image database. We will consult many other research teams to borrow Yami images and video recordings. ( 2) Design criteria to choose the images. We will select appropriate images and develop possible connections between Yami expressions and a set of pictures. (3) Build a special annotated database and use the Yami language to annotate the image data. The annotated algorithms are based on the fuzzy logic style (Kecman 2001) or the Coherent Language model (Jin 2004). ( 4) Build a corresponding mapping relation between a Yami expression and a set of annotated images. The mapping relations are a set of contexts and symbolic tables similar to a set of induction rules. ( 5) Build a sound connection between each Yami word and its phonetic symbols by using the fuzzy logic learning algorithm.\n\nThe results of multimedia transformation can be used as a foundation for creating online learning material. The results are stored in a relational multimedia database as well as the XML pages.\n\nThe final task of our project is to find an effective way to teach the Yami language to urban Yami youngsters and other learners of Yami as a second language. To build an open and selflearning environment, the computer-based learning or the webs for learning is our choice. There have been various discussions about how to use information technologies and the web to learn a different language. Gerbault (2002) showed that it is viable to set up a proper multimedia environment for leaning a language without a teacher's participation. Fujii et al. (2000) demonstrated a project using the Internet as a tool for the teacher to post course materials and create an online learning environment. In addition, Lamb (2005) suggested rethinking pedagogical models for e-learning from the what, the why and the how. e-Learning consists of self-access, reference sources, discussion forum, and virtual learning classrooms. The main motives for introducing e-learning include improving student multimedia learning experience, enhancing learner autonomy and widening participation.\n\nFinally, e-learning can be controlled primarily by tutors or students, depending on objectives, contents, learning tasks, length/time/place of study, or choice of assessment activities.\n\nAs mentioned in a study by Leung (2003), the computer-based learning environment is very important as a way to help students learn effectively. In order to provide an effective learning environment, Leung (2003) suggested that four contextual issues should be considered in design and implementation of computer-based learning. These issues are topic selection, authenticity, complexity, and multiple perspectives. The design of the web-based computer-assisted learning program for the Yami language takes these four issues into consideration. We outline our design as follows.\n\nThe learning environment in this project is a virtual classroom without teacher participation. Students can select the Yami language learning materials prepared by the second author. If a student asks for clues or explanation of a specific Yami word or expression, a suitable image or video clip is retrieved from the multimedia database. If a student is not familiar with a specific Yami sound, a similar phonetic symbol is provided to him/her. The learning materials are arranged in three different settings, scenario setting, easy-to-difficult condition setting and learner's choice setting. The scenario setting uses related scenes in Yami society such as the flying fish festival as a main theme of the learning materials. The easy-to-difficult condition setting allows the learner to select different levels of the Yami language materials. The levels are based on word frequencies and complexity of grammar. The learner can arrange his/her learning materials in the learner's chosen setting. The learning system will give detailed guidelines to explain how to choose the learning materials. If a student wants to learn the Yami language, he/she can choose different learning materials based on his/her interest. The learning materials are designed as theme units with exercises and rubrics for self-assessment. The design of these Yami language exercises is based on a study about the reactions of students to using a web-based system for learning Chinese in Taiwan (Yang, 2001).\n\nWe use the annotated image database as a tool to help the learners understand the meaning of Yami words or expressions. To make the pictorial explanation more understandable, an animation clip combined with several images is created to explain them.\n\nA study by Aist (2002) showed that different designs of the oral-reading interactions can help students understand the language more. The learning system will provide several reading modes for students to listen and practice. These modes include: to read the entire sentence without interruption, to read the entire sentence by isolating each word, to read a word slowly syllable-by-syllable, recue the whole sentence and recue the selected words.\n\nThe interface of the proposed learning environment is built on a web server with a dynamic web page. To establish a more efficient learning environment, all the learning materials are edited into reusable learning objects. The user interface is developed as an adaptive style following Mich et al.'s (2004) PARLING system.\n\nThe proposed framework is illustrated in Figure 1.\n\nWe implement the proposed framework as a hybrid system with many different processes including:\n\n(1) Data collection and formulation: to collect the original Yami language data and to build the metadata and the table for digital archiving.\n\n(2) System design and analysis: to design and develop suitable computer systems and servers to accommodate the proposed framework.\n\n(3) Research and construction of proposed framework: to develop each subsystem or database shown in Figure 1, such as the OLAC metadata database, the annotated image database and the Yami language learning materials.\n\n(4) Assessment and evaluation: to test the effectiveness of the proposed learning ma-terials and to evaluate whether the project goals were accomplished.\n\nCurrently, we are collecting the Yami language materials and building the system server for the proposed framework. We will use a SQL server as the main sever to manage the workflow and the documentation logs. A PHP web server with mySQL server is used as a server for multimedia transformation. Another SQL server is used as the archiving server. The system diagram of the proposed framework is shown in Figure 2.\n\nFigure 2 Diagram for the proposed framework\n\nThis paper describes an integrated framework for archiving and processing the Yami language. In addition, the framework includes the process for developing online learning materials for the endangered language. We use this framework for the Yami language preservation project. The project is continuously developing. We hope that this project can serve as a model for other endangered language preservation projects in Asia.\n\nWith the improvement of speech processing technologies, spoken dialogue systems that appropriately respond to a user's spontaneous utterances and cooperatively execute a dialogue are desired.\n\nIt is important for cooperative spoken dialogue systems to understand the intentions of a user's utterances, the purpose of the dialogue, and its achievement state (Litman, 1990). To solve this issue, several approaches have been so far proposed. One of them is an approach in which the system expresses the knowledge of the dialogue with a frame and executes the dialogue according to that frame (Goddeau, 1996;Niimi, 2001;Oku, 2004). However, it is difficult to make a frame that totally defines the content of the dialogue. Additionally, there is a tendency for the dialogue style to be greatly affected by the frame. In this paper, we describe the construction of a structurally annotated spoken dialogue corpus. By statistically dealing with the corpus, we can achieve the automatic acquisition of dialoguestructural rules. We suppose that the system can figure out the state of the dialogue through the incremental building of the dialogue structure.\n\nWe use the CIAIR in-car spoken dialogue corpus (Kawaguchi, 2004;Kawaguchi, 2005), and describe the dialogue structure as a binary tree. The tree expresses the purpose of partial dialogues and the relations between utterances or partial dialogues. The speaker's intention tags were provided in the transcription of the corpus. We annotated 789 dialogues consisting of 8150 utterances. Due to the advantages of the dialogue-\n\n0022 -01:37:398-01:41:513 F:D:I:C: (F えーっと) [FILLER:well] &(F エーット) おいしい [delicious] &オイシー おうどんの [Udon] &オウドンノ お店 [restaurant] &オミセ 行きたいんですが<SB> [want to go] &イキタインデスガ<SB> 0023 -01:42:368-01:49:961 F:O:I:C: はい [well] &ハイ この [this area] &コノ 近くですと [near] &チカクデスト 諏訪屋 [SUWAYA] &スワヤ 千種豊月が [\"CHIKUSA HOUGETSU\"]&チクサホーゲツガ ございますが<SB> [there are ] &ゴザイマスガ<SB> Figure 2: Transcription of in-car dialogue speech Discourse act Action Object Express (Exp) Express (Exp) Propose (Pro) Propose (Pro) Request (Req) Request (Req) Statement (Sta) Statement (Sta) Suggest (Sug) Suggest (Sug) Confirm (Con) Confirm (Con) Exhibit (Exh) Exhibit (Exh) Guide (Gui) Guide (Gui) ReSearch (ReS) ReSearch (ReS) Reserve (Rev) Reserve (Rev) Search (Sea) Search (Sea) Select (Sel) Select (Sel) ExhibitDetail (ExD) ExhibitDetail (ExD) Genre (Gen) Genre (Gen) IntentDetail (InD) IntentDetail (InD) Parking (Par) Parking (Par) ParkingInfo (PaI) ParkingInfo (PaI) RequestDetail (ReD) RequestDetail (ReD) ReserveInfo (ReI) ReserveInfo (ReI) SearchResult (SeR) SearchResult (SeR) SelectDetail (SeD) SelectDetail (SeD) Shop (Sho) Shop (Sho) ShopInfo (ShI) ShopInfo (ShI)\n\nFigure 3: A part of the LIT structural rules being represented by context free grammars, we were able to use an existing technique for natural language processing to reduce the annotation burden.\n\nIn section 2, we explain the CIAIR in-car spoken dialogue corpus and the speaker's intention tags. In sections 3 and 4, we discuss the design policy of a structurally annotated spoken dialogue corpus and the construction of the corpus. In section 5, we evaluate the corpus.\n\nThe Center for Integrated Acoustic Information Research (CIAIR), Nagoya University, has been compiling a database of in-car speech and dialogue since 1999, in order to achieve robust spoken dialogue systems in actual usage environments (Kawaguchi, 2004;Kawaguchi, 2005)． This corpus has been recorded using more than 800 subjects. Each subject had conversations with three types of dialogue system: a human operator, the Wizard of OZ system, and the conversational system.\n\nIn this project, a system was specially built in a Data Collection Vehicle (DCV), shown in Figure 1, and was used for the synchronous recording of multi-channel audio data, multi-channel video data, and vehicle related data. All dialogue data were transcribed according to transcription standards in compliance with CSJ (Corpus of Spontaneous Japanese) (Maekawa, 2000) and were assigned discourse tags such as fillers, hesitations, and slips. An example of a transcript is shown in Figure 2. Utterances were divided into utterance units by a pause of 200 ms or more.\n\nThese dialogues are annotated by speech act tags called Layered Intention Tags (LIT) (Irie, 2004(a)), which indicate the intentions of the speaker's utterances. LIT consists of four layers: \"Discourse act\", \"Action\", \"Object\", and \"Argument\". Figure 3 shows a part of the organization of LIT. As Figure 3 shows, the lower layered intention tag depends on the upper layered one. In principle, one LIT is given to one utterance unit. 35,421 utterance units have been tagged by hand (Irie, 2004(a)).\n\nIn this research, we use parts of the restaurant guide dialogues between a driver and a human operator. An example of the dialogue corpus with LIT is shown in Table 1. In the column called Speaker, \"D\" means a driver's utterance and \"O\" means an operator's one. We used the Discourse act, Action, and Object layers and extended them with speaker symbols such as \"D+Request+Search+Shop\". There are 41 types of extended LIT. Because the \"Argument\" layer is too detailed to express the dialogue structure, we omitted it.\n\nIn this research, we assume that the fundamental unit of a dialogue is an utterance to which one LIT is given. To make the structural analysis of the dialogue more efficient, we express the dialogue structure as a binary tree. We defined a category called POD (Part-Of-Dialogue), according to the observations of the restaurant guide task, that was especially focused on what subject was dealt with. As a result of this, 11 types of POD were built (Table 2). Each node of a structural tree is labeled with a POD or LIT. The dialogue structural tree of Table 1 is shown in Figure 4.\n\nTo consider a dialogue as an LIT sequence, LIT providing process (Irie, 2004(b)) usually should be done. Furthermore, repairs and corrections are eliminated because they do not provide LIT. In this research, we used an LIT sequence provided in the corpus. After that, the annotation of the dialogue structure was done in the following way.\n\nMerging utterances: When two adjoining utterances such as request and answer, they seem to be able to pair up and merge with an appropriate POD. In Table 1, for example, the utterance \"Should I make a reservation?\" (#286) is a request and the answer to #286 is \"No, a reservation is not necessary\"(#287). In this way, utterances are combined with the POD \"S INFO\".\n\nWhen the LIT's of two adjacent utterances are corresponding, these utterances are supposed to be paired and merged with the same LIT. Utterance \"Fresh and roe\" (#280) and \"I want to have Hotpot\" (#281) are related to choosing the style of restaurant and are provided with the same LIT. Therefore they are combined with the LIT \"D+Statement+Select+Genre\".\n\nMerging partial dialogues: When two adjoining partial dialogues (i.e. a partial tree) are composing another partial dialogue, they are merged with a proper POD. In Table 1, for example, a search dialogue (from #277 to #285, SRCH) and a shop information dialogue helping search (from #286 to #287, S INFO) are combined and labeled as the POD \"SLCT\".\n\nWhen the POD's of two adjacent partial dialogues are corresponding, these dialogues are merged with the same POD. Two search dialogues (one is from #277 to #282, other is from #283 to #285) are combined with the same POD \"SRCH\".\n\nThe root of the tree: The POD of the root of the tree is \"GUIDE\", because the domain of the corpus is restaurant guide task.\n\nWe made a dialogue parser as a supportive environment for annotating dialogue structures.\n\nApplying the dialogue-structural rules, which are obtained from annotated structural trees (like Figure 4.), the parser analyzes the inputs of the LIT sequences and the outputs off all available dialogue-structural trees. An annotator then chooses the correct tree from the outputs. When the outputs don't include the correct tree, the annotator should rectify the wrong tree rewriting the list form of the tree. In this way, we make the annotation more efficient.\n\nThe dialogue parser was implemented using the bottom-up chart parsing (Kay, 1980). The structural rules were extracted from all annotated dialogues. In the environment outlined above, we have worked at bootstrap building. That is, we 1. outputed the dialogue structures through the parser.\n\n2. chose and rectified the dialogue structure using an annotator.\n\n3. extracted some structural rules from some dialogue-structural trees.\n\nWe repeated these procedures and increased the structural rules incrementally, so that the dialogue parser improved it's operational performance.\n\nWe built a structurally annotated dialogue corpus in the environment described in Section 4.1, using the restaurant guide dialogues in the CIAIR corpus. The corpus includes 789 dialogues consisting of 8150 utterances. One dialogue is composed of 11.61 utterances. Table 3 shows them in detail.\n\nNow, I'm navigating to \"MARU\" Sure. I see. Please guide me there. No, reservation is not necessary. Should I make a reservation? How about this? \"MARU\" restaurant is suitable. I love Japanese Hotpot. Well, there are restaurant near hear that serve sumo wrestler's stew, Japanese hotchpotch and sliced beef boiled with vegetables. I want to have Hotpot. Fresh and row. Which kind do you like? Let me see. I'd like to eat sea bream.\n\nDescription 2 9 1 2 9 0 2 8 9 2 8 8 2 8 7 2 8 6 2 8 5 2 8 4 2 8 3 2 8 2 2 8 1 2 8 0 2 7 9 2 7 8 2 7 7 U t t e r a n c e N u m b e r D O O D O D O O D O D D O O D Speaker T h a n k s .\n\nNow, I'm navigating to \"MARU\" Sure. I see. Please guide me there. No, reservation is not necessary. Should I make a reservation? How about this? \"MARU\" restaurant is suitable. I love Japanese Hotpot. Well, there are restaurant near hear that serve sumo wrestler's stew, Japanese hotchpotch and sliced beef boiled with vegetables. I want to have Hotpot. Fresh and row. Which kind do you like? Let me see. I'd like to eat sea bream.\n\nTo evaluate the scalability of the corpus for creating dialogue-structural rules, a dialogue parsing experiment was conducted. In the experiment, all 789 dialogues were divided into two data sets. One of them is the test data consists of 100 dialogues and the other is the training data consists of 689 dialogues. Furthermore, the training data were divided into 10 training sets. By increasing the training data sets, we extracted the probabilistic structural-rules from each data. We then parsed the test data using the rules and ranked their results by probability.\n\nIn the evaluation, the coverage rate, the correct rate, and the N-best correct rate were used. In Figure 5, both the coverage rate and the correct rate improved as the training data was increased. The coverage rate of the training set consisting of 689 dialogues was 92%. This means 0.80 0.35 0.40 0.45 0.50 0.55 0.60 0.65 0.70 0.75 0.80 0.85 1 2 3 4 5 6 7 8 9 1 0 N-best N -b e s t c o r r e c t r a t e Data size 70 Data size 210 Data size 350 Data size 490 Data size 630 Data size 689 that the rules that were from the training set enabled the parsing of a wide variety dialogues. The fact the correct rate was 86% shows that, using the rules, the correct structures can be built for a large number of dialogues.\n\nThree in eight failure dialogues had continued after a guidance for a restaurant. Therefore, we assume that offering guidance to a restaurant is a termination of the dialogue, in which case they couldn't be analyzed. Another three dialogues couldn't be analyzed because they included some LIT which rarely appeared in the training data. The cause of failure in the other two dialogues is that an utterance that should be combined with its adjoining utterance is abbreviated.\n\nFigure 6 shows that the 10-best correct rate for the training set consisting of 689 dialogues was 80%. Therefore the correct rate is 86%, and approximately 93% (80/86) of the dialogues that can be correctly analyzed include the correct tree in their top-10. According to Figure 5, the number of average parse trees increased with the growth of the training data. However, most of the dialogues that can be analyzed correctly are supposed to include the correct tree in their top-10. Therefore, it is enough to refer to the top-10 in a situation where the correct one should be chosen from the set of candidates, such as in the speech prediction and the dialogue control. As a result, the high-speed processing is achieved.\n\nIn this paper, we described the construction of a structurally annotated spoken dialogue corpus.\n\nFrom observating the restaurant guide dialogues, we designed the policy of the dialogue structure and annotated 789 dialogues consisting of 8150 utterances. Furthermore, we have evaluated the scalability of the corpus for creating dialoguestructural rules.\n\nWe now introduce the application field of the structurally annotated dialogue corpus.\n\nDiscourse analysis: Using a POD labeled information for each partial structure of the dialogue, we can obtain information such as the structure of the domain, the user's tasks, the dialogue formats, etc.\n\nA system builds the structure of an input up to date and extracts the dialogue example that is most similar to the structure of the input from the corpus. If the next utterance or LIT of the extracted dialogue is the user's, the system waits for the user's utterance and predicts its meaning and intention. If the system's utterance is next, the system uses the utterance or LIT to control the dialogue.\n\nAt the present time, we have run up the data of the corpus and built probabilistic dialogue-structural trees. Next, we will apply the trees to some com-ponents of the spoken dialogue systems such as speech prediction and dialogue control.\n\nA knowledgebase which systemizes lexical and conceptual information of human knowledge is a basic infrastructure for Natural Language Processing (NLP) applications. Wordnets, pioneered by the Princeton WordNet (WN, Fellbaum 1998), and greatly enriched by EuroWordnet (EWN, Vossen 1998), have become the standard for a lexical knowledgebase enriched with lexical semantic relations. In addition to the multilingual architecture of EWN, there are some proposals to construct the expansion for monolingual wordnets to parallel wordnet systems, such as Pianta and Girardi (2002). However, the construction of multilingual wordnets eventually faces the challenge of low-density languages, which is dealt with in Huang, et al. (2002). Low-density languages, as opposed to high-density languages, usually refer to languages that are not spoken by a large number of people. However, there is neither a direct correspondence between language population and language technology, nor an objective population number that defines density level. In this work, we use the availability of language resources instead to define language density. That is, low-density languages are languages that do not have enough language resources to support fully automated language processing, such as machine translation. In our current line of work, we (Huang et al. 2002) refer to low-density languages as those which do not have enough existing resources for semi-automatic construction of monolingual wordnet.\n\nThere are two alternative approaches to build parallel wordnets, as shown in Figure 1. The first approach relies on two fully annotated monolingual wordnets with synsets and LSR's. The second approach requires only one fully annotated WN in addition to LSR-based cross-lingual translation correspondences.\n\nApproach I maps and pairs Language A synsets with Language B synsets and annotates cross-lingual LSR's. The result is a fully annotated parallel wordnet. Approach II maps language A synsets to language B through translation equivalents. After language B synsets are thus established, language B LSR's are predicted based on corresponding LSR's in language A. A new set of monolingual LSR's is bootstrapped and predicted basing on inference rules governed by translation LSR's (T-LSR's). In general, approach I applies to high-density languages while approach II applies to low-density languages. In this paper, we will focus on the application of approach II to build a Chinese Wordnet with conceptual cohesion.\n\nThe current model was first explored in Huang et al. (2003). This previous study covered 210 lemmas, consisted of the top ranked lemmas in each part-of-speech (POS). The translation LSR's discussed in the previous model were antonymy, hypernymy and hyponymy. In this current work, we expand our study to all possible LSR's as well as to all the bilingual lexical pairs in our English-Chinese translation equivalents databases. Moreover, the LSR's in Princeton WordNet are again used as the basis for bootstrapping. In addition, we establish a set of evaluation for the results. The approach will be evaluated in term of both the precision of prediction and the confidence of prediction. We aim to show that T-LSR's bootstrapped approach does provide an effective model for building parallel wordnets for low-density languages.\n\nAfter the introduction, the main part of this paper consists of the following sections: in section 2, we briefly introduce the existing resources required for this work. We discuss methodology of T-LSR bootstrapping step by step in section 3. A series of LSR-predicting inference rules are also given in this section. In section 4, we plan to evaluate the results of our experiment and demonstrate the feasibility of maintaining conceptual cohesion in cross-lingual LSR mapping.\n\nAs we mentioned above, the T-LSR approach to parallel wordnet requires two language resources: a fully annotated monolingual wordnet and a set of translation LSR's to map the wordnet information to the target language. In our current study, we use the English WN as the source of synset and LSR information. The semantic relation between an English synset and its Chinese translation is based on The English-Chinese Translation Equivalents Database (ECTED, Huang et al. 2002).\n\nThe basic idea of ECTED is to provide the Chinese translation equivalents for each\n\nAPPROACH I Given fully annotated monolingual wordents with synsets and LSRs Fully annotated parallel wordnet APPROACH II Given fully annotated WN of language A; and bilingual translation equivalents annotated with LSR Map LSR-annotated synsets in Language A to Language B through translation LSRs (T-LSR's) Grow LSR links among Language B synsets by using language A LSR and cross-lingual LSR inference rules Map and pair Language A and Language B synsets with cross-lingual LSRs\n\nWN English synset. Our ECTED was bootstrapped with a combined lexical knowledgebase integrating at least four English-Chinese or Chinese-English bilingual resources. Based on this combined LKB, a group of translators chose (or created) up to three best translation equivalents for each WN synset. In addition, for each English-Chinese translation equivalent, a lexical semantic relation is annotated. In addition to synonym, the semantic relations marked including antonym, hypernym, hyponym, holonym, meronym, and near-synonym. We use all semantic relations, with the exception of antonymy, in this study.\n\nThe Cognitive Science Laboratory of Princeton University created WN, a lexical knowledgebase for English, in 1990 (Fellbaum, 1998). Synsets (a group of form-meaning pairs sharing same sense) are the main units used in WN to organize the lexicon conceptually. Each sense can be expanded either by gloss or context. It is easy for users to distinguish each sense by simply checking the synonyms, the example sentences or explanation. Nouns, verbs, adjectives and adverbs are the main lexical categories to classify all the lexicons. Such classification of lexicons is based on the principles in psycholinguistics. Besides, the semantic relations of each sense in WN are also expressed like a Word-network. In other words, WN resembles an ontology system and links all the semantic relations of words. Therefore, English WN is not just a lexical knowledgebase but also an ontological system that expresses the semantic relations and the concepts of words.\n\nThe current version of WN is Wordnet 2.0, but Wordnet 1.6 is more widely used by the most applications in NLP and linguistic research. Therefore, after considering the compatibility with other applications, we connected the ECTED with Wordnet 1.6. However, we are still working on keeping updating our systems by using the content in the new version of WN. We believe this will keep the information updated and shorten the gap caused by the different versions of WN.\n\nAs we mentioned above, WN does not only express the knowledge of lexicons but also cover the semantic relations of lexicons. Therefore, in order to present such semantic relations clearly and logically, Huang (2002) proposed to use cross-lingual Lexical Semantic Relations (LSRs) to predict the semantic relations in the target language. The proposed framework is shown in Diagram 1.\n\nIn Diagram1, EW1 and EW2 are head words for two different English synsets. CW1 and CW2 are translation equivalents in ECTED for these two head words. LSR i and ii are the T-LSRs stipulating the semantic relations between the head words and their Chinese TEs. In WN, each synset is linked to a network of their synsets through a number of LSR's. Hence, we use LSR x to represent the semantic relation\n\nCW1 EW1(Synset number) EW2(Synset number) CW2 y i x ii x = EW1-EW2 y = CW1-CW2 i = Translation LSR ii = Translation LSR The unknown LSR y = i+x+ii\n\nbetween EW1 and EW2. The four LSR's form a closed network that includes three know LSR's: two T-LSRs, i and ii, and one English LSR, x, from WN. The only unknown LSR is y, the semantic relation between CW1 and CW2. Huang et al (2002) claimed that LSR y can be inferred as a functional combination of the three LSRs -i, x and ii.\n\nLanguage translation does not only involve the semantic correspondences but also the human decision in choosing translation equivalents that are affected by the social and cultural factors. Our main priority in this paper is to infer the lexical semantic information across different language rather than the translational idiosyncrasies, so the elements regarding translational idiosyncrasies are excluded here. In order to simplify the complexity of LSR combination and get a better prediction of LSR, here, we only take account of the situations when LSR ii is exactly equivalent, EW2=CW2 or ii=0. Therefore, we have a reduced model of the translation-mediated LSR Prediction as shown in diagram 2.\n\nDiagram 2. Translation-mediated LSR (the reduced model) Synonym, hypernym, hyponym, holonym, meronym and near-synonym are the main semantic relations that we will discuss in the following sections. First of all, we would like to discuss the foundational situation of LSR prediction, synonym, as shown in diagram 3. When translation LSR i is exactly equivalent, i.e. CW1=EW1, and LSR ii is also exactly equivalent, i.e. EW2=CW2, the LSR combination, LSR y, is directly inherited the semantic relation of LSR x. As shown in diagram 4 above, according to the ECTED, the English head word 'thin' is exactly equivalent with 'shou4' in Chinese. The LSR x between EW1 and EW2 in WN is marked 'ANT' which means 'fat' is the antonym of 'thin.' Therefore, according to the prediction in diagram 3, we can infer that the CW2 (fei2pang4de5) is the antonym of CW1 (shou4). The above inference can also be applied to another example in diagram 4. The LSR prediction in WN plays a very crucial role in determining the unknown LSR y. Even an English head word may have more than one sense, it is still very clear to infer the LSR between the TEs. However, there is a potential problem within this inference. If a head word has more than one Chinese TEs which can all correspond to the head word, there might be a problem to consider whether those TEs are really synonyms.\n\nHowever, the situation is not always that ideal as above. When the Chinese translation equivalents and the corresponded English synset have a non-identical semantic relation, CW1≠EW1, the prediction of LSR y needs to be considered further and carefully. 4 Implementation and Evaluation WN 1.6 contains 99,642 English synsets and expands to 157,507 English lemma tokens. On the other hand, the total number of Chinese lemma types found in our ECTED is 108,533. Hence, each Chinese lemma type translates roughly 1.1 English synsets in average.\n\nIn comparing the two approaches to parallel wordnet building, we treat at baseline the cases where the translation LSR is synonymy. In others words, these are the cases where both approach I and approach II will make highly accurate predictions (e.g. Huang, et al. 2003). However, if the T-LSR is other than synonymy, we expect the prediction based on source language LSR will be much lower.\n\nIn our study, there are in total 372,927 lexical semantic relations that can potentially be bootstrapped when the T-LSR is one of the five semantic relations in study. These are expanded from the following types of translations equivalence relations: 11,396 translation near-synonyms, 2,782 translation hypernyms, 2,106 translation hyponyms, 252 translation meronyms and 145 translations holonyms. For evaluation, due to constraints on resources, we exhaustively check the types with less than 300 lemmas, while randomly checked close to 300 lemmas for the other types.\n\nWe first introduce the baseline model where synonym is assumed. This is where source language LSR's will be mapped directly to target languages. We have shown that if the T-LSR is really synonymy, the precision will be 62.7%. However, when the T-LSR's are different, the baseline precision is much lower. In Table 1, such naïve prediction is manually classes into three types: Correct, Incorrect, and Others. 'Correct' means that the prediction is verified. 'Incorrect' means the assigned LSR is wrong. Two scenarios are possible. One is that there is a possible prediction and another one is the correct LSR is different from the predicted one. 'Others' refers to exceptional cases where these is no lexical translation, or the source language LSR is wrongly assigned and so on. Table 1 shows that the baseline for non-synonymous T-LSR is only 47% in average, and range from 30% to 65% for each semantic relation.\n\nIt is interesting to note that the classes with least improvements are hypernymy and hyponymy. Since these are the classical IS-A relations, we hypothesize that their predictions are similar to the baseline relation of synonym. If we take these two relations out, the T-LSR model with inference rules has a precision difference of 17.3% (178/1030), as well as an improvement of 35.6% (178/500). These are substantial improvements over the baseline model. The result will be reinforced when the evaluation is completed. We will also analyze the prediction based on each T-LSR to give a more explanatory account as well a measure confidence or prediction. The result offers strong support for T-LSR as a model for bootstrapping parallel wordnets with a low-density target language.\n\nJane S. Tsay Institute of Linguistics, Chung Cheng University Min-Hsiung, Chia-Yi 621, Taiwan lngtsay@ccu.edu.tw\n\nTaiwan Child Language Corpus contains scripts transcribed from about 330 hours of recordings of fourteen young children from Southern Min Chinese speaking families in Taiwan. The format of the corpus adopts the Child Language Data Exchange System (CHILDES). The size of the corpus is about 1.6 million words.\n\nIn this paper, we describe data collection, transcription, word segmentation, and part-of-speech annotation of this corpus.\n\nApplications of the corpus are also discussed.\n\nTaiwan Child Language Corpus (TAICORP) is a corpus of text files transcribed from the child speech recorded between October 1997 through May 2000. The target language is Southern Min Chinese spoken in Taiwan.\n\nAll fourteen children participated were from Taiwanese-speaking families in Min-Hsiung Villlage, Chiayi County, Taiwan. There were nine boys and five girls, aged from one year two months to three years and eleven months at the beginning of the project. More than half of the children were recorded over more than two years.\n\nThe recordings were made through regular home visits. Spontaneous speech of these children at play was recorded using Mini Disc recorders. The interval of the sessions was about two weeks. There were totally 431 recording sessions, each 40 to 60 minutes long, totaling about 330 hours.\n\nEach recording session was transcribed into a separate text file, using Chinese orthography. For words that do not have a conventionalized written form, the Taiwan Southern Min romanization system, i.e., Taiwan Southern Min Pinyin was used.\n\nAbout half of the sessions (from children under two and a half years old) also have phonetic transcription in unicode IPA (International Phonetic Alphabet).\n\nThe three primary transcribers, who were also the investigators who did the recordings, were well-trained linguists. All recordings were first transcribed by the investigator of the specific session and then checked by the other two transcribers.\n\nTAICORP adopts the format of CHILDES (Child Language Data Exchange System), originally set up by Elizabeth Bates, Brian MacWhinney, and Catherine Snow, to transcribe and code the recordings of child speech into machine-readable text (MacWhinney & Snow 1985, MacWhinney 1995).\n\nThe main components of CHILDES format are headers and tiers.\n\nObligatory headers are necessary for every file. They mark the beginning, the end and the participants of the file. Constant headers mark the name of the file and the background information of the children.\n\nChangeable headers contain information that can change within the file, such as the recording date, duration, coders and so on.\n\nThese headers begin with @, for example:\n\nObligatory headers: @Begin @End @Participants Constant headers: @Age of XXX: @Birth of XXX: @Coder: @Educ of XXX: @Filename: @ID: @Language: @Language of XXX: @SES of XXX: social and economic status of a specific speaker @Sex of XXX: @Warning: the defects of the file Changeable headers: @Activities: @Comment: @Date: @Location: @New Episode: @Room Layout: @Situation: @Tape Location: @Time Duration: @Time Start:\n\nThe content of a file is presented in tiers, including main tiers and dependent tiers. A main tier, indicated by *, contains the utterance of the speaker.\n\nThe main tiers used in TAICORP include the following:\n\n＊ INV: the utterance of the investigator ＊ CHI: the utterance of the target child ＊ MOT: the utterance of mother ＊ FAT: the utterance of father ＊ SIS: the utterance of sister ＊ BRO: the utterance of brother ＊ GRM: the utterance of grandmother ＊ GRF: the utterance of grandfather ＊ OTH: the utterance of other people\n\nThe main tier is the most important tier because it is where the utterances are listed. The utterances in the main tier were transcribed in the romanization (pinyin) system of Taiwan Southern Min (to be explained and illustrated in Section 5).\n\nAdditional information is given in dependent tiers, indicated by %, following the main tier. Dependent tiers can be changed according to the design and goals of each corpus.\n\nThe dependent tiers used in TAICORP include the following: %ort: transcription in standard orthography %cod: part-of-speech coding %pho: phonetic transcription in IPA %ton: tone value in 5-point scale For adults' speech, only %ort and %cod tiers are used. For younger children's speech, %pho and %ton tiers are also used. The following text is an example from TAICORP. ([m…] = speech in Mandarin; SHI = 是 \"be\") @Begin @Participants: CHI Lin Target_Child, INV Rose Investigator, MOT Mother, OTH Great Grandmother @Age of CHI: 2;1.22 @Birth of CHI: 28-AUG-1995 @Sex of CHI: Male @Coder: Rose, Kay, Joyce @Language: Taiwanese @Date: 20-OCT-1997 @Tape Location:\n\nLin D1-1-56 @Comment: Time Duration 37 minutes @Location:\n\nChiayi, Taiwan @Transcriber: Rose @Comment: Track number is D1-1\n\n*INV: bo2lin2@s [:=m], li2 tha5tu2a2 khi3 to2? %ort: [m 柏林], 你頭拄仔 去 陀? %cod: Nb Nh Nd VCL Ncd *CHI: hia1/hin1. %ort: 遐 1. %cod: Ncd %pho: h i a %ton: 55 *INV: hia1 si7 to2ui7? %ort: 遐 是 陀位? %cod: Ncd SHI Ncd *CHI: hm0. %ort: hm0. %cod: I %pho: ?? %ton: ?? *MOT:li2 kin1a2 ciah8 bi2ko1 si7 bo0? %ort: 你 今仔 1 食 米糕 是 無 3? %cod: Nh Nd VC Na SHI T @End 3 Statistics of the corpus The corpus size is about 1.6 million words (more than 2 million morphemes/Chinese characters). The number of utterances/lines, words, mean length of utterances (MLU) are listed in Table 1. Lines Words MLU Children 161,253 434,557 2.695 Adults 336,173 1,211,946 3.605 Total 497,426 1,646,503 3.150 Table 1 Statistics of the corpus It might be worth mentioning that the MLU of adults in this corpus is relatively short. This could be attributed to the nature of this corpus as being child-directed speech.\n\nSouthern Min and Mandarin are both Sinitic languages. They are very similar in their morphology and syntactic structures. Therefore, we adopted the part-of-speech coding system of the Sinica Corpus, Academia Sinica, Taiwan (see various CKIP technical reports). However, among the 115 categories used in the Sinica Corpus (CKIP 1993), only 46 codes were used in TAICORP. In other words, categorization in TAICORP is broader. These codes are listed in Table 2.\n\nTable 2 Part-of-Speech Tagset in TAICORP Coding Part-of-speech A non-predicative adjective Caa coordinate conjunction Cab listing conjunction Cba conjunction occurring at the end of a sentence Cbb following a subject Da possibly preceding a noun Dfa preceding VH through VL Dfb following adverb Di post-verbal Dk sentence initial D adverbial Na common noun Nb proper noun Nc location noun Ncd localizer Nd time noun Neu numeral determiner Nes specific determiner Nep anaphoric determiner Neqa classifier determiner Neqb postposed classifier determiner Nf classifier Ng postposition Nh pronoun I interjection P preposition T particle VA active intransitive verb VAC VB active pseudo-transitive verb VC active transitive verb VCL transitive verb taking a locative argument VD ditransitive verb VE active transitive verb with sentential object VF active transitive verb with VP object VG classifactory verb VH stative intransitive verb VHC stative causitive verb VI stative pseudo-transitive verb VJ stative transitive verb VK stative transitive verb with sentential object VL stative transitive verb with VP object V_2 DE *special tag for the word \"的\" SHI special tag for the word \"是\" FW foreign words *Di/T *marker following pseudotransitive active verb *CIT *special tag for the word \"得 2\"\n\nOrthography-related issues for a speech-based corpus of Southern Min\n\nAs mentioned in Section 2, utterances in the main tier are transcribed in romanization (Southern Min pinyin). The romanization system used in TAICORP is the Taiwan Southern Min Phonetic Alphabetic (also known as Taiwan Language Phonetic Alphabet, TLPA, originally proposed by the Taiwan Language Society in 1991) announced officially by the Ministry of Education of Taiwan in 1998.\n\nChinese characters are used in the dependent tier %ort as the standard orthography. This is a reasonable way because most of the Southern Min words are cognates of Mandarin words. However, because Southern Min does not have as conventionalized orthography as Mandarin, quite a few words in Southern Min do not have a consistent way of writing them. Some of them don't even have very obvious corresponding Characters.\n\nIn order to ensure consistency in the corpus, Southern Min dictionaries were used. These dictionaries are listed after the References.\n\nThis issue is particularly important for a corpus based on spontaneous speech, rather than written text. For example, the following common words in Southern Min have to be checked in the dictionary about their written forms because they do not occur in Mandarin: 蠓罩 /bang2tah4/ \"mosquito net\" 挽 /ban2/ \"to pick\" 奇巧 /ki5kha2/ \"unusual\" If a written form cannot be found in one of the major Southern Min dictionaries, romanization is used.\n\nRomanization is also used if the written form of a word is found in the dictionary but has so low frequency that it can't be found in the computer coding system.\n\nFor homonyms, a number is added after the character to indicate different lemmas. For example:\n\n蓋 1 /kah4/ \"to cover with a blanket\" 蓋 2 /kham3/ \"to cover\" 蓋 3 /kua3/ \"a cover\"\n\nIn order to speed up the building of the corpus, a word auto-segmentation program is necessary. Yet, when the program is segmenting words from the text, it can also deal with some related problems at the same time, such as the consistency of the transcription, adding romanization, and expanding the lexicon.\n\nAs the basis of the auto-segmentation program and the spell-cheker, a corpus-based lexicon has been constructed which includes the lemma (both in romanization and in Chinese characters), alternative forms, synonyms, and part-of-speech. (See the Appendix for a sample of the lexicon.)\n\nTaiwanese speech recognition is still developing, so there is no way to transcribe the data with machine. Hence, transcription can only be done manually. The transcribers might be inconsistent in choosing the written form. For example, 按 怎 (an3cuann2) \"how\" can be transcribed as 怎樣, 怎麼樣, 按怎, 怎麼, 什 麼 and so on. Therefore, it is very important to design a program can identify the inconsistency. When the program is segmenting the text, it tries to match a string which matches the word in the column of \"Chinese character\" in the lexicon bank. It then segments the word and codes its pinyin. Figure 1 shows the input text in the frame, and Figure 2 shows the output of after segmentation. Word segmentation standard follows mostly that of the Sinica Corpus (Chen et al. 1996).\n\nIf the transcription happens to be one of the \"other forms,\" it will be replaced with the standard form listed under the \"Chinese character.\"\n\nIf a word does not exist in the lexicon, it will be added to the lexicon after the file manager confirms its status.\n\nIn short, the word auto-segmentation program is able to do four things at the same time:\n\n1 segment words in the text 2 code the pinyin for the characters 3 correct the inconsistent written forms 4 expand the lexicon bank\n\nThis corpus has been used for studies on various aspects of child language acquisition, including tone acquisition (Tsay and Huang, 1998;Tsay, Myers, and Chen, 2000;Tsay, 2001), consonant acquisition (Liu and Tsay, 2000), classifier acquisition (Myers and Tsay, 2000), final particle acquisition (Hung, Li, and Tsay, 2004), verb acquisition (Lee and Tsay, 2001;Lin and Tsay, 2005), vocabulary acquisition (Tsay and Cheng, in progress). More studies are on the way.\n\nBecause this corpus is based on spontaneous speech, it also has its applications in addition to linguistic research. For example, this corpus can be used in extracting important speech features. This corpus will be released by the Association for Computational Linguistics and Chinese Language Processing, Taiwan, in fall of 2005. Figure 2 Output text\n\nAppendix Sample of the Lexicon Chinese character Southern Min Pinyin Part-ofspeech Meaning (or Mandarin synonyms) Example 未記e0 be7ki3e0 VK 未見笑 be7kian3siau3/ bue7kian3siau3 VH 不要臉 賣了 be7liau2/ bue7liau2 VB 賣完 賣了了 be7liau2liau2/ bue7liau2liau2 VB 賣光光 賣了了去 be7liau2liau2khi3/ bue7liau2liau2khi3 VB 賣光光去 未使 be7sai2/ bue7sai2 D 不行、不能、不可 以、未saih6 你未使去(修飾動 詞) 未使 be7sai2/ bue7sai2 VH 不行、不能、不可 以、未saih6 伊知道這樣未使 未使得 be7sai2cit4/ bue7sai2cit4 D 不能 未輸 be7su1/bue7su1 D 未su1、好像 好像 未當 be7tang3/ bue7tang3 D 不能、不可以、不 行、未能、未tang3 未當得 be7tang3cit4/ bue7tang3cit4 D 不能、不可以 賣掉 be7tiau7/bue7tiau7 VC 賣掉去 be7tiau7khi3/ bue7tiau7khi3 VB 未振未動 be7tin2be7tang7 VA 一動也不動 賣著 be7tioh8/ bue7tioh8 VC 賣場 be7tiunn5/ bue7tiunn5 Nc 未拄好 be7tu2ho2/ bue7tu2ho2 VH 配合得不好 賣完 be7uan5/bue7uan5 VC 欲 beh4/bueh4 D 會、愛、要、要1 (+動詞) 我要去市 仔買菜 欲 beh4/bueh4 D 快要 快來不及了 欲 beh4/bueh4 VC 會、愛、要、要1 (+名詞組)我要這 領衫 欲愛 beh4ai3/ bueh4ai3 D 欲愛、想要、欲要、 要愛 欲愛 耍 [m 玩具] 欲愛 beh4ai3/ bueh4ai3 VC 欲愛、想要、欲要、 要愛 欲無 beh4bo5 Cbb bue4無、bue2bo5 (連接詞)本來… 但 1 Introduction With the rapid development of the Internet, the capacity of textual information has been greatly improved. How to acquire accurate and effective information has become one of the great concerns among Internet users. Open-Domain Question Answering System (QA) has gain great popularities among scholars who care the above problem (Li, et al. 2002;Moldovan, et al. 2003;Zhang, et al. 2003), for QA can meet users' demand by offering compact and accurate answers, rather than text with corresponding answers, to the questions presented in natural language. Therefore, it saves users' great trouble to find out specific facts or figures from large quantity of texts.\n\nThe study of Question Classification (QC), as a new field, corresponds with the research of QA. QC is an essential part of QA, for to correctly answer users' questions, the system has to know what the users are looking for, and it is QC that presents important searching clues for the system. QC can be defined to match a question to one or several classes in K category so as to determine the answer type. Every class presents some semantic restrictions on the answer searching, which serves QA with various strategies in locating the correct answer.\n\nThe result of QC can also serve QA in the answer selecting and extract, which influence the performance of QA directly. The first reason is that QC minish searching space. For example, if the system knows that the answer type to the question \"Who was the first astronaut to walk in space?\" is a person's name, it can confine the answer in the names, rather than every word in the texts. The second reason is that QC can determine the searching strategies and knowledge base QA may need. For instance, the question \"What county is California in?\" needs the name of a country as its answer, so system needs the knowledge of countries' name and name entities tagging to identify and testify the place name, while the question \"What is Teflon?\" expects an answer in a sentence or a fragment, in the form of Teflon is <…. >. In fact, almost all the QA have the QC module and QC is the one of the most important factors what determines the QA system performance (Moldovan, et al. 2003).\n\nAt present the studies on QC are mainly based on the text classification. Though QC is similar to TC in some aspects, they are clearly distinct in that ： Question is usually shorter, and contains less lexicon-based information than text, which brings great trouble to QC. Therefore to obtain higher classifying accuracy, QC has to make further analysis of sentences, namely QC has to extend interrogative sentence with syntactic and semantic knowledge, replacing or extending the vocabulary of the question with the semantic meaning of every words. In QC, many systems apply machine-learning approaches (Hovy, et al. 2002;Ittycheriah, et al. 2000;Zhang, et al. 2003). The classification is made according to the lexical, syntactic and parts of speech. Machine learning approach is of great adaptability, and 90.0% of classifying accuracy is obtained with SVM method and tree Kernel as features. However, there is still the problem that the classifying result is affected by the accuracy of syntactic analyzer, which need manually to determine the weights of different classifying features. Some other systems adopting manual-rule method make QC, though may have high classifying accuracy, lack of adaptability, because regulation determination involves manual interference to solve the conflicts between regulations and to form orderly arranged rule base.\n\nThe paper combines statistic and rule classifiers, specifically statistics preceding regulation, to classify questions. With rule classifier as supplementary to statistic, the advantages of respective classifier can be given full play to, and therefore the overall performance of the classifier combination will be better than the single one. Moreover, as far as the QC task is concerned, the paper compares various classifier combinations, statistic-rule classifier, voting 、 Adaboost and ANN. To represent questions, the paper uses dependency structure from Minipar (Lin 1998) and linguistic knowledge from Wordnet (Miller 1995;Miller, et al. 2003). In the following parts of the paper, classifying method and features is first introduced, and then comparisons are made between different type features and between feature combination methods. The comparisons are testified in experiments. The last part of the paper is about the conclusion of the present research and about the introduction of the further work to be done on this issue.\n\nIn machine learning method, every question should at first be transformed into a feature vector. Bag-of-word is one typical way of transforming questions, where every feature is one word in a corpus, whose value can be Boolean, showing whether the word is present in questions, and which can also be an integer or a real number, showing the presence frequency of the word. In this paper, every question is represented as a Boolean vector. 1. Bag-of-word: all lexical items in questions are taken as classifying features, because stop-word such as \"what\" and \"is\" playing a critical role in QC. 2. Wordnet Synsets: Wordnet was conceived as a machine-readable dictionary. In Wordnet, word form is represented by word spellings, and the sense is expressed by Synsets, and every synset stands for a concept. Wordnet shows both lexical and semantic relationships. The former exists between word forms, while the latter exists between concepts. Among various semantic relations in Wordnet, we choose hypernyms between nouns as our only concern. The classifying features are the senses of the nouns in the sentences and synsets of their hypernyms. 3. N-gram: the model is founded on a hypothesis that the presence of a word is only relevant to the n words before it. The frequently used are Bi-gram and Tri-gram, and Bi-gram is chosen as the classifying features in the present research. Compared with word, Bi-gram model investigates two historical records, and reflects the partial law of language. It embodies the features of word order, and therefore it can reflect the theme of the sentence more strongly. 4. Dependency Structure: Minipar is a syntactic analyzer, which can analyze the dependency relation of words in sentences. It describes the syntactic relationships between words in sentences. Such relation is direction-oriented, semantically rather than spatially, namely one word governs, or is governed by, another concerning their syntactic relation. In one sentence (W1W2…Wn), compared with Bi-gram, Dependency structure concerns WiWj ， but not need limitation j= i+1. Obviously, Dependency Relation goes further than Bi-gram in language understanding. Dependency structure is specified by a list of labeled tuples. The format of a labeled tuple is as follows:\n\nlabel (word pos root governor rel exinfo …) \"Label\" is a label assigned to the tuple. If the tuple represents a word in the sentence, label should be the index of the word in the sentence. \"Word\" is a word in the input sentence. \"Pos\" is the part of speech. \"Root\" is the root form. \"Governor\" if the label of the governor of word (if it has one), \"rel\" is type of dependency relationship, and \"exinfo\" for extra information. Minipar output is represented by the word dependency relationship via \"governor\". Though only 79% of recall and some word relations fail to be analyzed, the accuracy reaches 89%, which guarantees that a large proportion of dependency relations from the output are correct. And the experiment proves that Dependency structure has more classify precision than Bi-gram as classifying feature.\n\nFor example, as to the question \"Which company created the Internet browser Mosaic?\" Minipar may produce the following results:\n\nE0 (() fin C * ) 1 (Which ~ Det 2 det (gov company)) 2 (company ~ N E0 whn (gov fin)) 3 (created create V E0 i (gov fin)) E2 (() company N 3 subj (gov create) (antecedent 2))\n\nAccording to the tuple, we can get dependency relationships between words in sentences. tuple 1 (Which ~ Det 2 det gov company) shows us the det relationship between \"which\" and \"company\" in the sentence. Therefore, we can get a words-pair ( which company), and likewise other five pairs of words can be obtained -(company create)、 ( the Mosaic ) 、 (Internet Mosaic) 、 (browser Mosaic) 、 (create Mosaic), which will be the item of vector represented the question.\n\nSVM is a kind of machine learning approach based on statistic learning theory. SVM are linear functions of the form f (x) = <w•x> +b, where <w•x> is the inner product between the weight vector w and the input vector x. The SVM can be used as a classifier by setting the class to 1 if f(x) > 0 and to -1 otherwise. The main idea of SVM is to select a hyperplane that separates the positive and negative examples while maximizing the minimum margin, where the margin for example x i is y i f(x) and y i ∈ [-1,1] is the target output. This corresponds to minimizing <w•w> subject to y i (<w•x> +b) ≥ for all i. Large margin classifiers are known to have good generalization properties. An adaptation of the LIBSVM implementation (Chang, et al. 2001) is used in the following. Four type of kernel function linear, polynomial, radial basis function, and sigmoid are provided by LIBSVM .\n\nTBL has been a part of NLP since Eric Brill's breakthrough paper in 1995(Brill 1995), which has been as effective as any other approach on the Part-of-Speech Tagging problem. TBL is a true machine learning technique. Given a tagged training corpus, it produces a sequence of rules that serves as a model of the training data. Then, to derive the appropriate tags, each rule may be applied, in order, to each instance in an untagged corpus.\n\nTBL generates all of the potential rules that would make at least one tag in the training corpus correct. For each potential rule, its improvement score is defined to be the number of correct tags in the training corpus after applying the rule minus the number of correct tags in the training corpus before applying the rule. The potential rule with the highest improvement score is output as the next rule in the final model and applied to the entire training corpus. This process repeats (using the updated tags on the training corpus), producing one rule for each pass through the training corpus until no rule can be found with an improvement score that surpasses some predefined threshold. In practice, threshold values of 1 or 2 appear to be effective.\n\nTherefore, we present compositive QC approach with rule and statistic learning. At first, questions are represented by Bag-of-word, Wordnet Synsets, Bi-gram, and Dependency structure, and are classified by the same samples and same SVM. Then output of SVM is transformed to the input of TBL, and thus every sample in TBL training data is featured by four-dimensioned vectors, from which a new is obtained as training data of TBL. When the errors produced in initial marking process are corrected in TBL to the greatest extent, a final-classifier is produced as follows (Figure1).\n\nFigure1 SVM-TBL QC Algorithm TBL is composed of three parts: unannotated text, transformation templates, and objective function. In the experiment, unannotated text is obtained from SVM. The transformation templates define the space of transformations; here is combination of SVM output. Suppose we have k basic classifiers, and each classifier may put questions into N types, then we have rule templates. Objective function is the precision of classifier.\n\nThe research adopts the same UIUC data and classifying system as (Zhang, et al. 2003) shows. There are about 5,500 labeled questions randomly divided into 5 training sets of sizes 1,000, 2,000, 3,000, 4,000 and 5,500 respectively. The testing set contains 500 questions from the TREC10 QA track. Only coarse category is test.\n\nA question can be represented directly as a vector with multi-kind-features: Bag of Word, Dependency Structure, Synonym and Bi-gram. Figure2 provides an accuracy comparison of the results derived from classification with four features and classification with only one kind feature. Experimental result indicates that, results from classification with four type features do not excel the best classification precision with only one feature.\n\nMulti-classifier combination is often used to obtain better classification results. Adaboost (Schapire 1997; Schapire 1999) is an effective classifier combination method. Yet in question classification training, chances of samples to be faultily classified are slim. Therefore, greater accuracy on classification can hardly be realized with Boost.\n\nWe have also tried to use nerve network to combine the output results of 4 classifiers. We build a BP network with 4 input nodes and 1 output node. The number of hidden nodes chosen comes from the empirical formula: m=sqrt(nl), whose \"m\" indicates hidden nodes, \"n\" input nodes, and \"l\" output nodes. Thus, the number of hidden layer nodes is \"2\".Figure3 shows, when training samples are relatively less, classification accuracy of BP is greater compared to that of single-feature classifier, but not in cases where the number of samples increases.\n\n70% 75% 80% 85% 90% 95% 1000 2000 3000 4000 5000 Number of Training Examples Precision Bag-of-word Wordnet Bigram Dependency ANN Figure 3. ANN combine several classifiers 4.5 Using the method of voting to combine several classifiers 70% 75% 80% 85% 90% 95% 1000 2000 3000 4000 5000 Number of Training Examples Precision Bag-of-word Wordnet Bigram Dependency VOTE Through the method of voting, we can also get the combination results, according to the class label outputted by SVM with different type features. Experimental results are given in Figure 4. We may see that, due to the rule of \"more votes winning\" in voting, when there are a number of not-so-accurate classifiers, the accuracy of voting can not compete with the greatest accuracy of a single classifier. initial tagger. Therefore, TBL classification will not produce results inferior to the best results of ra y. BagOfWord_2 $$ $$ _3=_1 _0 $$ _#=_0 …… the first class. ready been tagged as 3, it ill be put in class 2. initial tagging.\n\nWe obtain from the experiment all together 251 conversion rules, the foremost ones of which are listed as follows. From these rules which come from TBL training, we may also deduce that, TBL makes use of, firstly, the results of the most accurate classifier (parser), and secondly, the results of other classifiers, especially those of dependency structure rectified by Bi-gram results. It puts the accuracy of SVM single-feature classification into full use to secure greater accu c\n\nRule 1 shows that: in cases where Dependency Structure is adopted as the feature, when the classification result is 1 and the question is not classified, the question belongs to Rule 2, 3, 4, and 5 is similar to 1. Rules 6, 7 involve classification results from multiple classifiers. Rule 6 indicates that, if sentence is placed in 3 when Dependency Structure is adopted as feature, in class 2, when Bi-gram or Synset or Bag-of-Word is adopted, and questions have al w multi-type-features to represent questions directly. igure 7. Using dependency structure or not lso promote precision, with a percentage of 1.8. weig Figure 6 gives us the classification results of 500 questions of Trec10 in different method of combination. It can be seen that, TBL combination of classifiers is better than voting and ANN; TBL and SVM working together is better than SVM classification using 80% 82% 84% 86% 88% 90% 92% 94% 1000 2000 3000 4000 5000 Number of Training Examples Precison TBL SVM SVM-TBL-\n\nFigure7 provides a comparison of classification accuracy between TBL combining multi-classifier and SVM directly using several type features, in conditions of adopting or not adopting Dependency Structure as feature. TBLand SVM-both mean classifier not adopting. The results show: Using such method of QC as blending \"statistics\" and \"rules\", that is, the accuracy of classification is 1.6% greater than that of not using TBL; adopting Dependency Structure as feature can a\n\nCompared to (Zhang, et al. 2003) using \"tree kernel\" as the classification feature, this thesis adopts the \"statistics and rules blended\" method in QC (\"statistics first and rules next\"), lifting the precision of classification to 1.4% higher than it used to be. Moreover, it also avoids the problem of artificial selection in different feature hting that appearing in Zhang's paper. Tests using the \"statistics and rules blended\" pattern of question classification unfold that, 34.1% of faulty classification of sentences arouses from the using of improper statistical methods. The manifest of this is that all the SVM classifiers with 4 features place questions into class \"i\", while they actually belong to class \"j\". Classification features that have relatively big differences are needed to work as basic classifier to improve the final result. And also, 31.8% of the faulty classification stems from the fact that, there are no corresponding rules in the rule sets derived from TBL training, so that the rule sets cannot correct the errors caused by wrong statistical methods. This may because our question corpus is Limited, and therefore, some of the classification combinations never even appear.\n\nto further the research on QC using Wordnet. QC, an important module in the QA system, can conduct answer choosing and selection. This thesis experiment several different methods in QC, and studies features like the Dependency Structure, Wordnet Synsets, Bag-of-Word, and Bi-gram. It also analyzes a number of kernel functions and the influence of different ways of classifier combination, such as Voting, Adaboost、ANN and TBL, on the precision of QC. Adopting the \"statistics and rules blended\" method of question classification (\"statistics first and rules next\") and using language information such as the Synset from Wordnet and the dependency structure of Minipar as classification features promote the accuracy of question classification. TBL combination multi-classifier method can be extended, easily. As long as new classifying algorithm or new feature set is found, the classifying result from them can be transformed to rule set, which can lead to further classifying function. Wordnet has provided us with semantic relation, examples, explanation, etc. The present study only investigates the semantic relation of hyponymy. There are still much to be done in the future\n\nBitexts, also referred to as parallel texts or bilingual corpora, collections of bilingual text pairs aligned at various levels of granularity, have been playing a critical role in the current development of machine translation technology. It is such large data sets that give rise to the plausibility of empirical approaches to machine translation, most of which involve the application of a variety of machine learning techniques to infer various types of translation knowledge from bitext data to facilitate automatic translation and enhance translation quality. Large volumes of training data of this kind are indispensable for constructing statistical translation models (Brown et al., 1993;Melamed, 2000), acquiring bilingual lexicon (Gale and Church, 1991;Melamed, 1997), and building example-based machine translation (EBMT) systems (Nagao, 1984;Carl and Way, 2003;Way and Gough, 2003). They also provide a basis for inferring lexical connection between vocabularies in cross-languages information retrieval (Davis and Dunning, 1995).\n\nExisting parallel corpora have illustrated their particular value in empirical NLP research, e.g., Canadian Hansard Corpus (Gale and Church, 1991b), HK Hansard (Wu, 1994), INTERSECT (Salkie, 1995), ENPC (Ebeling, 1998), the Bible parallel corpus (Resnik et al., 1999) and many others. The Web is being explored not only as a super corpus for NLP and linguistic research (Kilgarriff and Grefenstette, 2003) but also, more importantly to MT research, as a treasure for mining bitexts of various language pairs (Resnik, 1999;Chen and Nie, 2000;Nie and Cai, 2001;Nie and Chen, 2002;Resnik and Smith, 2003;Way and Gough, 2003). The Web has been the playground for many NLPers. More and more Web sites are found to have cloned their Web pages in several languages, aiming at conveying information to audience in different languages. This gives rise to a huge volume of wonderful bilingual or multi-lingual resources freely available from the Web for research. What we need to do is to harvest the right resources for the right applications.\n\nIn this paper we present our recent work on harvesting English-Chinese parallel texts of the laws of Hong Kong from the Web and construct-ing a subparagraph-aligned bilingual corpus of about 20 million words. The bilingual texts of the laws is introduced in Section 2, with an emphasis on HK's legislation text hierarchy and its numbering system that can be utilized for text alignment to subparagraph level. Section 3 presents basic methodology and technical details for harvesting and aligning bilingual Web page pairs, extracting content texts from the pages, and aligning text structures in terms of the text hierarchy via utilizing consistent intrinsic features in the Web pages and content texts. Section 4 presents XML schema for encoding the alignment results and illustrates the display mode for browsing the aligned bilingual corpus. Section 5 concludes the paper, highlighting the value of the corpus in term of its volume, translation quality, specificity and comprehensiveness, and alignment granularity. Our future work to explore the Web for harvesting more quantities of parallel bitexts is also briefly outlined.\n\nThe laws of Hong Kong (HK) before 1987 were exclusively enacted in English. They were translated into Chinese in the run-up to the handover in 1997. Since then all HK laws have been enacted in both English and Chinese, both versions being equally authentic. This gives rise to a valuable set of bitexts in large quantity and high quality that can be utilized to facilitate empirical MT research.\n\nThe bilingual texts of the laws of Hong Kong have been made available to the public in recent years by the Justice Department of the HK-SAR through the bilingual laws information system (BLIS). All these texts are freely accessible from http://www.justice.gov.hk/.\n\nBLIS provides the most comprehensive documentation of HK legislation. It contains all statute laws of Hong Kong currently in operation, including all ordinances and subsidiary legislation of HK (and some of their past versions dating back to 60 June 1997), the Basic Law and the Sino-British Joint Declaration, the constitution of PRC and national laws that apply in HK, and other relevant instruments. The entire bilingual corpus of BLIS legal texts contains approximately 10 million English words and 18 million Chinese characters. Lexical resources of this kind are particularly useful in bilingual legal terminology studies and text alignment work.\n\nBLIS organizes the legal texts in terms of the hierarchy of the Loose-Leaf Edition of the Laws of Hong Kong. At the top level, the ordinances are arranged by chapters, each of which is identified by an assigned number and a short title, e.g., The content of an ordinance, exclusive of its long title, is divided and identified according to a very rigid numbering system which encodes the hierarchy of the texts of the laws. Both the Chinese and English versions of an ordinance follow exactly the same hierarchical structures such as chapters (¡), parts (), sections (¦), subsections ( ), paragraphs (!) and subparagraphs (\"). This allows us to align the bitexts along this hierarchical structure, once they are downloaded from the BLIS official site. To our knowledge, a well-aligned bilingual corpus of this size covering a special domain so comprehensively is seldom readily available for the Chinese-English language pair.\n\nExcerpts from the BLIS corpus are illustrated in Figure 1 and 2, one illustrating its hierarchy and the other a pair of BLIS bitexts. From the excerpts we can see that not everything has an exact match between a pair of BLIS Web pages. For example, the Chinese side has a gazette number \"25 of 1998 s. 2\" and a piece of \"remarks\" at the beginning of content text, whereas its English counterpart has none of them.\n\nBasically two phases are involved in constructing the bilingual corpus of the laws of HK. The first phase is to harvest the monolingual texts of HK laws from the BLIS site and align them into pairs. It involves the following steps: (1) downloading Web pages one by one with the aid of a Web crawler, (2) extracting the texts from them by filtering out the HTML markup, and (3) aligning the extracted monolingual texts into bilingual pairs. The second phase is to align finer-grained text structures within each text pair.\n\nA BLIS Web page does not necessarily correspond to any particular text structure such as a chapter, a part, a section, a subsection, or a paragraph in the BLIS hierarchy. A chapter, especially a short one, may be organized into a few sections in a Web page or in several contiguous pages. Some sections, e.g., the long ones, are divided into several pages. In general, BLIS does not maintain any reliable match between its Web pages and any particular text hierarchical structures.\n\nFortunately, in most cases a BLIS page always has a counterpart in the other language. There is a \"switch language\" button on each page to link to the counterpart page. Such linkage allows us to download the Web pages in pairs and, consequently, harvest a list of page-to-page aligned bitexts.\n\nIn addition to the pair link, each BLIS page also carries links for the \"next\" and the \"previous section of enactment\". These two kinds of linkage turn the pages into two double linked lists, each in a language, as illustrated in Figure 3, with each page as a node. Nodes in pairs are also double linked between the two lists.\n\nHowever, the pairwise linkage is not reliable in the BLIS site, because there are missing Web pages in one of the two languages in question (see Table 3 below for more details). In order to download all bitexts of legislation from the site, we need to go through one linked list and download each page and its counterpart, if there is one, in the other language. Such scanning gives a list of text pairs, where some pages may have a null Table 2: Naming downloaded files in terms of BLIS numbering\n\ncounterpart. An alternative strategy is to download each list separately, and then match the pages into pairs sequentially with the aid of numbering information in the header of each page -see 3.2 below. These two strategies verify one another, making sure that all pages are downloaded and put in the right pairs. The downloading is carried out by a Web crawler implemented in Java. In order to accomplish the above strategies, it also has to handle a number of technical issues.\n\n• It sleeps for a while (e.g., 10 seconds) when it finishes downloading a certain number of pages (e.g., 50 pages), because the BLIS site refuses continuous access from one site for a too long time.\n\n• When an error occurs, it remembers the current URL. Then it re-starts from where it stops.\n\nThe data about the file downloading from BLIS site is given in Table 1. One can conceive that if the time intervals for sleep and downloading could be automatically tuned by the crawler to maximize the downloading efficiency, it would get the job done significantly more quickly. Our option for 10 seconds sleep between every 50 files is based on error records of a number of test runs.\n\nEvery BLIS Web page is identified by a subtitle that carries numbering information about the page, as illustrated in Figure 1. Such a subtitle is exactly retained in the page as its HTML title.\n\nFiles English Chinese Aligned 50,506 (62.3MB) a 50,506 (38.5MB) Missing 132 4 Total 50,638 50,510 Size b 10.4M words 18.3M char.s a The size of extracted texts. b Exclusive of punctuation marks.\n\nTable 3: The number of aligned and missing files\n\nThis feature is utilized to align BLIS pages: all downloaded files are named in terms of the numbering information extracted from their HTML titles, as illustrated in Table 2. Consequently, all files are naturally aligned in pairs by their names. Any file names not in a pair indicate the missing counterparts in the other language. The statistics of file alignment are given in Table 3.\n\nBasically, this task involves two aspects, namely, filtering HTML markup and extracting content text. A straightforward strategy is that we first clean up HTML tags in each page and then the non-legal content. The tags are in brackets, and non-legal content in a consistent pattern throughout all BLIS pages. However, a more convenient way to do it is to make use of a reliable feature in the BLIS pages: legal content is placed in between two -the only two -horizontal bars in each page. Accordingly, we implement a strategy to first extract every thing in between the two bars and then clean up remaining HTML tags. The output from this procedure includes • a header as a fixed set of items, including chapter number, title, heading, etc., and\n\n• a piece of content text as a list of numbered items each in a line. (See the header and content text in Figure 2.)\n\nThe text in a BLIS page is displayed as a sequence of hierarchically numbered items, such as subsections, paragraphs and subparagraphs.\n\nAfter page (or file) alignment, each page finds its counterpart in the other language. After text extraction, a page gives a content text consisting of a list of numbered items, each in a line. A such\n\nRemarks: Adaptation amendments retroactively made -see 26 of 1999 s.3// a (1) All Ordinances shall be enacted and published in both official languages.// (2) Nothing in subsection (1) shall require an Ordinance to be enacted and published in both official languages where that Ordinance amends another Ordinance and-// (a) that other Ordinance was enacted in the English language only; and// (b) no authentic text of that Ordinance has been published in the Chinese language under section 4B (1).// (3) Nothing in subsection (1) shall require an Ordinance to be enacted and published in both official languages where the Chief Executive in Council-(Amended 26 of 1999 s.3)// a Indicating a text line break.\n\nTable 4: Anchors in a sample text item can be divided into a numbering item and the remaining content text in the line, as illustrated in Table 4. The Chinese counterpart of this text carries similar lines, if no missing line in any page of the pair.\n\nUnfortunately, missing lines are found in some BLIS pages, as exemplified in Figure 2. There is no guarantee that matching text lines one by one in sequence would carry out the expected alignment within a page pair. However, the numbering items at the beginning of each line can be utilized as anchors to facilitate the alignment. The strategy along this line is given as follows.\n\n1. Anchor identification: numbering items at the beginning of each line are recognized as anchors, with the beginning and the end of the whole content text as two special anchors, resulting in a list of anchors for each page;\n\n2. Anchor alignment: match the two lists of anchors sequentially. If a pair of anchors does not match, give up the smaller one (in terms of the BLIS numbering hierarchy) and move on to the next possible pair, working in exactly the same procedure as matching identical anchor pairs between two sorted lists of anchors.\n\n3. Text line alignment: a pair of matched anchors give a pair of matched lines; an unmatched anchor indicates a missing line in the other language.\n\nXML is applied to encode the text alignment outcomes output from the above alignment procedure. It has been a standard for data representation and exchange on the Web, and also accepted by the NLP community as a standard for linguistic data annotation and representation (Ide et al., 2000;Mengel and Lezius, 2000;Kim et al., 2001). There are a series of yearly NLPXML workshops for it since 2001. It provides a platform-independent flexible and sophisticated plain text format for data encoding and manipulation. It is particularly suitable for hierarchical linguistic data such as the hierarchicallyaligned bilingual corpus that we have produced.\n\nWhat's more, converting data to XML format not only significantly reduces the complexity of data exchange among different computer systems but also enhances data transmission reliability and eases Web browsing.\n\nThere have been many corpora that are annotated with XML, e.g., HCRC Map Task Corpus (Anderson et al., 1991), American National Corpus (Ide and Macleod, 2001), the La Republica corpus (Baroni et al., 2004). Below we present the XML schema for our subparagraph-aligned BLIS bitexts, with sample annotation, and necessary Web browsing.\n\nThe current version of the XML schema for the bilingual BLIS corpus, as given in Figure 4, focuses on encoding all text structures in the BLIS hierarchy, including all elements in each BLIS Web page. It is to be extended to cover finergrained structures such as clauses, phrases and words, as we proceed to align the BLIS bitexts at these linguistic levels. For simplicity, we allow para to subsume all types of text line, be they a section, subsection, paragraph or subparagraph. The annotation of a sample bitext with this schema is illustrated in Figure 5. Annotation of this kind is carried out by a Java program automatically for the entire bitext corpus.\n\nA number of display modes are designed for browsing the subparagraph-aligned bitexts, including bilingual modes and monolingual modes. In a bilingual mode, text line pairs are displayed in sequence. Switch of language order or from one mode to another is allowed any time during browsing. The bilingual display mode is illustrated in Figure 6.\n\nWe have presented in the above sections our recent work on harvesting and aligning the bitexts of the laws of Hong Kong, including basic techniques for downloading English-Chinese bilingual legal texts from BLIS official site, sound strategies for aligning the bitexts by utilizing the numbering system in the legal texts, and necessary XML annotation for the alignment results. The value of the outcomes, i.e., the subparagraphaligned bilingual corpus, can be evaluated in terms of the following aspects.\n\nThe entire corpus is of 10.4M English words and 18.3M Chinese characters, several times larger than the well-known Penn Treebank Corpus in size. Translation quality All texts of the corpus are prepared by the Law Drafting Division of the Department of Justice, Hong Kong Government. Legal texts are known to be more precise and less ambiguous than most other types of text. Specificity and comprehensiveness The corpus covers specifically the domain of Hong Kong legislation. It is the most authoritative and complete text collection of the laws of Hong Kong.\n\nThe entire corpus is aligned precisely to the subparagraph level. Most subparagraphs in the legal texts are phrases, fragments of a clause, or clauses; as shown in Table 4. A bilingual corpus of this size and quality covering a specific domain so comprehensively is particularly useful not only in empirical MT research but also in computational studies of bilingual terminology and legislation. Our future work will focus on word alignment for inferring bilingual lexical resources and on automatic recognition of legal terminology. Also, our experience in constructing this bilingual corpus has laid a foundation for us to continue to harvest more bilingual text materials from the Web, e.g., from Hong Kong government's Web sites. We find that almost all Hong Kong government web sites, which are in large numbers, maintain their Web pages consistently parallel in English and Chinese. We are not sure if such bitexts in such pages are larger than that in the BLIS site in volume. We do know they cover a large number of distinct domains. This is particularly useful for MT. If we can harvest and align the bitexts from such Web pages efficiently via utilizing their intrinsic characteristics of URL correspondence and text structure, it would not be a dream any more to put an end to the time of having too few existing translation materials for empirical MT studies, at least, for the language pair of Chinese and English.\n\ntable shows the collocations of these words and their frequencies.\n\nOn average, 8.89 bunsetsu in a sentence.\n\nEven if only top-10 parse results are considered, our CFG have a possibility to outperform KNP and CaboCha\n\nIn some studies, it is said that lexical information has little impact on accuracy(Bikel, 2004). However, we think some lexical information is useful for disambiguation, and it is necessary to consider what kind of lexical information could improve the accuracy.\n\nSentence (出租车/n 只/d 在/p 规定/v 的/de 路线/n 走/v 。) |__NNP__ n 出租车 | |__VP__d 只 | |___VP__PP*__p 在 | | |____NNP__v 规定 | | |____de 的 | | |_____n 路线 | | | |___VP__v 走 | | ___ w 。\n\nsentence (请/vw 给/p 我/r 送/v 杯/q 咖啡/n。) |__VP__vw 请 | | | |___VP**__PP__p 给 | | |___r 我 | | | |___VP__VP__v 送 | | | |___NNP__q 杯 | |____n 咖啡 | |__w。"
}