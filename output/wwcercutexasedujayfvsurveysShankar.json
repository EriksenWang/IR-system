{
    "title": "An Introduction to Assertional Reasoning for Concurrent Systems",
    "publication_date": "N/A",
    "authors": [
        {
            "full_name": "A Udaya Si-Iankar",
            "firstname": "A Udaya",
            "lastname": "Si-Iankar",
            "affiliations": [
                {
                    "organization": "Department of Computer Sczence and Znst[tute for /idLanced Computer Studzes, Unwerstty of Maryland",
                    "address": {
                        "postcode": "20742"
                    }
                }
            ]
        },
        {
            "full_name": "A Udaya Shankar",
            "firstname": "A Udaya",
            "lastname": "Shankar",
            "affiliations": [
                {
                    "organization": "[Logics and Meanings of Programs] Specifying, I CONTENTS",
                    "address": {}
                }
            ]
        }
    ],
    "abstract": "This is a tutorial introduction to assertional reasoning based on temporal logic The objective is to provide a working familiarity with the techmque. We use a simple system model and a simple proof system, and we keep to a minimum the treatment of issues such as soundness, completeness, compositionahty, and abstraction. We model a concurrent system by a state transition system and fairness requirements. We reason about such systems using Hoare logic and a subset of hnear-time temporal logic, specifically, invariant assertions and leads-to assertions. We apply the method to several examples.",
    "full_text": "1. INTRODUCTION have recently been proposed to specify A concurrent system consists of several and analyze concurrent systems. One such approach is assertional reasoning processes that execute simulta~eouslY based on temporal logic.1 and interact with each other during the Reasoning assertionally about procourse of their execution via shared varigrams is not new. Floyd [1967] introables or message passing. This is unlike duced assertional reasoning for sequena sequential system consisting of a single tial programs, and Hoare formulated this process that interacts with its environment only at the start and the end of its as a logic, namely, Hoare logic [Hoare execution. Indeed, many concurrent systems are useful only while executing, for INTRODUCTION BASIC NOTIONS 21 Safety 22 Progres> and Fairness 2J State Transltlon Systems SYSTEM LIODEL AND ASSERTION LANGUAGE J 1 System Model 32 Assertion Language 3 3 Au.xdlary Variables 34 Relatlonshlp to Other Formalisms PROVING SAFETl\" .4ND PROGRESS ASSERTIONS 41 Reasoning about Actlon~with Hoare-Tr]ples 42 Reasoning about Actlonswlth Weakest Precondltlons 43 Reasoning about Events .44 Proof Rules for Invariance 45 Generating Invariant Requirements 46 Proof Rules for Leads-To EX'AMPLESOF CONCURRENT SYSTEMSANALYSES! 51 A Bounded-Buffer Producer-Consumer E~amplc 52 An Interactlng-I,ooph E~ample DISTRIBUTED SYSTEM MODEL 61 B1.cklng Channel6 2 N(,nblochlng Channels 63 Cbannel Falrne<s RequlIements EXAMPLES OF DISTRIBUTED SYSTEMS ANAI,YSES 71 AData Transfer Protocol with Flow Control 72 AShorte.t-Dl>tan ceAlg[]IILhm 7 3 A Termlnatlon I)etectlon Algorltbln for Dlffuslng Computations DISCUSSION APPENDIX 1 REFERENCES 1969; Apt 1981]. Dijkstra [1976] extended this to nondeterministic sequential programs with guarded commands and introduced weakest preconditions. Reasoning about concurrent programs involves several extensions. Frost, because the processes of a concurrent program interact (and interfere) with each other, it is necessary to assume some level of atomicity in their interaction [Dijkstra 1965]. Second, the properties of interest for concurrent programs are more complex than for sequential programs; we are interested, for example, in infinite executions where every nonblocked process eventually executes some statement, where every request is eventually satisfied, etc. [Pnueli 1977]. Invariants and termination suffice for sequential programs, but not for concurrent programs. Pnueli [1977; 1979] pioneered the use of temporal logic for reasoning formally about the properties of concurrent systems. Since then, various assertional methods based on temporal logic formalisms have been proposed, for example, Manna and Pnueli [ 1984; 1992], Owicki and Lamport [ 1982], Lamport [ 1983b;1989;1991], Chandy and Misra [ 1986;1988], Back and Kurki-Suonio [1983; 1988], Lynch and Tuttle [1987], Schneider and Andrews [1986], Lam and Shankar [1990].\n\nIn these methods, we reason about a concurrent system using two kinds of assertions, referred to as safety assertions and progress asser-tions2 [Lamport 1977].\n\nInformally, a safety assertion states that \"nothing bad can happen\" (e. g., variable\n\nx never exceeds 5), while a progress assertion states that \"something good will eventually happen\" (e.g., x will eventually become 5). (The distinction is made precise at the end of Section 3.2.) With these two kinds of assertions, we can reason about any property that holds for a concurrent system iff it holds for every possible execution of the system.\n\nThis class of properties includes partial correctness, invariant, termination, deadlock freedom, livelock freedom, worst-case complexity, hard real-time properties, etc. It does not include properties that involve operations over all possible behaviors, such as average complexity, probability distribution of response time, etc. Assertional reasoning can be done at a formal level using temporal Ioglc proof systems. However, we emphasize that assertional reasoning is not just about proofs. More importantly, it is a convenient language for talking unambiguously about concurrent systems, so that 2 Progress assertions are also referred to as liveness assertions The term \"progress\" m used in Chandy and Misra [ 1986; 1988] ACM Computmg Surveys, Vol 25, No 3, September Reasoning for Concurrent Systems 8 227 one person's view of a concurrent system can be communicated to another without distortion. The objective of this tutorial is to provide a working familiarity with assertional reasoning, so that the reader can apply it to concurrent and distributed systems of interest. Our approach is to use a simple state transition representation of concurrent systems and a simple proof system. We illustrate this approach on a variety of examples. We place minimum emphasis on theoretical issues such as models, semantics, soundness, completeness,\n\netc., because we feel that these issues are concerned with the foundation, rather than the application, of assertional reasoning.\n\nWe do not use a compositional model or proof system, because we feel that it would hinder, rather than help, the novice. We do, however, discuss compositional approaches in the conclusion.\n\nThe formalism we utilize is taken to a large extent from Lam and Shankar [1990] and Shankar and Lam [ 1987]. But the basic ideas are present in much of the recent work in assertional reasoning, including the temporal-logic approach of Manna and Pnueli [1984; 1992], UNITY [Chandy and Misra 1986;1988], TLA [Lamport 1991], and 1/0 automata [Lynch and Tuttle 1987]. This tutorial is organized as follows. In Section 2, with the help of a mutualexclusion algorithm, we informally introduce the basic notions of our approach, namely, state transition system, fairness requirements, invariant and leads-to assertions, and proof rules.\n\nIn Sections 3 and 4, we present these notions formally and describe how our approach fits in with those of others. Section 3 deals with the system model and assertion language, and Section 4 deals with proof rules and methods to apply them. In Section 5, we present examples of concurrent systems and their analyses. In Section 6, we specialize the system model for distributed systems. In Section 7, we present examples of distributed systems and their analyses. In Section 8, we motivate compositional and refinement tech-niques and review some of the literature in this area.\n\nLet us consider a simple solution by Peterson [1981] to the mutual exclusion problem involving two processes, 1 and 2. Each process can access a \"critical section\" (which may represent, for example, access to a shared data structure). The purpose is to ensure that (1) while process z is accessing the critical section, the other process j does not access it also, and (2) if a process i wants to access the critical section, then process i is eventually allowed to access it. The first is a safety property, and the second is a progress property. Throughout this example, we use i and j to identify the processes where i #j.\n\nThe solution uses two boolean variables, thinkingl and thinkingz, and a variable turn that takes values from {1, 2}. thinking, = true means process i is not interested in accessing the critical section; it is initially true. turn is used to resolve contention.\n\nIf process i wants to enter the critical section, it sets thinking, to false and turn to j, and it then checks the values of thinking] and turn. Process i enters the critical section only if thinking] = true or turn = i. When it leaves the critical section, it sets thinking, to true. Expressed in a traditional concurrent programming language, the solution is as follows;\n\nprocess 1 executes the first loop below; process 2 executes the second loop:s cobegin repeat S1: thmkingl + false; S2: turn * 2; S3: await thinkingz v turn = 1; \"critical section\"; S4: thmkmgl + true; forever\n\n.-3We have simplified Peterson's algorithm here by using await statements. As usual, we assume that the boolean guard of an await statement is evaluated atomically and that control goes to the next statement only if the guard is true. ACM Computmg Surveys, Vol 25. No 3, September 1993 * A. Udaya Shanlzar II re~eat RI, thlnkingz +false, R2: turn -1; R3 awaltthlnklngl '/turn=2 \"crihcal section\", R4: thinkingz +true; forever cobegln\n\nBecause we do not make any assumption about the relative speeds of the two processes, the algorithm has many possible executions.\n\nHow can we prove that the algorithm is correct, i.e., each of its executions satisfies the safety and progress properties?\n\nThe usual approach is to consider some example executions.\n\nConsider the safety property. Suppose process 1 enters the critical section, say at time tl. We want to show that process 2 is not in the critical section at the same time.\n\nAt tl, thinkingz v turn = 1 held; otherwise process 1 would not have entered the critical section. There are two cases to consider:\n\n(a) (b) Suppose thinkingz held.\n\nThen process 2 is not in the critical section, because process 2 sets thinkzngz to false before it attempts to enter the critical section, and sets th inkingz to true only after it leaves the critical section, Suppose ~think ing9 A turn = 1 held. Let us assume 'p~ocess 2 is in the critical section and reach a contradiction. Let t2 < tl be the time process 2 entered the critical section. Thus, thinkingl V turn = 2 held at ta. If thinkingl held at t2, then at some time t~between t2 and t~,pro-\n\ncess 1 executed S2 setting tz~rn to 2. Hence at t~, turn should equal 2, which is a contradiction. If T thinkingl A turn = 2 held at t2,then again turn should equal 2 at tl, since process 1 cannot set turn to 1. Again we have a contradiction. This kind of reasoning is referred to as operational (or behavioral) reasoning. The basic idea is to examine example execution sequences and to show that each case satisfies the desired property. In general, it is hard to be sure that we have exhausted all the possible executions. Operational reasoning is useful because it gives insight, but it is prone to errors. Assertional reasoning works differently. Instead of examining different execution sequences, we successively formulate assertions. Each assertion states a property about all executions of the program. The final assertion implies the desired property. Each assertion in the succession is proved by applying a proof rule. A proof rule consists of a list of conditions and a conclusion, such that if the conditions are satisfied by the program, then we can infer that the conclusion is satisfied by the program. Furthermore, the soundness of a rule should be \"obvious\" and not depend on the particular program or property being examined. In this tutorial, we use invariant assertions for expressing safety properties. An invariant assertion has the form Inwariant( P ), where P is a predicate (boolean expression) in the program variables. Inuaricznt( P ) states that at any instant during execution the values of the program variables satisfy P. A proof rule for invariance, informally stated, is the following: l~zuariant ( P ) holds if (i) P holds initially and (ii) every statement S of the program preserves P, i.e., executing S when P holds leaving P holding. Let us prove the mutual-exclusion property assertionally. The property is expressed by Inuariant( Ao), where: AO --(process 1 at S4 A process 2 at R4) We start by considering the following predicates: Al = process 1 at S2, S3, or S4 ~7 thinkingl Az = process 2 at R2, R3, or R4 * 1 thinkingz We can prove that Inz]ariant ( Al ) holds by applying the invariance proof rule de-Reasoning for Concurrent Systems 9 229 scribed above. Here are the details: Initially Al holds, because process 1 is at S1 and thinkingl is true. S1 preserves Al because it makes both sides of the true. S2 preserves Al because both sides are true before execution (since process 2 is at S2, and we can assume Al), and S2 leaves both sides true. S3 preserves Al in the same way. S4 preserves Al because it makes both sides false. Every Ri preserves Al because it does not affect Al. The proof for Inuariant( Az ) is symmetric; simply interchange process 1 with process 2, and t?zinkingl with think ingz. We now consider another pair of predicates: As G process 1 at S4 == thinkingl V turn = 1 V process 2 at R2 Ad = process 2 at R4 * thinkingl V turn = 2 V process 1 at S2 172 uariant( As ) holds by the invariance rule. (Initially, As holds vacuously. S1, S2 and S4 establish Aa vacuously by falsifying the antecedent. S3 preserves As because it is executed only if think-ingL V turn = 1. RI preserves As because it establishes one disjunct in A3's consequent, namely, \"process 2 at R2.\" R2 and R4 preserve As in the same way; each of them establishes one disjunct in A~'s consequent.) Invariant ( Ai) follows by symmetry. We have established that Inuariant(A1 ) holds, for i = 1, 2, 3,4. It is easy to show that Al, Az, AJ, and Al imply A(l by predicate logic. (Assume ~A. and reach a contradiction: -AO and As imply thinhingz V turn = 1. T AO and AJ imply thinkingl V turn = 2. 1 AO and Al and Ay imply ~thinkingl and 7 thinkingz. Thus, we have turn = 1 and turn = 2, which is a contradiction.) Hence Inzmriant( AO) holds. The assertional argument differs from the previous operational argument in two important ways. First, properties are stated precisely. This M Important for communication: We may state an assertion that is not valid, for example, lnvariant(process 1 at S3 * process 2 not at R3), but there is no ambiguity as to what it means. Second, the assertional proof is in terms of applications of proof rules. It can be checked by examining the individual statements of the algorithm without understanding the algorithm. This seems central to what a \"proof' is all about. It may take an expert to invent an algorithm or a proof (whether operational or assertional), but it should not require an expert to check a proof. In fact, the assertional approach lends itself to mechanization, i.e., the process of checking a proof can be completely automated, and this motivates much of the work in theorem proving. A common complaint about assertional proofs of concurrent algorithms is that they are too tedious or too difficult and that the insight gained in doing operational reasoning is often lost or buried among the tedious and \"syntactic\" details of assertional proofs. We disagree. It is concurrent algorithms, and not assertional proofs, that are difficult to understand. An assertional proof can be made brief and insightful just like any other proofi by omitting steps and unnecessary detail; e.g., in the above proof, maybe the invariance of Al and Az is obvious, but that of A? and AJ is not, If you think a property 1s obvious, then state it assertionally (so we know what you mean); assume it without proofi and use it to prove other properties. Proof rules can be formulated to allow such reasoning. An example is the following generalization of the invariance rule: Inuariant(P) holds if, for some predicate Q, (i) Inuariant( Q) holds, (ii) P holds initially, and (iii) for every statement S of the program, executing S when P ~Q holds leaves P holding. This rule allows us to assume the invariance of Q, and we make use of it in proving Inuariant( P ). (It simplifies to the former rule if Q = true.) 2.2 Progress and Fairness Let us give an operational proof of the progress property of the mutual exclusion algorithm. Suppose process 1 wants to enter the critical section. It sets thinking ~to false, turn to 2, and checks for thinkingz v turn = 1, say, at time tl.If process 2 is not attempting to enter the critical section, then thinkingz is true, and process 1 enters the critical section. If process 2 is also attempting to enter the critical section, then thinkingz will be false, and the value of turn determines which process enters first. There are two cases to consider: (a) If process 2 was the last process to assign turn, then turn equals 1 at tl, and process 1 enters the critical section first. (b) If process 1 was the last process to assign turn, then turn equals 2 at t~. Process 2 enters the critical section and process 1 has to wait. Assuming that process 2 does not stay indefinitely in the critical section, at some time t2 (> tl) it sets thinking? to true. At this point, one of two things can happen: (bl) Process 1 enters the critical section. (b2) Process 1 is slower than process 2, and before it can execute S3 process 2 executes Rl, say at time t~> t2.Then process 2 is again blocked. However, process 2 will soon execute R2 setting turn to 1, at which point process 1 becomes unblocked. More importantly, it remains unblocked because process 2 can never set turn to 2. Thus process 1 eventually enters the critical section. Clearly, there are more cases here than in the safety proof But there is also a fundamental difference. In the case of safety, we do not care if a process takes forever to execute a statement. But in the case of progress, that is not true in general. Consider process 2. If it is thinking, we do not care if it ever executes RI. But if it does execute Rl, then it must execute R2 in finite time; otherwise process 1 can wait forever (case b2). For the same reason, process 2 must also not delay indefinitely the execution of R3 and R4. Because R3 is an await statement whose condition {thinkingl V turn = 2) can be enabled and disabled by process 1, we need to be more precise in what we mean by \"process 2 must not delay indefinitely the execution of R3.\" Assume process 2 is at R3. q e One interpretation is that if R3 remains continuously enabled, then process 2 eventually executes R3. We refer to this as \"process 2 executes R3 with weak fairness.\" Another interpretation is that if process 2 is at R3-and R3 becomes enabled and disabled repeatedly,~then process 2 eventually executes R3 in one of its enabled periods. We refer to this as \"process 2 executes R3 with strong fairness.\" The notions of weak fairness and strong fairness were introduced in Lehmann et al. [198 1]. A detailed treatment of these (and other kinds of fairness) can be found in Francez [ 1986] and Manna and Pnueli [ 1992]. Weak fairness for a statement is easy to implement,5 whereas strong fairness is not [Sistla 1984; Apt et al. 1988]. It turns out that strong fairness implies weak fairness (see Section 3.1). The fairness terminology can be extended to statements like R1 and R4, simply by considering them to be always enabled. Weak fairness suffices for such statements because they cannot be disabled by another process. To summarize, we want R2, R3, R4, S2, S3, and S4 to be executed with weak fairness. Note that R1 and S 1 are the only statements that need not be executed with any fairness. Thus, if both processes are thinking, the system can stay in that state forever. In any other situation, the system is not \"at rest\" in 4 This can happen If, for example, the program exe cuted by process 1 IS changed to repeat turn + 1. tur]l + 2 forever 'For example, m a multlprogrammed cnwronment t)y simply using a FIFO queue for scheduhng en abled statements that it will eventually execute some statement. To reason asserticmally about progress, we consider assertions of the form P leads-to Q, where P and Q are predicates in the program variables. It means that if at some instant the program variables satisfy P, then at some later instant they satisfy Q. How long do we have to wait? No a priori time bound is implied, but we do know that it must hold whenever the system reaches a state where it is at \"rest,\" i.e., no process is at an enabled statement subject to fairness. To prove assertions like P leads-to Q, we rely on two kinds of proof rules. The first kind is for inferring leads-to assertions from program specification and fairness requirements. An example is the leads-to via S rule, where S is a program statement that is executed with weak fairness: P leads-to Q holds via S if (i) whenever P holds, S can be executed and its execution results in Q holding and (ii) for every statement R other than S, if P holds and R can be executed, its execution results in P v Q holding. Note that the leads-to via S rule requires us to examine every statement of the program, and not just S. This rule implies that once P holds, it will continue to hold (at least) until Q becomes true, and that there is at least one statement, S, which will eventually make Q hold (if no other statement makes it so). The second kind of proof rule is for inferring leads-to assertions from other leads-to assertions. For example, P leads-to Q holds if P leads-to R and R leads-to Q hold, or if P leads-to (Q v R) and R leads-to Q hold. Such rules are called closure rules. Now let us give an assertional proof of progress for the mutual exclusion algorithm. Suppose process 1 wants to access the critical section, It executes S1 and S2, at which point the following boolean condition holds: Xl = T thinkingl ~process 1 at S3 A turn = 2 Thus the desired progress property can be expressed by: YI -Xl leads-to process 1 at S4 Suppose Xl holds, and process 2 is at R1. What can happen next? S3 can be executed because thinkingz is true (which follows from Inuariant( Al ) and process 2 being at RI); its execution results in process 1 being at S4. Or R1 can be executed, resulting in Xl and process 2 at R2. No other statement can be executed. Because S3 has weak fairness, process 1 will eventually execute S3 unless process 2 executes R1. In fact, we have just given the details of applying the leads-to via S rule to establish Yz = Xl A process 2 at R1 leads-to process 1 at S4 V (xl A process 2 at R2) (via S3) The tag \"via S3\" at the right indicates that Yz, holds by the leads-to via S rule with S instantiated by S3. Here are some other assertions that hold by the leads-to via S rule: Ys = Xl A process 2 at R2 leads-to 1 thinkingl A process 1 at S3 A turn = 1 A process 2 at R3 (via R2) Yb = 1 thinkingl A process 1 at S3 A turn = 1 A process 2 at R3 leads-to process 1 at S4 (via S3) Y~= Xl ~process 2 at R3 leads-to X1 A process 2 at R4 (via R3) YG = Xl A process 2 at R4 leads-to X1 A process 2 at R1 (via R4) The desired result YI follows by applying closure rules to Yz through Y6: YT = Xl A process 2 at R2 leads-to process 1 at S4 (from Ys and YJ) Yg = Xl A process 2 at R1 leads-to process 1 at S4 (from Y, and Y,) Yg = Xl A process 2 at R4 leads-to process 1 at S4 (from Y6 and YS ) YIO = Xl A process 2 at R3 leads-to process 1 at S4 (from Y, and Y9) Finally, YI follows from YT, Y8, Yg, and YIO, because when Xl holds, process 2 has to be at one of the statements Rl, R2, R3, or R4. This completes our asser-q A. Udauya Shankar tionalproof ofprogress. As in the case of the safety proof, we point out that each step can be checked by a nonexpert. 2.3 State Transition Systems In our proofs for the mutual exclusion algorithm, we have implicitly assumed that each statement is executed atomically. That is, once a process starts executing a statement, another process cannot influence the statement's execution or observe intermediate points of the execution. This means that if two statements, say Si and Rj, are executed concurrently, then the net effect is either that of Si followed by Rj, or Rj followed by Si. (This assumption was made in both the operational and assertional proofs.) More generally, consider a system of processes concurrently executing on some architecture (hardware or software). To analyze such a system, we need a formal model of the system. Any formal model makes assumptions about the real world that ultimately have to be accepted on faith. Almost every model used for correctness analysis assumes that the execution of a concurrent svstem can be . viewed in terms of events that can be considered atomic.G Some events represent activities internal to a process (e.g., read or write of a local variable), while the remaining events represent communications between processes (e.g., a message transfer, a read, or write of a shared variable). The granularity of an event refers to the extent of the system that is affected by the event; for example, an event that reads an integer is more coarse-grained than one that reads a single bit. The level of atomicit y, i.e.. the granularity of events that we can consider atomic, depends on the architecture upon which the processes execute and the properties being analyzed. A well-known folk theorem is that any sequence of operations can be considered atomic if it contains only a single access to a single shared 'i For a dlscusslon, see SectIons 2.1 and 22 In Manna and Pnueh [ 1992] variable. Larger units can be treated as atomic by using synchronization constructs, such as awaits, semaphores, conditional regions, etc. In a messagepassing system, it is common to treat each message send or reception as atomic. (See Lam~ort [19901 for a discussion of the folk theorem and extensions to it. ) Because of the atomicity assumptions, we can view a concurrent program as a state transition system, Simply associate with each process a control variable that indicates the atomic statement to be executed next by the process. Then the state of the program is defined by the values of the data variables and control variables. In anv state, an atomic statement can be executed if and only if it is pointed to by a control variable and is enabled. Executing the statement results in a new state. Thus each statement execution corresponds to a state transition, and each execution of the concurrent m-ogram corresponds to a sequence of s~ate transitions. The distinction between data variables and control variables is natural in a concurrent program. Data variables are updated in assignment statements, whereas control variables are updated according to the control flow of the program statements. However. as far as understanding and analyzing the program is concerned, there is no fundamental difference between data and control variables. But dealing with control flow of program statements is rotationally more cumbersome than dealing with assignment statements. So it is natural to consider a system model where control variables are treated just like data variables, i.e., updated in assignment statements. This is the approach taken m many recent works, for example, Back and Kurki-Suonio [ 1988], Lamport [ 1991], Chandry and Misra [1986; 1988], Manna and Pnueli [1984; 1992], Lynch and Tuttle [1987].7 7An example of an approach that does not treat control variables just hke data variables ]s Owlckl and Lamport [ 1982] This means that the state transition system can be defined by a set of state variables (corresponding to the data and control variables) and a set of events (corresponding to the atomic statements). Each event has an enabling condition, which is a predicate on the state variables, and an action, which updates the state variables. Thus, a concurrent system is described by a state transition system and fairness assumptions on the events. Typically, the state transition system is nondeterministic in that more than one event can be enabled in a system state. This is illustrated with the mutualexclusion algorithm. For i = 1,2, let control, denote the control variable for process i. Let es~denote the event corresponding to Sk, and let e~~denote the event corresponding to Rk. The concurrent system is specified as follows: State variables and initial condition: thin kingl, thinking~: boolean. Initially true. turn: {1, 2}. controll, controlz: {1, 2,3, 4}. Initially 1. Events: esl enabled G control ~= 1 action = thinkingl + false; control, + 2 esz enabled E COTI trol ~= 2 action = turn ~2; control, + 3 esq enabled G control ~= 3 A (thlnkingz V tarn = 1] action = controll + 4 esh enabled E control ~= 4 action = th[nkingl + true; controll + 1 e~áº½ nabled G controlz = 1 action G thinklngz * false; controlz + 2 e~z enabled E controlz = 2 action ~turn + 1; controlz + 3 'R1 enabled = control~= 3 A (thinkingl V turn = 2) action = controlg + 4 eR4 enabled F control~= 4 action E thinkingl * true; control ~+ 1 Fairness requirements: Events esz, es~, es~, eRl> 'R,3, and 'R4 have weak fairness Although we have listed the events in the same order as in the program, they can be listed in any order. The desired safety property is expressed by Inuariant( 7 (controll = 4 ~controlz = 4)) and the desired progress property by control, = 2 leads-to controll = 4 and controlz == 2 leads-to controlz = 4. The above example illustrates how to encode read, write, await, and repeatforever statements in state transition notation. Other kinds of statements can be encoded similarly. For example, S1: if B then S2: (statement) else S3: (statement) becomes the event esl enabled = control = S1 action E if B then control + S2 else control + S3 if we assume that B is checked atomically. If instead B = C ~D, where C and D are atomically evaluated in order, then we insert a control point, say S la, between C and D, and model S1 by two events: one event has enabling condition con trol = S1, and its action sets control to Sla or S3 depending on the value of C; the other event has enabling condition control == Sla, and its action sets control to S2 or S3 depending on the value of D. For another example, consider \"S1: P(sem); S2: (statement) ,\" where sem is a semaphore. S1 can be modeled by an event with enabling condition control = 234 q A. Uclaya Shankar S1 ~sem > 0 and action sem G sem -1; control + S2. Similarly, \"S 1: V( sen2 ); S2: (statement)\" can be modeled by an event with enabling condition control = S1 and action sem + sem + 1;control G S2. As mentioned in the Introduction, properties such as partial correctness, invariant, termination, deadlock freedom, livelock freedom, etc., can be modeled by safety and progress assertions. Invariant and livelock freedom (or starvation freedom) were illustrated in the mutual exclusion example. Deadlock freedom for a concurrent program means that the program can never reach a state where all processes are blocked. It is modeled by Inz~ariant(E ), where E denotes the disjunction of the enabling conditions of all events. Note that deadlock freedom is a safety property. For a concurrent program that is supposed to terminate, partial correctness means that if the program terminates then some desired predicate P holds. Let control, denote the control variable for the i th process in the program. Let start, denote its initial value, and end, denote its value at termination. Partial correctness is specified by Inuariant(['di: control, = end, ] * P), and termination of the program is specified by [Vi: control, = start, ] leads-to [b'i: control, = end,]. 3. SYSTEM MODEL AND ASSERTiON LANGUAGE In Section 2, we informally introduced a system model, namely, state transition systems and fairnem requirements, an assertion language, namely, invariant and leads-to assertions, and some proof rules. In this section, we describe the system model and assertion language precisely, introduce a few extensions, and show how our formalism fits in with those of other authors. Proof rules are dealt with in Section 4. Currently, our notion of fairness applies to an individual event. We will ex-tend this to a set of events, because this is often more appropriate in many situations. We will allow assertions that consist of invariant assertions and leads-to assertions joined by logical connective. We will allow auxiliary state variables, for recording history information of system execution. With auxiliary variables, any safety and progress property, including fairness requirements, can be expressed in terms of invariant and leads-to assertions. 3.1 System Model A (concurrent) system A is defined by q a state transition system defined by -VariablesA, a set of state variables and their domains. -Initiali, an initial condition on Varia- bles.. -Eue~ts., a set of events. q -For ea~h event e q Euentsi: enabled, an enabling condition (predicate in Variablesi ); and actionA( e ), an action (sequential program that updates Variablesi ); a finite set of fairness requirements -each fairness requirement is a subset of Euents~tagged with\" weak fairness\" or \"strong fairness.\" VariablesA defines the set of system states; specifically, each value assignment to the variables denotes a system state. Initial+q defines a subset of system states, referred to as the initial states. We assume that the set of initial states is nonempty. For each event e, the enabling condition and action define a set of state transitions, specifically, {(s, t): s, t are system states; s satisfies enabled~( e ); and t is the result of executing action~( e) in s}. We assume that action~( e) always terminates when executed in any state satisfying enabled~( e) and that its execution is atomic. A behavior is a sequence of the form (sO, eO, sl, el,... ) where the sl's are states, the e,'s are events, so is an initial state, and every (s~, sl + ~) is a transition of e~. A behavior can be infinite or finite. By definition, a finite behavior ends in a state. Note that for any behavior o-, every finite prefix of a ending in a state is also a behavior. Let 13ehauiors( A) denote the set of behaviors of A. Behauiors( A) is sufficient for defining safety properties of A but not its progress properties (because it includes behaviors where A's fairness requirements are not satisfied). We next define the behaviors of A that satisfy the fairness requirements. Let E be a subset of Euents~. The enabling condition of E, denoted enabled, is defined by [~e E E: enabled~(e)]. Thus, E is enabled (disabled) in a state iff some (no) event of E is enabled in the state. Let u= (so, eo, sl, el, . . . ) be an infinite behavior. We say \"E is enabled (disabled) infinitely often\" in cr if E is enabled (disabled) at an infinite number of s,'s. We say \"E occurs infinitely often\" in o if an infinite number of et's belong to E. A behavior cr of A satisfies weak fairness for E iff (1) a is finite and E is disabled in the last state of u, or (2) u is infinite and either E occurs infinitely often or is disabled infinitely often in m [Lynch and Tuttle 1987]. Informally, this means that if E is enabled continuously, then it eventually occurs. A behavior o of A satisfies strong fairness for E iff ( 1) u is finite and E is disabled in the last state of cr, or (2) u is infinite and if E is enabled infinitely often in o, then it occurs infinitely often in a. Informally, this means that if E is enabled infinitely often, then it eventually occurs. A behavior w of A is allowed iff o satisfies every fairness requirement of A. Let AllowedBehauiors( A) denote the set of allowed behaviors of A. AllowedBehauiors( A) is sufficient for defining the progress properties of A, as well as the safety properties of A. Note that a prefix of an allowed behavior is not necessarily an allowed behavior. Intuitively, a finite behavior u 1s allowed iff the fairness requirements of A do not require A to extend u in the future. This does not mean that A must not extend u. It just means that A is not obliged to extend u. If A is not subject to fairness requirements, then every behavior of the system is an allowed behavior. It may appear that fairness requirements are a complicated way of forcing an event to occur. However, a little thought shows that this is not so. For example, we cannot insist that an event occur as soon as it is enabled, because this means that two or more events cannot be enabled in the same state; i.e., it eliminates nondeterminism, which is fundamental to our modeling of concurrency. Another approach is to insist that events occur within some T seconds of being continuously enabled. Although this approach allows nondeterminism, its real-time constraint makes it harder to implement, and hence undesirable unless we are interested explicitly in real-time properties.\n\nWe allow events to have parameters. This is a convenient way of defining a collection of events. For example, consider an event E(i) with enabling condition x = O and action\n\nx + i, where\n\nx is an integer state variable and where the parameter i ranges over {1, 2,. ... 50}. Event E(i) actually specifies a collection of 50 events, E(l), E(2),... , E(50).\n\nLet A be a system that we want to analyze. Henceforth, we use the term\n\nstate formula to refer to a predicate in the state variables of A. A state formula evaluates to true or false for each state of the system.8 We say that a state satisfies a state formula to mean that the state formula evaluates to trz~e at that state. In Section 2, we considered assertions of the form Inuariant( P ) and P leads-to Q, where P and Q are state formulas. 8 The preczse meaning of evaluatin~a state formula P at a state s is as follows: for each state variable u that appears free in P, replace u by the value of the state variable in s, and then evaluate the resulting P. q A. Udaya S?lankar We now define precisely what it means for an assertion to hold (or be satisfied) for system A. We first define what it means for an assertion to satisfy a behavior of A. Let cr= (so, eo, sl, el,... ) be a (finite or infinite) sequence of alternating states and events of A. Sequence u satisfies Inuariant( P) iff every state S, in o satisfies P. Sequence u satisfies P leacls-to Q iff for every s, in m that satisfies P there is an Sj in u, j > i, that satisfies Q. System A satisfies Inzariant( P ) iff every behavior of A satisfies Inuariant( P ). System A satisfies P leads-to Q iff every allowed behavior of A satisfies P leads-to Q. Actually, for system A to satisfy Zn-L,ariarlt(p), it is sufficient if Inuarzant(P) holds for every finite behavior. And because every finite behavior is a prefix of an allowed behavior, it is sufficient if Inuariant( P) holds for every allowed behavior. So, we can say that an (invariant or leads-to) assertion holds for A iff it holds for every allowed behavior of A. We now extend the class of assertions in two ways. First, we allow assertions that are made up of invariant assertions or leads-to assertions joined by logical connective (for example, ( ~rzuarian t ( ?\") A ( P leads-to Q)) * (R leads-to S)). Such an assertion L is satisfied by CT iff L evaluates to true after each invariant or leads-to assertion X in L is replaced by X(m), where X( CT) is true if [r satisfies X and false if v does not satisfy X.g As before, system A satisfies L iff every allowed behavior of A satisfies L. Our second extension is to allow assertions to contain parameters, which are variables distinct from state variables (and thus not affected by events) 10 Parameters are convenient for defining classes of assertions. For example, x = n '] Thus, (. satisfies (InL,arzant(T) A (P leads-to Q)) ~( R leads-to S ) Iff u satlsfles R leads-t{] b', or u does not satky ~n~arfant( T ) or F' leads-to Q.) '\" parameters are akm referred to as rzgtd uanab[es In the literature [Lamport 1991; Manna and Pnuell 1992] leads-to y = n + 1, where n is an integer parameter, defines a collection of leads-to assertions. When evaluating an assertion, every parameter is universally quantified. Thus, x = n leads-to y = n + 1 holds iff [Via: x = n leads-toy = n + 1] holds. Throughout this tutorial, unless otherwise indicated, we assume the following precedence of operator binding power: arithmetic and data structure operators, such as +, = , prefix, subset, bind stronger than logical operators; the logical operators 1, ~, V, and ~arein decreasing order of binding power; followed by the leads-to operator. Here are some examples of invariant and progress assertions, together with an informal English interpretation: 0 a q q * Inuariant( x > -y): x is always greater than y; x = O leads-to y = 1: if x equals O, then eventually y equals 1; x = n leads-to x = n + 1: x keeps increasing; .x=n~y#O leads-to x~n+lvy = O: x grows without bound unless y becomes O; (x>n Ieads-to x>n+l)+(v>m leads-to y z nl + 1): y grows w~thout bound if x grows without bound. Note that the third assertion is satisfied only by infinite behaviors, whereas each of the other assertions is satisfied by some finite behaviors and some infinite behaviors. We use invariant assertions to express safety properties and use assertions built from leads-to and invariant assertions to express progress properties. We now make precise the terms safet.~property and progress property. Assertional reasoning is concerned with properties P such that for every sequence CT of alternating states and events, P is either true or false. P is a safety property if for any ir, if P holds for u then it holds for any prefix of CT. This means that if a safety property does not hold for some Q, then there is a point in CT where it first stops holding. P is a pure progress property if any finite cr can be extended to a sequence that does satisfy P. Alpern and Schneider [1985] showed that every property (that evaluates to true or false for every sequence o-) can be expressed as the conjunction of a safety property and a pure progress property. 3.3 Auxiliary Variables Our assertion language uses only two operators on sequences, namely, Inzmriant and leads-to. Because of this, we may not be able to express all safety and progress properties of interest for a given system A. (he way to overcome this is to add more operators on sequences, as in Manna and Pnueli [1984; 1992] (discussed below). Another way, which is the one taken in this tutorial, is to augment system A with auxiliary variables [Owicki and Gries 1976]. Auxiliary variables are state variables that record some history of system execution, but they do not affect the system execution and hence do not have to be implemented. Auxiliary variables are also known as history variables [Abadi and Lamport 1988]. Specifically, we can declare a subset Vars of the state variables of A to be auxiliary variables iff the variables in Vars (1) do not appear in event-enabling conditions, and (2) do not affect the update of any state variable not in Vars. Because we specify actions by programs, we can express condition (2) using the Owicki and Gries [1976] syntactic criteria: that is, variables from Vars can appear only in assignment statements; and if a variable from Vars appears in the right-hand side of an assignment statement, then the left-hand side must be also a variable from Vars.] 1 There is a difference between our use of auxiliary variables and that of Owicki and Gries [1976]. We use them in stating and proving desired properties, whereas 11Implicit in this syntactic criteria is the assumption that the value of a variable can be changed only by assignment Owicki and Gries used them only in proving; their desired properties were stated without recourse to auxiliary variables. With auxiliary variables, we can express fairness requirements as progress assertions. For an event set E subject to fairness, let cozmt( E ) be an auxiliary variable indicating the number of times E has occurred since the beginning of system execution; that is, include cozmt( .?3) + count(E) + 1 in the action of every event e = E. The following assertions are equivalent to weak and strong fairness, respectively:\n\nfairness) 3.4 Relationship to Other Formalisms As mentioned earlier, most of the recent approaches to assertional reasoning of concurrent systems use a state transition model, for example, Abadi and Lamport [1988; 1990], Lamport [1989; 1991], Manna and Pnueli [1984; 1992], Chandy and Misra [1986; 1988], Back and Kurki-Suonio [1988], Lynch and Tuttle [1987], Lam and Shankar [1990]. All these approaches use a set of state variables to define the system state, but they differ in how they define the state transitions of an event, and in the kinds of fairness requirements. In this tutorial, an event is defined by an enabling condition and an action. For example, a state transition system with three integer state variables, x, y, z can have an event e with enabling condition ~=2andactiony+y+l; x*3. In UNITY [Chandry and Misra 1986; 1988], the abstraction from program is taken one level further. Each event, referred to as a UNITY statement, is considered to be always enabled, and the action has the form of a multiple-assignment statement with an optional guard. Thus, the above event e would become q A. Udaya Shankar the UNITY statement \"(x, y) + (3, y + 1) if x = 2,\" Although the statement is always enabled, its occurrence changes the system state only if the guard is true. In both this tutorial and in UNITY, the assignment statement is used to change the value of a state variable. Consequently, Hoare logic or weakest precondition logic (and in particular the assignment axiom) is needed to prove properties of individual events. For example, to prove that the above event e preserves a state formula P,lz we would have to prove the Hoare-triple {P ~z = 2} y -y + 1; x + 3{ P}. (These logics are discussed in Section 4.) An alternative approach is to do away with assignments (e.g., Lamport [1983a; 1991], Shankar and Lam [ 1987], and Lam and Shankar [1990]). Define an event by a predicate in primed and unprimed versions of the state variables, where the primed version of a state variable refers to its new value. In this approach, the above event e is defined by the predicate x=2~.x'=3Ay '=y +lAz.'=z. Any state pair (s, t) that satisfies the predicate is a transition of the event. Because there is no assignment statement, reasoning about the transitions does not need Hoare logic; standard logic is sufficient. For example, to prove that event e preserves a state formula P, one hastoprove x=2~x'=3Ay ' =.v+l AZ' =ZAP*P(, Where p' is P with every free occurrence of x, y, and z replaced by x', y', and z'. A variation of this method is to use pre-and post-conditions to define the transitions of an event [Lynch and Tuttle 1987]. Event e can be specified by precondition x = 2 A y = n and postcondition x = 3 ~y = n + 1. Note that n is not a state variable but a parameter used for referring to the value of y before the event occurrence (thus a precondition is not the same as our enabling condition). The notions of weak fairness and strong fairness were introduced in Lehmann et al. [198 1]. A detailed treatment of them 'L That M, to prove that the execution of e in any state where P holds results m a state satisfying P (and other kinds of fairness) can be found in Francez [1986] and Manna and Pnueli [1992]. The definitions of behaviors and weak fairness used in this tutorial are taken from Lynch and Tuttle [ 1987] .13 The definition of strong fairness is taken from Lam and Shankar [1990]. UNITY uses the same notion of behaviors. The standard fairness notion in UNITY is that every UNITY statement is executed infinitely often. This corresponds to weak fairness for every event, if we treat a UNITY statement as an event with the UNITY guard becoming the event's enabling condition. Manna and Pnueli [1992] and Lamport [ 1991] have a technically different definition of behaviors. They prefer to deal only with infinite behaviors. So they augment the system being studied with a hypothetical \"idling event\" that is always enabled and whose occurrence does not change state. Thus a finite behavior is extended to an infinite one by appending an infinite sequence of idling transitions. Also, a finite sequence of idling transitions can be inserted between any two transitions. Lamport refers to this as \"stuttering.\" The fairness requirements in Lamport [1991] are, as in this tutorial, defined in terms of event sets subject to weak or strong fairness. In Manna and Pnueli [ 1992], individual events are subject to weak or strong fairness.lh Manna and Pnueli's [1984; 19921 temporal logic is a logic for reasoning about sequences of states. It has a variety of temporal operators, including u (henceforth), 0 (eventz~ally), O (next), and U (until ), for constructing assertions (temporal formulas) from state formulas. Let P and Q be state formulas, and let a = 13Lynch and Tuttle [1989] use the terms \"executions\" for our behaviors and \"actions\" for our events. They reqmre that different event sets subject to fan-ness must be mutually excluslve, and they do ~,ot consider strong famness Lamport [ 1991] usee the term \"actIon\" for our event Manna and Pnueh [ 1992] use the term \"transition\" for our event, \"transltlon relatlon\" for our set of transitions, \"JustIce\" for weak famness, \"compassion\" for strong fau-ness, and \"process-Justice\" for tbe fan-ness cm event sets. Reasoning for Concurrent Systems 9 239 ( so, SI, ) be an infinite sequence of states. u P is satisfied by o iff every s, satisfies P. OP is satisfied by u iff there is some S, that satisfies P. OP is satisfied by o-iff SI satisfies P. P UQ is satisfied by a iff the following holds: if so satisfies P, there is some s, that satisfies Q and every s], O < j < i, satisfies P. In the above expressions, P can be replaced by a temporal formula, resulting in a rich assertion language. For example, P + OQ is satisfied by a iff the following holds: if so satisfies P, then there is some s, that satisfies Q. u (P * OQ) is satisfied by Q iff for every s, that satisfies P, there is some s~, j > i that satisfies Q. u(P ~OQ) is satsified by CT iff for every S, that satisfies P, s,. ~satisfies Q. The above temporal operators can be thought of as \"future\" operators, because they examine the states to the right of so. For each of these operators, Manna and Pnueli [1992] also define a \"past\" version that examines states to the left. A thorough treatment of the relationships between different temporal operators (e.g., m El = P is equivalent to OP) and proof rules is given in Manna and Pnueli [1992]. In this tutorial, we make use of a fragment of Manna and Pnueli's temporal logic. Specifically, our Inuariant(P ) is u P, and our P leads-to Q is u(P ~OQ). Using only these two temporal operators may require the use of auxiliary variables to state certain properties. For example, the property \"x never decreases\" is specified in Manna and Pnueli's logic by u(X = n ~Ox > n), and in our logic by Inuariant(xOl~s x), where xOl~is an auxiliary variable that is assigned the value of x at the start of every event action (which may affect x). Of course, if this is not convenient, we can always include additional temporal operators from Manna and Pnueli's logic (e.g., see Alaettinoglu and Shankar [ 19921). Lamport [1991] defines a Temporal Logic of Actions, referred to as TLA, in which he can express event specifications, fairness requirements, and a fragment of Manna and Pnueli's temporal logic (consisting of u and O) under one unified logic. 4. PROVING SAFETY AND PROGRESS ASSERTIONS Recall that our safety assertions are invariant assertions, and our progress assertions are built from lead-to assertions and invariant assertions. In Section 2, we informally described proof rules for proving invariant and leads-to assertions. In this section, we describe a more complete set of proof rules and give a rigorous justification for them. Because the system model and assertion language of this tutorial are very similar to those in Lamport [1991], Manna and Pnueli [1984,1992], and Chandry and Misra [1986; 1988], our proof rules are also similar, and in many cases identical, to the rules found in those references.\n\nProof rules contain statements such as \"e preserves P,\" where e is an event and P is a state formula.\n\nTo reason rigorously about such statements, we resort to Hoare logic [Hoare 1969; Apt 1981], a well-known formalism for sequential programs. We also describe Dijkstra's weakest precondition logic [Dijkstra 1976], another well-known formalism for sequential programs. Although weakest precondition logic is not needed for stating or checking proofs, it is very helpful in inventing proofs. In Section 4.1, we describe Hoare logic for reasoning about actions. In Section 4.2, we describe Dijkstra's weakest precondition logic for reasoning about actions. In Section 4.3, we extend this notation to reason about individual events. In Section 4.4, we describe rules for proving invariant assertions, and in Section 4.5 we describe a heuristic for applying the rules. In Section 4.6, we describe rules for proving leads-to assertions. Throughout this section, P, Q, and R denote state formulas. 4.1 Reasoning about Actions with Hoare-Triples A Hoare-triple has the form {P} S{ Q}, where P and Q are state formulas and where S is an action. {P}S{Q} means that for every state s satisfying P, the execution of S starting from s terminates in a state that satisfies Q. 240 \" A. Udaya Shankar A Hoare-triple may be valid or invalid. Here are some valid Hoare-triples: \"{~j~~x +ythenx+y+l{.r=3 o{trae} ifx+ythenx+y+l{x=y +lvx=y} *{x= O~y=n}x-x+y{x=n} q{x=n}for i= OtolO:x+.X+i{x = n + 55} q{.~=O~y =l}whilex>Odox -2X {y = 1} And here are some invalid Hoare-triples: q{.x=3 }x+y+l{.Y =4} *{x= l~y=l}while .x> Odox~2X {y = 1} * {P} S{ false}, for any S and P. We have given examples of Hoare-triples, but we have not given proof rules for them. The actions that we will encounter in this tutorial are simple. Consequently, we will be able to generate valid Hoare-triples by inspection, as in the above examples. At the same time, there are simple proof rules when the actions do not involve loops, and we now explain them. We can use them instead of, or to supplement, our \"answer by inspection.\" For any state formula P, let P[ .~/t ] denote the state formula obtained by replacing every free occurrence of x in P by t.15The proof rules for Hoare-triples 'sFor example, lf F' -x = 2 V y = 3. then P[ .1/5] ~5 = 2 V y = 3 (which IS eqmvalent to y = 3), P[x/x + 1]= .I + 1 = 2 Vy = 3 (which IS equlvalent to x=1 VY =3), P[a,'2]=2=2\\ly=3 (which 1s equmalent to true), and F'[ .Y/z, y/z] -z =2vz=3 Every variable in P is either free or bound, I e , wlthm the scope of a quantifier. If the expression t contains an Identifier that happens to be also used to ldentlfy a bound variable of P, then suitable renaming 1s needed to avoid name clashes. For example, consider P -x = 2 A [3x .I = y]. P has three variables the r Inside the scope of the existential quantification, which is bound, the x outside the scope, which is free, and y, which is free To obtain P[ y/a], It 1s necessary to rename the bound x to somethmg else, e g , n, so that there is no name clash, thereby ohtammg z = 2 A [3 n. n = \"X1. are as follows (for rules of additional constructs, see Hoare [ 1969], Apt [ 1981], and Gries [ 1981]): * {P}x ~e{Q} holds if P = Q[ .~/e] holds. * {P} if B then S{Q} holds if {P ~B}S{Q} and P~7B*Q hold. q {P} if B then S, else S,{Q} holds if {P A B} S1{Q} and {P ~~B} S2{Q} hold. q {P} while B do S{Q} holds if {P B}S{P} and P A ~B = Q hold. \" {P}SI: SZ{Q} holds if for some state formula R, {P} SI{R) and {R} SJ{Q} hold. 4.2 Reasoning about Actions with Weakest Preconditions Dijkstra's weakest precondition terminology offers another way to reason about actions. This terminology is more involved than Hoare-triples, and it is not needed for stating proofs. But it is very helpful for inventing proofs. Throughout we use \"wrt\" as an abbreviation for \"with respect to.\" P is a sufficient precondition of Q wrt S means that {P}S{Q} holds. P is a weakest precondition of Q wrt S means that (a) P is a sufficient precondition of Q wrt S and (b) R * P holds for any other sufficient precondition R of Q wrt S. That is, a weakest condition P specifies the largest set of states where the execution of S terminates with Q holding. One way to obtain weakest preconditions is by inspection. Another way is to use Dijkstra's predicate transformer wp(S, Q), which for a program S and state formula Q returns a weakest precondition of Q wrt S. For the constructs we consider here, [LIp( S, Q) is as follows (for additional constructs, see Dijkstra [1976]):\n\nThus, P e wp(S, Q) holds means that P is a weakest precondition of Q wrt S, and P * wp(S, Q) holds means that P is a sufficient precondition of Q wrt S. 4.3 Reasoning about Events We extend the Hoare-triple notation to an event e by defining {P}e{Q} to mean {P A enczbled(e)}action( e){ Q}. That is, for every state s satisfying P, either e is not enabled at s, or the execution of action(e) starting from s terminates in a state that satisfies Q. For example, given an event e with enabling condition x # y and action x ~.y + 1, {x # y}e{x = y + l}, {x=y}e{x#y+ l}, and{x+y~y -n -l}e{x = n} hold, and {x # y}e{x + y + 1} does not hold. We extend the weakest precondition notation to events. P is a sufficient precondition of Q wrt e means that {P}e{Q} holds. P is a weakest precondition of Q wrt e means that P is a sufficient precondition of Q wrt e, and R ~P holds for any other sufficient precondition R of Q wrt e, We define P to be a necessary precondition of Q wrt e if for every state s satisfying T P, e is enabled and its action results in a state satisfying = Q. If P is both a sufficient precondition of Q wrt e and a necessary precondition of Q wrt e, then P is a weakest precondition of Q wrt e. The wp predicate transformer for event e is defined by wp(e, Q) = enabled(e) * wp(action(e), Q). 4.4 Proof Rules for Invariance There are two kinds of rules for proving invariants. The first kind is for inferring invariant assertions from the system specification: Invariance Rule. Invariant(P) is satisfied by system A if the following hold: (i) Initial.. ~P (ii) for every event e of A: {P}e{P} Proof of Soundness. Let w = (sO, eo, sl, el,... ) be a finite behavior of system A. We have to show that conditions (i) and (ii) imply that every s, in u satisfies P. We prove this by induction on the length of a. Condition (i) implies that so satisfies P. Assume that for some n, states so,. ... s~in cr satisfy P. Assume that s. is not the last state of a (otherwise, we are done). Thus, em, s., follows s,, in o. It suffices to prove that sn + I satlsf~es P. Because u is a behavior, s. satmfies enabled~(e~). From the induction hypothesis, we have that s,, satisfies P. Therefore, condition (ii) implies that s., ~satisfies P. u Suppose we know that system A satisfies invariant(Q) for some state formula Q. How can we exploit this information in proving Invariant(P)? Basically, we can relax condition (ii) in rule 1 to {P Q}e{Q = P}, because we do not have to consider state transitions (s, t) where s or t does not satisfy Q. That is, the above invariance rule can be generalized to the following: Inuariant( P ) is satisfied by system A if the following hold for some state formula Q: (i) Initial* = p (ii) for every event e of A: {P ~Q}e{Q *P} (iii) Invariant is satisfied by system A Note that the general version reduces to the simple version if Q -true. When we apply these rules in our examples, we shall say Inuariant( P ) holds by the invariance rule assuming Invariant(Q) to mean that P and Q satisfy the conditions of the general invariance rule. We shall say Invariant(P) ?Lolds by the invariance rule to mean that P satisfies the conditions of the simple invariance rule. The second kind of proof rule is for inferring invariant assertions from other invariant assertions. Here are two examples: q lnuariant( P ) holds if for some state formula Q, Q = P and invariant(Q) hold. 0 Invariant(P) holds if for some state formulas Q and R, Q A R -P, Invariant( Q), and Invariant(R) hold. Actually, the first rule is a special case of the second rule with R -true. Because these rules are so obvious, we do not give them any special name. When we use the first (or second) rule, we simply say Inuarian t ( P ) holds because of Invariant(Q) (or Invariant and lnuariant(R)). Each rule above defines some sufficient conditions for invariance. Suppose we have a system and a state formula P, and we have to prove that the system satisfies Invariant(P). Where do we start? If we do not already know some invariant for the system, the first step is to see whether P satisfies the invariance rule. If we are lucky, it may. But in general, {P}e{P} will not hold for some event e. This is natural because P is a desired property, and for any nontrivial desired property, the system has to maintain additional properties to achieve P. We need to unearth these additional properties, in order to find a state formula Q that implies P and satisfies the invariance rule. Accumulator Example Consider the following concurrent program written using the cobegin/coend construct: x: Integer Inlhally x = O cobegin X+X+2011X+X+2111X+X+2211 ~~~Ilx+ X+2N-1 coend The above program has N subprograms that are executed concurrently. Let us assume that each x -x + 2' statement is atomic. We can model the program by the following state transition system, where i is a parameter that ranges over {O, . . . . N -1} and where b(i) denotes the control for the ith subprogram: State variables and initial condition: x: integer. Initially x = O. b(z): {O, 1}. Initially b(t) = O Events e(z) enabled = tJ(z) = O actzon =x+x+2'; b(i)-1 Fairness requirements: {e(0), . . . . e(lV -1)}has weak famness. Suppose we want to prove that x > 2' if the i th subprogram has terminated. This property is stated by lnuartant(l?o ), where BO-b(i)=l*x>2[. B. happens to satisfy the invariance rule: It holds initially. {Bo}e(t ){BO} holds because e(i) makes the consequent true (by adding 22 to x). {Bo}e(k){BO} holds for k # i because e(k) does not make the antecedent true or the consequent false. Suppose we want to prove that x = 2 N -1 holds at termination of the program. The program is terminated iff all N subprograms have terminated. Thus the property can be stated as Inuariant( A(] ), where Ao-[VZ: b(Z) =l]-.r=2N-l. Our first approach is to use the invariance rule. However, {Ao}e(i){Ao) does not hold. For example, consider a state s that satisfies b(0) = O, b(i) = 1 for i + O, and x#2N-2. State s satisfies A. (vacuously). But e(0) is enabled at s, and its occurrence would result in a state that does not satisfy AO. Clearly, we need to keep more information about the relationship between the b( i)'s and x, which is that at any instant, x has accumulated the 2' contributions of the i's where b(i) = 1. This leads us to the following state formula: Al-x= ~2'where J={t:b(i)= l}. lGJ Al satisfies the invariance rule (make sure of this). Al implies AO. Therefore A. is invariant. 4.5 Generating Invariant Requirements Suppose we have a system and a state formula AO that is to be proved invariant for the system. The difficulty is in coming up with a state formula that satisfies the invariance rule and implies AO (e.g., the state formula Al in the accumulator example above). This requires invention and insight into why the system works. Although there is no algorithm to generate assertions, there is a heuristic based on weakest preconditions that is often successful [Shankar and Lam 1987]. The heuristic generates, starting from AO, a succession of state formulas, Al, Az,... , AK. ~, such that the conjunction AO A . . . A AK. ~satisfies the invariance rule. At any point, the heuristic maintains the following: e 0 A set of state formulas, AO, A1,..., A~_l, where AO is the state formula to be proved invariant. Each A, is referred to as an invariant requirement. K indicates the number of invariant requirements currently defined. For each A,, Initial * Al holds. (We want Inum-iant( A,) to hold.) A marking, defined as follows. Each ( Aj, e) pair, where ~\" ranges over {o ,... , K -1} and where e ranges over the system events, is either marked or unmarked. Associated with each marked (Al, e) pair is a subset J of {AO,..., A ~_ ~} such that (the conjunction of the state formulas in) J is a sufficient precondition of A~wrt e; that is, {) A A, e{ A,} A,EJ holds. We refer to J as the justification for marking ( A~, e). Note that the marking indicates the extent to which AO A . . . A AK. ~satisfies the invariance rule. If all ( A,, e) pairs are marked, then AO ~\"\"\" A AK. ~satisfies the invariance rule, The justifications allow us to \"undo\" parts of the proof if needed (see below). (The justifica-tions are also useful for checking the proof.) At the start of a heuristic application, assuming Initial = A. holds, we have a single invariant requirement, namely, AO, and nothing is marked. (If Initial * AO does not hold, then AO is not invariant.) At each step of the heuristic, we choose an unmarked ( AJ, e) entry and do the following: generate a weakest precondition P of Al wrt e. if Initial = P does not hold then STOP \"heuristic terminates unsuccessfully\" else begin if Al A ... A A~_l * P does not hold then begin A~=P; K~K+ lend; \"add a new invariant requirement\" mark ( Aj, e ) with justification AK end else mark (Al, e) with justification J where J q {Al, ..., A~.l} such that A A,. ~AJ * P holds end The heuristic terminates successfully if all (Al, e) pairs are marked; in this case, AOA.. AA \" ~-.1 Satlsflle.s the invariance rule. The heurlstlc termmates unsuccessfully if a precondition P is generated that does not satisfy Initial; in this case, we can conclude that AO is not invariant [Shankar and Lam 1987]. Typically, a brute-force application of the heuristic will not terminate (except in special cases such as finite state systems). The following should be kept in mind when applying the heuristic. First, it is crucial to simplify the expression for P as much as possible in each iteration. Otherwise the Al's grow unmanageably. In addition to the usual algebraic and predicate calculus transformations, it is possible to make use of an existing invariant requirement, say AZ, to simplify the expression for P. For example, if P = y = O * x G {O, 1} and A, -x G {1,2}, then we can simplify P to ACM Computmg Surveys, Vol 25, No 3, September q A. Udaya Shankar y =, O * x = 1; note that Al now has to be included in the justification for marking (Al, e). Second, the choice of the unmarked (A,, e) pair in each iteration is often very important. It is often very convenient to generate a precondition with respect to a sequence of events, rather than just one event; for example, wp( e], A,) may be complicated while z~lp(el, u)p(ej, ... wp(e~, AL ) ~~)) is simple. Third, if the expression for a weakest precondition P becomes unmanageable (and this depends on our ingenuity and patience [Dijkstra 1976]), then we can obtain either a sufficient precondition or a necessary precondition. If we obtain a necessary precondition P, then we cannot mark ( AJ, e). However, this step is still useful because it gives us another invariant requirement. If we obtain a sufficient precondition P, then we can mark ( Aj, e). However, after this if the heuristic terminates unsuccessfully, i.e., without all ( A,, e ) pairs marked, we cannot conclude that A. is not invariant. This is because the sufficient precondition P that was introduced as an invariant requirement may not be invariant: in which case, the heuristic failed because it attempted to prove that P is invariant. Thus, whenever we use sufficient preconditions, we must be prepared to roll back the heuristic in case of unsuccessful termination. (If we find that we have to remove an Ak from the set of invariant requirements, the justifications allow us to easily locate the marked ( A~, e) pairs that have to be unmarked.) Fourth, after a few iterations of the heuristic, it is quite possible that our insight into the system improves, and we are able to guess a state formula Q that we believe is invariant and relevant to establishing Inuarian t( A{, ) (i.e., it allows us to mark some unmarked ( A , e) pairs.) We simply add Q to the set 0$ invariant requirements, after making sure that InitLa[ _ Q holds. In the same way, we can incorporate a property Q that is known a priori to be invariant, except that in this case we need not worry about marking Q wrt to the events. 4.6 Proof Rules for Leads-To We have two kinds of leads-to proof rules. The first kind is for inferring leads-to assertions from the system specification: Leads-to via Event Set Rule. Given a system A with weak fairness for event set E G Eventsk, P leads-to Q is satisfied by A if the following hold: (i) for every event e q E: {P}e{Q} (ii) for every event e e Events~-E: {P}e{P v Q} (iii) Invariant( P = enabled~( E)) is satisfied by A Proof of Soundness. Let g = (sO, eO, sl, el, . . . ) be an allowed behavior of system A. We have to show that the conditions of the rule imply that a satisfies P leads-to Q. Let S, satisfy P (if there is no such z, P leads-to Q holds vacuously). We have to show that there exists an s,, j > i, in cr such that s] satisfies Q. Let us assume the negation: (iv) for all s~in o, k > i, Sk does not satisfy Q. From (i) and (ii), we know that if Sk satisfies P and if sk is not the last state in m, then s},+ ~satisfies P V Q. From (iv), we know that s~, ~does not satisfy Q. Thus, every s~in m, k > i satisfies P, and hence the enabling condition of E (from condition (iii )). Also from condition (i), we know that eh E E for e, in u, k > z (otherwise, Q would hold). If o-is finite, then E is enabled in the last state. If u is infinite, then E is continuously enabled but never occurs. Either case is not possible because a is an allowed behavior and E has weak fairness. u If event set E has strong fairness instead of weak fairness, then in condition (iii) of the above rule we can replace Inlariant(P * enabled, by the weaker P leads-to Q V enubled~(E) (see Lam and Shankar [ 1990] for details). The second kind of leads-to proof rule is for inferring leads-to assertions from other leads-to assertions. We refer to them as closure rules. Here are some ACM ~omputmg Surveys, Vol 25, No 3, Scptemhc, Assertional Reasoning for Concurrent Systems \" 245 obvious examples (for a complete treatment, see Chandy and Misra [1988] and Manna and Pnueli [1984; 1992]): o P leads-to Q holds if Invariant( P * Q) holds. e P leads-to Q holds if for some R, P leads-to R. and R leads-to Q hold. 0 P leads-to Q holds if for some R, P leads-to Q v R and R leads-to Q hold. e P leads-to Q holds if P = PI V Pz, PI leads-to Q, and Pz leads-to Q hold. e P leads-to Q holds if Inuariant( R) and P A R leads-to R * Q hold. Sometimes we have to apply a closure rule N times, where N is a parameter of the problem being solved. For such cases, we need a generalization based on wellfounded structureslG [Manna and Pnueli 1984; Chandry and Misra 1988; Lamport 1991]: Leads-To Well-Founded Closure Rule. Let (Z, > ) be a well-founded structure. Let F(w) be a state formula with parameter w G Z. P leads-to Q is satisfied if the following hold: (i) P leads-to Q V [2x: H x)] (ii) F(w) leads-to Q v [=x < W: F(x)] Different instances of well-founded structures are appropriate in different situations. One special case of a wellfounded structure is the natural integers; here the ordering is total. Another special case is the partial ordering induced by set inclusion on the subsets of a countable set. When we use these rules in our examples, for brevity we shall say P leads-to Q holds via E to mean that P, Q, and E satisfy the conditions of the above leadsto via event set rule. We shall say P leads-to Q holds by closure of Ll, Lz,..., where Ll, L2, \"\"\" are other assertions, to mean that P leads-to Q holds by apply-16A well-founded structure (Z, > ) is a partial order > on a nonempty set Z such that there is no infinite descending chain z ~> z ~> where each z, E z. ing the closure rules to Ll, Lz, . . . . Finally, it is often the case when P leads-to Q holds via E, that only a subset F of the events in E are enabled when P holds. To explicitly indicate this, we say that P leads-to Q holds via F c E; formally, this means that P leads-to Q holds via E and P ~1 enabled( E -F) holds. Accumulator Example (Continued)\n\nLet us prove that the accumulator program (at the end of Section 4.4) satisfies\n\nRecall that event set E = {e(0),..., e( N -1)}has weak fairness.\n\nWe expect LO to hold, because for each i, if b(i) = O then e(i) eventually sets b(i) to 1, and after that b(i) is not affected. Define J = {i: b(i) = 1).We expect the following to hold:\n\nLI -IJI =n <Nleads-tol J = n + 1.\n\nLI holds via event set E. The details are as follows:\n\nbecause of the definition of J. For every event e = E, {IJI = n < N}e{l J I = n + 1}, because e's occurrence increases IJ I by 1. There is no system event not in E.\n\nThe following can be derived from LI using N applications of the leads-to transitivity rule (or more precisely, using the well-founded closure rule with the naturals as the well-founded structure and F(w)-N-IJI = W):\n\nLz = IJI = O leads-to IJI =N.\n\nLz implies LO because of the definition of J (or more precisely, using the last closure rule). This completes the proof of LO.\n\nIn this section, we consider some con-\n\ncurrent systems and analyze desirable properties. The weakest precondition 246 q A. Udaya Shanhar heuristic for obtaining invariant requirements is illustrated. Many of our examples involve sequences. If B is a set of values, then sequence of B denotes the set of finite sequences whose elements are in B. It includes the null sequence, denoted by (). For any sequence y, let Iyl denote the length of y, and let y(i) denote the ith element in y, with the Y(O) being the leftmost element. Thus, -y =\n\n(y(o),..., y(lyl -1)).\n\nWe say \"y prefix-of 2\" to mean Iyl < Iz I and y = (z(0), . . ..z(lyl -1)). For any nonnull sequence y, define tail(y) to be (y(l),..., y(lyll)); i.e., y with the leftmost element removed.\n\nFor any sequence y, define heaci( y) to be y(0) if y is nonnull and a special value nil (that is not in any variable's domain) if y is null. We use @ as the concatenation operator for sequences. Given two sequences y and .Zj y@~is the sequence (y(0),.\n\n... y(lyl -,.. ., Z(IZI -1)). >\n\nProducer-Consumer Example Consider a producer process and a consumer process that share a FIFO buffer of size N > 0. The producer can append data items to the buffer.\n\nThe consumer can remove data items from the buffer. To avoid buffer overflow, the processes maintain a variable indicating the number of spaces in the buffer.\n\nWe assume that if the buffer is not empty, the consumer process eventually consumes the item at the head of the buffer.\n\nHowever, we do not require the producer to repeatedly produce data items.\n\nThis system can be modeled as follows, where DATA denotes the set of data items that can be produced, and parameter data has domain DATA: State variables and initial condition: buffer: sequence of DATA. Initially (). {The FIFO buffer shared between the processes) numspaces: integer. Initially N. {The number of spaces currently available in the buffer} Events: Produce(data) enabled G numspaces > 1 actzon = buffer ~buffer@ ( data); numspaces ~numspaces -1 Consume( data) enabled = head( buffer) = data actzon G buffer G tail(buffer); numspaces ~nurnspaces + 1 Fairness requirements: {Consurne(data): data E DATA} has weak fairness.\n\nSuppose we want to say that the buffer never overflows.\n\nThis safety property can be specified by the following assertion:\n\n(1) Inuariant(lbufferl < N).\n\nSuppose we want to specify that data items are consumed in the order they were produced. This is a safety property.\n\nWe cannot specify this property on the above model because it does not have any state variables that indicate the order of production or of consumption. So we introduce two auxiliary variables as follows: q produced: sequence of DATA. Initially (). {Records data blocks in the order they are produced} \" consumed: sequence of DATA. Initially (). {Records data blocks in the order they are consumed} The events are modified as follows (note that the auxiliary variable condition is satisfied).\n\nq produced\n\n* produced~(data) is added to the action of Produce( data). q consumed ~consumed @(data) is added to the action of Consume(data   ).\n\nThe desired property can now be formalized by the following assertion:\n\n(2) Invariant (consumed prefix-of produced). Suppose we want to say \"the buffer is empty just before data is produced.\" How can we specify this safety property? We can rephrase it as \"the buffer is empty whenever data can be produced, i.e., whenever Produce(dzzta) is enabled,\" and this is specified by the following assertion:\n\n(3) Invariant (n umspaces >0 * Ibufferl = O).\n\nSuppose we want to say that whatever is produced is eventually consumed. This is a progress property.\n\nIt can be specified by the following assertion:\n\n(4) produced = n leads-to consumed = n.\n\nGiven the safety assertion Inuariant ( consumed prefix-of produced), it can also be specified by ( 5) Iproduced I = n leads-to Iconsumedl = n.\n\nSuppose we want to say that the producer keeps producing data blocks. This progress property can be specified by the following assertion:\n\n(6) Iproducedl = n leads-to Iproducedl = 12 + 1.\n\n(l), ( 2), (4), and ( 5) are satisfied by the system. Assertion\n\n(3) is not satisfied unless N = 1 or N = O. Assertion ( 6) is not satisfied; it would be satisfied if, say, {Produce(data): data G DATA} is subject to weak fairness. We next give proofs of assertions (1), (2), and (5). Proof of a Safety Property. Let us prove that Inuaria~zt( AO ) holds for the system, where AO -Ibzzfferl < N. We use the heuristic for generating invariant requirements. The first step is to check whether Initial = AO, which it does. Next, we set up the marking. We represent the marking by a table that has a row for each invariant requirement and a column for each system event. For an invariant requirement A, and an event e, if ( A,, e) is unmarked, its entry in the table is blank. If ( A,, e ) is marked, its entry indicates the justification, i.e., a subset of the invariant requirements such that their conjunction is a sufficient precondition of AZ wrt e. Thus, the reader can easily check the validity of the marking. Also, an (A,, e) entry in the table contains NA to indicate that e does not affect any of the state variables of A,; thus { AZ}e{ A,} holds trivially. Finally, just to remind ourselves that each invariant requirement must be checked first against Initial, we add a column for that purpose. It will contain OK to indicate that Initial =+ AJ holds, At the start, we have the following marking. I Initial Produce(data) Consurne( data) ÃO OK Next we try to mark the unmarked (Al, e) pairs. We can mark ( AO, Consume( data)) with the justification AO because {A O}Consz~me(data){AO} holds (since Consunze(data) decreases Ibufferl by 1). What about ( AO, Prodz~ce( data))? Produce(data)'s action increases Ibuffer I by 1. So in order for AO to hold, it is necessary (and sufficient) that Ibuffer I < N -1 hold whenever Produce(data) is enabled. That is, the following is a weakest precondition of AO wrt Produce(data): Al = nz~rnspaces >1 * Ibufferl < N -1. Al is not implied by AO, so we can add Al as an invariant requirement. But Al reminds us that we need to investigate the relationship between n umspaces and buffer. In fact, the relationship is obvious; numspaces indicates the number of spaces in buffer: Az E Ibufferl + nz~mspaces = N. Observe that Az implies Al. Az holds initially. { Az}Produce( data){ Az} holds because Produce(data) decrements numspaces by 1 and increments Ibuffer I by 1. {Az}Consume(data){ Az} holds in the same way, with numspaces and Ibuffer I interchanged. We are done. Our proof is summarized in the following marking, \" A. Udaya Shankar where * is used to indicate an old entry: lInztzal Produce(data) Consume(data)l A, ' A, Au Ag OK A2 AZ In fact Az implies A,], so we can remove the AO row in the above marking and just note that Az * AO holds. Is Az the weakest state formula that satisfies the invariance rule and implies AO? See Note 1 in Appendix 1 for the answer. u Proof of a Safety Property. Let us prove that lnoarian t( BO ) holds for the system, where BO G consumed prefix-of produced. BO holds initially. {B O}Produce ( data){llo} holds because Prodzzce(dczta) appends data to the right of produced and does not affect consumed. At this point, we have the following marking: IndLa[ Produce(data ) Consume( data) BO OK BO Consider (BO, Consume( data)). Consume preserves BO iff head( buffer) is the next element in sequence after the last element in consumed. That is, the following is a weakest precondition of BO wrt Consume( data): BI E Ibuffei -> 0 * consunLed@] ( buffer(0)) prefix-of produced. BI reminds us that we need to investigate the relationship between buffer, produced, and consumed. In fact, buffer stores whatever has been produced and not yet consumed. This gives us the following: Bz = produced == conszimedfibz~f fer. Note that Ba implies BO and BI. Bz holds initially. {Bz}Produce(data ){ B,} holds because Produce(data) appends data to the right of prodz(ced and to the right of buffer, and it does not affect consumed. {B2}Consurned( data){B2} holds because Consunze( data) transfers the leftmost element in buffer and appends it to the right of consumed, provided bz~ffer was nonnull before the occurrence. We are done, as summarized in the following marking, where we also indicate that Bz implies BO: Initial Produce( data) Consunze( data) B2 OK B2 Bz Bz = B. Is Bz the weakest state formula that satisfies the invariance rule and implies BO? See Note 2 in Appendix 1 for the answer. u Note that the proofs of Inuariant( Az ) and Invariant ( Bz ) are independent of each other. Proof of a Progress Property. Let us prove that LO holds for the system, where LO s ~producedj > n leads-to Iconsumedl > rz.\n\nWe expect this to hold because as long as Iprodz~ced~> n and lconsz~medl < n hold, the buffer is not empty, and eventually Consume will extend consumed.\n\nConsider the following assertion:\n\nleads-to Iprodz(cedl > n ~Iconsunzedl = ?n + 1 Using closure rules, we can derive LO from LI (make sure of this). Thus, it suffices to establish L1. We now show that LI holds via event set E = {Consume(data): data G DATA}. The details are as follows: Because consumed@buffer = produced (from Bz or Bl), Iproducedl z n ~Iconsumedl = m < n implies buffer # (), which implies enabled( E). The occurrence of any event in E (i.e., Consume( data) for any data) establishes Iproducedl > n ~Iconsunzedl > ACM Computmg Surveys, Vol 25, No 3, September m + 1. The occurrence of any event not in E (i.e., Produce( data) for any data) preserves Iproducedl > n ~Iconsumedl =m <n. u 5.2 An Interacting-Loops Example Consider the following program written in a traditional concurrent programming language. x: integer. Initially x = 4. cobegin repeat x + 1 until x = 3 II repeat if x = 1 then x + 2 else x + 4 until x = 3 II repeat if x = 2 then x + 3 else x + 4 until x = 3 coend Assuming that each if statement and each x = 3 test is atomically executed, we can model the above program by the following system, where state variables a, b, and c represent the control variables of the three processes. Proof of a Safety Property.\n\n.\n\n249 weak fair-It is obvious that ~equals'3 if the program terminates; that is, Inuariant(AO ) holds, where AO=a=b=c=2~x~3, because AO satisfies the invariance rule. u Proof of Negation of a Safety Property. Does .x equal 3 if only some of the loops have terminated? That is, does Inuariant (B. ) hold, where BO~a=2Vb=2Vc=2~x =3.\n\nWe shall prove that lnz~ariant(BO) does not hold, by providing a finite behavior that ends in a state that does not satisfy BO. Let us represent the system state by the value of the 4-tuple (x, a, b, c). Consider the following sequence of alternating states and events: ~= ((4, 0,0, 0), el, (l, l, (),0), e27 (l, o,o, o), fl, (2,0,1,0 ),gl, (3,0,1,1), f2, (3,0,2,1\n\n),el, (l,l,2,1))\n\nIt is easy to check that o is a behavior of the system and that its last state (1, 1,2, 1) does not satisfy BO. (Is there a shorter counterexample?) u Proof of Nega tion of a Progress Property. Does the system eventually terminate? That is, does LO hold, where LO~a=b=c=O leads-to a= b=c =2. It is obvious that the system has terminating behaviors, for example, the following behavior (for brevity, we show only the sequence of events in a behavior): f ). CTo= (el, fl, gl, e2j 2jg2 It is also obvious that the system has nonterminating behaviors, for example, the infinite behavior (e], ez, el, ez, ..\" ). However, we cannot conclude from this behavior that the system does not satisfy \" A. Udaya Shankczr LO because it is not an allowed behavior (e.g., fl is continuously enabled but never occurs). We now disprove LO by demonstrating allowed behaviors that are nonterminating. In fact, we show something stronger, that the system can reach a state from where termination is impossible. Consider the following behaviors: After a certain point in behavior o-1, only el and e~are active. After a certain point in behavior ZTz, only el, ez, fl, and f2 are active. In both cases, g ~and gz are permanently disabled. Because g ~is the only event that can set x to 3, the system has no possibility of terminating after that point. u 6. DISTRIBUTED SYSTEM MODEL In this section, we specialize our system model for message-passing distributed systems. We consider a distributed system to be an arbitrary directed graph whose nodes are processes and whose edges are one-way communication channels. A channel can be either perfect or imperfect. A perfect channel is a FIFO buffer. An imperfect channel can lose, reorder, and/or duplicate messages in transit. The state transition system modeling the distributed system has a state variable for each channel indicating the sequence of messages traveling in the channel. IT For each process, there 's a set of nonauxiliary state variables. Additionally, the system can have other state variables that are auxiliary. 17The pract]ce of modehng a channel by the sequence of messages in transit has been used by Chandy and Mmra [ 1988] and m networking hterature (e.g., Knuth [ 1981] and Shankar and Lam [19831).\n\nAnother way to model a channel IS by the sequence of messages sent mto It and the sequence of messages received from It [ Hadpern and Owlckl 1983]. The state transition system has events for each process and for each imperfect channel; a perfect channel has no events (enqueuing and dequeuing of messages is done by send and receive primitives in process events). The events of an imperfect channel model the imperfections of the channel; they can access (read or write) only the channel state variable and auxiliary state variables. The events of a process can access only auxiliary state variables, the state variables of that process, and state variables of channels connected to the process.l~Furthermore, a process event can access an outgoing (incoming) channel state variable only by sending (receiving) messages. To formalize these constraints, let transit, denote the state variable for a ~. channe (Z, ,)) from process i to process j. Define the following operations: Send( transit,,, m ) ~transit,] -transit, j@(m) Remove ( transit,]) = transit,, ~tail( transit,,) 6.1 Blocking Channels We first consider distributed systems with blocking channels, i.e., where a channel can block a process from sending a message into it. Specifically, let state formula ready( transit,]) be true iff channel (i, j) is ready to accept a message from the process, for example, ready (transitlj) -Itransit, I < N. Each # event of process i is one o the following three types: -An internal event e (i.e., does not send or receive messages) has the enabled G P action = S form: lB In fact, these conditions can be relaxed further a process or channel event can read nonauxdlary state variables of other processes and channels provided them values are used only to update auxdlary state variables e q A send event e(m) that sends message m into an outgoing channel (i, j) has the form: enabled G P A ready (transit,j ) action = S; Send(transitl~, m ) A receive event e(m) that receives message m from an incoming channel (j, i) has the form: enabled E P A head(transitl, ) = m action E Remove( transit],); S where P and S do not access nonauxiliary state variables of other processes or channels.lg 6.2 Nonblocking Channels We next consider distributed systems with nonblocking channels, i.e., a channel never blocks a process from sending a message. Such a distributed system can be modeled as above, with ready( transit, ~) = true. However, in this case a simpler model can be used [Lamport 90]. We can classify the events of process i into those that receive a message and those that do not receive a message, as follows: q A receive event e(m) that receives message m from an incoming channel (j, i) has the form: enabled = P A head(transit~l ) = m action ~Remove( transit],); S q An event e that does not receive a message has the form: enabled = P action ~S where P and S are as in the blocking case above, except that S can now include send operations on outgoing channels. lgOf course, they can access auxiliary variables provided the auxiliary variable condition is satisfied. 6.3 Channel Fairness Requirements\n\nIn order to prove useful progress properties for a distributed system, it is generally necessary to assume some fairness requirement for every channel (i, j) of the system. For each message m that can be sent into channel (i, j), let E(m) denote the set of process events that can receive message m from channel (i, j). For any set of messages lV, let E(N) = U ~. ~E(m).\n\nWe say the receive events for channel (i, j) are always ready iff head(transitll) = m * enabled(E(m)) is invariant for the distributed system; that is, there is always an event ready to receive whatever message is at the head of channel (i, j). For every perfect channel (i, j), we assume the following fairness requirement: For any message set N, {E(N)} has weak fairness. Thus, if the receive events are always ready, any message in the channel is eventually received. For every imperfect channel (i, j), we assume the following fairness requirement: If the receive events for channel (i ,j) are always ready, then for every allowed behavior CT of the distributed system and for every message set N, if messages from N are sent infinitely often in a, then messages from N are received infinitely often in o. Thus, any message that is repeatedly sent is eventually received [Hailpern and Owicki 1983]. (This is similar to strong fairness, and it is not implied by weak fairness for {E(N)} for any message set N.) The above fairness requirements justify the following proof rule, where count (N) is a (auxiliary) variable indicating the number of times messages from N have been sent since the beginning of system execution. Leads-to Via Message Set Rule. Given a channel whose receive events are always ready and a set of messages N that can be sent into the channel, P leads-to Q is satisfied if the following are satisfied: (i) for every event e G E(i'V): {P}e{Q} (ii) for every event e @ E(N): ' {P}e{P v Q} This completes the proof because Al A Az implies AO, and each of Al and Az satisfies the invariance rule. Is Al ~Az the weakest state formula that satisfies the invariance rule and implies AO? See Note 3 in Appendix 1. u Proof of a Safety Property. Let us prove Inuariant(BO A Bl), where B() = consumed prefix-of produced Ill = Iproduced/ -Icon. sumedl < s -a. Because channel (1, 2) is a perfect FIFO buffer, we expect the following to be invariant: Bz G consunzed@transitl, ~= produced. Bz implies BO and ]producedl -Iconsunzecll = Itransitl,, 1. We know that Itransitl, ~] < s -a (from Al). The proof is complete, as summarized in the following marking: Bz = B. B2~Al=Bl u Proof of a Progress Property. Let us prove that LO holds, where Lo = Iproduced I z n leads-to Iconsumedl > n. We can establish LO, proceeding as in the bounded-buffer producer-consumer example. Define the following assertion: Ll = Iproducedl > n A Iconsunzedl = m < n leads-to Iproduced I > n A Iconsunzedl = m + 1. LO can be derived from LI using closure rules. LI holds via event set {RecDATA(data): data G DATA} because of I?z (make sure of this). c1 7.2 A Shortest-Distance Algorithm Consider a distributed system with an arbitrary but finite topology. Let the set of processes be {1, . . . . IV}, and let the set of channels be E G {1, . , N) x {1,..., IV} -{(i, i): i = I,..., N}. Associated with each channel (i, ,j) is a nonnegative length D(i, j). We say process i is reachable iff i = 1 or if there is a path in E from process 1 to process i. For each reachable process i, let D(i) indicate the length of a shortest path from process 1 to process i. We consider an algorithm that informs each reachable node of its shortest distance from process 1. Specifically, each process i maintains an estimate of the shortest distance from process 1 in a variable dist( i ). Process 1 starts the algorithm by sending on every outgoing channel (1, j) a message containing D( 1, j). When a process i receives a message d, it sends d + D(i, j) on every outgoing channel (i, j) iff d is less than dist(i). The algorithm specification follows, where i, j G {1,2, ..., N), and z is considered to be greater than any number. For convenience, we assume an initial state where process 1 has already started the algorithm. Process z state variable, initial condition, and events: dist( i ): real. Initially dist( 1) = O A [Vi # 1: dist(i) = CC] Rec,(J, d) enabled s head(translt,, ) = d action = Rernow( transit,,); if d < dzst ( L) then begin dist(t) ~d; forall(i, k)=El Send(transit, h, cZ+D(i, k)) end Channel (i, j), (i, j) ~E, state variable, and initial condition: transit,J: sequence of messages. Initially = ( D( 1, j)) A transltl,l transit,, = [V2# 1:()] Fairness requirements: Fairness requirements for the channels. Proof of a Safety Property. Let us prove that if dist (i ) + M, then i is reachable and dist ( i ) is the length of some 254 9 A. Udaya Shankar path from 1 to i, that is, Invariant, where: AO=dist(i)=d #xthere is a path from 1 to i of length d. AO holds initially. The following is a sufficient precondition of AO wrt an occurrence of Ret, ( j, c1) that changes dist(i): Al G d E transztl, a there is a path from 1 to L of length d. Al holds initially and is preserved by every event. This completes the proof, as summarized in the following marking: Inztial Ret, Au OK Al, A. Al OK Al u Proof of a Progress Property. Let us prove that every reachable process eventually learns its shortest distance, i.e., LO holds, where LO\n\nOne way to prove this is to consider a shortest path from process 1 to process i and establish that each process on this path eventually informs its successor on the path of the successor's shortest distance from process 1. In the rest of the proof, let i be a reachable process; let ( jO, . . . . j. ) be a shortest path from 1 to z where jfl = 1 and j. = i, and let k range over {O, . . . , n -1}. Define the following progress assertion:\n\nLO follows by closure of LI (specifically. using the chain rule with F( n -k ) -dist( jk ) = D( j~)).\n\nThus, it suffices to prove Li. Define state formula II(1) to be true iff the lth message in transit,,, ~h+, is D( jh+ ~), that is, H(l) = transitl,, ~, , ~1) = D(jk , ~). Define the following assertions, where for brevity we use X to denote dist(j~) = D(jt) A dzst(j}, ,1) > ll(j~, ~) A, -X=[S1: H(l)] Lz -X~H(l) A 1> 0 leads-to dist(jk+ ~) = D(jh , ,) V(XA~(/ -1)) Lz = X A H(0) leads-to dist(jfi+l) = D(j~+l) AJ satisfies invariance rule 1. Each of Lz and L~hold via event set {Recj,{jk + 1,\" )}. LI follows by closure of Inuarzant( AJ, L2, and Lj. u Proof of a Progress Property. Let us prove that the algorithm eventually terminates, i.e., L~holds, where Ld E Initial leads-to transit,, = {). Because of L ~, it suffices to prove the following: L~\n\nLet G denote the number of messages in transit in all channels. Define the following:\n\nLG\n\nG<n LG holds via event set {Ret,} using Al. Lb follows from closure of LG. n 7.3 A Termination Detection Algorithm for Diffusing Computations We consider an algorithm presented in Dijkstra and Scholten [ 1980] for detecting the termination of diffusion computations. Consider a distributed system with a set of processes {1, , . . . N} and a set of channels Ec{l, . . .. N}x{l. N}. ,N}-{(i, i):i= l,... , N} such that if (z, j) = E then (j, i) q E. * A. Ua?aya Shankar deficzt,: integer. Inltlally O. The number of messages sent by process z for which signals have not been received. engager,: {1,...N} U {zzzZ}. Initially engagerl = 1 A [tfi # l:t?ngager, = nil]. nL/ lff process z is disengaged. Local, enabled = actlL,et A P action = S Sendl( j, m) erzabled = actlle, A P actzon = Se?ld( transzt, , nz ); S; deficit, ~de~cit, + 1 Rec,(J, ?Tz ) enabled = heczd(transztJ, ) = m actiorz = Remoue( transLtJ, ); S; actiue, ~trac; if engagerr = nd then wzgager, F J else Send(translt,J, slgtzal) DeActzl~atel enabled = actlue, A p action = S; actzle, ~false RecSlgnal,(J) enabled = kead( transltJ, ) = signal action G R.enzoue(transitJ, ); deficltt G deficLtl -I DLsEngageL for L # I enabled = ~active, A engager, # nil A deficit, = O action G Send( transzt,l, szgnal ) where j = erzgager,; engager, * n d Channel (z, J), (z, J) E E, state variable, and initial condition: transztlJ: sequence of messages. Initially ( ), Fairness requirements: {Disengage,} has weak fairness, Fairness requirements for channels. Proof of u Safety Property. Let us prove that if deficitl = O and process 1 is not active, then the diffusion computation has terminated; i.e., no process is active, and no (diffusion computation) messages are in transit. Formally, let Termination = [Vi: ~active, ] A[v(z, j) GE:\n\nno messages in transit,]] , and let us prove In Ljarian t ( A{] ), where AO = deficztl = O A T actiuel * Termination.\n\nWe next define some functions on the system state: q F,j, for every (Z, J) E E, is 1 if engager, --i and is O if engager, + i.\n\nThe set of engaged processes, Engaged = {i: engager, # niz}.\n\nq\n\nThe set of engagement edges, Engagements = {(J\", L): engager, = L A i + nd} -{(1, l)}.\n\nNote that 1 is an engaged process and (1, 1) is not an engagement edge. Define the following: Al E deficit, = ~(, ~, ~~number of messages in transit,, + number of signals in transztll + F,,. Az = i G Engaged -{1} * there is a path of engagement edges from i to 1. Ay = activeh ~k q Engaged. Ab G deficith >0 ~k q Engaged. Al implies that if deficit, = O then process L has no incoming engagement edge. Az implies that the engaged nodes and the engagement edges form an in-tree rooted at process 1; recall that each engaged process other than 1 has exactly one outgoing edge and that process 1 has no outgoing edge. A3 and Ad imply that a disengaged process is not active and has zero deficit. It can be checked that Al satisfies invariance rule 1 and that Az A As A Ai satisfies invariance rule 1 given that Al is invariant. Also Al A AZ A As A Ad implies AO, as follows: Assume deficitl = O; because of Al and AZ, this implies that i G Engaged for i # 1, which implies 1 actiue, (from A~) and deficit, = O (from Ai ), which implies that no messages are in transit (from Al). The proof is summarized in the following marking, where we have abbreviated the event names: Reasoning for Concurrent Systems * 257 m DeAct RecSig DwEng Al NA Al Al Az NA NA Al AZ true NA true A. NA A. true A1AA2AA3~A,1-A0 u Proof of a Progress Property. Let us prove that if the diffusion computation has terminated, then eventually deficitl becomes O; that is, Lo holds, where L,, G Termmation leads-to deficit ~= O.\n\nWe shall prove that once Termination holds, the leaf nodes of the engagement tree keep leaving the engagement tree until it consists of only process 1. Define the following functions on the system state:\n\nq The set of leaf nodes, Leaoes = {i: i q Engaged A [Vj: (j, i ) @ Engagements]}.\n\no State formula II( n, m ) = true iff IEngagedl = n and (E, ~,,,.,,,, deficitl ) = m. Define the following progress assertions: LI = Termination ~H( n, m) ~f2>l Am>0 leads-to Term ination A(~(n, m -1) V [31: H(~2 -1,1)]) Lg = Termination A H(I, m ) A m > 0 leads-to Termination A H(I, m -1) L{ z Termination A H(n, O) A n > 1 leads-to Termination A [21: H(n -1,1)]\n\nEach of LI and Lj holds via event set {RecSignal,: i = Leaues}. Lg holds via event set {DisEngage,: i c Leaues}. In each case, the event set is not empty because Leaves is never empty. Consider a lexicographic ordering of integer 2-tuples; i.e., (j, k) < (n, m) iff j < n or j = n A k < m. Then, we get the following from the closure of LI, Lz, and La: LJ = Termination A H( n , m) A (n, m) > (1, O) leads-to Termination A[~(j,~) < (n, m): H(j, k)l Using the chain rule on this, we get L~E Termination A H( n, m ) leads-to H(l, O) Because process 1 is always engaged, [3(n, m) > (1, O): H(~2, m)] is invariant, From the definition of H( n, m), we have that H(l, O) implies deflcitl = O. Combining these with L~, we obtain LO. u 8. DISCUSSION In this tutorial, we focused on the following: Given a concurrent system S and desired properties P, express P in terms of safety and progress assertions and prove that S satisfies P using a set of proof rules. We modeled a system by a set of state variables, a set of events each with an enabling condition and an action, and a set of fairness requirements on the events. We used only invariant and leads-to assertions (but other kinds of assertions can be easily added). We introduced auxiliary state variables whenever needed to express a correctness property. As discussed in Section 3.4, our system model, assertion language, and proof rules are similar to those of other authors, for example, Lamport [ 1989; 1990], Lynch and Tuttle [1987], Manna and Pnueli [1984; 1992], Chandy and Misra [1986; 1988], Back and Kurki-Suonio [1988], and Abadi and Lamport [1988; 1990]. The formalism in this tutorial comes to a large extent from Lam and Shankar [1990]. These references also contain many examples of assertional analyses.\n\nOther examples may be found in Dijkstra [1965;1976;1977], Dijkstra\n\nand Schloten [ 1980], Dijkstra et al. [ 1978; 1983], Drost and Leeuwen [1988], Drost and Schoone [1988], Hailpern and Owicki, [1983], Knuth [1981], Lamport [ 1982; 1987], Murphy and Shankar [1991], Andrews [1989], Schneider and 258 q A. Udaya Shankar Andrews [1986], Schoone [1987], Shankar [1989], Shankar and Lam [1983; 1987], Tel [ 1987], Tel et al. [ 1988], and AIaettinoglu and Shankar [ 1992] (this list is only a sampling). Assertional reasoning allows the proof of a system property to be presented at a convenient level of detail, by omitting obvious details of proof rule applications. (Of course, what is obvious to one person may not be so to another person. ) The difficulty in proving a system property P is in coming up with additional properties Q such that Q satisfies the proof rules and implies P. The most successful approach to obtaining the additional properties of Q seems to be to develop them while developing the system, as demonstrated by Dijkstra [ 1976; 1977] in his numerous program derivations; see also his paper \"Two Starvation-Free Solutions of a General Exclusion Problem,\" EWD 625, Plataanstraat 5,5671, Al Nunen, The Netherlands, date unknown. In this approach, one starts with a skeleton system and a set of desired properties and successively adds (and modifies) states variables, events, and desired properties. The process ends when we have a system and a set of properties that satisfy the proof rules. This approach has been formalized into stepwise refinement techniques by several authors. See, for example, Abadi and Lamport [1988], Back and Kurki-Suonio [ 1988], Back and Sere [ 1990], Chandy and Misra [ 1986; 1988], Lamport [ 1983; 1989], Lynch and Tuttle [ 1987], and Shankar and Lam [ 1992]. Typically, a concurrent system S consists of smaller concurrent systems S'l, . . . . S. that interact via messagepassing primitives (mcludmg procedure calls) or shared variables. (The structure can be hierarchical in that S[ can itself consist of concurrent systems.) For example, a data transfer protocol consists of a producer system, a consumer system, and two channel systems; an operating system may consist of a process management system, a memory management system, and a file system. We can analyze such a composite system S by ignor-ing its subsystem structure (and that is what we did with distributed systems in this tutorial). Although this is efficient for small systems, it does not generally scale up to larger systems. A composi- tional approach is required, where we can prove that S satisfies a property P in two stages: first prove that each S, satisfies some property P,, and then prove that the P,'s together imply P. For such an approach to work, we need a composition theorem of the kind: if each S, satisfies P,, then the composition of the S,'s satisfies the conjunction of the P,'s. It turns out that such composition theorems are not a straightforward matter. Typically, each P, consists of an assumption on the environment of S[ and a requirement on S,, and the difficulty is in avoiding circular reasoning of progress properties. There are several compositional approaches based on temporal logic in the literature. See, for example, Abadi and Lamport [ 1990], Chandy and Misra [ 1988], Lam and Shankar [ 1992], Lynch and Tuttle [1987], and Pnueli [ 1984]. Each places certain restrictions on the types of properties and compositions allowed. So far, we have thought of P, as a desired property of S,, that is, a property of interest to the environment of S,. Let us go one step further and think of an embellished Pl, say E,, that includes all (and only those) properties of interest to the environment of S,. In addition to safety and progress properties, E, must include information needed for composing S, with systems in its environment, such as which events and variables of S, are visible to the environment, which transitions are controlled by the environment, and which by S,, etc. Given E,, we can think of S, as an implementation of E,. More importantly, we can replace S, by another implementation T, that satisfies E,, without affecting the properties of S. Such a compositional approach is very useful for building, maintaining, and updating large concurrent systems. Perhaps the most difficult step in applying this approach is in identifying which properties of a system S, are important to its environment. Such compositional theories are presented. See, for example, Abadi and Lamport [1990], Chandy and Misra [1988], Lam and Shankar [1982], and Lynch and Tuttle [1987]. APPENDIX 1 Note 1 Let us go back to the point just after we obtained Al and see whether a bruteforce application of the heuristic would yield Az. At this point, (Al, Produce(data)) is unmarked. wp(Produce(data), Al) = enabled( Produce(data)) * wp( action( Produce( data), Al ) = numspaces > 1 * (numspaces -1 >l*lbufferl+l<N-1) = nurnspaces 2 1 ~numspaces > 2 -Ibufferl <N-2 -nurnspaces ~2 * Ibufferl < N -2 Thus, we have a new invariant requirement: As E nurnspaces 22 * Ibufferl < N -2. Note that A:] is a weakest precondition of AO with respect to two successive occurrences of Produce, i.e., wp( Produce, wp(Produce, Ao)). If we consider a weakest precondition of AO with respect to k occurrences of Produce, where 1 < k < numspaces, we get the following invariant requirement: A~G nurnspaces > k * Ibufferl < N -k. Observe that Al * Al[k/k -1]. So there is no need to consider Al, for every k. It suffices to consider Ai[ k/numspaces ], which is numspaces 2 numspaces Ä¨buffer I < N -numspaces. Because the antecedent is always true, the above is equivalent to its consequent, which yields: As = Ibuffei -+ nurnspaces < N It is easy to see that Initial * As, {As}produce( data){A~}, and {A~}Con -sume(data){A~} hold. Also As * AO holds. Thus, As is a weaker substitute for Az. It is probably fair to say that when we obtained Az, we felt that there is nothing weaker that satisfies AO and invariance rule 1. Now we see that this is not true. This is typical of how weakest preconditions throw additional light on even the simplest algorithms. Another way to think of it is that once we understand an algorithm, we usually know more about it than we need to. Note 2 Let us go back to the point just after we obtained BI and see if a brute-force application of the heuristic would yield Bz. We derive the following weakest precondition of BO wrt k occurrences of Consume, where k = Ibuffer I (similar to the derivation of As above):\n\nBA ~consumed@ buffer prefix-of produced.\n\nWe next obtain a weakest precondition of B~wrt Produce(data): u)p(Produce(data), Ba ) * consumed @buffer @ ( data ) prefix-of produced@{ data ) N consumed@ bu ffer prefix-of produced (i) ((lconsumedl + Ibufferl < Iprodz~cedl ~data = produced( consumedl + Ibufferl + 1)) V (ii) ( Iconsumedl + Ibufferl = Iproduced))\n\nAbove, disjunct (i) requires the data item produced to equal a previously produced data item, Because this cannot be enforced in the current system, the only way to achieve the weakest precondition is to enforce disjunct (ii), which yields Bb = consumed@ buffer = produced.\n\nSo in this case, brute force has yielded the same invariant requirement as obtained by using intuition, i.e., Bz.\n\nACM ComputmgSurveys, Vol 25, No 3, September\n\nComput,ngSurveys, Vol 25, No 3, September 199.3\n\nACM ComputmgSurveys, Vol 25, No 3. September\n\n3, September\n\nSeptember\n\nACIVI ComputmgSurveys, Vol 25, No 3, September"
}