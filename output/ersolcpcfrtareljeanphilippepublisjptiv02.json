{
    "title": "Real Time Obstacle Detection in Stereovision on Non Flat Road Geometry Through \"V-disparity\" Representation",
    "publication_date": "1998",
    "authors": [
        {
            "full_name": "Raphael Labayrade",
            "firstname": "Raphael",
            "lastname": "Labayrade",
            "affiliations": []
        },
        {
            "full_name": "Didier Aubert",
            "firstname": "Didier",
            "lastname": "Aubert",
            "affiliations": []
        },
        {
            "full_name": "Jean-Philippe Tarel",
            "firstname": "Jean-Philippe",
            "lastname": "Tarel",
            "affiliations": []
        }
    ],
    "abstract": "Many roads are not totaly planar and often present hills and valleys because of environment topography. Nevertheless, the majority of existing techniques for road obstacle detection using stereovision assumes that the road is planar. This can cause several issues : imprecision as regards the real position of obstacles as well as false obstacle detection or obstacle detection failures. In order to increase the reliability of the obstacle detection process, this paper proposes an original, fast and robust method for detecting the obstacles without using the flat-earth geometry assumption; this method is able to cope with uphill and downhill gradients as well as dynamic pitching of the vehicle. Our approach is based on the construction and investigation of the \"v-disparity\" 1 image which provides a good representation of the geometric content of the road scene. The advantage of this image is that it provides semi-global matching and is able to perform robust obstacle detection even in the case of partial occlusion or errors committed during the matching process. Furthermore, this detection is performed without any explicit extraction of coherent structures such as road edges or lane-markings in the stereo image pair. This paper begins by explaining the construction of the \"v-disparity\" image and by describing its main properties. On the basis of this image, we then describe a robust method for road obstacle detection in the context of flat and non flat road geometry, including estimation of the relative height and pitching of the stereo sensor with respect to the road surface. The longitudinal profile of the road is estimated and the objects located above the road surface are then extracted as potential obstacles; subsequently, the accurate detection of road obstacles, in particular the position of tyre-road contact points is computed in a precise manner. The whole process is performed at frame rate with a current-day PC. Our experimental findings and comparisons with the results obtained using a flat geometry hypothesis show the benefits of our approach. Future work will be concerned with the construction of a 3D road model and the test of the system for Stop'n'Go applications.",
    "full_text": "I N the field of stereo vision-based road obstacle detection, a number of assumptions are frequently made about the environment in order to facilitate the process. The majority of existing techniques assumes that the road is planar [1] [2]. Some techniques assume that there is a constant plane [3], others perform a dynamic estimate of the inclination of the road plane and the relative height of the stereoscopic sensor [4] [5]. In [4], lane-markings are extracted and matched between the left and right images in order to obtain the parameters of the road plane; however this method is limited to the precision of lane-markings extraction tech-1 v is the ordinate of a pixel in the (u,v) image coordinate system niques which are sometimes not reliable (poor quality of lane-markings, etc.). Another possibility is to model the suspensions of the vehicle; however the imperfections of the road surface (holes etc.) can not be taken into consideration. This paper present a method for robustly estimating the road parameters -including vehicle pitching-which is not affected by these problems. Furthermore, while the hypothesis of a flat road geometry is reasonable in the vicinity of the vehicle, it may not be valid for the entire part of the road visible in the image. Obstacle detection is therefore only reliable on the locally planar area, which limits the detection distance. In order to cope with non flat geometry roads, this paper present a robust method for locally estimating the longitudinal road profile. Our method does not need any extraction of lane-markings but exploit all the relevant information in the image (texture of the road, shadows, road edges, etc.). Thanks to this estimation, the result of the obstacle detection process is far more reliable and accurate.\n\nOur approach is based on the construction and subsequent processing of the \"v-disparity\" image, which provides a good and robust representation of the geometric content of road scenes. This paper is structured as follows: Section II presents the models we have used with respect to the stereoscopic sensor and the longitudinal road profile. Section III explain the construction of the \"v-disparity\" image and describe its main properties. Section IV presents our method for performing obstacle detection. Experimental results are shown including comparisons with the results obtained using a flat road geometry assumption. Lastly, Section V concludes the paper and discusses the potential for future work.\n\nThe two image planes of the stereo sensor are supposed to belong merely to the same plane and are at the same height above the road (see Fig. 1). This camera geometry means that the epipolar lines are parallel.\n\nIn what follows we will need to perform positioning in three coordinate systems shown in Fig. 1: R a (absolute), R cr (right camera) and R cl (left camera). R a is the road coordinate system. The other parameters on the figure are as follows: • θ : is the angle between the optical axis of the cameras and the horizontal, • h : is the height of the cameras above the ground, • b : is the distance between the cameras (i.e. the stereoscopic base).\n\nIn the camera coordinate system, the position of a point in the image plane is given by its coordinates (u, v). The image coordinates of the projection of the optical center will be denoted by (u 0 , v 0 ), assumed to be at the center of the image. The intrinsic parameters of the camera are f (the focal length of the lens), t u and t v (the size of pixels in u and v). We also use α u = f/t u and α v = f/t v . With the cameras in current use we can make the following approximation:\n\nUsing the pin-hole camera model, a projection on the image plane of a point (X,Y,Z) in R a is expressed by:\n\nOn the basis of Fig. 1, the transformation from the absolute coordinate system to the camera coordinate system is achieved by the combination of a vector translation\n\n, and a rotation around X by an angle of -θ. Let T i denote the translation matrix, R the rotation matrix and D i = RT i . In homogeneous coordinates, the different transformation matrices are therefore:\n\nwhere i is equal to r, l (right or left).\n\nIt is necessary to perform a perspective projection in order to express fully the coordinates of the points in the image plane coordinate system. The perspective projection matrix M proj is expressed as follows:\n\nFinally, we obtain the matrix of transformation T ri from the absolute coordinate system R a to the image coordinate system i (i is equal to l or r):\n\nIf P is a point with homogeneous coordinates (X, Y, Z, 1) T in R a , its homogeneous coordinates in the image coordinate system i are:\n\nWe can then compute the non-homogeneous (u, v) coordinates of P as:\n\nIn what follows we will consider that the road is modelled as a succession of parts of oblique planes in R a with respect to the plane of the stereoscopic sensor. This model will allow us to extract the longitudinal profile of the road as a piecewise linear curve (see Section IV.A). Our main assumption is only that the profile curvature is of constant sign.\n\nWe suppose that a disparity map I ∆ has been computed from the stereo image pair (see Fig. 6 Up Left). For example, this map is computed with respect to the epipolar geometry; the primitives used are horizontal local maxima of the gradient; matching is local and based on normalized correlation around the local maxima.\n\nLet H be the function of the image variable I ∆ such that H(I ∆ ) = I v∆ . We call I v∆ as the \"v-disparity\" image (see Fig. 6 Up Right ). H accumulates the points with the same disparity that occur on a given image line i. For the image line i, the abscissa u M of a point M in I v∆ corresponds to the disparity ∆ M and its grey level i M to the number of points with the same disparity ∆ M on the line i : i M = P ∈I∆ δ vP ,i δ ∆P,∆M where δ i,j denotes the Kronecker delta.\n\nOnce I ∆ has been computed, I v∆ is built by accumulating the pixels of same disparity in I ∆ along the v axis (see Fig. 6 Up).\n\nFor a given image line, the grey level of a point in I v∆ expresses the number of coherent points with disparity ∆ M in the same image line of the pair of stereo images. The construction of I v∆ in facts amounts to a global analysis of an image line in I Gr : we determine how this image line matches the same image line in I G l , for different horizontal offsets, that is to say for different disparities. In this manner, the horizontal order constraint is satisfied and the matching is semi-global (global for an image line).\n\nLet P be a point with coordinates (X, Y, Z, 1) T in R a .\n\nFrom system (6), the ordinate of the projection of this point on the left or right image is\n\nMoreover, the disparity ∆ of the point P is:\n\nFrom ( 7) and ( 8), the plane with the equation Z = aY +d in R a is projected along the straight line of equation ( 9) in the \"v-disparity\" image:\n\n(9) Thus, a surface which is formed by a succession of parts of planes is therefore projected as a piecewise linear curve.\n\nA.1 Case of a flat road geometry.\n\nThe plane of the road is projected in I v∆ as a straight line with mean slope 0.70 (considering that mean values are b = 1 m, h = 1.4 m, θ = 8.5 o ). The longitudinal profile of the road is therefore a straight line in I v∆ . Robust detection of this straight line can be achieved by applying a robust 2D processing to I v∆ . In our application we use a Hough transform, the bounds of Hough space depending on the extreme values of h and θ that are tolerated.\n\nThe pitching and relative height of the stereo sensor are dynamically estimated by simply extracting the straight line of the road (see Fig. 2). Let c r denote the slope and v or the value of v for ∆ = 0 on the straight line of the road; we can obtain the following expression for θ and h: A.2 Case of a non flat-earth road geometry.\n\nThe road is modelled as a succession of parts of planes. As a matter of fact, its projection in I v∆ is a piecewise linear curve. Computing the longitudinal profile of the road is then a question of extracting a piecewise linear curve in I v∆ . Any robust 2D processing can be used. In our application we currently use the Hough Transform. θ and h can still be estimated. Indeed, in the vicinity of the vehicle, the road is planar. Thus, it is possible to extract the projection of the planar part of the road (which is a part of a straight line in the right partion of I v∆ ) and estimate θ and h.\n\nTransform.\n\nThe bounds of Hough space can be limited considering the maximal 3D road slope tolerated. In the considered area, the k highest Hough Transform values are retained (in our application, k is taken between 5 and 12). The k selected points correspond to k straight lines in I v∆ . The piecewise linear curve researched is either the upper (when approaching a downhill gradient) or the lower (when approaching an uphill gradient) envelope of the family of the k straight lines generated. We choose between these two as follows: I v∆ is investigated along both curves extracted and a score is computed for each : for each pixel on the curve, the corresponding grey level in I v∆ is accumulated. The curve is chosen with respect to the best score obtained (see Fig. 3).\n\nOnce the longitudinal profile of the road has been extracted, the disparity values on the road surface are known for each scanning line (it is exactly the disparity value corresponding to the longitudinal profile curve extracted for the scanning line in question). Let ∆ i denote this value. Thus, it is straightforward to extract the obstacles from the disparity map I ∆ already computed: for a given scanning line, pixels whose disparity is equal to ∆ i are located on the road surface; other pixels belong to potential obstacles. On Fig. 4, note that the vehicle located at almost 80 meters is well perceived as a potential obstacle.\n\nOnce the obstacle areas have been computed, the free space on the road surface can be extracted (see also [6][7]), using a growing area algorithm (see Fig. 6 Down). The part of the image corresponding to the free space area can be used, for example, for extracting the lane-markings in more suitable conditions.\n\nBy definition, the points located on the horizon line are at a distance of infinity from the vehicle. Consequently, from (8), their disparity is nil. Furthermore, these points belong to the road. In \"v-disparity\" space, the position of the horizon line is therefore given by the value of v corresponding to ∆ = 0 on the straight line of the road.\n\nOn Fig. 5, the maximum difference between the position of the horizon line when manually estimated and when automatically estimated does not exceed 2 pixels. Middle: the corresponding obstacle areas computed when assuming that the road is planar. Down: the corresponding obstacle areas computed when there is no flat geometric assumption. In the first case, lane-markings located a few meters in front of the vehicle are considered to belong to obstacles while there is not such problem in the second case. H I∆ Iv∆ H I∆ Iv∆\n\nFig. 6. Up Left: the disparity map (the grey level increases the higher the disparity). Up Right: the corresponding \"v-disparity\" image computed from the disparity map. Down: in grey, the free space on the road surface. The border of the black area on the Low Right corresponds to the longitudinal profile of the road extracted from the \"v-disparity\" image and is not a straight line but a piecewise linear curve.\n\nAn obstacle is characterized by a vertical plane. With the mean camera position used, the corresponding straight line is quasi-vertical in I v∆ . It can be extracted by locating maxima on a histogram that sums the pixels in each column of I v∆ .\n\nThe tyre-road contact point of a vehicle is located at the intersection between the surface of the road and the vertical plane, and therefore, in I v∆ it is the intersection between the longitudinal profile of the road and the quasi-vertical straight line corresponding to the rear of the vehicle (see Fig. 7). Fig. 8 shows the result of the estimation of the tyre-road contact point on a non flat road geometry over time. Vehicle is located at about 80 m in front of our vehicle. It should be noted that even if the disparity value of the lower parts of the vehicles is erroneous, the position of tyre-road contact point will still be estimated correctly as the point of intersection between the \"obstacle\" plane projection and of the road longitudinal profile.\n\nThe alignments in I v∆ corresponding to the longitudinal profile of the road or to obstacles can be detected by robust methods such as the Hough transform. Thus, the presence of several alignments in I v∆ merely affects the precision in which they are extracted. Furthermore, the identification of 2D alignments means that only the structures which are globally coherent in 3D space are selected and ensures that detection is robust to partial occlusions.\n\nIt should also be noted that:\n\n• the construction of I v∆ required no explicit extraction of coherent structures in the left and right images. This increases the robustness of our approach as the extraction of coherent structures in 2D images is often a source of errors. Furthermore, all the information in the disparity map I ∆ is exploited and the accumulation performed by H increases the density of the alignments in I v∆ . Any matching errors that occur when I ∆ is computed cause few problems as the probability that the points involved will generate coincidental alignments in I v∆ is low.\n\n• no back projection that is likely to reduce precision or amplify noise due to discretization is involved in the construction of I v∆ .\n\n• I v∆ corresponds to the image of a cross-section through the (u, v, ∆) space, in a vertical plane which is oriented in the direction of the optical axis of the camera. All the matched points are accumulated onto this plane. Thus, the road obstacles, which are orthogonal to this cross-section plane, generate dense alignments as they are observed edge on. The other objects -for example tree lines, buildings, etc.-only generate diffuse areas in I v∆ as they are not orthogonal to the plane of the cross-section. For this reason the projection of these planes has little effect on the extraction of meaningful information (road profile, obstacles).\n\n• our method works whatever the robust process used for computing the disparity map or for processing the \"vdisparity\" image.\n\nThe whole process for extracting the longitudinal profile of the road and computing the tyre-road contact points is performed within 40 ms with a current-day PC. The hardware used for the experiments is a Pentium IV 1.4 GHz running under Windows 2000. Images are grabbed using a Matrox Meteor II graphic card. The focal length of the lens is 8.5 mm. Image size is 380x289.\n\nIn this paper we have described a fast, accurate and robust method for detecting the road obstacles either on a flat road geometry road or on a non flat road geometry using stereo-vision. The detection process is based on the construction and the processing (through a Hough transform) of the \"v-disparity\" image. This image provides a 2D summary of all the information that is required in order to rapidly detect and robustly estimate the position of obstacles even in the event of partial occlusion or errors committed during the matching process. Furthermore, it provides semi-global matching and reveals the matches which are the most coherent globally in the 3D road scene. The longitudinal profile of the road is extracted precisely. All other information concerning obstacles are then deduced in a straightforward manner : obstacle areas, free space on the road surface, position of tyre-contact points. This detection is performed without any explicit extraction of specific structures (road edges and lane-markings, etc.) but exploits all the relevant information in the stereo image pair. Computational time does not exceed 40 ms for images of size 380x289 on a current day PC with no special hardware.\n\nThe system will be tested on our experimental vehicules for Stop'n'Go applications. Future work will also be concerned with the accurate extraction of lane-markings, the detection of obstacles in our lane, and the construction of a 3D road model. The matching process could also be performed in a different manner: instead of basing this process on solely the maximum of correlation (which sometimes leads to the lost of good matches) it would be possible to consider the k best matches. Very fast disparity image computation techniques will also be tested, even at the cost of obtaining disparity maps of poorer quality, since our method is likely to cope with such poor disparity maps. The generalization of our method to any accumulation axis (and no longer the v axis) can lead to the estimation of roll and yaw rate values. Subsequent research will tackle this problem. The precise analysis of road scenes, including roll and yaw rate estimation could thus be achieved in real time."
}