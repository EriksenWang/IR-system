{
    "title": "Generation of Object-Centric Datasets with Adaptive Sky",
    "publication_date": "2008-05-13",
    "authors": [
        {
            "full_name": "Michael C Burl",
            "firstname": "Michael C",
            "lastname": "Burl",
            "affiliations": [
                {
                    "organization": "Jet Propulsion Laboratory, California Institute of Technology",
                    "address": {
                        "city": "Pasadena",
                        "postcode": "91109"
                    }
                }
            ]
        },
        {
            "full_name": "Michael J Garay",
            "firstname": "Michael J",
            "lastname": "Garay",
            "affiliations": [
                {
                    "organization": "",
                    "address": {
                        "city": "Raytheon Pasadena",
                        "postcode": "91101"
                    }
                }
            ]
        },
        {
            "full_name": "Clare Averill",
            "firstname": "Clare",
            "lastname": "Averill",
            "affiliations": [
                {
                    "organization": "",
                    "address": {
                        "city": "Raytheon Pasadena",
                        "postcode": "91101"
                    }
                }
            ]
        },
        {
            "full_name": "Benjamin Bornstein",
            "firstname": "Benjamin",
            "lastname": "Bornstein",
            "affiliations": [
                {
                    "organization": "Jet Propulsion Laboratory, California Institute of Technology",
                    "address": {
                        "city": "Pasadena",
                        "postcode": "91109"
                    }
                }
            ]
        },
        {
            "full_name": "Lukas Mandrake",
            "firstname": "Lukas",
            "lastname": "Mandrake",
            "affiliations": [
                {
                    "organization": "Jet Propulsion Laboratory, California Institute of Technology",
                    "address": {
                        "city": "Pasadena",
                        "postcode": "91109"
                    }
                }
            ]
        },
        {
            "full_name": "Yi Wang",
            "firstname": "Yi",
            "lastname": "Wang",
            "affiliations": [
                {
                    "organization": "California Institute of Technology",
                    "address": {
                        "city": "Pasadena",
                        "postcode": "91125"
                    }
                }
            ]
        },
        {
            "full_name": "Justin Ng",
            "firstname": "Justin",
            "lastname": "Ng",
            "affiliations": [
                {
                    "organization": "California Institute of Technology",
                    "address": {
                        "city": "Pasadena",
                        "postcode": "91125"
                    }
                }
            ]
        }
    ],
    "abstract": "Adaptive Sky is an ESTO-funded Advanced Information Systems Technology activity that is developing software to enable multiple sensing assets to be dynamically combined into sensor webs. The ASky feature correspondence toolbox consists of a variety of methods for automatically relating the observations of one instrument at time t to the observations of another instrument at time t'. A key end product from this task will be the ability to generate objectcentric datasets in which observations from multiple satellite and in-situ assets are organized not merely by the instrument packaging scheme (e.g., granules, blocks, images, swaths) or by spatial-temporal address (lat, lon, time), but by association with particular physical objects and processes. We have produced an early demonstration of this concept combining selected Adaptive Sky components to identify, track, and reacquire volcanic ash clouds generated by the October 2007 eruption of Bezymianny in Kamchatka, Russia. The wide area coverage and high temporal sampling of GOES coupled with ASky tracking capabilities provides a bridge between the less frequent overpasses of NASA's polar orbiting satellites. With this approach, a rich objectcentric dataset including measurements from at least five different instruments on four different spacecraft platforms was obtained covering a time span of approximately 30 hours and movement of the ash clouds over 400km from the eruption site. Future work includes combining overhead satellite observations of clouds with ground-based measurements.",
    "full_text": "The Earth Observing System (EOS) was conceived by NASA in the late 1980's as a series of missions to increase scientific understanding of the Earth and its processes through the use of new, sophisticated spaceborne sensors [9]. The funda-mental importance of using multiple instruments to measure different aspects of the Earth system was recognized early on and shaped today's EOS, which includes a wide variety of instruments such as the Moderate Resolution Imaging Spectroradiometer (MODIS), the Multi-angle Imaging SpectroRadiometer (MISR), the Cloud-Aerosol LIdar with Orthogonal Polarization (CALIOP), the Cloud Profiling Radar (CPR), high-resolution hyperspectral imagers (e.g., ASTER and Hyperion), and many others. A new group of innovative instruments, such as DESDynI (interferometric synthetic aperture radar), ACE (backscatter lidar, multiangle polarimeter, and Doppler radar), and 3D-Winds (Doppler lidar), is currently under study in response to priorities identified in the Decadal Survey by the National Academy of Sciences [11].\n\nDespite this impressive collection of sensing assets, much of the potential of EOS has not been realized as few studies combine high-resolution information from multiple instruments. Part of the problem can be traced to the way in which data analysis is funded, with instrument-specific science teams basically doing stovepipe work on the data collected by \"their\" instrument. Additionally, the organization of the collected data into very different, instrument-specific packaging schemes such as granules, blocks, images, and swaths hinders joint studies. Even two imaging instruments on the same spacecraft, such as MODIS and MISR on Terra, use completely different schemes to break up their data into manageable chunks. Just getting the data from these two instruments, which are hosted on the same spacecraft, to \"play together nicely\" is a challenge.\n\nTimestamping and georeferencing to lat-lon-time coordinates can alleviate some of the problems; however, this spatio-temporal addressing approach works best for ingestion into coarse-grained models such as Global Climate Models (GCMs), which may use 250km coarsely-lumped cells, or with phenomena or processes that are spatially stationary. Many important natural objects, such as hurricanes, tornadoes, thunderstorms, clouds, pollution, volcanic ash, bird flocks, algae blooms, and fires, occur on finer spatial scales and are not bound to any particular (lat, lon) location. To better understand and model such phenomena, convenient access to the relevant data is required, but this step is more complex than simply querying to obtain the recorded measurements at a specific grid location. Going a step further, one realizes that just working with the data after it has been collected may be too late. A recent, front-page feature on the Cloud-Sat website (archived at [10]) highlighted a CPR slice taken through an active severe thunderstorm complex that spawned over 100 tornado reports according to preliminary reports by the Storm Prediction Center (SPC). Numerous fatalities and significant property damage were attributed to this storm system. The CPR image, while visually impressive, was literally a \"one in a thousand\" shot. The SPC storm reports for this date (available online at [12]) list a total of 524 events, including 131 tornado reports, 267 severe and damaging wind reports, and 126 reports of large hail. Restricting these events to Â±15 minutes of the A-Train overpass, which includes both CloudSat and the MODIS instrument on the Aqua satellite, leaves 23 reports of all types, or just over 4% of the total, including four tornado reports and 19 severe and damaging wind reports. The 2330 km wide swath of MODIS encompasses all these events. However, only a single, severe and damaging wind report falls within even 10 km of the effective 1 km swath of the CPR within this time window. Even though this was a significant severe weather outbreak with a large number of damage reports, the CPR directly observed about 0.2% of the total events and only 4% of the events observed by the MODIS instrument.\n\nDynamically combining instruments into sensor webs offers the possibility of obtaining targeted measurements of specific phenomena. By using a variety of instruments with different observational characteristics, we can hope to exploit the strengths while overcoming the weaknesses of each instrument. Further, sensor webs can enable quick reaction to short-lived, or otherwise high-value, e.g., dangerous, objects. Moreover, by tracking individual objects -such as clouds -over time, sensor webs can sample their temporal evolution from multiple viewpoints. This, in turn, may provide insights into important underlying dynamics and yield a more unified, integrated, and comprehensive view of important geophysical processes that are currently poorly understood and/or modeled.\n\nAdaptive Sky, while not a sensor web per se, attempts to provide one piece of the technological infrastructure for rapidly developing new sensor web applications. Section 2 provides a high-level overview of Adaptive Sky. Further details are available in [2,8]. Section 3 describes a demonstration sensor web scenariofoot_0 in which multiple ash clouds generated by the eruption of Bezymianny Volcano on the Kamchatka Peninsula on October 14, 2007 were tracked using Geostationary Operational Environmental Satellite (GOES) brightness temperature difference (BTD) images and reacquired using instruments on both the Terra satellite and the A-Train group. Further technical details are available in [3]. Section 4 describes a future application of Adaptive Sky to combine overhead satellite observations with measurements from ground stations. Section 4 summarizes and concludes the paper.\n\nThe central element of Adaptive Sky is a robust feature correspondence toolbox that includes a variety of methods for automatically relating the observations of one instrument at time t to the observations of another instrument at time t'. A detailed set of scientific use scenarios was developed and used to drive the development of the initial toolbox capabilities [2]. Thus, the toolbox contains a mixture of purely data-driven methods (e.g., featurebased image registration, video stabilization, segmentation), as well as hybrid approaches that utilize metadata and ancillary information (e.g., sensor footprint collisions, open-loop georeferencing based on sensing geometry and imaging parameters, multiobject tracking using dynamical models). At a recent checkpoint the toolbox contained an estimated 20,000 source lines of code (SLOC), with a well-documented applications programmer interface (API) helping to insure that future Earth Science sensor webs will be able to leverage the toolbox in much the same way that the numerical computing community has leveraged tools such as the LINear Algebra PACKage (LINPACK) [6] and Numerical Recipes [7]. In addition to the main library, the ASky toolbox contains several standalone example programs and source code demonstrating the library's major features and capabili- ties. Additional utilities (e.g., command-line parse, image input/output) are included in a separate library (libasky utils), but are not part of the parsimonious libasky library.\n\nComponents from the Adaptive Sky toolbox were combined to enable a demonstration sensor web scenario in which multiple ash clouds generated by the eruption of Bezymianny Volcano were tracked using GOES BTD images and reacquired using instruments on both the Terra satellite and the A-Train group. The basic strategy leverages the wide area coverage/high temporal sampling of NOAA's geostationary GOES-West satellite and the high spatial resolution/specialty instruments on NASA's polar orbiting satellites (e.g., Terra and the members of the A-Train).\n\nThis demonstration scenario definitively shows how sensor webs can overcome the limitations of individual instruments to provide a more complete, object-centric perspective. Following an initial trigger signal (hypotheticallyfoot_1 from the IRIS Global Seismographic Network (GSN), which is used to monitor large earthquakes [13]; a magnitude 4.2 earthquake was indeed detected in the vicinity of Bezymianny prior to the eruption event), we use GOES BTD image sequences to track features (volcanic ash clouds) over time. The IRIS GSN has the advantage of global coverage, very rapid detection of events, but limited perspective on the nature of the event and no information on what is happening above the ground. The geostationary GOES satellites have the advantage of wide area coverage, relatively high temporal sampling, and the ability to dwell over an area of interest; on the other hand, they have the disadvantage of limited spatial resolution due to distance and lack of specialty instruments. NASA's polar orbiters have the advantage of high spatial resolution and the availability of a variety of specialty instruments such as MISR, CALIOP, and CPR; the main disadvantage is that these sensors pass overhead quickly and do not revisit a site for considerable time (poor temporal sampling).\n\nTo tie all these instruments together into a sensor web, the main technology from ASky that we use is a feature tracking algorithm along the lines of [4]. The key idea is to use the relatively frequent GOES observations to follow the location of the ash clouds between the infrequent overpasses of the polar orbiters. This procedure allows the sensor web to unambiguously associate measurements made over mid-ocean by the MISR instrument on Terra and by the CALIOP instrument on CALIPSO with volcanic ash clouds from Bezymianny despite a time separation of â¼30 hours and a spatial separation of â¼400km from the initial eruption event.\n\nTo our knowledge, this marks the first ever unambiguous daytime observation of a tropospheric volcanic ash cloud with CALIOP and the first joint observations by both MISR and CALIOP of the same volcanic ash cloud (enabling, for example, interinstrument height retrieval comparisons). With agile satellites or instruments (capable of pointing), an even richer dataset could be acquired.\n\nAnother compelling application for Adaptive Sky involves combining satellite and ground observations of clouds. As one example, ground-based camera observations of clouds over the Santa Catalina Mountains near Tucson, Arizona were acquired by Joseph Zehnder of Arizona State University and colleagues in the summer of 2006 as part of the Cumulus Photogrammetric In-situ Doppler Observations (CuPIDO) field campaign [5].\n\nFor this scenario, the goal is to combine overhead satellite imagery with the ground-based camera imagery to acquire new information about the cloud 3-D (three-dimensional) structure and development. The overpass times of the satellites can be used to retrieve corresponding images from the ground-based dataset. Figure 4 shows coincident measurements by MODIS-Terra, MISR, and one of the CuPIDO cameras (located on the campus of the University of Arizona). Without the overhead views, it is difficult to resolve how the distances to different parts of the cloud mass seen in the ground camera view vary. Conversely, without the side view from the ground camera, it is difficult to determine the thickness of the cloud mass.\n\nIn a more advanced (and difficult) version of this scenario, dense temporal observations of clouds from the ground camera at a fixed spatial location could be converted into a predicted spatial distribution of clouds over a broader area at the specific time of the overpass. In this way, the joint observation process is not limited to just those clouds that happen to be in the ground camera field-of-view when the satellite passes overhead, but could also include clouds that had already passed by the ground station (typically appearing to the east of the ground station) and clouds that have not yet passed by the ground station (typically appearing in the overhead imagery to the west of the ground station). Due to the very narrow cross-track footprint of both the CloudSat radar and the CALIOP lidar, it is quite unlikely that the footprints will catch a cloud that happens to be within the ground camera field of view. However, by performing the more complex matching in which temporal observations are converted to spatial information, it becomes possible (in theory) to obtain overhead imagery, ground camera imagery, and CPR/CALIOP measurements of many more clouds. Some of the technical difficulties in achieving this type of combined dataset might be alleviated by using a spatial array of cameras with slightly overlapping fields-of-view. Since the measurements made by CPR/CALIOP are relatively new, having the corresponding ground-based imagery would enable these new measurements to be more easily interpreted and understood.\n\nA recent presentation by Thomas Ackerman of the University of Washington [1] illustrated another potential opportunity for this type of capability. In his work, he was comparing upward-looking radar imagery from an ARM station on Manus Island with down-looking CloudSat CPR imagery with the predictions of a radar simulator. One problem is  that the CloudSat orbit never causes the CPR footprint to pass directly over the ground station, although there are some near-misses that can be used as shown in Figure 5. By incorporating a cloud tracking and matching capability, CPR measurements of clouds that are spatially removed from the ARM station, but eventually advect over the station, could be associated with measurements made at the ground station significantly enriching the value of the collected dataset.\n\nAdaptive Sky technology will enable multiple instruments to be dynamically combined into an integrated sensor web capable of collecting objectcentric datasets. The basic idea has been demonstrated using historical data from the October 2007 Bezymianny eruption. In particular, ash cloud observations were obtained from five instruments on four different satellite platforms over a period of 30 hours and at a spatial separation of 400km from the launch site. A future application involves using Adaptive Sky capabilities to combine ground-based and overhead observations.\n\nThis demonstration consists of analysis of historical data rather than realtime analysis of data from an operational sensor web.\n\nThe trigger signal could instead come from a volcanospecific in-situ instrument or from overhead satellite imagery."
}