{
    "title": "The Relevance of Chaos to Environmental Ethics",
    "publication_date": "1999",
    "authors": [
        {
            "full_name": "Frances M C Robinson",
            "firstname": "Frances M C",
            "lastname": "Robinson",
            "affiliations": [
                {
                    "organization": "Lancaster University",
                    "address": {
                        "postcode": "2001"
                    }
                }
            ]
        },
        {
            "full_name": "Mave Dissertation",
            "firstname": "Mave",
            "lastname": "Dissertation",
            "affiliations": [
                {
                    "organization": "Lancaster University",
                    "address": {
                        "postcode": "2001"
                    }
                }
            ]
        }
    ],
    "abstract": "The problem at the heart of environmental ethics is the distinction being made between intrinsic and instrumental value. This problem is delaying the development of an environmental ethic. At the heart of the problem is the distinction being made between subjects and objects; and the basis of this distinction lies in the ideas of both the science and the philosophy of Modernity. More recent developments in science present a very different picture of the world. Chaos is that science. This paper examines the central problem in environmental ethics in the light of these new scientific findings.",
    "full_text": "Ethics show us how we ought to live. Modern ethical theories are concerned with establishing which actions are right; and 'right' in this context means good. Until recently, modern ethical theories addressed only the interactions between human beings. Environmental ethics address the interactions between humans and entities that are 'other than human'. Thus it seemed that environmental ethicists needed to address two problems. The first problem was how to expand the existing modern ethical theories to encompass the interaction between humans and 'other than human' entities. The second problem was with which interactions these theories should be concerned; whether or not they should be concerned only with our interactions with sentient species, or with our interactions with all biota, or with our interactions with all biotic and abiotic systems.\n\nThese two problems, however, are fundamentally insoluble in traditional metaethics. The reason is that traditional metaethics is based on a metaphysics that is itself based on Newtonian science; and Newtonian science does not deal with the interactions with which environmental ethics are concerned. The reason that Newtonian science does not do so is that Newtonian science deals only with systems that are classified as linear systems, or as non-linear systems with independent variables. More recent developments in science have shown that the real world is composed mainly of non-linear systems that have interdependent variables. These variables affect, and are affected by, each other. Chaos is the name given to the study of non-linear interdependent systems. Thus it seems reasonable to argue that, in order to develop an environmental ethic, one must first look at the discoveries in Chaos in order to understand the nature of the interactions in non-linear interdependent systems. This is of particular importance in the light of the growing belief that all systems are part of one non-linear interdependent system.\n\nIt must be noted that Chaos is a recent development of science; and that, although it has had a revolutionary effect on the way the world is perceived by us, it may be found that at some time in the future some of the present hypotheses in this field may need to be either modified, or even abandoned. Nevertheless there now appears to be a well-substantiated foundation on which Chaos has become firmly established. In this text I have endeavoured to use only information that is credited as being well substantiated.\n\nWhy is interdependency important? The nature of interrelationships is important because different types of interrelationship produce different outcomes. In Chapter 1 the characteristics of chaotic systems are presented, and compared with the characteristics of those systems with which Newtonian science can deal.\n\nIn Chapter 2 the problem that is at the heart of environmental ethics is discussed. This problem is connected with the attribution of value, which itself results from our present conception of the relationship between subject and object.\n\nIn Chapter 3 this problem in environmental ethics is discussed in the light of the discoveries in Chaos. The conclusion summarises the findings of this paper.\n\nFrom Newtonian Science to Chaos\n\nIn the late 1970s, a minor ecological catastrophe was brewing in the grassy countryside of southern England. Hordes of rabbits were devastating hundreds of thousands of acres of rich farmland. ----[T]he British government had a safe and easy biological solution ready to hand. The myxomatosis virus thrives almost exclusively in the bodies of rabbits. ----By introducing myxomatosis, authorities reasoned, they could manage the rabbit population with little adverse effect on the balance of the countryside ecology. Of course, things were not that simple.\n\nMyxomatosis did bring the number of rabbits crashing down within a few years. Meanwhile, however, livestock prices fell, and grazing animals became relatively unattractive to farmers. With fewer animals grazing, and fewer rabbits nibbling, the grass in the fields of southern England grew taller than usual. This doesn't sound particularly grave. But there is an ant named Myrmica sabuleti that thrives in short grass, and does less well in longer grass, and soon grassland populations of Myrmica were decimated. This ant has a peculiar relationship with the large blue butterfly Maculinea arion. When this butterfly lays its eggs, the ants carry them into their burrows, and foster the larvae through hatching and into adulthood. Unfortunately the population of Maculinea arion was already struggling in the late1970s, and when the number of ants fell, the number of butterflies plummeted. The introduction of myxomatosis made for taller grass and fewer ants and obliterated from England a beautiful blue butterfly. (Buchanan, 2000, p113-114) That anyone could have foreseen this sequence of events is doubtful; that there are other consequences that have, as yet, remained unrecognised is possible. Maculinea arion might still be thriving in England today, if livestock prices had remained a little higher, or if, for any other reason, the grass had been prevented from growing to the length that it did. However such events did not happen. It is unlikely that the Government made the political decision to eradicate the large blue butterfly;\n\nnevertheless the Government's decision had just that effect. If the Government had neither intended nor foreseen this effect, one might argue that the eradication of the large blue butterfly was an unfortunate accident. However it can also be argued that if such accidents are to be avoided in the future, there is a need for a greater understanding of causality.\n\nThe key to why Chaosfoot_0 has brought about a revolutionary change in our thinking is to do with causality. Traditionally one looked for the cause of an effect;\n\nChaos forces physics to acknowledge that the vast majority of causality is irreducibly complex. (Goerner, 1994, p18) Since the ideas of causality in Newtonian science differ from those in Chaos, a suitable first step in trying to increase one's understanding of causality might be to compare Newtonian science with Chaos.\n\nModern science began with Galileo in the late sixteenth century. Galileo introduced the idea of taking measurements. By the late seventeenth century Newton was creating the foundational model for science. Newton believed that systems could be precisely predicted through the equations of motion; and, through his scientific work and the use of calculus, he not only was able to explain planetary motion, but he also formulated the three laws of motion that became the foundation for future work in physics. Newton's success can be explained in terms of his winning combination;\n\nnamely, the use of calculus on calculus-approachable systems. (Goerner, 1994, pp.29-30) Calculus-approachable systems exhibit the following characteristics:\n\n• Any system that can be integrated can be represented as a set of independent elements, all changing in isolation from one another.\n\n• All integrable systems exhibit smooth continuous change.\n\n• All integrable systems can be broken down and approximated by simpler curves.\n\n• Once their equations of motion are known, precise prediction and control are possible in principle. (Goerner, 1994, p.14)\n\nThe calculus-solvable systems created a Newtonian mechanistic image of how things work; and led to the belief that one could isolate causes, predict precisely, reduce to independent elements, and control change. However when this Newtonian image moved insidiously into our everyday beliefs about how things worked, it proved to be not only inaccurate, but also dangerous. The idea of controllability provided an excuse for an ethic of power. (Goerner, 1994, pp.14-15) According to Goerner,\n\n[I]f you believe that things always stay the same ---, this affects your actions. If you believe that big things can only be changed by big forces, this affects your actions. If you believe that the universe is a bunch of colliding particles going nowhere and the only thing that determines survival is competitive self-interest, why should one act for any reason other than competitive self-interest?\n\nThe mechanistic model supports all of these impressions. (Goerner, 1994, p.25) Newtonian physics started with a simple cause and effect model. The strategy was to change one variable, while holding all the other variables constant in order to find out what the effect would be, as shown:\n\nThis is classified as independent causality. However causality never goes just in one direction; mutual causality occurs in all interactions, and this understanding was expressed in Newton's Third Law by 'equal and opposite action and reaction'.\n\nHowever an assumption was then made in the calculus-based view that such interaction effects could and should be removed from these working models.\n\nInteraction effects can never be removed, but in some systems they are well behaved in the Newtonian sense; and the Newtonian models dealt only with such 'two body' systems. (Goerner, 1994, p.43) Limitations to this mechanistic model were first identified by Poincaré in what became known as the 'three body' problem; and this problem appeared to be insoluble using calculus. The problem arose from the interactive effects of three bodies. It was not until the computer was invented that the 'three body' problem was solved. On the computer it was discovered that what had appeared to be erratic, or random, behaviour now appeared to have a pattern or form. The speed with which the computer could do the calculations revealed in hours or days what would have taken nearly a lifetime to calculate using calculus.\n\nA non-linear system is any system in which the output is not proportional to the input, and is everything of which the graph is not a straight line. Calculus could solve many non-linear problems, but not when there were interactive effects between the variables. The realisation that these variables were mutually affecting, and being affected by, each other, either instantaneously or in a loop fashion, led to a number of concepts such as feedback, recursion and self-referentiality. In Fig. 2.8 (Goerner, 1994, p.44) the different types of interactive causality are illustrated.\n\nChaotic systems are thought to be the result of these interactive effects, particularly of self-referentiality and of recursion. (Goerner, 1994, p.16) Chaotic Systems.\n\nIn 1963 Edward Lorenz could compute only a few strands of what turned out to be an attractor for his simple system of equations, but he recognised that there must have been an extraordinary structure on invisibly small scales. (Gleick, 1998, p.140).\n\nFig. 1a illustrates the early attractor, and Fig. 1b illustrates what became known as the 'Lorenz Attractor'.\n\nFig. 1a The First Strange Attractor. (Gleick, 1998, p.140) Fig. 1b The Lorenz Attractor. (Gleick, 1998, p.28) What is so remarkable about this discovery is that it has opened up a completely new physics; and a completely new understanding about how the world works. Whereas the Newtonian view took linearity as the base line; the view from Chaos is that nonlinear interdependence is the norm. Not only did this insight reverse the frame of reference, it also caused a change in perspective: systems, previously thought of as being static, were found to be dynamic.\n\nIt was discovered that the way to understand the relationships between variables was to develop a computer model that would show the overall pattern of flow of the system; and to make graphs of the results, so that these patterns of flow could be seen. In this way one got an overview of how the whole system worked, and also how it was influenced by its starting conditions. The amazing discovery was that pattern, or structure, emerged out of what had appeared to be random, erratic behaviour. These structures were formed as a result of the interdependence between the variables concerned; and these structures were called Attractors. Fig. 2.4 is a diagram of the relationship maps that illustrate different types of attractor.\n\nFig. 2.4 (Goerner, 1994, p.36) These structures apply to all types of non-linear interdependent systems -weather systems, biological systems etc.\n\nIt was discovered that if one changed the value of one of the parameters in a system, the pattern of behaviour of the system might change. When the behaviour remained the same, it meant that the attractor had remained the same; but when the behaviour changed, it meant that the attractor had changed. However different forms of behaviour are hidden in the same equation. The relationship between the variables has not changed; there has only been a change in the value of one or more of those variables. Thus the same system can show different types of behaviour. The information about a system's behaviour can be condensed on to a two dimensional graph, known as a Bifurcation Diagram 2 . Examples of bifurcation diagrams are illustrated in Fig. 2.5 and Fig. 2.6, and show qualitative transformations of behaviour.\n\nFig. 2.5 (Goerner, 1994, p.37) Fig. 2.6 (Goerner, 1994, p.38) 2 Bifurcation diagrams, Separatrixes and Basins of attraction are all maps showing where transformations occur in dynamic flow patterns.\n\nUnlike the Newtonian image of smooth and continuous change that is traceable, the bifurcation diagrams show periods of sameness punctuated by abrupt transitions to different forms of behaviour; it illustrates punctuated equilibrium. Of crucial significance is that the effects of a particular disturbance cannot be tracked back across a bifurcation. Behaviour is both trait-like, and context dependent. The behaviour of a system is stable within the domain of an attractor; but a small change in the value of one or more of the system's variables may result in a change of attractor with an associated change of behaviour. (Goerner, 1994, pp.37, 39) Thus, rather than looking for causal chains, one should be looking at a system's overall pattern of behaviour.\n\nSystems can be simple, as seen with the point attractor; or they can be very complex as seen with strange attractors. With strange attractors, the system's behaviour never repeats itself exactly, but conforms to a bounded pattern or form.\n\nConceptually, it appears that behaviour is drawn towards the attractor's form. A system may have multiple forms of behaviour, and thus multiple attractors. An example of a system having multiple attractors is seen in the development of an acorn into an oak tree.\n\nThere are two important differences to the Newtonian way of thinking. The first is that chaotic systems have a sensitive dependence upon the initial conditionsthe context matters. Fig. 54 and Fig. 55 foot_1 illustrate this point. Fig. 55 Plant shapes created by context-sensitive L-systems. (Stewart, 1998, 134-135) Small differences can have a critical effect and cause large changes. Thus small differences are determinative. Secondly, because of this sensitive dependence, the future path of a system cannot be predicted. Chaotic systems are both deterministic and unpredictable.\n\nNon-linear systems can be divided into dissipativefoot_2 systems and conservative systems. Strange attractors are found in dissipative systems, and homoclinic tangles are found in conservative systems. Both are maps of chaotic behaviour; and both are fractals. A fractal is a particular type of structure that is created by an iterative, selfreferential process; and the structure itself has fractional dimensions, such as 2.3 or 1.5. (Goerner, 1994, p.40)  The blood vessels around the retina.\n\nThe bronchial/arterial structure of the lungs. (Ball, 1999, p.130) (Ball, 1999, p.111) An important feature of fractals is that they exhibit the phenomenon of scaled self. If one took a small piece of a fractal and magnified it, one would see a similar structure to the structure that one could see in the whole fractal. The structure is similar at all\n\nscales. An example of this is shown in Fig. 3.\n\nFig. 3 A cross section of a cauliflower shows a fractal shape. (Stewart, 1998, Plate 7) The self-similarity and scaling of fractals repudiates the Newtonian assumption that a complex structure can be understood by reducing it to its simpler components.\n\nFractals are infinitely complex. In addition, measurement becomes scale-dependent;\n\nsuch that not only will the world appear differently to different observers on different scales, it will measure differently. (Goerner, 1994, p.41) Earlier in this text, chaotic systems were described as being self-referential or recursive. 'Recursive mixing' means stretching and folding, as one would handle dough when making bread. Technically this action is referred to as Smale's stretching and folding of phase space. In mathematical terms this refers to points in a computer model that originate closely together and finish up widely distributed.\n\nA feature of non-linear interdependent systems is universality. By this one means that one can model the dynamics of complex systems with very simple equations. All equations of a particular class will display certain universal, qualitative and quantitative patterns of behaviour. This applies to all chaotic systems, regardless of their nature. (Goerner, 1994, pp.41-42) In Fig. 6 and Fig. 3.26 similar patterns in different types of system are illustrated. Chemical chaos: the Beluzov-Zhabotinsky reaction. Colonies of slime mould, Dictyostelium (Gleick, 1998, p.287) discoideum. These patterns are generated when some cells emit periodic pulses of a chemical attractant, towards which other cells travel. (Ball, 1999, p.71) Such similarities are also illustrated in Fig. 4.40 The double spiral pattern of phyllotaxis Fig. 4.39 The patterns of phyllotaxis in the a) Florets in a flower head. b) Leaflets in a pine cone.\n\nmonkey puzzle tree. (Ball, 1999, p.106) (Ball, 1999, p.105) Thus non-linear interdependent systems cannot be described, nor explained, nor interpreted using the methods or rules of Newtonian calculus-based science. They follow different rules, require the use of new scientific methods, and, above all, necessitate a radical change in our view of how the world works.\n\nCharacteristics of an interactive world.\n\nTo have a clearer understanding of how the world works, one needs to understand what the characteristics of such an interactive world are. These characteristics will be discussed under the following specific categories of inseparability, attraction, stability, feedback and folding, and coupling; and they will also be discussed in more general terms.\n\nIn the Newtonian view, it is possible to vary one variable and hold the other variables constant. It is not possible to do this with chaotic systems. They are inseparable and irreducible.\n\nConceptually an attractor pulls behaviour towards it. In reality, the interactive dynamic pulls molecules into its flow; and in the process it maintains its form. This is exemplified in the action of both whirlpools and tornadoes.\n\nOnce an attractor becomes established, it tends to be self-stabilising; and returns to its form after small perturbations. However it can become unstable. This leads to two possibilities. Either a new attractor develops with an associated change in the system's behaviour; or the attractor ceases to exist without the development of a new attractor. In the latter case, the system collapses. Thus an attractor can:\n\n• exist\n\n• not exist, or\n\n• change.\n\nIn the Newtonian view, stability implies a single final state, in terms of a repeated pattern, equilibrium or homeostasis. In contrast, stability in chaotic systems may mean that a system never repeats the same way twice; it may move backwards and forwards between multiple attractors; and it may be in a locally stable pattern that is nevertheless part of an overall progression of states. (Goerner, 1994, p.46) Feedback and Folding:\n\nThat variables affect, and are affected by, each other explains the curving back and folding that creates fractals and strange attractors. This bounding effect of feedback is known as negative feedback, and it is this that leads to the notion of control. However the feedback can also be positive. In such cases an explosive growth of one or more of the variables occurs. It is positive feedback that leads to the notion of amplification. (Goerner, 1994, pp.46-47) Coupling:\n\nThe interactions between two or more stable systems can result in the emergence of a single higher system, that is itself stable. This coupling effect is the basis for the formation of higher and higher systems that are not only more complex, they are also often more stable. (Goerner, 1994, p.47) It is important to understand that a chaotic system's behaviour is selfgenerated. It is generated from its own internal dynamics. External influences, known as perturbations, may or may not affect the system's behaviour. When they do affect the system such that the system's behaviour changes, it means that there has been a change of attractor; and the change of attractor is the result of the system's own internal dynamics.\n\nDifferent systems interact with each other to form more and more complex systems. Goerner refers to such systems as networks and as 'Hypercycles' (cycles of cycles). (Goerner, 1994, p.72) Thus ultimately, global order results from local activity. Sometimes what appears to be erratic local behaviour does in fact appear to be quite orderly from a global perspective. In addition, once global behaviour is established, it becomes active, and affects the very activity from which it arose. This has led to an understanding that local action is embedded in an overall context. It has also led to an increased understanding of causality. Reductionists believe that the source of any causation is to be found in the parts that make up the whole. Those supporting holism believe that a source of any causation is to be found in the system as a whole. Chaos suggests that causation originates from both sources. Although the source of causation may appear to come from either the whole or the parts of the whole, causation comes from both. It can be referred to as a 'top-down and bottomup' causality; it is effectively a circular causality. (Goerner, 1994, pp.48-49) According to Diner (1986),\n\nSingularity is no more given in advance but generated inside a totality ---This is the deep philosophy of Bifurcation theory and Catastrophe theory. The local properties get a real meaning only through their relations to the global properties. (Goerner, 1994, p.49) Our expanded understanding of non-linear interdependency has led to a deeper understanding of the essential interconnectedness of the world. Traditionally, one thought about things in the framework of 'either'/ 'or'. Such a framework depends upon independent causality. With interdependent causality, questions about 'this' or 'that' make no sense. The following examples illustrate this point:\n\n• Does your father or your mother influence your genotype? Yes!\n\n• Does your genotype, your physical environment, or your social environment affect your phenotype? Yes!\n\n• Does the weather, the soil type, or the genotype of the seed affect the crop growth? Yes!\n\n• Did the Government's decision to release the myxomatosis virus, the price of livestock, or the weather affect the demise of the large blue butterfly? Yes!\n\nIn an interactive world, there is a web of cause and effect that has coherence, hidden order, inseparability and subtle connectivity. (Goerner, 1994, p.54) Linear and non-linear 'independent' systems are idealisations. The use of calculus and Euclidean geometry in Newtonian science has been proven to be very effective when applied to certain systems. However the world is composed of mainly non-linear interdependent systems; and the understanding of these systems necessitates a different type of geometry; namely, a fractal geometry. The difference between these different types of system is related to energy gradients, and thus energy flow; and this will be discussed briefly in Chapter 3.\n\nThis chapter began with an example of the complexity of interrelationships.\n\nThe extinction of the large blue butterfly was the net effect of those interactions at that particular time. An increased understanding both of the complexity of causality and of the unpredictability of non-linear interdependent systems necessitates a more cautionary policy towards the release into the environment of potentially harmful substances, biological or otherwise. If one were ignorant of the fact that one might cause harm, then one cannot be accused of acting unethically. However, with an increased understanding of the unpredictability of consequences -at least beyond a limited time frame, and with an increased understanding of the essential interrelatedness of the world, it can be argued that there is a great potential for causing harm; and thus any decisions about whether or not to release such substances do have an ethical dimension, and ought to be made within the framework of an environmental ethic.\n\nA central problem in environmental ethics is the dispute over the attribution of value. Environmentalists agree that there is a need for an environmental ethic to protect the environment from the destructive activities of humans. However they do not agree over the ethical reason for the development of such an ethic. Those who believe that the environment has only instrumental value believe that the necessity of developing an environmental ethic arises out of the growing danger to mankind from environmental damage. Their reasoning is that the reduction in natural resources and the increase in environmental pollution are, at worst, threatening the future existence of mankind; and are, at best, ensuring the misery of future generations. Those who believe that the environment has intrinsic value believe that the ongoing destruction of the environment is ethically wrong in itself, and not only because of the potentially harmful effect on humans. The tragedy of this situation is that the dispute itself is delaying the development of an environmental ethic, since the dispute over the attribution of value has led to a dispute over how one ought to act.\n\nThose who argue that the environment has only instrumental value believe that it is only humans who have intrinsic value; and that any intrinsic value exists only in humans as valuing subjects. Those who believe that entities within the environment have intrinsic value are nevertheless in disagreement about which entities do. For example, some people believe that only sentient species do, and thus they favour attributing intrinsic value to 'other than human' subjects. Other people favour attributing intrinsic value to both subjects and objects within the environment. The view that either the subject or the object has intrinsic value is making the assumption that the subject and the object are independent entities. Thus a first step to resolving the problem at the heart of environmental ethics is to investigate this assumption.\n\nThe conceptual separation of subject and object arose out of Descartes' method of philosophical inquiry. Descartes began his philosophical inquiry by doubting the existence of everything. His first fundamental 'truth' centred on his own existence, and was expressed in his words: 'I think, therefore I am'. However there is much in his reasoning that remains open to doubt. According to Damasio, Descartes made the claim that:\n\nFrom that I knew that I was a substance, the whole essence or nature of which is to think, and that for its existence there is no need of any place, nor depend on any material thing; so that this \"me\", that is to say, the soul by which I am what I am, is entirely distinct from body, and is even more easy to know than is the latter; and even if body were not, the soul would not cease to be what it is. (Damasio, 1996, p.249) The logical proof of Descartes' argument ultimately depended upon the existence of God; and Descartes could not prove the existence of God. In spite of the lack of logical proof, or the support of empirical data, Descartes' argument still remains influential to this present day.\n\nDescartes had been influenced by the work of Galileo, who, by the process of taking measurements, had introduced into science the idea of objectivity. In England,\n\nFrancis Bacon was introducing into the study of nature a new method based on eliminative induction. Bacon's dream was to conquer nature. (Merchant, 1980, p.186) As a result of Descartes' influence, not only did the idea prevail that subjective experience was independent of the objective material body, but the idea also prevailed that animals were objects without subjective experience. Henceforth the dissection of nature began.\n\nThe idea of the independent existence of subject and object was further entrenched by the ideas of John Locke in the late seventeenth century. However the basis of Locke's ideas differed from the basis of Descartes' ideas. According to\n\nI see no reason ---to believe, that the soul thinks before the senses have furnished it with ideas to think on; and as those are increased, and retained; so it comes, by exercise, to improve its faculty of thinking ---. ----[H]e that will suffer himself, to be informed by observation and experience, and not make his own hypothesis the rule of nature, will find few signs of a soul accustomed to much thinking in a new-born child, and much fewer of any reasoning at all. (Locke, 1997, p.119) In An Essay Concerning Human Understanding Locke made the distinction between the primary and secondary properties of objects. The primary properties were the properties of the objects themselves; and consisted of solidity, extension, figure, motion or rest, and number. The secondary qualities were the powers of the object to produce in the subject the sense of colour, sound, smell, taste and touch. (Locke, 1997, pp.135, 139) Thus, although Locke based his philosophy on a more empirical foundation, he retained the separation between subject and object by making a clear distinction between the properties of an object and the subject's perception of that object.\n\nIn the eighteenth century, the Age of the Enlightenment, as a result of the advances both in physics, following the work of both Galileo and Newton, and in the biological sciences, from followers of both Bacon and Descartes, the power and the influence of the Church began to decline. Since morality had been associated with religion, it was feared that the decline in the Church's influence would result in a decline in morality. This led to the development of two secular moral theories. The first, known as Deontology, was a duty based morality founded upon the moral law known as the Categorical Imperative; and this theory was developed by Immanuel Kant. Kant believed that to act morally was to act out of duty, and not out of inclination. He reasoned that since only a rational person would choose to act out of duty, rather than out of instinct, only rational persons had moral worth, and therefore only rational persons had intrinsic value; everything else had instrumental value.\n\nBeings whose existence depends, not on our will, but on nature, have none the less, if they are non-rational beings, only a relative value as means and are consequently called things. Rational beings, on the other hand, are called persons because their nature already marks them out as ends in themselves -that is, as something which ought not to be used merely as a means -and consequently imposes to that extent a limit on all arbitrary treatment of them. (Kant, 1991, pp.90-91) Kant believed that the only thing that was good in itself was the good will; and the argument that he presented for his particular moral theory was based on the good will.\n\nIn his argument Kant reasoned that rational beings belonged to an intellectual world, and that the latter was separate from the world of the senses, or the natural world.\n\nHowever Kant admitted that there was no knowledge of this intellectual world, and that the intellectual world was a concept. He also admitted that the concept of the will was to be seen as negatively free from sensuous causes, and positively free to act on the principle of autonomy. In so doing, Kant retained the idea of the independence of the subject; and by his sub-division of the subject into its rational self and its sensuous self, he further reduced the boundaries of moral considerability.\n\nThe other moral theory, which was developed by Jeremy Bentham, was known as Utilitarianism. In this theory, the right action is the action that produces the greatest happiness for the greatest number of people. Utilitarianism is a form of consequentialist theory; and, for any consequentialist theory, whether or not an action is right depends upon the consequences of that action, and not upon the action itself.\n\nHowever, for all forms of consequentialism, it is necessary to be able to predict what the consequences of an action will be.\n\nThe influence of Newtonian science dominated the nineteenth century. In the late nineteenth and early twentieth centuries the certainty that had been espoused by Newtonian science, and by the philosophy that had been based upon it, was significantly undermined. Serious doubt had crept into both science and philosophy;\n\nand the reasons for that doubt were multiform.\n\nIn science, through the work of Einstein, Bohr, Heisenberg and Schrodinger, new ideas about the fabric of reality were evolving; and these new ideas were summarised in Quantum Theory and the Theory of Relativity. It was discovered that, at the scale of the elementary particles, the position and the momentum of an elementary particle could not be ascertained at the same time. It was possible to measure one or the other, but not both. This meant, at least at the elementary scale, that the Newtonian laws of motion did not apply; and so neither did the ideas of precise prediction or control. Secondly, from the understanding that light travelled at a constant speed, and that nothing could travel faster than the speed of light, came the understanding that distance and 'mechanistic' time were relative. This relativity is of much greater significance on the macro-scale; and needs to be taken into account in Space travel. However, of significance to science was the implication of relativity to causality. It meant that Newtonian science could only be applied to a limited scale. In summary, Newtonian science did not apply at the extremes of either the micro-scale or the macro-scale.\n\nIn philosophy, Husserl was questioning the absolute influence of Newtonian science. Husserl was concerned both about the influence of technology, and about the use of primary and secondary qualities as a complete description of the interaction between entities. His concern over technology was that, although technology was beneficial to mankind, it was becoming so powerful that it could be used as a tool, politically and socially, to manipulate and control mankind. His concern about the inadequacy of the descriptions of our interactions in the world developed out of his interest in consciousness and mental states. He had been influenced by Brentano, who believed that all mental states had intentionality; that is, that all mental states were directed towards something. By reflection one can confirm that one always hopes, believes, loves, dislikes and wishes something. Husserl proceeded to try to develop a greater understanding of how one does interrelate with the world, and such a study became known as Phenomenology.\n\nOne of Husserl's pupils was Martin Heidegger. Heidegger was also a phenomenologist; but his view differed from that of Husserl's in one important respect. Heidegger believed that the interrelationships in the world were more essential than one had previously been led to believe. He believed that subjects and objects were essentially related. Unlike Husserl, who believed that the subject was a transcendental 'ego' distinct from the world of which it was aware, Heidegger did not.\n\nIt is on the basis of his own belief that Heidegger began to question the very basis of metaphysics; and as such, the foundations of philosophy itself. He believed that the correct question was not being asked in metaphysics; and that, if the correct question was not being asked, then one could not expect to find the correct answer. Heidegger believed that rather than asking about 'being as beings', metaphysics should be asking about 'Being' itself. (Heidegger, 1949, Internet Ref.1) The question of 'Being' became central to Heidegger's metaphysical inquiry.\n\nThe separation of one's subjective experience from one's objective material The ethical theories that were developed in the eighteenth century were based upon the ideas that were prevalent at that time; and those ideas were based upon Newtonian science, and therefore upon the ideas of both Locke and Galileo. It is probable that Kant and Bentham were also influenced by the ideas of both Descartes and Bacon.\n\nCritics of consequentialist theories, such as utilitarianism, have focused on the following criticisms:\n\n• That there is a risk of tyranny by the majority.\n\n• That there is a lack of restrictions upon actions.\n\n• That the theories are impersonal.\n\n• That it is questionable that all of the consequences are predictable.\n\nIt would not be possible to adequately address all of these criticisms in this paper.\n\nHowever, the predictability of consequences is relevant to this argument. Recent developments in science suggest that it is not possible to predict beyond a limited time frame; and therefore any consequentialist theory would be an inadequate ethical theory for an environmental ethic.\n\nThe deontological theory was developed by Kant; and it has been shown that Kant's argument was based upon the good will; and the good will is dependent upon autonomy. His argument depends upon the independent existence of the rational self from sensuous causes -that is from nature. The concepts of intrinsic and instrumental value were introduced into, and supported by, Kant's argument. Therefore, if the rational self, or even the entire self, is not, and cannot be, independent of natural entities, then Kant's argument fails, and the ideas of intrinsic and instrumental value are not justified.\n\nThese values emerged out of those beliefs that had both preceded, and been influenced, by Newtonian science. At present such beliefs are being superseded by new beliefs that are emerging from a new science that offers a deeper understanding of reality. It seems reasonable to argue that if the basis of Kant's argument is found to be incorrect, then the development of an environmental ethic should not be based upon it.\n\nSome of the findings of Chaos were discussed in Chapter 1. Other developments within science concern our understanding of both objects and subjects.\n\nIt would be appropriate now to examine these findings.\n\nBefore examining the concepts of an object and a subject, it would be appropriate to examine first what is meant by an entity -whether it be subject or object. At the end of Chapter 1 a distinction was made between Newtonian systems and non-linear interdependent systems, in terms of energy gradients and energy flow.\n\nThermodynamics is the science of energy flow; and thermodynamics offers an explanation both of the distinction between these different systems, and of the emergence of an entity.\n\nA common misconception is that energy is an independent, self-contained entity that drives change. On the contrary it is the configuration of the system's energy that determines a system's potential for doing work. What drives change is the relationship between different concentrations of energy in the field. The occurrence of an energy disequilibrium or energy gradient in the field results in energy flow; and it is the energy flow that causes movement, because an energy concentration in the field creates a force that presses energy to flow towards equilibrium. The three elements of an energy flow system include the field, the forces and the flows; and they form a tightly bound non-linear ecology. The forces and the flows co-effect each other, since a greater force will generate a faster flow; and the faster flow, in turn, causes a reduction in the energy concentration, and thereby reduces the force. A force may generate multiple flows; and all of these flows are interdependent, because they all drain the same equilibrium. By definition, energy can be neither created nor destroyed, but only converted between the different forms of energy. The energy flow system applies to all types of energy. Thus the forces and the flows form an interactive causal web. (Goerner, 1994, pp.60-61) When a force generates multiple flows, that force will distribute energy to each path in accordance with the capacity of each path. The differential allocation of energy is a form of selection. Above a certain disequilibrium, the flow becomes nonlinear; and selection results in new patterns of flow that generate new forms. The generation of a new form is known as self-organisation. Selection has a preference for faster and more efficient paths. The faster the path, the more energy it receives; and above a critical disequilibrium, the energy flow becomes non-linear and amplifies itself. Once an attractor has emerged, it carries an 'on-board potential' for being selfsustaining; and the 'on-board potential' is the source of its 'being' and growth. (Goerner, 1994, p.66) In biological systems, the on-board potential is metabolism.\n\nThe emergence of an attractor corresponds to the emergence of a new 'thing'. In an energy field, a change in the balance of forces that results in a steeper gradient will create the field conditions that are primed for a new type of behaviour; and therefore the potential for a new attractor.\n\nEntities are not static sets of material, nor are they the products of a fixed energy field. They are dynamic. An atom is not a solid 'thing' but a dynamic system; a molecule is not a solid 'thing' but a whirling dynamic system made up of atoms; a human body is a dynamic system made out of molecules; and society is a dynamic system made out of human bodies. (Goerner, 1994, p.69) Newtonian science was able to deal with linear and non-linear 'independent' systems. These are the systems that are nearer to the field's equilibrium. However, most systems are far from equilibrium; and these systems are non-linear interdependent systems.\n\nPhenomenologists are not the only people to question the adequacy of description. The physicist, Lee Smolin, did so by pointing out that if one tried to describe a friend or a relative by describing that person as he or she 'is now', one fails to communicate adequately what is essential about that person. A better approach is to talk about some of the episodes in that person's life. A person's character is often best described by how that person reacts to different situations, and by what that person has chosen to do or to become. Thus the solution is to give a narrative of that person's life. What is important is not so much the episodes themselves, but the connections between those episodes. The events in a person's more distant past are to some extent the causes of the more recent events in that person's life; and it is this understanding of causality that makes narrative so useful. Causality gives the world its structure; and this is why narratives are more informative than descriptions. (Smolin, 2000, pp.50-51) Entities such as humans, other living organisms and cultures are only adequately described by narrative; the reason being that they are not really 'things', but processes unfolding in time. In contrast, it does seem to be possible to describe 'objects' more adequately, since objects do not appear to change. However, works of art, household goods, transport vehicles etc. do change over time. These objects are also processes, and they only differ from those entities that one more readily categorises as processes by their rates of change. The difference is relative.\n\nSmolin uses an analogy to illustrate this point. In watching a film, one is really watching a series of still photographs presented at such a rate that one sees movement.\n\nIt is sometimes described as 'an illusion of movement'. In fact, the reverse is true. It is the still photographs that are the illusion. The photographs are also processes that change over time; but they change much more slowly than do ourselves. In presenting the still photographs at the rate at which they are presented in the film, one is really recreating the world as it is. The world is made up of processes, and it is dynamic.\n\nThe illusion of 'things' is brought about by the relative differences in the rates of change. (Smolin, 2000, pp.51-52) In Classical, or Newtonian science, the description of the 'state' of a particle does not include time. Once the 'state' of the particle has been described, then time is introduced to describe how the particle changes. The idea of a 'state' is an illusion of a frozen moment, in much the same way as is the still photograph. The idea of a 'state' gives rise to the illusion of a world composed of objects. Both quantum theory and the theory of relativity indicate that this is not the case. In contrast, they indicate that our world is actually a history of processes. According to Smolin,\n\n[T]he universe consists of a large number of events. An event may be thought of as the smallest part of a process, a smallest unit of change. But do not think of an event as a change happening to an otherwise static object. It is just a change, no more than that. The universe of events is a relational universe. That is, all its properties are described in terms of relationships between events. The most important relationship that two events can have is causality. (Smolin, 2000, p.53) There is no meaning to the past of an event except the set of events that caused it; and there is no meaning to the future of an event other than the set of events that it will influence. (Smolin, 2000, p.54) Hence to talk meaningfully of any process requires a historical narrative of that process.\n\nThus it seems that we categorise some processes as 'subjects', and some processes as 'objects'. The difference between subjects and objects is the rate of change in these processes relative to the rate of change in ourselves. This might seem to be an adequate explanation for the differences in the perception of different entities; but it does not adequately explain perception itself. Subjective experience, or consciousness, requires further explanation.\n\nBernard Baars makes the distinction between consciousness and 'intelligence'.\n\n'Intelligence' is the ability to solve problems; and problem-solving abilities are highly species-specific. For example, pigeons excel at finding their way in air space. Their ability to do so far exceeds the unaided abilities of humans. (Baars, 2001, p.33) Consciousness is awareness; and the brain mechanisms of conscious alertness and conscious perception have an extremely widespread distribution among vertebrates and invertebrates. Species differences, such as the size of the neocortex, seem to be irrelevant to the existence of wakefulness and perceptual consciousness. (Baars, 2001, p.33) Since the 1920s it has been recognised that there is a major difference between the electroencephalograms (EEGs) of waking consciousness and those of deep, unconscious sleep. In waking consciousness, the EEG shows fast, irregular and low voltage field activity throughout the thalamocortical core. Such activity supports the reports of the conscious experiences of humans. The underlying brain activity is so similar in monkeys and cats, that they are routinely substituted for humans in experiments. The EEG reflects the irregular firing of billions of single neurons, and the complex interactions between them. In contrast, in deep, unconscious sleep there is slow, regular and high voltage field activity throughout the thalamocortical core. In this case the EEG reflects the highly regular and highly synchronised firing patterns in the same billions of individual neurons. The same pattern of a slow-wave, highly synchronised EEG appears in other states of global unconsciousness, such as in general anaesthesia, coma and epileptic 'states of absence'. In all of these cases, humans do not report the events that they experience during the conscious waking state. All mammalian species that have been studied so far exhibit the same massive contrast in electrical brain activity between waking and deep sleep. Baars was unable to find a single exception in the findings. There has been over 70 years of highly consistent evidence. (Baars, 2001, p.36) Waking consciousness is not some vaguely global property of the brain.\n\nRather it is dependent upon a few highly specific brain locations. In all mammals the state of waking consciousness requires the brainstem reticular formation and the intralaminar nuclei of the thalamus. Brainstem mechanisms, like the reticular formation, are extremely phylogenetically ancient; going back at least to the early vertebrates. Thalamic structures, like the intralaminar nuclei, also exist in mammals generally. Both of these facts indicate that the brain anatomy of waking consciousness is very ancient indeed. (Baars, 2001, p.36) There have been fewer studies of consciousness in invertebrates than there have been studies of consciousness in vertebrates. According to Sherwin, a central difficulty is that:\n\nInvertebrates have different sensory organs and nervous systems and so might perceive nociception or pain in an entirely different way to vertebrates, but still experience a negative mental state. ----[He continues:] [P]ublished studies ---show that invertebrates such as cockroaches, flies and slugs have short-and long-term memory; have age effects on memory; have complex spatial, associative and social learning; perform appropriately in preference tests and consumer demand studies; exhibit behavioural and physiological responses indicative of pain; and, apparently, experience learned helplessness. The similarity of these responses to those of vertebrates may indicate a level of consciousness or suffering that is not normally attributed to invertebrates. (Sherwin, 2001, pp.104, 103) Thomas Nagel made the distinction between the first and the third person perspectives of consciousness; the first person perspective being centre-based, and the third person perspective being centre-less, or objective. Nagel pointed out that there was an awkward tension between the two perspectives; since, from a maximally detached point of view, consciousness ceases to be a perspective, and is dissociated from its subjective nature. He reasoned that a centre-less perspective is incomplete in itself; and, for a complete understanding of the world, one needs to have a centre-less and a centre-based perspective. Chalmers makes the point that both perspectives are essentially concerned with the acquisition of knowledge; and seeks to unify the two perspectives in terms of information theory. (Wemelsfelder, 2001, pp.130-131) A similarity between the computer and the brain is that they are both information processors. A problem with the early computers was their lack of speed; a result of the single gate system that allowed only single logical steps in linear sequence. Attempts to produce computers working with parallel systems failed because there was no 'intelligence' to co-ordinate the work. The development of transistors and silicon chips resolved the need for network computers, since they greatly increased the working rate of computers. In the 1980s computer learning rules were discovered; and a distributed form of 'intelligence' replaced the existing centralised programme. This distributed form of intelligence consisted of each processing unit working out responses for itself by means of trial and error.\n\nCompetition and adaptation amongst a network of connected elements could create a self-organising processing landscape. (McCrone, 1999, pp.46-47) However, although these computers were excellent at certain forms of recognition, pattern matching and making generalisations, they were of little use in conventional computing tasks. It was then realised that it was necessary for the computer to have 'smart' hardware as well as 'smart' software; and the development of artificial neural networks began to appear in the late 1980s. (McCrone, 1999, pp.48-49) However, it was soon realised that artificial neural networks would need to become more dynamic; and that processing and feedback could not remain separate.\n\nA brain uses active competition to evolve its way to an answer. One of the hallmarks of genuine competition is that there is an element of unpredictability about the outcome. It was also realised that the assumption that brains were digital computers was inaccurate. This assumption had been based upon the following reasons:\n\nThat there appeared to be a separate input and output to each individual neuron,\n\nThat there appeared to be a physical logic in the wiring patterns.\n\nThat responses appeared to be binary -either 1 or 0.\n\n( McCrone, 1999, pp.49-51) The electrical activity in the brain is based upon a moving electrical charge, that is carried on ions across the cell wall. The membrane of the neuron is finely covered with pores. A pump action at some pores forces the ions in and out of the cell; whereas other pores appear to act as valves to allow the ions to flood back, and so swiftly right the balance of charges. Control of this is immensely complex:\n\nA change in the electrical activity at one pore influences not only its own behaviour, but also the voltage in the region.\n\nDifferent classes of pore handle different types of ions, and react to different voltages in different ways.\n\nPores are controlled by a whole range of neurotransmitters and neuromodulators; hundreds of different chemical substances open and shut the pores. The effect of these substances may be instant; or it may be gradual, occurring over a period of minutes or even days. Some substances affect only one type of pore; and other substances affect all types of pore.\n\n( McCrone, 1999, p.52) Every bit of the membrane of a neuron is an individual. The blend of pores can be tailored to do a particular task; and that blend can be finely tuned at any time. There is a plasticity that makes the outside of a neuron appear to resemble a learning surface;\n\nthat is, a landscape of competition and adaptation. In addition, whatever the response turns out to be, there is no certainty about any of the steps in the sequence of that response. (McCrone, 1999, pp.53-54) Two recent discoveries concern feedback. The first is that consciousness levels of attention and alertness appear to influence the response of individual synapses. It appears that the circuits create the results, and the results create the circuits. Secondly, it appears that an output spike can travel in both directions along a neuron. This indicates that there can be negative and positive feedback. Feedback mechanisms dominate the brain; they are everywhere. There is no shortage of pathways through which the activity of the wider network can feedback and influence the behaviour of its individual components. No part of the chain of transmission is immune from adjustment. A neuron remains joined to a group of approximately 10,000 neurons; and thus any change in the neuron can only involve a slight shift in the balance of connections. (McCrone, 1999, pp.55-57) The brain uses feedback to adjust circuits; and competition to evolve answers, thus introducing a level of unpredictability. All of this is directed towards producing a well-organised response. The spikes and the connection patterns emerge out of a sea of metabolic and growth processes; and need some kind of dynamic balance to create a particular state of response. (McCrone, 1999, p.58) In contrast, digital computers are made from standardised components; the transistors are identical. Computers deal only in defined bits of data, and in defined processing paths. There is no room for unpredictability. The computer relies upon its circuits being insulated from any background interference, or 'noise', that might interfere with its clockwork progression of '1's and '0's. The ability to make exact copies depends upon this insulation. The disadvantage is that a small error or interference can cause the system to fail. (McCrone, 1999, pp.50, 53, 58) In the 1990s an increased understanding of complex systems arose; systems The philosophical implications of this are considerable. Kant based his argument upon the good will; and the good will required autonomy. There is nothing to suggest in the evidence available that any thought process can be independent of the system from which it emerges; and the system from which it emerges is essentially related to all other processes in the energy field.\n\nIn addition, Kant argued that only rational persons had moral worth, and therefore only rational persons had intrinsic value. According to Kant everything else had only instrumental value. McCrone points out that human brains can think logically; that is, that humans are able to reason in a sequential, linear fashion that is not unlike a computer programme. (McCrone, 1999, p.73) One seriously questions whether one should base an environmental ethic upon our ability to 'think' like a computer.\n\nHusserl was concerned that technology was being used as a political and social tool to manipulate mankind. My belief is that technology has now not only permeated our political and social spheres, but it has also permeated our very 'Being'. Our ability to think rationally has created technology; and the feedback from this has been that\n\ntechnology is now controlling our thinking. The problem is that linear and non-linear 'independent' systems are the exception and not the norm in the natural world. They are systems that are nearer to equilibrium in the energy field. Mankind extracts and stores energy to power technology; and most of technology consists of these linear and non-linear 'independent' systems. Our sequential, linear thinking is increasingly placing us 'out of step' with the natural world of which we are a part. The destructive consequences are all around us; in the loss of biological diversity, in environmental pollution and in global climatic change.\n\nHeidegger spoke of mankind's instrumentality. By this, he meant that mankind only recognised anything that was 'other than mankind' as a tool or instrument for his/her own use. Such instruments he referred to as being 'ready to hand'. It was only when an instrument or tool became broken that he/she noticed it for itself; only then did it become 'present at hand'. (Heidegger, 1962, p.104) Our environment is seriously damaged. The root of many of our present environmental problems lies in our instrumentality; in our inability to appreciate anything that is 'other than mankind' for itself. Therefore it seems that any environmental ethic that shows us how we ought to live needs to address not only our actions, but also our thoughts.\n\nChaos is at the heart of recent developments in our understanding of the world.\n\nIt has led to new insights both about ourselves, and about the world of which we are a part, and not apart as was previously believed. The ideas of intrinsic and instrumental value arose out of our earlier understanding of the world. That earlier understanding has been proven to be incorrect. Kant's argument for intrinsic and instrumental values was based upon that earlier understanding of the world. Therefore Kant's argument is fundamentally unsound.\n\nOur treatment of species other than our own has been, and still is, appalling.\n\nThis needs to change. The search for an environmental ethic requires new values.\n\nI conclude with these insights from Mahatma Gandhi:\n\n'Love is the supreme value of life'\n\nMohandas Karamchand Gandhi (McGreal, 1995, p.265) 'When I despair, I remember that all through history the way of truth and love has always won. There have been tyrants and murders and for a time they can seem invincible, but in the end they always fall. Think of it. Always.'\n\nMahatma Gandhi (Goerner, 1999, p.293)\n\nThe term chaos with a small 'c' refers to a chaotic system or systems; whereas Chaos with a capital 'C' refers to the study of non-linear interdependent systems.\n\n\"L-systems\" are short for \"Lindenmayer systems\" after Lindenmayer who developed an algebraic system for generating fractal forms similar to the branching structures of plants.(Stewart, 1998, p.131)\n\nThe common understanding of the distinction between dissipative and conservative systems is that in conservative systems the energy is conserved, and in dissipative systems the energy is dissipated into its surroundings. According to Baranger (1990) a dissipative dynamical system is one in which the volume of phase space shrinks as time evolves, with the result that the system ends up in a region of phase space, with a lower number of dimensions, and this region is called an attractor.(Goerner, 1994, pp.209, 211)"
}