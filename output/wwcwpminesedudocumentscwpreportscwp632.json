{
    "title": "Imaging effects due to multi-scale model heterogeneity",
    "publication_date": "1989",
    "authors": [
        {
            "full_name": "Yong Ma",
            "firstname": "Yong",
            "lastname": "Ma",
            "affiliations": [
                {
                    "organization": "Center for Wave Phenomena, Colorado School of Mines",
                    "address": {}
                }
            ]
        },
        {
            "full_name": "Paul Sava",
            "firstname": "Paul",
            "lastname": "Sava",
            "affiliations": [
                {
                    "organization": "Center for Wave Phenomena, Colorado School of Mines",
                    "address": {}
                }
            ]
        }
    ],
    "abstract": "Velocity models used for wavefield-based seismic imaging represent approximations of the velocity characterizing the area under investigation. We can conceptually decompose the real velocity model into a background component which can be inferred using conventional velocity analysis techniques, and into another unknown component encapsulating the model heterogeneities. This unknown component is responsible for mispositioning of reflection energy which usually takes the form of imaging artifacts. Model heterogeneity can be described stochastically using, for example, correlated Gaussian random distributions or fractal distributions. Data simulated for the various distributions are characterized by spectra with different shapes when analyzed in the log-log domain. For example, Gaussian distributions are characterized by exponential functions and fractal distributions are characterized by linear functions with fractional slopes. These properties hold for both data and migrated images after deconvolution of the source wavelet. On the other hand, the image heterogeneities induced by model heterogeneities can be considered as noise to be removed by an image filtering operation. Among many possibilities, filtering with the seislet transform (a wavelet transform technique) and Gabor-Wigner distribution (a time-frequency analysis technique) are effective at suppressing noise, although both techniques affect the signal corresponding to the major geologic structure. Such filtering can be applied at different stages of wave-equation imaging, for example on data, on the reconstructed wavefields, or on the migrated image. Of all possibilities, filtering of the wavefield is the most effective.",
    "full_text": "Wave-equation migration consists of two steps (Claerbout, 1985). The first step represents wavefield reconstruction at every location in the subsurface from data recorded at the surface using a numeric solution to a wave equation. The second step consists of extracting reflectivity information from the reconstructed wavefields using an imaging condition. The accuracy of wavefield reconstruction, which directly determines the quality of migrated images, depends on the accuracy of both the velocity model and the wave-equation used for wavefield reconstruction.\n\nConventionally, we decompose the Earth's velocity into two models corresponding to large-scale (low-frequency) and to small-scale (high-frequency) components. We refer to the large-scale component as the velocity model and to the smallscale component as the reflectivity model. The large-scale component of the model is used for wavefield reconstruction, and the small-scale component of the model is the object of the imaging condition. However, real geologic environments do not follow this clear separation of scales. Evidence from well logs and rock outcrops indicates that a better description of the subsurface requires heterogeneity at all scales of variation (Richter-Bernburg, 1987). We refer to this type of models as multi-scale. The multi-scale variability is usually ignored in imaging which usually assumes that the mid-range of variability does not exist. As a consequence, imaging with smooth models leads to inaccurate wavefield reconstruction and to corresponding distortions of migrated images.\n\nIn this paper, we study the effects of multi-scale heterogeneity on imaging. First, we analyze various types of heterogeneity, their impact on seismic data and migrated images and whether this information can be extracted from data or migrated images. Since the mid-scale heterogeneities are not accounted for in imaging, their effect on images has the character of artifacts overlapping the geologic structure which corresponds to the bi-modal decomposition of the model. Second, we evaluate techniques designed to attenuate the arti-facts caused by disregarding the mid-scale heterogeneities in the imaging process. Although not necessarily consistent with geology, the goal here is to eliminate from the migrated images what is inconsistent with the assumed bi-modal theoretical framework described in the preceding paragraphs.\n\nIn the first part of this paper, we investigate the composition of multi-scale heterogeneities. Conventionally, velocity heterogeneity is described as random perturbations superposed on a large-scale background distribution (Hoshiba, 2000). An alternative description of mid-scale heterogeneities is based on the fractal character of natural objects, which is documented by many geological and geophysical phenomena, e.g., rock fragments, faults, earthquakes, and well logs (Mandelbrot, 1982;Turcotte, 1997;Dolan et al., 1998). Fractals posses the property of scale invariance which means that they are built using self-similarity relations.\n\nWithin our imaging framework, we regard the artifacts caused by the absence of mid-scale heterogeneities from the models used for imaging as noise which we attempt to remove from the images. From the wide variety of techniques that can be employed for noise attenuation, we consider methods from the wavelet-decomposition family and from the timefrequency analysis family. Our choice of wavelet-like decomposition is the seislet transform which is specifically designed for application to seismic data. The seislet transform decomposes seismic signals to different scales using the dominant slope at every location (Fomel, 2006). Then, the decomposed data can be truncated to emphasize the components that are most consistent with our assumption of the local slopes. Our choice of time-frequency decomposition is similar to the Wigner distribution functions (WDF) (Wigner, 1932;Ville, 1948) which can be employed for noise attenuation in seismic migration, e.g. as an interferometric imaging condition (Sava & Poliannikov, 2008). Imaging conditions based directly on WDFs can attenuate significant noise from the reconstructed wavefields, but have the drawback that they make the phase of output signals ambiguous due to the quadratic nature of the transformation (Cohen, 1995). To address this problem, we employ an alternative time-frequency method called Gabor-Wigner distribution (Pei & Ding, 2007) which does not suffer from the same drawback.\n\nThe velocity model of the subsurface cannot be known exactly in a realistic field experiment, but it can be approximated as the superposition of a known background velocity and unknown perturbations. Figure 1  (Hoshiba, 2000). In the following section, we discuss different models for subsurface heterogeneity.\n\nMid-scale velocity heterogeneities can be approximated by random distributions. Correlated Gaussian random distributions can be constructed by convolution of uncorelated random noise n (x) with a Gaussian smoothing function g (x)\n\n.\n\n(1)\n\nThe Gaussian function g (x) is obtained by inverse Fourier transform of\n\nwhere σ governs the correlation distance and k represents the wavenumber associated with variable x. By definition, we can relate the wavenumber k with the wavelength λ by λ = 2π k . Then, we can write\n\ntherefore, by taking the natural logarithm, we obtain\n\nThe interpretation of equation 4 is that the ln G -ln λ dependence is exponential. Furthermore, if we observe random noise with this general dependence, then we can conclude that the input signal has a Gaussian character. Figure 3(a) shows an example of correlated Gaussian random noise with 10 m correlation in depth and Figure 3(b) shows the associated reflection coefficients. Figure 4 shows a 2-D example of Gaussian random noise with correlation lengths in the horizontal and vertical directions of 0.05 km and 0.01 km, respectively.\n\nBy definition, fractals are quantities characterized by selfsimilarity (Mandelbrot, 1982). Fractals are often initiated with a large scale generator which is repeated iteratively at finer scales. For example, for a generator function l (x), a selfsimilar fractal function has the property\n\nwhere r is a scaling factor, and Ha is known as the Hausdorff measure which determines the fractal dimension D = 2 -Ha (Turcotte, 1997).\n\nWe can construct stochastic self-similar functions by convolution of uncorelated random noise n (x) with a fractal series f (x)\n\nThe fractal series f (x) is obtained by inverse Fourier transform of a function with the power-law dependence:\n\nwhere β is related to the fractal dimension D as β = 2.5 -D  (a) (b) Figure 3. (a) Gaussian random perturbations with 10 m correlation in depth. (b) The reflection-coefficient series governed by velocity heterogeneity in (a). (a) (b) Figure 5. (a) The fractal perturbations with a order of 0.50, corresponding to the log-log spectrum in Figure 7(d). (b) The primary reflectioncoefficient series governed by the fractal heterogeneity in (a). ( Turcotte, 1997). Replacing the wavenumber k with the wavelength λ, we can write\n\ntherefore, by taking the natural logarithm, we obtain\n\nThe interpretation of equation 9 is that the ln F -ln λ dependence is linear. Furthermore, if we observe random noise with this general dependence, then we can conclude that the noise has a fractal character. Figure 5(a) shows an example of fractal random noise with power law of order 0.5 and Figure 5(b) shows the associated reflection coefficients. Figure 6 shows a 2-D example of fractal random noise with power law of order 0.5.  (Stefani & De, 2001). However, the linear slope is different from 1 which distinguishes the fractal profile from the blocky one shown in Figure 7(b). In this case the slope of the log-log fit is 0.5.\n\nWe The main distinction between the two kinds of data modeling is that convolution represents single interaction of the wavelet with the reflectivity function, while finite-difference modeling incorporates other physical phenomena, e.g. multiple scattering. By studying the two types of simulation, we attempt to understand whether the character of the random fluctuation is influenced by wave propagation and whether we can\n\nTable 1. Heterogeneity parameters for the blocky, Gaussian, and fractal models. These parameters are extracted from data shown in Figures 8 and 9 using least-squares fitting.\n\nrecover information about the random character of the model through direct observations of recorded data.\n\nFigure 10 compares log-log spectra of the data displayed in Figures 9(a)-9(b). The solid, dashed, and dotted lines correspond to data of the blocky, Gaussian, and fractal velocities, respectively. We can observe that the data for the blocky model, Figure 9(a), overlaps the data corresponding to the models with random variations, Figures 9(b)-9(c), over the entire frequency band of the signals. It is difficult to determine the parameters of the signal corresponding to the random fluctuations by simple spectral analysis, or to separate the main reflectors characterizing the background model from events related to the random model fluctuations. Thus, we cannot design simple frequency/wavenumber filters to reduce the signal caused by the model random fluctuations.\n\nFrom the analysis of the data spectra, it is apparent that the dominant contributor to the spectrum is the actual signal wavelet. Assuming that the wavelet is known at least approximately, we can deconvolve the wavelet from the recorded data and analyze the remaining spectrum to extract information about the model fluctuations.\n\nFigures 11(a)-11(f) depict the log-log spectra of reflectivities extracted from data shown in Figures 8 and 9. The left panels correspond to the data obtained by convolution, Figures 8(a)-8(c), while the right panels correspond to the data obtained by finite-differences modeling, Figures 9(a)-9(c). For both types of modeling, we obtain similar spectra which characterize the types of random model fluctuation. For example, the spectrum of the blocky model corresponds to a slope close to 1. The spectrum of the data for the model with Gaussian variability shows an exponential trend fitted by parameters α3 = -π 2 σ 2 = -0.001 which implies that σ = 0.01, indicating a correlation length of about 10 m. The spectrum of the data for the model with fractal variability shows a linear trend fit by parameters α1 = 0.51 and α1 = 0.49 which are both close to the power order of 0.50, which characterizes the velocity model. These trends are consistent with the trends obtained by analyzing the spectra of the velocity model themselves, which indicates that properties of the random component of the model are preserved in data and can be extracted, assuming that we know the corresponding wavelet with sufficient accuracy. Table 1 summarizes the fitting results for the various combinations of heterogeneity and data modeling.\n\n(a) (b) (c) (a) (b) (c) Figure 8. (a)-(c): Synthetic seismic data obtained by convolution of a Ricker wavelet with the reflection coefficient series shown in Figures 2(b), 3(b), and 5(b), respectively. (a) (b) (c) Figure 9. Synthetic seismic data obtained by finite-differences modeling in 1-D models characterized by reflection coefficient series shown in Figures 2(b), 3(b), and 5(b), respectively.\n\nThe analysis performed in the preceding section addresses the question whether we can access information about the model heterogeneity through the analysis of recorded data. In this section we address an alternative question, i.e. whether we can access the same information through analysis of migrated images. For this analysis, we use a portion from a well-log acquired in the field. In this case, we do not know a-priori the nature of the randomness. Figure 12(a) shows the P-wave velocity constructed from well measurements superimposed on a velocity model obtained as horizontal extension of the welllog.\n\nFigure 13(a) shows the log-log spectrum of the well-log. The thick straight line represents the linear least-squares fit applied to the spectrum. The slope is equal to 1 which is consistent to the fact that the well log is dominated by a smooth non-constant background component, or put another way, the spectrum is dominated by a slope inversely proportional with the wavenumber k (Shtatland, 1991). In order to emphasize the heterogeneities presented in the model, we first remove the k -1 spectrum. In the k domain, according to the nonlinear least-squares fitting y = ak -1 , we estimate the intensity of the k -1 component which corresponds to the background velocity. Because of the linear assumption of velocity model composition, we can apply a linear operation in the k domain, i.e. we subtract the nonlinear least-squares fit from the entire spectrum. After removing the k -1 component, we analyze separately the remaining spectrum shown in Figure 13(b). The slope of the linear least-squares fit is equal to 0.53 which, as expected, indicates that the model randomness has a fractal character.\n\nFigure 12(b) shows a simulated shot-record data with a source located at x = 2.0 km, z = 0 km. The zero-offset trace is superimposed on the data. Migration of the data in a smoothed background velocity produces the image shown in Figure 12(c). The zero-offset image trace is also superimposed on the image. As for the preceding example, we analyze the expression of model randomness on image using the log-log plots of the spectra, after we deconvolve the seismic wavelet from the image. Figure 14(a) displays log-log spectra of the zero-offset image trace. As before, we separate the k -1 component obtaining the spectrum shown in Figure 14(b). The linear least-squares fit to the image spectrum has a slope of 0.54, which is close to the slope obtained from the direct analysis of the well-log. Thus, we can conclude that the migrated image indicates the presence of a model with fractal parameter β approximately equal to 0.53. Figure 15 shows the dependence of extracted heterogeneity information from image on the horizontal position with respect to the source location. It is apparent that the extracted heterogeneity parameters in the near offset are more precise than in the far offset.\n\nThe procedure discussed here requires knowledge of the source wavelet to extract heterogeneity parameters from data or migrated images. However, only the amplitude spectrum matters, therefore we conjecture that we can still obtain satisfactory results even if small phase errors in our wavelet estimation exist.\n\nOur analysis show that various types of heterogeneity look different when analyzed in log-log plots, as illustrated in Figures 11(a)-11(f). Assuming that the background model of the subsurface is a combination of a relatively smooth background plus a few strong interfaces with a blocky character, we can attempt to infer the statistics of model heterogeneities currently undetectable by conventional seismic methodology.\n\nAlternatively, we can consider the effects of mid-scale heterogeneities on seismic data as noise and attempt to remove them from migrated images. Our experiments show that conventional denoising methods based on bandwidth analysis do not have a good chance of success given the overlap between various components of the model. However, we suggest that it would be helpful to understand the statistics of this noise before attempting to remove it.\n\nDespite the fact that multi-scale heterogeneities are present in the Earth, we normally describe their expression in seismic data as noise and their expression on migrated images as artifacts. This is simply because we do not have good procedures to estimate models with such variability and to image those data. In this section, we explore the applicability of two kinds of de-noising procedures: seislet transform (ST) which belongs to the wavelet transform methods, and Gabor-Wigner distribution (GWD) which belongs to the time-frequency analysis (TFA) methods.\n\nThe seislet transform belongs to the general family of wavelet transform. By definition, this transformation decomposes the signal to different scales using the dominant slope at every location (Fomel, 2006). ST can be used for de-noising by a simple soft thresholding operation in the transformed domain designed to preserve the locally dominant slopes in the data or image, thus filtering out perturbations from the dominant slope. Filtering using ST makes the assumption that the data are correctly described by locally coherent events, while noise is not.\n\nTFA methods decompose non-stationary signals as functions of the local frequency at various times (Cohen, 1995). This type of transformation can be generalized to multidimensional signals, e.g. to seismic data or wavefields. Wigner distribution functions (WDF) (Wigner, 1932;Ville, 1948) are an example of TFA method with a quadratic character (Hlawatsch & Boudereaux-Bartels, 1992). WDFs are effective at suppressing noise from data, but suffer from the drawback that the phase of their output is ambiguous. To alleviate this problem, we use an alternative TFA transformation, called the Gabor-Wigner distribution (GWD) (Pei & Ding, 2007), which has the property that it attenuates the noise similarly to WDF, but without affecting the phase of the signal. For the multidimensional signal s (x, t), the Gabor-Wigner distribution is given by\n\nIn equations 10 and 11, g (x, t) = e\n\nis a multi-dimensional Gaussian window with spatial and temporal standard deviations of σx and σt, which has the purpose of reducing cross-talk (Choi & Williams, 1989); sw (x, t) is the WDF transform result of s (x, t) in the time-space domain; x h and t h are variables spanning space and time intervals within X and T , respectively.\n\nWave-equation imaging for shot-record experiments consists of two steps: first, simulate the source and receiver wavefields using the background velocity model; second, apply an imaging condition to extract the reflectivity information from the reconstructed source and receiver wavefields. A conventional imaging condition extracts the image as the zero-lag of the cross-correlation between the reconstructed wavefields\n\nwhere y denotes the image coordinates, us (y, t) and ur (y, t) are the reconstructed source and receiver wavefields, and R (y) is the extracted image. Wavefields corresponding to propagation in models with multi-scale heterogeneity are not properly reconstructed in the subsurface if we use an approximate blocky model for wavefield reconstruction. Consequently, fluctuations corresponding to the part of the model that is not accounted for during extrapolation are present in the wavefields. The question we address here is whether we can use one of the noise attenuation techniques outlined earlier to filter out the unwanted component of data. We discuss three possible strategies corresponding to filtering before wavefield reconstruction (i.e. filter the data), filtering before the imaging condition (i.e. filter the wavefields), or filtering after the imaging condition (i.e. filter the image) as illustrated in Figure 16.\n\nIn workflow (a), the denoising process is directly applied to the recorded data before wavefield reconstruction. In this case, we attempt to remove from the data what we consider to be unwanted signal and then follow with a conventional imaging procedure. This option is advantageous because it operates on relatively small data volumes, but it has the disadvantage that data are often complicated with many conflicting dips which makes it difficult to define a predominant slope at some location and time.\n\nIn workflow (b), the denoising process is applied to the reconstructed wavefields before the application of the imaging condition. This is the strategy employed by Sava & Poliannikov (2008) in the design of the so-called interferometric imaging condition based on WDFs. This option is advantageous because we take into consideration the redundancy of the entire reconstructed seismic wavefields to define the locally dominant components, but it has the disadvantage that it operates on large data volumes making it computationally expensive.\n\nIn workflow (c), the denoising is applied to the migrated image after the application of the imaging condition. This option is advantageous because we apply it directly on the final product of the imaging process, thus removing all types of artifacts that are not locally consistent, and that it is computationally efficient since it operates on small data volumes. This option is disadvantageous because it assumes the presence of single dominant events at every location, which eliminates from consideration geologic structures with sharp truncations.\n\nWe apply the technique proposed in the preceding section to the models shown in Figures 17(a)-17(c), which are based on the Sigsbee 2A model (Paffenholz et al., 2002). The models are characterized by correlated random Gaussian heterogeneities, Figure 17 The goal of this experiment is to evaluate whether the attenuation techniques described earlier can reduce the noise in the final migrated images. We simulate data using the models with random fluctuations and image by reverse-time migration using a smooth version of the background model, Figure 17(a). In all experiments, we use wavelets with a central frequency f = 20 Hz, the model is discretized on a grid with ∆x = ∆z = 0.00762 km, and the perturbations represent 10% of the background model.\n\nFigures 17(d)-17(f) show the simulated data for the velocity models shown in Figures 17(a)-17(c), respectively.  show the images obtained by migrating the data in Figures 17(d)-17(f) with a conventional imaging condition and the background velocity model. Figure 17(g) corresponds to modeling and migration using models without random fluctuations and serves as a reference for all subsequent migrations. Both images constructed from data corresponding to the random models, Figures 17(h) and 17(i), are corrupted with artifacts due to incorrect wavefield reconstruction in the subsurface. In the following paragraphs, we discuss the application of the seislet transform (ST) and the Gabor-Wigner distribution (GWD) for the three implementation strategies discussed earlier.\n\nFigures 18(a)-18(f) correspond to the data simulated with the model characterized by Gaussian fluctuations, Figure 17(e). Panels 18(a)-18(c) correspond to de-noising using the ST applied to the data, wavefield and image, respectively, and panels 18(d)-18(f) correspond to de-noising using GWD applied to the data, wavefield and image, respectively. Likewise, Figures 19(a (a) (b) (c) (d) (e) (f) Figure 18. Images corresponding to the model with correlated Gaussian random fluctuations. Panels (a)-(b)-(c) correspond to denoising with ST applied to the data, wavefield and image, respectively. Panels (d)-(e)-(f) corespond to denoising with GWD applied to the data, wavefield and image, respectively. (a) (b) (c) (d) (e) (f) Figure 19. Images corresponding to the model with fractal velocity fluctuations. Panels (a)-(b)-(c) correspond to denoising with ST applied to the data, wavefield and image, respectively. Panels (d)-(e)-(f) corespond to denoising with GWD applied to the data, wavefield and image, respectively. the ST applied to the data, wavefield and image, respectively, and panels 19(d)-19(f) correspond to de-noising using GWD applied to the data, wavefield and image, respectively. Both ST and GWD used in all three workflows help reduce the random fluctuations from the migrated images, although none produces images with the coherence comparable with that of the reference image, Figure 17(g). This is not surprising since both de-noising techniques attempt to filterout information incorrectly positioned in the subsurface, rather than relocate it. However, it is apparent that better results are produced when de-noising is applied to the wavefields, rather than to the data or the image. The main reason for this is that more coherency exists in the wavefields along the space and time axes. The data and the image are subsets of the wavefields, therefore these domains are not as effective at noise suppression.\n\nWe can quantify the differences between the various denoised images and our benchmark image using the mean squared error (MSE) (Lehmann & Casella, 2003). The MSE values characterize the dissimilarity between the de-noised images and the reference and the larger the MSE value, the more dissimilar the images. The raw images shown in Figures 17(h) and 17(i) have a mean squared error of 0.011 and 0.014, respectively, relative to the benchmark image shown in Figure 17(g). Table 2 lists the mean square errors between the images in Figures 18(a)-18(f) and Figures 19(a)-19(f) relative to the benchmark image. According to this analysis, the best denoising strategy is to apply either ST or GWD to the wavefields after wavefield reconstruction but before the imaging condition, with a slight efficiency advantage for GWD relative to ST.\n\nWe compare different types of multi-scale heterogeneities and investigate whether information about the parameters characterizing such models can be derived from the images. Assuming that we can estimate the seismic wavelet with sufficient accuracy, we can isolate reflectivity profiles from both recorded data and migrated images and extract the media properties. We can identify models with correlated Gaussian fluctuations by their exponential dependence in log-log spectra. In contrast, models with fractal fluctuations show, as predicted by the theory, a linear dependence of the log-log spectra with a fractional slope. This conclusion holds for both the data and image domains. Regardless of the type of fluctuations in the model, imaging with approximate velocity (e.g. blocky models) leaves a distinct random-looking imprint on the migrated images which may obstruct identification of geologic structures.\n\nWe refer to this kind of imprint as noise and attempt to remove it using conventional statistical procedures. We test the seislet transform (curvelet-like method) and Gabor-Wigner distributions (time/fraquency-like method) to attenuate noise at different stages of depth migration. The noise attenuation can be applied to the data before wavefield reconstruction, or to the reconstructed wavefields, or to the migrated image, after the application of the imaging condition. Of all possibilities, filtering of the wavefield seems to be the most effective method of noise attenuation, although this option is also the costliest."
}