{
    "title": "Geodesics Guided Constrained Texture Deformation",
    "publication_date": "2001",
    "authors": [
        {
            "full_name": "Carsten Stoll",
            "firstname": "Carsten",
            "lastname": "Stoll",
            "affiliations": [
                {
                    "organization": "Max-Plank-Institut für Informatik Stuhlsatzenhausweg",
                    "address": {
                        "city": "Saarbrücken",
                        "country": "Germany",
                        "postcode": "85 66123"
                    }
                }
            ]
        },
        {
            "full_name": "Zachi Karni",
            "firstname": "Zachi",
            "lastname": "Karni",
            "affiliations": [
                {
                    "organization": "Max-Plank-Institut für Informatik Stuhlsatzenhausweg",
                    "address": {
                        "city": "Saarbrücken",
                        "country": "Germany",
                        "postcode": "85 66123"
                    }
                }
            ]
        },
        {
            "full_name": "Hans-Peter Seidel",
            "firstname": "Hans-Peter",
            "lastname": "Seidel",
            "affiliations": [
                {
                    "organization": "Max-Plank-Institut für Informatik Stuhlsatzenhausweg",
                    "address": {
                        "city": "Saarbrücken",
                        "country": "Germany",
                        "postcode": "85 66123"
                    }
                }
            ]
        }
    ],
    "abstract": "We present a method that deforms an image plane to visually meet the shape and pose of a manifold surface. The user provides constraints that couple a small number of surface points with their corresponding image pixels to initially deform the plane. Matching, based on geodesic distances, couples additional points, followed by a second deformation that brings the image plane into its final pose and shape. The method works on any type of surface that supports geodesic distances evaluation. This includes not-triangulated and high genus models with arbitrary topology. The result is a smooth, visually pleasing and realistic textured surface that can be superimposed onto or used instead of the original model and with some limitations can be considered as a parameterization or remeshing method for the area of interest.",
    "full_text": "Texture mapping is a common technique in computer graphics that wraps a two-dimensional image around a polygonal mesh model to add details and enhance the visual appearance of the model. Constrained texture mapping is applied when alignments are required between the model and the image. A known application that uses constraints is facial texture mapping that requires the alignment of face-features such as eyes, nose, mouth, etc.\n\nIn computer graphics the term mapping or parameterization refers to the process of establishing a bijective (one-to-one and onto) correspondence between the 3D model and a 2D domain. Texture mapping is considered as a parameterization problem in which the 3D position of the model's vertices are defined as a bi-variant piecewise-affine function and the two independent variables are used as texture-coordinates. In constrained texture mapping the texture-coordinates for part of the vertices are enforced and the result is a bivariant function that complies with the constraints and parameterizes the remaining vertices. This makes the parameterization problem much more difficult and might even render the problem unfeasible.\n\nTexture mapping improves the visual appearance of a polygonal model. A highly detailed image gives the illusion of a detailed object, although the underlying geometric structure of polygons and vertices may be coarse. Hoverer, when closely examined, the rough geometric structure becomes noticeable and together with image distortion artifacts, caused by the parameterization process, the model may look less realistic.\n\nMesh parameterization and texture mapping received significant attention from the scientific community for several years. Rather than list them all, we point the interested reader to the excellent survey by Floater and Hormann [3] and references therein for more details on this topic. We note that common to most methods is their goal of minimizing a distortion measure while guaranteeing a bijective mapping (a mapping that is one-to-one and onto).\n\nMost parameterization methods focus on meshes with a topology homeomorphic to a disc and are limited to triangulated surfaces. To parameterize non-disclike meshes, it is common to first partition (segment) the mesh into disc-like patches, parameterize each separately and pack them back together in the parameterization space. See [9] and references therein for more details on atlas-based parameterization methods. A different parameterization approach can be applied to genus zero meshes with a topology equivalent to a sphere. Gotsman et al. [4] show how to generate a bijective mapping by generalizing barycentric coordinate methods for planar parameterization. Saba et al. [10] present an optimized numerical scheme that solves Gotsman's method efficiently.\n\nIn contrast to the proliferation of parameterization methods, only a few techniques satisfy positional constraints. Lévy [8] suggests adding the constraints to the linear parameterization system. He satisfies the constraints in a least-squares manner, yielding a \"soft\" constraints solution. For many applications such a solution is sufficient. However, when adding large number of constraints the method might result in a non bijective parameterization. Eckstein et al. [2] and Kraevoy et al. [7] suggest a method that guarantees the constraints' position together with the validity of the embedding. Both methods add new vertices, a.k.a. Steiner vertices, to the mesh when the constraints cause an over-determined system. Kraevoy's method also relies on a valid parameterization of the original mesh. Karni et al. [5] suggest using a free-boundary linear parameterization method that compels the positional constraints into their place. In case of an invalid solution, they suggest an iterative method that after 'several' iterations fixes the invalid areas. However, this method does not guarantee an upper bound on this number of iterations nor that a valid solution will be reached.\n\nTo the best of our knowledge, there are no methods for constrained parameterization of high genus models. Alexa [1] embeds genus zero meshes on a sphere with the presence of constraints. However, this suggestion does not guarantee a solution, even in the event that such a case exists.\n\nOur method deals with the constrained texture mapping challenge differently. Based on the constrained vertices, the image plane is deformed to roughly capture the 3D model's pose and shape (Section 4.1). Similar to Lévy [8] the constraints are satisfied in a least-squares manner. A matching based on geodesic distances is then used to couple the unconstrained vertices and the image pixels (Section 4.2). Using the matching and the initial constraints, the image plane is deformed again into its final shape (Section 4.3). Figure 2 visually presents the different stages of our method. We show that our technique results in a smooth, visually pleasing and realistic textured model that can be imposed onto or used instead of the original model.\n\nAside from its visual advantages, our method has the virtue of being applicable to any type of a manifold surface, in particular high genus models and nontriangulated meshes, as long as it supports the evaluation of geodesic distances. Figure 1 shows a texture deformed to meet the shape of a human's head model, which is of genus zero (higher genus models can be used in the same way). Our method is not meant to be a parameterization technique and hence does not guarantee a bijective mapping. However, for many cases it achieves a valid parameterization and traditional texture mapping can be also applied as well.\n\nLet M be a 3D mesh (not necessarily triangulated) represented by the pair (V,T), where V represents the vertices' position in 3 and T represents the mesh connectivity. Let S be an image surface (embedded in 3D\n\nSorkine et al. [12] use the connectivity together with constraints to reconstruct a mesh. They use the uniform Laplacian operator to state the surface smoothness and together with the constraints establish an over determined system. The position of the mesh vertices is the least-squares solution of this system. In a similar way we use a Laplacian based mesh editing technique to deform the image plane into its initial pose. Mesh Laplacian was first introduced by Taubin [14] for mesh processing and Karni and Gotsman [5] for mesh compression.\n\nLet A be an adjacency matrix and D a diagonal matrix such that D ii = d i , where d i is the degree of vertex i.\n\nns for P , the new \"pixel\" positions, using lea e matrix L = I-D A -1 , where I is the identity matrix, is the mesh Laplacian (with uniform weights).\n\nThe image plane does not have an explicit connectivity but instead a grid structure. Therefore, we use t placian as it is defined for images. The adjacency matrix holds for each pixel, its four closest neighbors: one from its left, right, bottom and top. Exceptions are boundary pixels with three neighbors and corner pixels with two.\n\nTo deform the image surface S we solve the following equatio st-squares:\n\nThe deformed surface S = (P ,C) roughly captures the mesh pose as it is imposed by the constraints. It is important to note that S does not exactly satisfy the ositional constraints. However, it minim wing function: p izes the follo\n\nBesides mimicking the mesh pose, the initial deformation has an important role in scaling the image surface to approximate the area of the mesh surface. This stage is esse min - We would like to refer the interested reader to the excellent state-of-the-art report by Sorkine [11] and the references therein for more details on Laplacian mesh processing.\n\nhe matching stage couples the rest of the T tices v i i∈{k+1,…,|V|} with correspondence pixels {p i } i∈{k+1,…,|P|}. The matching is one-to-one but not onto, meaning that several pixels exist without a matching (it is common to assume that the number of pixels in the imag The matching should capture the intrinsic properties of the two surfaces. For example: a vertex that lies between two constraint vertices should be matched with a pixel that lies between the corresponding constraint pixels. Zayer et al. [15] used vector fields generated by harmonic maps to match between two meshes for the applic e principle of the matching is: Let FM and FS be the vector fields along the mesh and image surface, respectively. For each vertex v i i∈{k+1,…, |V|}, we match the pixels p j j∈{k+1,…, |P|} such that j = argmin( FM -FS i j ) and FM -FS i j ≤ TH. The second term prevents the matching of points that are too far from any constraints and the difference between their vector fields is too high. In our implementation TH is defined to be one percent of the model's bounding box multiplied by k (the number of constraints).\n\nHarmonic functions have a cyclic nature that can cause the mapping not to be bijective. Therefore, our matching is based on vector field of geodesic distances. We calculate the distances using the method introduced by Surazhsky et al. [12], starting from each constraint vertex to the entire mesh vertices and from the con- Figure 4: Geodesic distances along the surfaces of the Igea and face models together with their corresponding deformed image surface. Each color represents one entry in the distances vector field.\n\nstraint pixels to the rest of the image pixels on the deformed image surface. This generates a vector field of dimension k (each entry is a distance from one constraint vertex or pixel) along the surfaces of the mesh and the deformed image. Figure 4 shows a threedimensional subset of the vector field as [R,G,B] colors on the Igea and face model surfaces together with their deformed image surface.\n\nDeforming an image around a disc-like mesh surface using geodesic distances, results in a valid matching. However, when dealing with closed meshes (genus-0) or high-genus models, a trivial geodesic distance matching might lead to a mismatch. Figure 5 demonstrates the problem for a simple twodimensional case. The bar, analog to an image plane, is to d from the distance vectors for pixels and points, the entire set of matched points is added. This results in a r system that is a generalization of Eq. ( 1) and is solved using least-squares.\n\nanalog to an image plane, is to d from the distance vectors for pixels and points, the entire set of matched points is added. This results in a r system that is a generalization of Eq. ( 1) and is solved using least-squares. eform around the circle, analog to a genus-0 cylinder, using the marked constraints. Observe that the distance along the bar between points 5 and 6 is significantly different than the distance between the corresponding points on the circle. This might lead to matching between points in the surroundings of point 4 on the bar to points in the surroundings of point 6 on the circle and to a mismatch which will result in a distorted deformation and for sure will lead to an invalid parameterization.\n\nTo avoid this problem we recognize a potential mismatch by inspecting the distance vectors at the constraint vertices and pixels for significant variations. A mismatch is recognized when the ratio FM i /FS i at the constraint points i∈{1,...,k} is below 0.8 or above 1.25. When such a mismatch is discerned, the suspected entries are eliminated eform around the circle, analog to a genus-0 cylinder, using the marked constraints. Observe that the distance along the bar between points 5 and 6 is significantly different than the distance between the corresponding points on the circle. This might lead to matching between points in the surroundings of point 4 on the bar to points in the surroundings of point 6 on the circle and to a mismatch which will result in a distorted deformation and for sure will lead to an invalid parameterization.\n\nTo avoid this problem we recognize a potential mismatch by inspecting the distance vectors at the constraint vertices and pixels for significant variations. A mismatch is recognized when the ratio FM vertices close to the suspected region.\n\nThe final deformation brings the image surface into its final pose. Similar to what was described in Section 4.1, a Laplacian based deformation is used, but instead of considering only the initial constrained vertices close to the suspected region.\n\nThe final deformation brings the image surface into its final pose. Similar to what was described in Section 4.1, a Laplacian based deformation is used, but instead of considering only the initial constrained new, over-determined linea new, over-determined linea i /FS i at the constraint points i∈{1,...,k} is below 0.8 or above 1.25. When such a mismatch is discerned, the suspected entries are eliminated\n\nThe least squares solution minimizes the f function: (a) (b) (c) Figure 9: Constrained Texture Deformation: (a) Polygonal surface (b) Texture image (c) Deformed texture surface together with the texture image\n\nBy adjusting the value of ω, the user can control the penalty measure for any deviation from the original constraints position. High value of ω is considered as ard-constraints. However, forcing hard-constraints mig ablishes texture-coordinates. Therefore, we of Section 4.2 to render surface using traditional text mesh surface. The embeddin h ht result in internal surface intersections and other not visually pleasing results. By adjusting the value of σ the user can control the smoothness degree of the deformed surface. A small value of σ will reduce the influence of the matched points. For example, setting its value to 0 will result in the initial smooth deformed surface.\n\nMatching the vertices of a mesh surface to image pixels est can use the matching results the image plane on the mesh ure mapping. Figure 6 shows the texture mapping of the tiger onto the face model together with its parameterization. However, the matching stage neither guarantees to cover the entire mesh vertices, nor to establish a valid mapping.\n\nZigelman et al. [16] used a multi-dimensionalscaling technique on the geodesic distances to embed the mesh vertices on a 2D plane by preserving their original distances along the g on a plane by itself is sufficient to generate texture-coordinates. However, their method that aims on facial texture-mapping also does not guarantee the validity of the mapping, and also does not satisfy positional constraints.  An analog to Zigelman's method would be to match the mesh vertices to the image pixels based on the geodesic distances along the mesh surface and the image plane (instead of the deformed image surface). Calculati uggested method and it works as follows: The user loads a polygonal model and interactively marks pairs of constraints points between the two. From this point on the sys ls, and in Figure 8, a text ise over the me bei n AMD Opteron-250 system with 2GB of memory. Table 1 performance of our method on several of the models. We would like to emphasize that the tim\n\nFace Igea Igea Male Eight ng geodesic distances along a plane sums up to calculating Euclidian distances. Figure 7 shows the differences between the two approaches. It is easy to see that our approach (on the left) visually performs better. The distortions in the Euclidian distances method (right image) and the failure to meet the constraints are due to the differences in the distance measurements, especially around the nose area.\n\nWe implemented the s and an image tem is completely automatic. It generates the initial deformed surface, calculates the geodesic distances and uses them for matching. Finally, it generates the final deformed surface. The user can then interactively add and remove constraints and change the weights of the final least-square system (see Section 4.3) to fine-tune the result and fit it to its needs.\n\nWe tested our method with several types of surfaces. Figure 9 shows a texture-deformation for a disclike surface. In Figure 2e and Figure 1 our method is challenged with genus-0 mode ure plane is deformed around one handle of the Figure Eight model (a genus-2 model). All the results show that the deformed texture-surface followed the shape of the mesh-surface while keeping the positional constraints in place, as much as they can be held, due to the least-squares nature of the solution.\n\nIn Figure 10 our method was tested with a noisy mesh. Gaussian noise was added to the Igea model and the same texture plane as in Figure 2 was deformed over it. It is evident that in spite of the no sh surface, the matching based on geodesic distances was successful and the deformed texture-surface inherited the noisy nature of the model surface. By fine-tuning the weights of the second deformation stage, we were able to generate a smooth version of the deformed texture while preserving all the facial details. The smoothed version looks visually better and natural.\n\nIn Figures 2, 8 and 10 we provide a texture-mapped model based on geodesic-distances parameterization. We did not check for the validity of the mapping although visually we could not find any evidence for it ng invalid. In all examples the texture is well placed and the model looks visually good. However, the smooth version of the deformed texture-surface seems to us more natural, and in other words, better.\n\nAll experiments were preformed using a summarizes the ings listed in Table 1 are for the initial constraints points. Adding or removing constraints requires only an update of the already factorized deformation systems and the evaluation of geodesic distances from the new points alone.\n\nTable 1: Time performances for the different stages of the \"The Mask\" system (in sec) Vertices 1394 33K 33K 220K 1536 Pixels 40K 65K 262K 65K 65K Constraints 24 26 26 24 26 Deform 1 2.25 4.45 35.03 4.32 4.42 M d esh Geo 0.12 14.38 14.38 31.2 0.312 Text Geod 1 2 12 2 2 5.36 7.56 3.24 5.44 7.56 Matching 0.01 0.49 3.36 1.17 1.17 Deform 2 2.23 4.52 36.51 4.48 4.48 Total 19.97 51.4 212.52 66.61 36.83 It is evid ime perform e t t jo r i m 's t s t e t im t inf th m o s and the geodesic distance calculations. This is not surpri sol nt tha nce i he ma he siz r facto of the n the xture ethod age. a e perfor e formati I n stage luences ances of the de sing.\n\nIn most cases the number of pixels in the texture image is significantly larger than the number of vertices in the mesh model. In our experiments we used small and medium sized images. However, we would like our method to handle images with 5 to 10 Mega-pixels, such as current digital cameras produce.\n\nIt is important to note that the texture image surface has the special connectivity structure of a grid. Our solver, which was used in the deformation stages, does not exploit this property. We believe that by using vers and an algorithm for geodesic distance computation that are dedicated to work on grid structures (e.g., multi-grid methods), we will be able to significantly reduce the computation time of those stages and enable the use of large images.\n\nWe present a method that deforms an image plane to meet the geometry of a mesh surface. The deformaeasing surface that can be used instead of the original or as a parameteri tion results in a smooth and visually pl zation of it. We show that the method performs on any type of mesh surface, even those with high genus.\n\nThere are several directions for future work: The least-squares optimization solver that is used for the image surface deformation should be replaced by one that will exploit the grid structure of an image. Such a ver will enable our method to be interactive even when dealing with today's image sizes.\n\nIn texture mapping, fine details in the texture are flattened onto the polygon surface. For example, the fine details of the tiger's whiskers are not influenced in the geometry. They are snapped onto th e and hence look flat. The fine geometry structure of the deformed image surface enables us to add the image's fine details to the geometry. This will lead to highly detailed and much more realistic models.\n\nFinally, this method can serve as a fundamental basis for surface reconstruction out of points-clouds. Developing this is a real challenge, mostly because there is no easy or fast way to calculate geodesic dis ng a points-cloud surface."
}